#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_mmad_convert_api_.py
DESC:     tik_mmad_conver_api_
CREATED:  2021-12-03 5:59 AM
MODIFIED: 2021-12-03 5:59 AM
"""
from collections import namedtuple
from tbe.tik.tik_lib.tik_mmad_convert_api.tik_mmad_convert_operation import Load2DApi
from tbe.tik.tik_lib.tik_mmad_convert_api.tik_mmad_convert_operation import Load2DV3Api
from tbe.tik.tik_lib.tik_mmad_convert_api.tik_mmad_convert_operation import Load3DV1Api
from tbe.tik.tik_lib.tik_mmad_convert_api.tik_mmad_convert_operation import Load3DV2Api
from tbe.tik.tik_lib.tik_mmad_convert_api.tik_mmad_convert_operation import Col2ImgApi
from tbe.tik.tik_lib.tik_mmad_convert_api.tik_mmad_other_operation import BroadcastUbToL0cApi
from tbe.tik.tik_lib.tik_mmad_convert_api.tik_mmad_other_operation import MMadBroadCastApi
from tbe.tik.tik_lib.tik_mmad_convert_api.tik_mmad_other_operation import LoadWinoGardFmApi
from tbe.tik.tik_lib.tik_mmad_convert_api.tik_mmad_other_operation import LoadWinoGardWeApi
from tbe.tik.tik_lib.tik_mmad_convert_api.tik_mmad_other_operation import WinoFmTfApi
from tbe.tik.tik_lib.tik_mmad_convert_api.tik_mmad_other_operation import WinoWeTfApi


class TikMMadConvertApi:
    """
    mmad convert instruction api
    """
    load2d_api = namedtuple('Load2DApi', ['name', 'dst', 'src', 'start_index', 'repeat_times', 'dst_gap',
                                          'src_stride', 'sid', 'en_transpose', 'addr_mode'])

    load2dv3_api = namedtuple('Load2Dv3Api', ['name', 'dst', 'src', 'm_start_pt', 'k_start_pt', 'src_stride',
                                              'dst_stride', 'm_step', 'k_step', 'en_transpose'])

    load3dv1_api = namedtuple('Load3DV1Api', ['dst', 'src', 'pad', 'l1_h', 'l1_w', 'c1_index', 'fetch_filter_w',
                                              'fetch_filter_h', 'left_top_w', 'left_top_h', 'stride_w', 'stride_h',
                                              'filter_w', 'filter_h', 'dilation_filter_w', 'dilation_filter_h',
                                              'jump_offset', 'repeat_mode', 'repeat_time', 'csize', 'pad_value'])

    load3dv2_api = namedtuple('Load3DV2Api', ['dst', 'src', 'pad', 'l1_h', 'l1_w', 'channel_size', 'k_extension',
                                              'm_extension', 'k_start_pt', 'm_start_pt', 'stride_w', 'stride_h',
                                              'filter_w', 'filter_h', 'dilation_filter_w', 'dilation_filter_h',
                                              'en_transpose', 'en_small_k', 'pad_value'])

    col2img_api = namedtuple('Col2Img', ['dst', 'src', 'pad', 'l1_h', 'l1_w', 'fetch_filter_w', 'fetch_filter_h',
                                         'left_top_w', 'left_top_h', 'stride_w', 'stride_h', 'filter_w', 'filter_h',
                                         'dilation_filter_w', 'dilation_filter_h', 'repeat_time'])

    b_ubl0c_api = namedtuple('BroadcastUbToL0cApi', ['dst', 'src', 'nburst', 'burst_len', 'strides'])

    mmad_b_api = namedtuple('MMadBroadCastApi', ['dst', 'src', 'repeat_mode', 'nburst', 'burst_repeat',
                                                 'dst_gap', 'src_gap'])

    load_w_fm_api = namedtuple('LoadWinoGardFmApi', ['dst', 'src', 'pad', 'm_extension', 'm_start_pt',
                                                     'k_extension', 'k_start_pt'])

    w_fm_tf_api = namedtuple('WinoFmTfApi', ['dst', 'src', 'l1_h', 'l1_w', 'l1_c', 'pad_left', 'pad_right',
                                             'pad_top', 'pad_bottom', 'm_extension', 'm_start_pt', 'k_extension',
                                             'k_start_pt', 'column_indicator', 'dst_stride'])

    w_we_tf_api = namedtuple('WinoWeTfApi', ['dst', 'src', 'column_indicator', 'repeat_dir', 'repeat_times',
                                             'dst_blk_stride', 'dst_rep_stride', 'src_rep_stride', 'en_weight_offset',
                                             'smask'])

    def load2dv1(self, dst, src, index, repeat_times, src_stride, sid,
                 if_transpose=False, addr_mode=None):
        """
        Pass the offline processed convolution right
        matrix (davinci format) from gm to ca/cb/cbuf or from cbuf to ca/cb

        Parameters
        ----------
        dst : destination tensor
        src : source tensor
        index : [0, 65535] data index
        repeat_times : [1, 255]
        sid: default 0
        src_stride : offset of src tensor between adjacent data segment
        if_transpose : if transport. True/False

        Returns
        -------
        None
        """
        api_name = "load2dv1"
        load2dv1_api = TikMMadConvertApi.load2d_api(api_name, dst, src, index, repeat_times, None,
                                                    src_stride, sid, if_transpose, addr_mode)

        load2dv1_obj = Load2DApi(self, load2dv1_api)
        load2dv1_obj.run_all()

    def load2dv2(self, dst, src, start_index, repeat_times, dst_gap, src_stride, sid,
                 if_transpose=False, addr_mode=None):
        """
        Pass the offline processed convolution right
        matrix (davinci format) to scope_ca/scope_cb

        Parameters
        ----------
        dst : destination tensor
        src : source tensor
        start_index : [0, 65535] data index
        repeat_times : [1, 255]
        dst_gap: gap of dst tensor between adjacent data segment
        src_stride : stride of src tensor between adjacent data segment
        sid: default 0
        if_transpose : if transport. True/False
        addr_mode: address mode, default is None

        Returns
        -------
        None
        """
        api_name = "load2dv2"
        load2dv2_api = TikMMadConvertApi.load2d_api(api_name, dst, src, start_index, repeat_times, dst_gap,
                                                    src_stride, sid, if_transpose, addr_mode)

        load2dv2_obj = Load2DApi(self, load2dv2_api)
        load2dv2_obj.run_all()

    def load2dv3(self, dst, src, m_start_pt, k_start_pt, src_stride, dst_stride, m_step, k_step, en_transpose=False):
        api_name = "load2dv3"
        load2dv3 = TikMMadConvertApi.load2dv3_api(api_name, dst, src, m_start_pt, k_start_pt, src_stride, dst_stride,
                                                  m_step, k_step, en_transpose)
        load2dv3_obj = Load2DV3Api(self, load2dv3)
        load2dv3_obj.run_all()

    def load3dv1(self, dst, src, pad, l1_h, l1_w, c1_index, fetch_filter_w, fetch_filter_h, left_top_w, left_top_h,
                 stride_w, stride_h, filter_w, filter_h, dilation_filter_w, dilation_filter_h, jump_offset,
                 repeat_mode, repeat_time, _csize=0, pad_value=0):
        """
        image to colomn, only support L1 to L0A/L0B/UB

        Parameters
        ----------
        dst: destination operator
        src: source operator
        pad: [left, right, top, bottom]
        l1_h: height of src tensor
        l1_w: width of src tensor
        c1_index: C channel position/16 for f16, C channel position/32 for b8
        fetch_filter_w: fetch position in filter w dimension
        fetch_filter_h: fetch position in filter h dimension
        left_top_w: the start left top corner coordinate of windown in feature map(1st window position in w dimension)
        left_top_h: the start left top corner coordinate of windown in feature map(1st window position in h dimension)
        stride_w: filter stride size in w dimension
        stride_h: filter stride size in h dimension
        filter_w: width of filter
        filter_h: height of filter
        dilation_filter_w: dilation size of filter in w dimension
        dilation_filter_h: dilation size of filter in h dimension
        jump_offset: jump offset size of destination
        repeat_mode:
        repeat_time:
        _csize:
        pad_value: value for padding, default = 0

        Returns
        -------
        None
        """
        load3dv1_api = TikMMadConvertApi.load3dv1_api(dst, src, pad, l1_h, l1_w, c1_index, fetch_filter_w,
                                                      fetch_filter_h, left_top_w, left_top_h, stride_w, stride_h,
                                                      filter_w, filter_h, dilation_filter_w, dilation_filter_h,
                                                      jump_offset, repeat_mode, repeat_time, _csize, pad_value)

        load3dv1_obj = Load3DV1Api(self, load3dv1_api)
        load3dv1_obj.run_all()

    def load3dv2(self, dst, src, pad_list, l1_h, l1_w, channel_size, k_extension, m_extension, k_start_pt, m_start_pt,
                 stride_w, stride_h, filter_w, filter_h, dilation_filter_w, dilation_filter_h, en_transpose=False,
                 en_small_k=False, pad_value=None):
        """
        image to colomn, only support v200, only support L1 to L0A/L0B/UB

        Parameters
        ----------
        dst: destination operator
        src: source operator
        pad_list: [left, right, top, bottom]
        l1_h: height of src tensor
        l1_w: width of src tensor
        channel_size: number of src tensor's channels
        k_extension: k direction extension steps from the start position
        m_extension: m direction extension steps from the start position
        k_start_pt: k direction start position of the feature matrix
        m_start_pt: m direction start position of the feature matrix
        stride_w: filter stride size in w dimension
        stride_h: filter stride size in h dimension
        filter_w: width of filter
        filter_h: height of filter
        dilation_filter_w: dilation size of filter in w dimension
        dilation_filter_h: dilation size of filter in h dimension
        en_transpose: enable transpose, default = None
        en_small_k: enable small_k, default = None
        pad_value: value for padding, default = None

        Returns
        -------
        None
        """
        load3dv2_api = TikMMadConvertApi.load3dv2_api(dst, src, pad_list, l1_h, l1_w, channel_size, k_extension,
                                                      m_extension, k_start_pt, m_start_pt, stride_w, stride_h,
                                                      filter_w, filter_h, dilation_filter_w, dilation_filter_h,
                                                      en_transpose, en_small_k, pad_value)

        load3dv2_obj = Load3DV2Api(self, load3dv2_api)
        load3dv2_obj.run_all()

    def col2img(self, dst, src, pad, l1_h, l1_w, fetch_filter_w, fetch_filter_h, left_top_w, left_top_h,
                stride_w, stride_h, filter_w, filter_h, dilation_filter_w, dilation_filter_h, repeat_time):
        """
        only support L1 to L0A/L0B/UB
        pad : [left, right, top, bottom]
        no Csize<=4, C0=16
        """
        col2img_api = TikMMadConvertApi.col2img_api(dst, src, pad, l1_h, l1_w, fetch_filter_w, fetch_filter_h,
                                                    left_top_w, left_top_h, stride_w, stride_h, filter_w, filter_h,
                                                    dilation_filter_w, dilation_filter_h, repeat_time)
        col2img_obj = Col2ImgApi(self, col2img_api)
        col2img_obj.run_all()

    def broadcast_ub_to_l0c(self, dst, src, nburst, burst_len, *strides):
        """
        copy the data from tik.ubuf to tik.cc's tensor

        Parameters
        ----------
        dst : destination operator
        src : source operation
        nburst : [1, 255] continuous data segment for transfer instruction
        burst_len: nburst's length [1, 255]
        *strides: [src_gap, dst_gap]

        Returns
        -------
        None
        """
        b_ubl0c_api = TikMMadConvertApi.b_ubl0c_api(dst, src, nburst, burst_len, strides)
        b_ubl0c_obj = BroadcastUbToL0cApi(self, b_ubl0c_api)
        b_ubl0c_obj.run_all()

    def mmad_broadcast(self, dst, src, repeat_mode, nburst, burst_repeat, dst_gap, src_gap):
        """
        burst on src side is given in term of 1*16 elements, burst on dst side is given in term of 16*16 elements,
        gap on src side is given in term of 32B, gap on dst side is given in term of 16*16 elements.
        repeatMode=0: burst is effective, each 1*16 is broadcast to 16*16 fractal(repeat on N-dim)
        repeatMode=1: burst is restricted to 1, each burst(1*16) is broadcast to repeat*(16*16) fractals(repeat on
        M-dim);
        """
        mmad_b_api = TikMMadConvertApi.mmad_b_api(dst, src, repeat_mode, nburst, burst_repeat, dst_gap, src_gap)
        mmad_b_obj = MMadBroadCastApi(self, mmad_b_api)
        mmad_b_obj.run_all()

    def load_winograd_fm(self, dst, src, pad, m_extension, m_start_pt, k_extension, k_start_pt):
        """
        Reads feature map data from L1 and performs winograd feature map conversion during the read process.
        Parameters
        ----------
        dst: dst
        src: src
        pad: Number of padding rows/columns
        m_extension: Indicates the transmission length of the instruction in the M dimension of the destination operand.
        m_start_pt: The instruction starts at the M dimension of the destination operand.
        k_extension: Indicates the transmission length of the instruction in the K dimension of the destination operand.
        k_start_pt: The instruction starts at the K dimension of the destination operand.

        Returns
        ----------
        No returns
        """
        load_w_fm_api = TikMMadConvertApi.load_w_fm_api(dst, src, pad, m_extension, m_start_pt, k_extension, k_start_pt)
        load_w_fm_obj = LoadWinoGardFmApi(self, load_w_fm_api)
        load_w_fm_obj.run_all()

    def load_winograd_weight(self, dst, src, dtype_mode):
        """
        The weight data is read from L1 to L0B. During the read process,
        winograd weight conversion is performed.
        This command is used to perform online weight matrix conversion.
        Parameters
        ----------
        dst: dst
        src: src
        dtype_mode: winograd data type mode

        Returns
        -------
        no return
        """
        load_w_we_obj = LoadWinoGardWeApi(self, dst, src, dtype_mode)
        load_w_we_obj.run_all()

    def winograd_feature_map_transform(self, dst, src, l1_h, l1_w, l1_c, pad_left, pad_right, pad_top, pad_bottom,
                                       m_extension, m_start_pt, k_extension, k_start_pt, column_indicator, dst_stride):
        """
        load input feature map from L1 to L0A and do partial winograd transform on-the-fly

        Parameters
        ----------
        dst: destination operator, scope_cbuf
        src: src operator, scope_ca
        l1_h: height of input feature_map
        l1_w: width of input feature_map
        l1_c: channels of input feature_map
        pad_left: col nums of padding left
        pad_right: col nums of padding left
        pad_top: row nums of padding top
        pad_bottom: row nums of padding bottom
        m_extension: m direction extension steps from the start position
        m_start_pt: m direction start position of the feature matrix
        k_extension: k direction extension steps from the start position
        k_start_pt: k direction start position of the feature matrix
        column_indicator: partial weight matrix indicator
        -                 0: the 1st column
        -                 1: the 2nd column
        -                 2: the 3rd column
        -                 3: the 4th column
        dst_stride: inner destination gap between 4 generated expansion feature maps in terms of fractal matrix(512B)

        Returns
        -------
        None
        """
        w_fm_tf_api = TikMMadConvertApi.w_fm_tf_api(dst, src, l1_h, l1_w, l1_c, pad_left, pad_right, pad_top,
                                                    pad_bottom, m_extension, m_start_pt, k_extension, k_start_pt,
                                                    column_indicator, dst_stride)
        w_fm_tf_obj = WinoFmTfApi(self, w_fm_tf_api)
        w_fm_tf_obj.run_all()

    def winograd_weight_transform(self, dst, src, column_indicator, repeat_dir, repeat_times, dst_blk_stride,
                                  dst_rep_stride, src_rep_stride, en_weight_offset=False, smask=None):
        """
        reads 9 fractal matrixes from L1, performs partial winograd transform and writes 4 transformed fractal matrix
        into L0B

        Parameters
        ----------
        dst: destination operator, scope_cbuf
        src: src operator, scope_cb
        column_indicator: partial weight indicator
        -                 0: the 1st column
        -                 1: the 2nd column
        -                 2: the 3rd column
        -                 3: the 4th column
        repeat_dir: repeating direction indicator which is used to indicate on which direction this instruction is
        repeating
        -           0: vertical
        -           1: horizontal
        repeat_times: the number of iterations this instruction would be executed
        dst_blk_stride: inner destination stride between the 4 weight matrixes to be written into L0B in one single
        iteration in unit of fractal matrix
        dst_rep_stride: destination repeat stride between the desitination addresses of 2 successive interations
        src_rep_stride: source repeat stride between the base source addresses of 2 successive iterations
        en_weight_offset: not support yet.
        smask: not support yet.

        Returns
        -------
        None
        """
        w_we_tf_api = TikMMadConvertApi.w_we_tf_api(dst, src, column_indicator, repeat_dir, repeat_times,
                                                    dst_blk_stride, dst_rep_stride, src_rep_stride, en_weight_offset,
                                                    smask)
        w_we_tf_obj = WinoWeTfApi(self, w_we_tf_api)
        w_we_tf_obj.run_all()
