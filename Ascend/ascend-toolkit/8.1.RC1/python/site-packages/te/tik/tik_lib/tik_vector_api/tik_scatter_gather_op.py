#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_scatter_gather_op.py
DESC:     provide params
CREATED:  2021-11-19 10:46:42
MODIFIED: 2021-11-29 14:46:15
"""
from tbe import tvm
from tbe.common.platform import scope_ubuf
from tbe.tik.api.tik_tensor import Tensor
from tbe.tik.api.tik_scalar import Scalar
from tbe.tik.common.common_util import vec_template_align
from tbe.tik.common.common_util import reduce_mul
from tbe.tik.common.util import get_bit_len
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.util import TikUtil
from tbe.tik.common.common_util import get_need_offset
from tbe.tik.tik_lib.tik_expr import Expr
from tbe.tik.tik_lib.tik_expr import is_basic_expr
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_params import ONE_BYTE_BIT_LEN
from tbe.tik.tik_lib.tik_params import MAX_REPEAT_TIMES
from tbe.tik.tik_lib.tik_params import ONE_REP_BYTE_SIZE
from tbe.tik.tik_lib.tik_params import BLK_NUM_PER_REP
from tbe.tik.tik_lib.tik_params import INDEX_IN_START
from tbe.tik.tik_lib.tik_params import MAX_INT32_VALUE
from tbe.tik.tik_lib.tik_params import BIT_LEN_32
from tbe.tik.tik_lib.tik_params import MASK_VALUE_64
from tbe.tik.tik_lib.tik_params import MASK_VALUE_128
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.tik_lib.tik_vector_api.tik_tensor_op import TensorOp
from tbe.tik.tik_lib.tik_vector_api.vector_common_util import gen_block_list

_MIN_DST_BLK_STRIDE = 1
_DEFAULT_BLK_STRIDE = 1
_DEFAULT_REP_STRIDE = 8


class ScatterGatherOp(TensorOp):
    """
    ScatterGather Ops
    """

    def __init__(self, tensor_obj, blk_stride, rep_stride, tensor_op_name):
        super().__init__(tensor_obj, blk_stride, rep_stride, tensor_op_name)
        self.tensor_op_name = tensor_op_name
        self.tensor_obj = tensor_obj
        self.context = None
        self.blk_stride = blk_stride
        self.rep_stride = rep_stride
        self.src_mask_value = None
        self.rep_stride_value = self.rep_stride
        self.blk_stride_value = 0
        self.base_addr = 0
        self.offset_value = None
        self.block_len = None
        self.nblock = None
        self.repeat_times_value = None
        self.mask_value = None
        self.stride_unit_value = 0

    def set_context(self, context=None):
        """
        debug set context

        Parameters
        ----------
        context

        Returns
        -------
        None
        """
        self.context = context
        self.eval_offset()

    def check_vscatter_vgather_offset(self, print_name):
        """
        check offset_scope and dtype for vscatter and vgather

        Parameters
        ----------
        print_name: print_name

        Returns
        -------
        None
        """
        TikCheckUtil.check_type_match(self.tensor_obj, Tensor, "%s should be Tensor. "
                                      "input type: %s" % (self.tensor_op_name, type(self.tensor_obj)))
        TikCheckUtil.check_equality(self.tensor_obj.scope, scope_ubuf, "%s's scope must be UB. "
                                    "input scope: %s" % (self.tensor_op_name, self.tensor_obj.scope))
        # v300 don't have int32 dtype limit
        if print_name == "vgather" and TikSocManager.is_v300_610l_soc():
            return
        TikCheckUtil.check_equality(self.tensor_obj.dtype, "int32", "dtype of %s should be 'int32', "
                                    "but input dtype is '%s'." % (self.tensor_op_name, self.tensor_obj.dtype))

    def check_vscatter_vgather_base_addr(self, base_addr):
        """
        check vscatter_vgather base_addr param

        Parameters
        ----------
        base_addr: base_addr

        Returns
        -------
        None
        """
        TikCheckUtil.check_type_match(
            base_addr, (int, Scalar),
            "base_addr's type should be int or Scalar,"
            " input type is {}".format(type(base_addr)))
        if isinstance(base_addr, int):
            # 2**31 - 1 is max base_addr, 31 bit len
            TikCheckUtil.check_in_range_by_dtype(
                base_addr, msg="base_addr should be in range of [%s, %s]. input base_addr: %s"
                % (INDEX_IN_START, MAX_INT32_VALUE, base_addr), var_range=[INDEX_IN_START, MAX_INT32_VALUE])

            # check valid
            dst_scope_size = reduce_mul(self.tensor_obj.original_shape) * get_bit_len(
                self.tensor_obj.dtype) // ONE_BYTE_BIT_LEN
            TikCheckUtil.check_le(base_addr, dst_scope_size,
                                  "base_addr should be less equal than {} tensor's buffer size: {},"
                                  " input base_add: {}".format(self.tensor_op_name, dst_scope_size, base_addr))
        elif isinstance(base_addr, Scalar):
            TikCheckUtil.check_equality(base_addr.dtype, "uint32", "Scalar base_addr should be dtype of uint32")

    def check_vscatter_vgather_offset_align(self):
        """
        check vscatter_vgather address_align param

        Parameters
        ----------
        Returns
        -------
        None
        """
        dst_offset_align = vec_template_align(self.tensor_obj.dtype)
        self.check_tensor_op_address_align(self.tensor_obj, dst_offset_align)

    def check_vscatter_vgather_offset_overflow(self, dst_offset_tensor_op, control_op, block_list):
        """
        check vscatter_vgather_offset overflow

        Parameters
        ----------
        dst_offset_tensor_op: dst_offset tensor
        control_op: control_op
        block_list: block_list

        Returns
        -------
        None
        """
        self.set_vscatter_stride_value(dst_offset_tensor_op)
        mask = control_op.mask
        if control_op.mask_mode == "normal":
            # all elements in src are read even their mask bits are invalid
            if get_bit_len(self.tensor_obj.dtype) == BIT_LEN_32:
                mask_len = MASK_VALUE_64
            else:
                mask_len = MASK_VALUE_128
        else:
            mask_len = mask

        # change offset dtype temporarily, for check overflow
        self.set_stride_unit(control_op.stride_unit)
        stride_unit_value = self.stride_unit_value
        self.stride_unit_value = 0
        dst_offset_tensor_op.tensor_obj.dtype = self.tensor_obj.dtype
        dst_offset_tensor_op.check_vscatter_vgather_overflow(mask_len, control_op, block_list)
        # reset dst_offset dtype: int32
        self.stride_unit_value = stride_unit_value
        dst_offset_tensor_op.tensor_obj.dtype = "int32"
        if control_op.stride_unit in (2, 3):
            # stide_unit:2,3 for gap, unit is element
            self.blk_stride_value = 0
        self.check_vscatter_vgather_overflow(mask, control_op, block_list)

    def set_vscatter_stride_value(self, dst_offset_tensor_op):
        """
        set vscatter_blk_stride value

        Parameters
        ----------
        dst_offset_tensor_op: dst_offset tensor

        Returns
        -------
        None
        """
        self.blk_stride_value = _DEFAULT_BLK_STRIDE
        dst_offset_tensor_op.blk_stride_value = _DEFAULT_BLK_STRIDE
        dst_offset_tensor_op.rep_stride_value = _DEFAULT_REP_STRIDE

    def check_vscatter_vgather_overflow(self, mask_value, control_op, block_list):
        """
        check vscatter_vgather overflow

        Parameters
        ----------
        mask_value: mask
        control_op: control_op
        block_list: block_list

        Returns
        -------
        None
        """
        repeat_times = control_op.repeat_times
        ori_offset = 0
        nblock, block_len = block_list
        self.block_len = block_len
        self.nblock = nblock
        if is_basic_expr(TikUtil.to_list(mask_value)) or \
                any(is_basic_expr([value]) for value in [repeat_times, self.blk_stride_value, self.rep_stride_value]):
            return
        if not isinstance(self.nblock, int) or repeat_times == 0:
            return
        # Check whether the mask is changed in counter mode
        if control_op.mask_mode == "counter":
            mask_value, repeat_times = self.cal_mask_rep_for_counter_mode(mask_value, repeat_times)

        offset = self.tensor_obj.offset
        if isinstance(offset, (tvm.tir.IntImm, tvm.tir.FloatImm, tvm.tir.StringImm)):
            offset = offset.value
        total_size = reduce_mul(self.tensor_obj.original_shape)
        extend_offset = self.vector_max_offset_cal(mask_value, control_op, repeat_times)
        # offset means offset away from tensor head address, it's 16 for tensor[16]
        # entend_offset means valid data offset
        need_offset = get_need_offset(ori_offset, extend_offset, offset)
        if need_offset is not None:
            TikCheckUtil.check_le(need_offset, total_size,
                                  "%s tensor overflow, expected elements nums: %s, actual elements nums: %s"
                                  % (self.tensor_op_name, need_offset, total_size))


class VGatherbOp(ScatterGatherOp):
    """
    VGatherb Ops
    """

    def __init__(self, tensor_obj, blk_stride, rep_stride, tensor_op_name):
        super().__init__(tensor_obj, blk_stride, rep_stride, tensor_op_name)
        self.tensor_op_name = tensor_op_name
        self.tensor_obj = tensor_obj
        self.blk_stride = blk_stride
        self.rep_stride = rep_stride
        self.blk_stride_value = self.blk_stride
        self.rep_stride_value = self.rep_stride
        self.base_addr = 0
        self.offset_value = None
        self.block_len = None
        self.nblock = None
        self.mask_value = None
        self.stride_unit_value = 0

    def chenk_debug_repeat_times(self):
        """
        check repeat_times

        Parameters
        ----------
        Returns
        -------
        None
        """
        TikCheckUtil.check_in_range_by_dtype(
            self.repeat_times_value, msg="repeat_times should be in the range of [%s, %s], input repeat_times: %s"
            % (0, MAX_REPEAT_TIMES, self.repeat_times_value),
            var_range=[0, MAX_REPEAT_TIMES])

    def check_vgatherb_overflow_with_fixed_length(self, control_op):
        """
        check vgatherb tensor overflow with fixed_length

        Parameters
        ----------
        control_op: control_op

        Returns
        -------
        None
        """
        if self.context is not None:
            src_offsets_offset = self.offset_value
            src_offsets_shape = self.original_shape_value
            length = self.repeat_times_value * BLK_NUM_PER_REP
        else:
            src_offsets_offset = self.tensor_obj.offset
            src_offsets_shape = self.tensor_obj.original_shape
            length = control_op.repeat_times * BLK_NUM_PER_REP

        if isinstance(src_offsets_offset, (tvm.tir.IntImm, tvm.tir.FloatImm, tvm.tir.StringImm)):
            src_offsets_offset = src_offsets_offset.value

        if isinstance(src_offsets_shape, (list, tuple)):
            total_size = reduce_mul(src_offsets_shape)
        else:
            total_size = src_offsets_shape

        need_offset = src_offsets_offset + length
        if Expr(need_offset).eval_value() is None or Expr(total_size).eval_value() is None:
            return
        TikCheckUtil.check_le(need_offset, total_size, "%s need %s but only %s"
                              % (self.tensor_op_name, need_offset, total_size))

    def check_vgatherb_tensor_overflow(self, print_name, src_tensor_op, control_op, context=None):
        """
        check vgatherb tensor overflow

        Parameters
        ----------
        print_name: print_name
        src_tensor_op: src_tensor_op
        control_op: control_op
        context: debug context
        Returns
        -------
        None
        """
        if context is not None:
            self.blk_stride = context.evaluate_expr(self.blk_stride)
        if self.blk_stride == 0:
            self.blk_stride = 1
        tensor_bit_len = max(get_bit_len(self.tensor_obj.dtype), get_bit_len(src_tensor_op.tensor_obj.dtype))
        block_list_dst = gen_block_list(tensor_bit_len, self.tensor_obj.dtype)
        control_op.mask = ONE_REP_BYTE_SIZE // DTYPE_SIZE.get(self.tensor_obj.dtype)
        control_op.mask_mode = "normal"
        control_op.stride_unit = self.stride_unit_value
        self.check_tensor_op_overflow(print_name, control_op, block_list_dst)

    def check_vgatherb_overlap(self, src_tensor_op, src_offsets_tensor_op):
        """
        check vgatherb overlap

        Parameters
        ----------
        src_tensor_op: src_tensor_op
        src_offsets_tensor_op: src_offsets_tensor_op

        Returns
        -------
        None
        """
        if src_tensor_op.tensor_obj.buffer == self.tensor_obj.buffer:
            TikCheckUtil.raise_error("vgatherb dst can't be same with src.")
        if src_tensor_op.tensor_obj.buffer == src_offsets_tensor_op.tensor_obj.buffer:
            TikCheckUtil.raise_error("vgatherb src can't be same with src_offsets.")
        if src_offsets_tensor_op.tensor_obj.buffer == self.tensor_obj.buffer:
            TikCheckUtil.raise_error("vgatherb dst can't be same with src_offsets.")
