#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_cube_api_.py
DESC:     provide cube calculation related instructions
CREATED:  2019-08-12 18:53:42
MODIFIED: 2020-12-7 19:17:00
"""
from collections import namedtuple

from tbe import tvm
from tbe.common.platform import scope_cc
from tbe.common.platform import scope_cbuf
from tbe.common.platform import scope_cb
from tbe.common.platform import intrinsic_check_support
from tbe.common.platform import api_check_support
from tbe.common.platform import AIC_610
from tbe.common.platform import HI3796CV300ESAIC
from tbe.common.platform.platform_info import scope_bt
from tbe.tik.api.tik_tensor import Tensor
from tbe.tik.api.tik_scalar import Scalar
from tbe.tik.tik_lib.tik_expr import Expr
from tbe.tik.api.tik_ir_builder import TikIRBuilder
from tbe.tik.tik_lib.tik_expr_convert import type_convert
from tbe.tik.common.tik_api_map import AIC_310P
from tbe.tik.common.tik_api_map import AIC_BS9SX1A
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.util import check_scalar_dtype
from tbe.tik.common.util import reduce_mul
from tbe.tik.common.util import ceil_div
from tbe.tik.common.common_check_func import check_depthwise_conv_params
from tbe.tik.tik_lib.tik_api_constants import DTYPE_MAP
from tbe.tik.tik_lib.tik_api_util import do_load3d_padding
from tbe.tik.tik_lib.tik_api_util import check_pad_value
from tbe.tik.tik_lib.tik_api_util import check_weight_offset
from tbe.tik.tik_lib.tik_params import MAX_MATRIX
from tbe.tik.tik_lib.tik_params import MIN_EXTENSION_WINO_V2
from tbe.tik.tik_lib.tik_params import MIN_MATRIX
from tbe.tik.tik_lib.tik_params import PIPE_M
from tbe.tik.tik_lib.tik_params import BYTE_PER_FRACTAL
from tbe.tik.tik_lib.tik_params import ELE_PER_FRACTAL_EDGE
from tbe.tik.tik_lib.tik_params import PIPE_MTE1
from tbe.tik.tik_lib.tik_params import gen_api_check_statement
from tbe.tik.tik_lib.tik_params import ONE_BLK_SIZE
from tbe.tik.common.common_util import check_depthwise_conv_l1_w
from tbe.tik.common.tik_get_soc_name import get_soc_name
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.common.tik_get_soc_name import get_soc_core_type
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_source_info import source_info_decorator
from tbe.tik.common.common_util import check_address_align
from tbe.tik.common.common_util import get_l0c_align
from tbe.tik.tik_lib.tik_params import MAX_EXTENSION_WINO_V2
from tbe.tik.debug.decorators_cube import move_bias_to_bt_decorator
from tbe.tik.debug.tik_vector_ops_debug.tik_vector_cube_debug import mmad_decorator
from tbe.tik.debug.tik_vector_ops_debug.tik_vector_cube_debug import depthwise_conv_decorator
from tbe.tik.debug.decorators_v210 import winograd_conv_decorator

_ENABLE_BIAS = 1
_MAX_IS_BIAS = 1
# elements per fractal's edge, 16
_ELE_PER_FRACTAL_EDGE = 16
# bits per Byte, 8
_BIT_PER_BYTE = 8

_DEPTHWISE_CONV_C0_MAP = {
    "uint8": 16,
    "int8": 16,
    "float16": 8
}


def temp_matrix_m_not_none(temp_mat_params, winograd_conv_api, dst_offset):
    """
    temp matrix m not none
    Returns
    -------

    """
    temp_matrix_m, temp_matrix_k, src_fm_offset, temp_matrix_n = temp_mat_params
    if temp_matrix_m != 0 and temp_matrix_k is not None and src_fm_offset is not None:
        dst_expected_ele = ceil_div(temp_matrix_m, 16) * 16 * temp_matrix_k * 16 + src_fm_offset
        dst_actual_ele = reduce_mul(winograd_conv_api.src_fm.original_shape)
        TikCheckUtil.check_ge(
            dst_actual_ele, dst_expected_ele,
            "src_fm tensor overflow, expected src_fm shape: %s, actual src_fm shape: %s"
            % (dst_expected_ele, dst_actual_ele))
    if temp_matrix_m != 0 and temp_matrix_n is not None and dst_offset is not None:
        if temp_matrix_n != 0:
            dst_expected_ele = ceil_div(temp_matrix_m, 16) * 16 * \
                               ceil_div(temp_matrix_n, 16) * 16 * 4 + dst_offset
            dst_actual_ele = reduce_mul(winograd_conv_api.dst.original_shape)
            TikCheckUtil.check_ge(
                dst_actual_ele, dst_expected_ele,
                "dst tensor overflow, expected dst shape: %s, actual dst shape: %s"
                % (dst_expected_ele, dst_actual_ele))


def winograd_conv_overflow_check(winograd_conv_api):
    """
    use to check overflow matrix_k, matrix_m, matrix_n, src_fm, src_filter, dst
    """
    temp_matrix_k = Expr(winograd_conv_api.matrix_k).eval_value()
    temp_matrix_m = Expr(winograd_conv_api.matrix_m).eval_value()
    temp_matrix_n = Expr(winograd_conv_api.matrix_n).eval_value()
    src_fm_offset = Expr(winograd_conv_api.src_fm.offset).eval_value()
    src_filter_offset = Expr(winograd_conv_api.src_filter.offset).eval_value()
    dst_offset = Expr(winograd_conv_api.dst.offset).eval_value()
    if temp_matrix_k is not None:
        src_c0 = 32 // DTYPE_SIZE[winograd_conv_api.src_fm.dtype]
        if temp_matrix_k != src_c0:
            TikCheckUtil.raise_error(
                "matrix_k should be equal to c0, "
                "input matrix_k: %s, c0: %s" % (temp_matrix_k, src_c0))
    if temp_matrix_m is not None:
        temp_matrix_m_not_none(
            (temp_matrix_m, temp_matrix_k, src_fm_offset, temp_matrix_n), winograd_conv_api, dst_offset)
    if temp_matrix_n is not None and temp_matrix_k is not None:
        if temp_matrix_n != 0 and src_filter_offset is not None:
            dst_expected_ele = temp_matrix_k * ceil_div(temp_matrix_n, 16) * \
                               16 * 16 + src_filter_offset
            dst_actual_ele = reduce_mul(winograd_conv_api.src_filter.original_shape)
            TikCheckUtil.check_ge(
                dst_actual_ele, dst_expected_ele,
                "src_filter tensor overflow, expected src_filter shape: %s, "
                "actual src_filter shape: %s"
                % (dst_expected_ele, dst_actual_ele))


def _calculate_mmad_extent(mmad_api):
    """
    calculate mmad extent

    Parameters
    ----------
    mmad_api:
    -        matrix_m: row of left_matrix
    -        matrix_k: col of left_matrix, row of right_matrix
    -        matrix_n: col of right_matrix
    -        dst_fm: destination tensor
    -        src_fm: source tensor_left
    -        src_filter: source tensor_right

    Returns
    -------
    dst_fm_extent
    src_fm_extent
    src_filter_extent
    """
    # m and n need to be 16 elements aligned
    # k*dtype_size need to be 32 Bytes aligned
    # all variables are element numbers
    m_round = ceil_div(mmad_api.matrix_m, _ELE_PER_FRACTAL_EDGE) * _ELE_PER_FRACTAL_EDGE
    k_round_blk_param = mmad_api.matrix_k * DTYPE_SIZE.get(mmad_api.src_filter.dtype)
    k_round = ceil_div(k_round_blk_param, ONE_BLK_SIZE) * ONE_BLK_SIZE // DTYPE_SIZE.get(mmad_api.src_filter.dtype)
    n_round = ceil_div(mmad_api.matrix_n, _ELE_PER_FRACTAL_EDGE) * _ELE_PER_FRACTAL_EDGE

    # dst_fm_extent is m_round*n_round*dtype_size
    dst_fm_extent = Expr(m_round * n_round * DTYPE_SIZE.get(mmad_api.dst_fm.dtype)).get()
    # src_fm_extent is m_round*k_round*dtype_size
    src_fm_extent = Expr(m_round * k_round * DTYPE_SIZE.get(mmad_api.src_fm.dtype)).get()
    # src_filter_extent is k_round*n_round*dtype_size
    src_filter_extent = Expr(k_round * n_round * DTYPE_SIZE.get(mmad_api.src_filter.dtype)).get()

    return dst_fm_extent, src_fm_extent, src_filter_extent


def _cal_extent_depthwise_conv(dst_fm, src_fm, pad_mode, l1_h, l1_w):
    """
    calculate depthwise_conv dst_fm/src_fm/src_filter extent

    Parameters
    ----------
    dst_fm: destination tensor
    src_fm: source tensor_left
    pad_mode:   0 - no padding
    -           1 - two colume on right side
    -           2 - two colume on left side
    -           3 - one colume on right&left side
    l1_h: height of src_fm
    l1_w: width of src_fm

    Returns
    -------
    """
    pad_mode = Expr(pad_mode).eval_value()
    if pad_mode is None:
        dst_fm_extent = (reduce_mul(dst_fm.original_shape) -
                         dst_fm.offset) * DTYPE_SIZE[dst_fm.dtype]
    else:
        # kernel_size is 3*3, dst_fm height h_o should be l1_h minus 2
        h_o = l1_h - 2
        if pad_mode == 0:
            # pad_mode 0 means no padding, dst_fm width w_o should be l1_w minus
            # 2
            w_o = l1_w - 2
        else:
            # pad_mode 1/2/3, w_o should be l1_w up to 16 aligned
            w_o = ceil_div(l1_w, _ELE_PER_FRACTAL_EDGE)
        dst_fm_extent = h_o * w_o * _ELE_PER_FRACTAL_EDGE * DTYPE_SIZE[dst_fm.dtype]
    dst_fm_extent = Expr(dst_fm_extent).get()
    src_fm_extent = l1_h * l1_w * _DEPTHWISE_CONV_C0_MAP.get(src_fm.dtype) * DTYPE_SIZE.get(src_fm.dtype)
    src_fm_extent = Expr(src_fm_extent).get()
    src_ft_extent = BYTE_PER_FRACTAL

    return dst_fm_extent, src_fm_extent, src_ft_extent


def _check_dc_fm_overflow(l1_h, l1_w, src_fm, pad_mode, dst_fm):
    """
    check whether depthwise_conv src_fm/dst_fm tensor overflow.

    Parameters
    ----------
    l1_h: height of src_fm
    l1_w: width of src_fm
    src_fm: source tensor_left
    pad_mode:   0 - no padding
    -           1 - two colume on right side
    -           2 - two colume on left side
    -           3 - one colume on right&left side
    dst_fm: destination tensor

    Returns
    -------
    None
    """
    # check src_fm overflow
    src_fm_expected = l1_h * l1_w * _DEPTHWISE_CONV_C0_MAP.get(src_fm.dtype) + src_fm.offset
    src_fm_actual = reduce_mul(src_fm.original_shape)
    src_fm_expected = Expr(src_fm_expected).eval_value()
    src_fm_actual = Expr(src_fm_actual).eval_value()
    if src_fm_expected is not None and src_fm_actual is not None:
        TikCheckUtil.check_ge(
            src_fm_actual, src_fm_expected,
            "In depthwise_conv, src_fm tensor overflow, expected elements: {}, "
            "actual elements: {}".format(src_fm_expected, src_fm_actual))
    # check dst_fm overflow
    if Expr(pad_mode).eval_value() is not None:
        if Expr(pad_mode).eval_value() == 0:
            w_o = l1_w - 2
        else:
            w_o = ceil_div(l1_w, ELE_PER_FRACTAL_EDGE) * ELE_PER_FRACTAL_EDGE
        dst_fm_expected = (l1_h - 2) * w_o * ELE_PER_FRACTAL_EDGE + dst_fm.offset
        dst_fm_actual = reduce_mul(dst_fm.original_shape)
        dst_fm_expected = Expr(dst_fm_expected).eval_value()
        dst_fm_actual = Expr(dst_fm_actual).eval_value()
        if dst_fm_actual is not None and dst_fm_expected is not None:
            TikCheckUtil.check_ge(
                dst_fm_actual, dst_fm_expected,
                "In depthwise_conv, dst_fm tensor overflow, expected elements: "
                "{}, actual elements: {}"
                    .format(dst_fm_expected, dst_fm_actual))


def _check_dc_ft_overflow(src_filter):
    """
    check whether depthwise_conv src_filter tensor overflow.

    Parameters
    ----------
    src_filter: source tensor_right

    Returns
    -------
    None
    """
    src_ft_expected = BYTE_PER_FRACTAL // DTYPE_SIZE[src_filter.dtype] + src_filter.offset
    src_ft_actual = reduce_mul(src_filter.original_shape)
    src_ft_expected = Expr(src_ft_expected).eval_value()
    src_ft_actual = Expr(src_ft_actual).eval_value()
    if src_ft_actual is not None and src_ft_expected is not None:
        TikCheckUtil.check_ge(
            src_ft_actual, src_ft_expected,
            "In depthwise_conv, src_filter tensor overflow, expected "
            "elements: {}, actual elements: {}"
                .format(src_ft_expected, src_ft_actual))


def _check_fm_scope(target_fm, target_type, target_fm_name):
    """
    check whether the input tensor matches target scope.

    Parameters
    ----------
    target_fm: input tensor
    target_type: target scope
    target_fm_name: input tensor name

    Returns
    -------
    None
    """
    target_fm_scope = target_fm.scope.split('.')[-1].lower()
    TikCheckUtil.check_type_match(target_fm, Tensor,
                                  "%s should be tensor" % target_fm_name)
    TikCheckUtil.check_equality(
        target_fm_scope, target_type,
        "scope of %s should be %s" % (target_fm_name, target_type))


def _check_dc_weight_offset_overflow(weight_offset):
    """
    check whether depthwise_conv weight_offset tensor overflow.

    Parameters
    ----------
    weight_offset: source tensor which contains weight offset data

    Returns
    -------
    None
    """
    # in 1 instruction, weight_offset only need 16B
    weight_offset_expected = 16 // DTYPE_SIZE[weight_offset.dtype] + weight_offset.offset
    weight_offset_actual = reduce_mul(weight_offset.original_shape)
    if Expr(weight_offset_actual).eval_value() is not None \
            and Expr(weight_offset_expected).eval_value() is not None:
        TikCheckUtil.check_ge(
            weight_offset_actual, weight_offset_expected,
            "In depthwise_conv, weight_offset tensor overflow, expected"
            " elements: {}, actual elements: {}"
                .format(weight_offset_expected, weight_offset_actual))


class TikCubeApi(TikIRBuilder):
    """
    Cube Operation Api
    """
    mmad_api = namedtuple('MmadOpApi', ["dst_fm", "src_fm", "src_filter", "matrix_m", "matrix_k",
                                        "matrix_n", "is_bias", "fm_offset", "en_weight_offset", "smask",
                                        "en_small_channel", "en_small_k", "en_ssparse", "en_winograd_a",
                                        "en_winograd_b", "bias_tensor_bt"])
    depthwise_conv_api = namedtuple('DepthwiseConvOpApi', ["dst_fm", "src_fm", "src_filter", "pad_mode", "l1_h", "l1_w",
                                                           "store_high_half", "feature_offset", "weight_offset",
                                                           "pad_value"])
    winograd_conv_api = namedtuple('WinogradConvOpApi', ["dst", "src_fm", "src_filter", "matrix_m",
                                                         "matrix_k", "matrix_n", "is_bias"])

    @staticmethod
    def check_mmad_params(mmad_api):
        """
        check mmad params

        Parameters
        ----------
        mmad_api: namedtuple of mmad

        Returns
        -------
        None
        """
        # check whether the input tensor matches the scope
        _check_fm_scope(mmad_api.dst_fm, "l0c", "dst_fm")
        _check_fm_scope(mmad_api.src_fm, "l0a", "src_fm")
        _check_fm_scope(mmad_api.src_filter, "l0b", "src_filter")
        align = 512
        check_address_align((mmad_api.src_fm, mmad_api.src_filter), ("src_fm", "src_filter"), align)
        dst_align = get_l0c_align(mmad_api.dst_fm)
        check_address_align((mmad_api.dst_fm,), ("dst_fm",), dst_align)

        # check dtype
        dtype_str = DTYPE_MAP.get(mmad_api.src_fm.dtype) + DTYPE_MAP.get(mmad_api.src_filter.dtype) + \
                    DTYPE_MAP.get(mmad_api.dst_fm.dtype)
        dtype_str_err = "src_fm %s src_filter %s dst_fm %s" % (mmad_api.src_fm.dtype,
                                                               mmad_api.src_filter.dtype, mmad_api.dst_fm.dtype)
        TikCheckUtil.check_equality(api_check_support("tik.mmad", dtype_str), True,
                                    gen_api_check_statement(dtype_str_err, "mmad"))
        # check m k n if both in [0, 4095]
        TikCheckUtil.check_type_match(mmad_api.matrix_m, (int, Expr, Scalar), "matrix_m should be int, Expr or Scalar")
        check_scalar_dtype(mmad_api.matrix_m, "matrix_m should be a scalar of int/uint")
        TikCheckUtil.check_in_range_by_dtype(
            mmad_api.matrix_m, msg="matrix_m should be in range of [%d, %d], input value is %s"
            % (MIN_MATRIX, MAX_MATRIX, str(mmad_api.matrix_m)), var_range=[MIN_MATRIX, MAX_MATRIX])
        TikCheckUtil.check_type_match(mmad_api.matrix_n, (int, Expr, Scalar), "matrix_n should be int, Expr or Scalar")
        check_scalar_dtype(mmad_api.matrix_n, "matrix_n should be a scalar of int/uint")
        TikCheckUtil.check_in_range_by_dtype(
            mmad_api.matrix_n, msg="matrix_n should be in range of [%d, %d], input value is %s"
            % (MIN_MATRIX, MAX_MATRIX, str(mmad_api.matrix_n)), var_range=[MIN_MATRIX, MAX_MATRIX])
        TikCheckUtil.check_type_match(mmad_api.matrix_k, (int, Expr, Scalar), "matrix_k should be int, Expr or Scalar")
        check_scalar_dtype(mmad_api.matrix_k, "matrix_k should be a scalar of int/uint")
        TikCheckUtil.check_in_range_by_dtype(
            mmad_api.matrix_k, msg="matrix_k should be in range of [%d, %d], input value is %s"
            % (MIN_MATRIX, MAX_MATRIX, str(mmad_api.matrix_k)), var_range=[MIN_MATRIX, MAX_MATRIX])

        # check is_bias in [0, 1]
        TikCheckUtil.check_type_match(mmad_api.is_bias, (int, Expr), "is_bias should be int or Expr")
        check_scalar_dtype(mmad_api.is_bias, "is_bias should be a scalar of int/uint")
        TikCheckUtil.check_in_range_by_dtype(mmad_api.is_bias, msg="is_bias should be %d or %d" % (0, _MAX_IS_BIAS),
                                             var_range=[0, _MAX_IS_BIAS])
        TikCheckUtil.check_type_match(mmad_api.en_small_channel, bool, "the type of en_small_channel should be bool")
        TikCheckUtil.check_type_match(mmad_api.en_small_k, bool, "the type of en_small_k should be bool")

        # check feature
        arch_version_str = get_soc_name() + get_soc_core_type()
        # small_k
        # winograd
        # main in smallhs or aic
        if mmad_api.en_winograd_a or mmad_api.en_winograd_b:
            TikCheckUtil.check_var_in_list(
                arch_version_str, [HI3796CV300ESAIC, AIC_610, AIC_310P, AIC_BS9SX1A],
                "%s not support winograd" % arch_version_str)

    @staticmethod
    def winograd_conv_check_params(winograd_conv_api):
        """
        winograd_conv check params

        Parameters
        ----------
        winograd_conv_api: named tuple of winograd_conv

        Returns
        -------
        None
        """
        TikCheckUtil.check_type_match(winograd_conv_api.src_fm, Tensor, "src_fm should be tensor")
        TikCheckUtil.check_type_match(winograd_conv_api.src_filter, Tensor, "src_filter should be tensor")
        TikCheckUtil.check_type_match(winograd_conv_api.dst, Tensor, "dst should be tensor")
        TikCheckUtil.check_equality(
            winograd_conv_api.dst.scope, "local.L0C",
            "dst scope should be l0c, input scope: {}".format(winograd_conv_api.dst.scope))
        TikCheckUtil.check_equality(
            winograd_conv_api.src_fm.scope, "local.L0A",
            "src_fm scope should be l0a, input scope: {}".format(winograd_conv_api.src_fm.scope))
        TikCheckUtil.check_equality(
            winograd_conv_api.src_filter.scope, "local.L0B",
            "src_filter scope should be l0b, input scope: {}".format(winograd_conv_api.src_filter.scope))
        src_dst_dtype = DTYPE_MAP.get(winograd_conv_api.dst.dtype) + DTYPE_MAP.get(winograd_conv_api.src_fm.dtype) + \
                        DTYPE_MAP.get(winograd_conv_api.src_filter.dtype)
        dtype_str_err = "src_fm %s src_filter %s dst %s" % (winograd_conv_api.src_fm.dtype,
                                                            winograd_conv_api.src_filter.dtype,
                                                            winograd_conv_api.dst.dtype)
        TikCheckUtil.check_equality(intrinsic_check_support("Intrinsic_" + "winograd_conv", src_dst_dtype), True,
                                    gen_api_check_statement(dtype_str_err, "winograd_conv"))
        # check m & k
        TikCheckUtil.check_type_match(
            winograd_conv_api.matrix_m, (int, Scalar, Expr),
            "matrix_m should be int, Scalar, Expr, input type of matrix_m: {}".format(type(winograd_conv_api.matrix_m)))
        check_scalar_dtype(winograd_conv_api.matrix_m, "matrix_m should be a scalar of int/uint")
        TikCheckUtil.check_type_match(
            winograd_conv_api.matrix_k, (int, Scalar, Expr),
            "matrix_k should be int, Scalar, Expr, input type of matrix_k: {}".format(type(winograd_conv_api.matrix_k)))
        check_scalar_dtype(winograd_conv_api.matrix_k, "matrix_k should be a scalar of int/uint")
        TikCheckUtil.check_type_match(
            winograd_conv_api.matrix_n, (int, Scalar, Expr),
            "matrix_n should be int, Scalar, Expr, input type of matrix_n: {}".format(type(winograd_conv_api.matrix_n)))
        check_scalar_dtype(winograd_conv_api.matrix_n, "matrix_n should be a scalar of int/uint")
        TikCheckUtil.check_in_range_by_dtype(
            winograd_conv_api.matrix_m, msg="matrix_m should be in the range of [{}, {}], input matrix_m: {}".format(
                MIN_EXTENSION_WINO_V2, MAX_EXTENSION_WINO_V2, winograd_conv_api.matrix_m),
            var_range=[MIN_EXTENSION_WINO_V2, MAX_EXTENSION_WINO_V2])
        src_c0 = 32 // DTYPE_SIZE[winograd_conv_api.src_fm.dtype]
        if isinstance(winograd_conv_api.matrix_k, int):
            TikCheckUtil.check_equality(
                winograd_conv_api.matrix_k, src_c0,
                "matrix_k should be equal to C0: {},input matrix_k: {}".format(src_c0, winograd_conv_api.matrix_k))
        TikCheckUtil.check_in_range_by_dtype(
            winograd_conv_api.matrix_n, msg="matrix_n should be in the range of [{}, {}], input matrix_n: {}".format(
                MIN_EXTENSION_WINO_V2, MAX_EXTENSION_WINO_V2, winograd_conv_api.matrix_n),
            var_range=[MIN_EXTENSION_WINO_V2, MAX_EXTENSION_WINO_V2])
        TikCheckUtil.check_type_match(winograd_conv_api.is_bias, int, "is_bias must be int.")
        TikCheckUtil.check_var_in_list(winograd_conv_api.is_bias, [0, 1],
                                       "is_bias must be 0 or 1, but get {}.".format(winograd_conv_api.is_bias))
        winograd_conv_overflow_check(winograd_conv_api)

    @staticmethod
    def check_params_scope(dst_fm, src_fm, src_filter):
        """
        check params's scope

        Parameters
        ----------
        dst_fm: destination tensor
        src_fm: source tensor_left
        src_filter: source tensor_right

        Returns
        -------
        None
        """
        TikCheckUtil.check_type_match(
            dst_fm, Tensor,
            "depthwise_conv dst_fm should be Tensor, input type: {}"
                .format(type(dst_fm)))
        TikCheckUtil.check_equality(
            dst_fm.scope, scope_cc,
            "depthwise_conv dst_fm scope should be L0C, input scope: {}"
                .format(dst_fm.scope))
        TikCheckUtil.check_type_match(
            src_fm, Tensor,
            "depthwise_conv src_fm should be Tensor, input type: {}"
                .format(type(src_fm)))
        TikCheckUtil.check_equality(
            src_fm.scope, scope_cbuf,
            "depthwise_conv src_fm scope should be L1, input scope: {}"
                .format(src_fm.scope))
        TikCheckUtil.check_type_match(
            src_filter, Tensor,
            "depthwise_conv src_filter should be Tensor, input type: {}"
                .format(type(src_filter)))
        TikCheckUtil.check_equality(
            src_filter.scope, scope_cb,
            "depthwise_conv src_filter scope should be L0B, input scope: {}"
                .format(src_filter.scope))

    @staticmethod
    def check_bias_tensor(dst_fm, bias_tensor):
        """
        dst_fm: dst in L0C
        bias_tensor: bias tensor in l1
        """
        TikCheckUtil.check_type_match(bias_tensor, Tensor, "bias_tensor should be a tensor")
        TikCheckUtil.check_equality(
            TikSocManager.is_910b_soc() or TikSocManager.is_310b_610l_soc(), True,
            "bias_tensor is not supported on {}".format(get_soc_name()))
        TikCheckUtil.check_equality(
            bias_tensor.scope, "local.L1",
            "bias_tensor scope should be L1, input scope: {}".format(bias_tensor.scope))
        bias_dtype = bias_tensor.dtype
        if bias_dtype == "float16":
            bias_dtype = "float32"
        TikCheckUtil.check_equality(
            bias_dtype, dst_fm.dtype,
            "type of bias_tensor should be same as dst_fm. input bias_tensor type is {}".format(bias_tensor.dtype))

    @source_info_decorator()
    def mmad(self, dst_fm, src_fm, src_filter, matrix_m, matrix_k, matrix_n, is_bias, fm_offset=0,
             en_weight_offset=False, smask=None, en_small_channel=False, en_small_k=False, en_ssparse=False,
             en_winograd_a=False, en_winograd_b=False, bias_tensor=None):
        """
        Matrix multiply-add operation.

        Parameters
        ----------
        dst_fm: destination tensor
        src_fm: source tensor_left
        src_filter: source tensor_right
        matrix_m: row of left_matrix
        matrix_k: col of left_matrix, row of right_matrix
        matrix_n: col of right_matrix
        is_bias: switch for mul_add function, 1 is mul_add, 0 is mul
        fm_offset: not support v100
        en_weight_offset: not support v100
        smask: not support v100
        en_small_channel: switch for small_channel funtion
        en_small_k: not support v100
        en_ssparse: not support v100
        en_winograd_a: not support v100
        en_winograd_b: not support v100
        bias_tensor: bias tensor in L1 buffer

        Returns
        -------
        None
        """
        bias_bt = None
        if bias_tensor is not None:
            self.check_bias_tensor(dst_fm, bias_tensor)
            bias_bt = self.move_bias_to_bt(bias_tensor, matrix_n)
        mmad_api = TikCubeApi.mmad_api(dst_fm, src_fm, src_filter, matrix_m, matrix_k, matrix_n, is_bias, fm_offset,
                                       en_weight_offset, smask, en_small_channel, en_small_k, en_ssparse,
                                       en_winograd_a, en_winograd_b, bias_bt)
        self.check_mmad_params(mmad_api)
        self.mmad_gen_code(mmad_api)

    def move_bias_to_bt(self, bias_l1, n_size):
        """
        bias_l1: bias tensor on L1, src of data_move instruction
        n_size: n of mmad instruction
        return: bais on bias-table scope
        """
        @move_bias_to_bt_decorator
        def gen_code(tik_instance, bias_l1, bias_bt, n_size, conv_control):
            """
            bias_l1: bias on l1
            bias_bt: bias on bt
            n_size: n of mmad instruction, uint byte
            conv_control: conv-control bit, enable src->dst conv
            """
            # nburst is 1 is enough for data_move
            # and only support continuous data move for l1->bt, src/dst gap must be 0
            nburst = 1
            src_gap = 0
            dst_gap = 0
            # burst length is in unit of 64B on v220/v300, and 32B on 610l
            burst_len_unit = 64 if not TikSocManager.is_610l_soc() else 32
            # burst length is referred to source data
            burst_len = ceil_div(n_size, burst_len_unit)
            bt_copy_instr_name = "copy_cbuf_to_bt"
            bt_tensor_addr = type_convert(bias_bt.access_ptr("w"), dtype="uint64_t")
            instr_data_to_bt = tvm.call_extern(
                bias_l1.dtype, bt_copy_instr_name, bt_tensor_addr,
                bias_l1.access_ptr("r"),
                *(type_convert([conv_control, nburst, burst_len, src_gap, dst_gap])))
            tik_instance.emit(instr_data_to_bt)
        conv_control = 0
        bias_dtype = bias_l1.dtype
        # bias in bias-table must be float32/int32
        # if bias_l1 is float16, mov_l1_to_bt can conv it to float32 using
        if bias_dtype == "float16":
            conv_control = 1
            bias_dtype = "float32"
        bias_bt = self.Tensor(bias_dtype, shape=(n_size,), scope=scope_bt, name="temp_bias_bt")
        n_size_in_byte = n_size * DTYPE_SIZE[bias_dtype]
        gen_code(self, bias_l1, bias_bt, n_size_in_byte, conv_control)
        return bias_bt

    @mmad_decorator
    def mmad_gen_code(self, mmad_api):
        """
        mmad gen code

        Parameters
        ----------
        mmad_api: namedtuple of mmad

        Returns
        -------
        None
        """
        if mmad_api.is_bias == _ENABLE_BIAS:
            # 0 l0c init disable: using real number in L0C
            l0c_init = 0
            dst_acc = "rw"
        else:
            # 1 l0c init enable: number in L0C is 0
            l0c_init = 1
            dst_acc = "w"

        # smask
        if mmad_api.en_weight_offset:
            check_weight_offset(mmad_api.smask, "mmad", "smask")
            smask_idx = mmad_api.smask.access_ptr('r')
        else:
            smask_idx = 0
        # code gen
        if TikSocManager.is_v100_soc():
            params = [mmad_api.matrix_m, mmad_api.matrix_k, mmad_api.matrix_n, l0c_init]
        elif TikSocManager.is_910b_soc() or TikSocManager.is_310b_610l_soc():
            unit_flag = 0
            k_align = False
            l0c_from_bt = mmad_api.bias_tensor_bt is not None
            # 910b & 310b, Use the mad(c, a, b, m, k, n, unitFlag, kDirectionAlign, cmatrixSource, cmatrixInitVal),
            # Parameters featOffset, smaskOffset, and isWeightOffset are not transferred.;
            params = [mmad_api.matrix_m, mmad_api.matrix_k, mmad_api.matrix_n,
                      unit_flag, k_align, l0c_from_bt, l0c_init]
            if l0c_from_bt:
                # need to insert bias-tensor for args when init l0c using bias-table
                bias_bt_addr = type_convert(mmad_api.bias_tensor_bt.access_ptr("r"), dtype="uint64_t")
                params.insert(0, bias_bt_addr)
        else:
            params = [mmad_api.matrix_m, mmad_api.matrix_k, mmad_api.matrix_n, mmad_api.fm_offset, smask_idx,
                      mmad_api.en_winograd_a, mmad_api.en_winograd_b, mmad_api.en_weight_offset,
                      mmad_api.en_ssparse, l0c_init]
        args = type_convert(params)

        dst_fm_extent, src_fm_extent, src_filter_extent = _calculate_mmad_extent(mmad_api)

        with self.new_scope():
            instr = tvm.call_extern(mmad_api.dst_fm.dtype, "mad",
                                    mmad_api.dst_fm.access_ptr(dst_acc, extent=dst_fm_extent),
                                    mmad_api.src_fm.access_ptr("r", extent=src_fm_extent),
                                    mmad_api.src_filter.access_ptr("r", extent=src_filter_extent), *args)
            self.scope_attr(tvm.thread_axis("cce"), "coproc_scope", PIPE_M)
            # 1 ir is call_extern
            self.emit(instr)

    @source_info_decorator()
    def depthwise_conv(self, dst_fm, src_fm, src_filter, pad_mode, l1_h, l1_w,
                       store_high_half=False, feature_offset=0, weight_offset=None, pad_value=None):
        """
        depthwise convolution operation.

        Parameters
        ----------
        dst_fm: destination tensor
        src_fm: source tensor_left
        src_filter: source tensor_right
        pad_mode: 0 - no padding
        -         1 - two colume on right side
        -         2 - two colume on left side
        -         3 - one colume on right&left side
        l1_h: height of src_fm
        l1_w: width of src_fm
        store_high_half: the high/low channels indicator, only works for type: {f16f16f16, f32f16f16}.Only support bool
        -                True: Cin/Cout is the lower 8 channels out of 16 channels.
        -                False: Cin/Cout is the higher 8 channels out of 16 channels.
        feature_offset: the feature map matrix offset, dtype is same as src_fm.If no offset is needed, set to 8'b0.
        Only works for src_fm dtype is b8.
        weight_offset: the weight matrix offset, not support yet.
        pad_value: value for padding, default = None

        Returns
        -------
        None
        """
        depthwise_conv_api = TikCubeApi.depthwise_conv_api(dst_fm, src_fm, src_filter, pad_mode, l1_h, l1_w,
                                                           store_high_half, feature_offset, weight_offset, pad_value)
        self.check_depthwise_conv_params(depthwise_conv_api)
        self.depthwise_conv_gen_code(depthwise_conv_api)

    def check_depthwise_conv_params(self, depthwise_conv_api):
        """
        check depthwise conv params

        Parameters
        ----------
        depthwise_conv_api: named tuple of winograd_conv

        Returns
        -------
        None
        """
        # function's input params is too much, so disable R0913, R0914
        # check dst/src
        self.check_params_scope(depthwise_conv_api.dst_fm, depthwise_conv_api.src_fm, depthwise_conv_api.src_filter)

        src_filter_align = 512
        check_address_align((depthwise_conv_api.src_filter,), ("src_filter",), src_filter_align)
        src_fm_align = 16
        check_address_align((depthwise_conv_api.src_fm,), ("src_fm",), src_fm_align)
        dst_align = get_l0c_align(depthwise_conv_api.dst_fm)
        check_address_align((depthwise_conv_api.dst_fm,), ("dst_fm",), dst_align)
        # check dtype
        dtype_str = DTYPE_MAP.get(depthwise_conv_api.dst_fm.dtype) + DTYPE_MAP.get(depthwise_conv_api.src_fm.dtype) + \
                    DTYPE_MAP.get(depthwise_conv_api.src_filter.dtype)
        dtype_str_err = "src_fm %s src_filter %s dst_fm %s" % (
            depthwise_conv_api.src_fm.dtype, depthwise_conv_api.src_filter.dtype, depthwise_conv_api.dst_fm.dtype)
        TikCheckUtil.check_equality(intrinsic_check_support("Intrinsic_" + "depthwise_conv", dtype_str), True,
                                    gen_api_check_statement(dtype_str_err, "depthwise_conv"))
        # check store_high_half
        TikCheckUtil.check_type_match(
            depthwise_conv_api.store_high_half, bool,
            "store_high_half should be bool, input type of store_high_half: {}".format(type(
                depthwise_conv_api.store_high_half)))
        # check pad_mode
        TikCheckUtil.check_type_match(
            depthwise_conv_api.pad_mode, (int, Scalar, Expr),
            "depthwise_conv pad_mode should be int, Scalar or Expr, input type:"
            " {}".format(type(depthwise_conv_api.pad_mode)))
        check_scalar_dtype(depthwise_conv_api.pad_mode, "pad_mode should be a scalar of int/uint")
        # check W/H
        TikCheckUtil.check_type_match(
            depthwise_conv_api.l1_h, (int, Scalar, Expr),
            "l1_h should be int, Scalar or Expr, input type of l1_h: {}".format(type(depthwise_conv_api.l1_h)))
        check_scalar_dtype(depthwise_conv_api.l1_h, "l1_h should be a scalar of int/uint")
        TikCheckUtil.check_type_match(
            depthwise_conv_api.l1_w, (int, Scalar, Expr),
            "l1_w should be int, Scalar or Expr, input type of l1_w: {}".format(type(depthwise_conv_api.l1_w)))
        check_scalar_dtype(depthwise_conv_api.l1_w, "l1_w should be a scalar of int/uint")
        # check feature_offset
        TikCheckUtil.check_type_match(
            depthwise_conv_api.feature_offset, (int, Scalar, Expr),
            "feature_offset should be int, Scalar or Expr, input type of "
            "feature_offset: {}".format(type(depthwise_conv_api.feature_offset)))
        check_scalar_dtype(depthwise_conv_api.feature_offset, "feature_offset should be a scalar of int/uint")
        # check params range
        check_depthwise_conv_params(depthwise_conv_api.src_fm, depthwise_conv_api.pad_mode, depthwise_conv_api.l1_h,
                                    depthwise_conv_api.l1_w, depthwise_conv_api.feature_offset)
        # check l1_w/pad_mode
        check_depthwise_conv_l1_w(depthwise_conv_api.pad_mode, depthwise_conv_api.l1_w)
        # check src_fm dst_fm overflow
        _check_dc_fm_overflow(depthwise_conv_api.l1_h, depthwise_conv_api.l1_w, depthwise_conv_api.src_fm,
                              depthwise_conv_api.pad_mode, depthwise_conv_api.dst_fm)
        # check src_ft overflow
        _check_dc_ft_overflow(depthwise_conv_api.src_filter)
        # cal extent
        # do padding
        if depthwise_conv_api.pad_value is not None:
            TikCheckUtil.check_type_match(
                depthwise_conv_api.pad_value, (int, float),
                "pad_value should be python int or float, input type: {}".format(type(depthwise_conv_api.pad_value)))
            check_pad_value(depthwise_conv_api.src_fm, depthwise_conv_api.pad_value)
        if depthwise_conv_api.weight_offset is not None:
            check_weight_offset(depthwise_conv_api.weight_offset, "depthwise_conv", "weight_offset")
            # check overflow
            _check_dc_weight_offset_overflow(depthwise_conv_api.weight_offset)

    @depthwise_conv_decorator
    def depthwise_conv_gen_code(self, depthwise_conv_api):
        """
        depthwise conv gen code

        Parameters
        ----------
        depthwise_conv_api: named tuple of winograd_conv

        Returns
        -------
        None
        """
        if depthwise_conv_api.pad_value is not None:
            do_load3d_padding(self, depthwise_conv_api.src_fm, depthwise_conv_api.pad_value)

        dst_fm_extent, src_fm_extent, src_ft_extent = _cal_extent_depthwise_conv(
            depthwise_conv_api.dst_fm, depthwise_conv_api.src_fm, depthwise_conv_api.pad_mode,
            depthwise_conv_api.l1_h, depthwise_conv_api.l1_w)

        if depthwise_conv_api.weight_offset is not None:
            weight_offset_en = 1

            # cal extent, actual 16B
            weight_offset_extent = _ELE_PER_FRACTAL_EDGE * DTYPE_SIZE.get(depthwise_conv_api.src_filter.dtype)
            args = [depthwise_conv_api.l1_w, depthwise_conv_api.l1_h, depthwise_conv_api.feature_offset,
                    depthwise_conv_api.weight_offset.access_ptr("r", extent=weight_offset_extent),
                    weight_offset_en, depthwise_conv_api.pad_mode, int(depthwise_conv_api.store_high_half)]
        else:
            weight_offset_en = 0
            args = [depthwise_conv_api.l1_w, depthwise_conv_api.l1_h, depthwise_conv_api.feature_offset, 0,
                    weight_offset_en, depthwise_conv_api.pad_mode, int(depthwise_conv_api.store_high_half)]
        with self.new_scope():
            # for depthwise_conv includes PIPE_MTE1 and PIPE_M, so emit
            # nop_instr for injecting pipe, temporary plan
            nop_instr = tvm.call_extern(
                depthwise_conv_api.src_fm.dtype, "dummy_intrin",
                depthwise_conv_api.src_fm.access_ptr("rw", extent=src_fm_extent),
                depthwise_conv_api.src_filter.access_ptr("rw", extent=src_ft_extent), )
            self.scope_attr(tvm.thread_axis("cce"), "coproc_scope", PIPE_MTE1)
            self.emit(nop_instr)
        with self.new_scope():
            instr = tvm.call_extern(
                depthwise_conv_api.dst_fm.dtype, "depthwise_conv",
                depthwise_conv_api.dst_fm.access_ptr("w", extent=dst_fm_extent),
                depthwise_conv_api.src_fm.access_ptr("r", extent=src_fm_extent),
                depthwise_conv_api.src_filter.access_ptr("r", extent=src_ft_extent),
                *type_convert(args))
            self.scope_attr(tvm.thread_axis("cce"), "coproc_scope", PIPE_M)
            self.emit(instr)

    @source_info_decorator()
    def winograd_conv(self, dst, src_fm, src_filter, matrix_m, matrix_k, matrix_n, is_bias):
        """
        The winograd matrix multiplication is performed on the winograd left and right matrices,
        and then the winograd inverse transform is performed, and the result tensor is output.

        Parameters
        ----------
        dst: dst
        src_fm: src left matrix
        src_filter: src right matrix
        matrix_m: The size of the left matrix in the M direction after expansion
        matrix_k: The size of the left matrix in the M direction after expansion
        matrix_n: N-direction size after right matrix expansion
        is_bias: Indicates whether to accumulate the previous winograd_conv calculation result.

        Returns
        -------
        no return
        """
        winograd_conv_api = TikCubeApi.winograd_conv_api(dst, src_fm, src_filter, matrix_m, matrix_k, matrix_n, is_bias)
        self.winograd_conv_check_params(winograd_conv_api)
        self.winograd_conv_gen_code(winograd_conv_api)

    @winograd_conv_decorator
    def winograd_conv_gen_code(self, winograd_conv_api):
        """
        winograd_conv gen code

        Parameters
        ----------
        winograd_conv_api: named tuple of winograd_conv

        Returns
        -------
        None
        """
        src_fm_extent = ceil_div(winograd_conv_api.matrix_m, 16) * 16 * \
                        winograd_conv_api.matrix_k * 16 * DTYPE_SIZE.get(winograd_conv_api.src_fm.dtype)
        src_fm_extent = Expr(src_fm_extent).get()
        src_filter_extent_params = winograd_conv_api.matrix_k * 16 * DTYPE_SIZE.get(winograd_conv_api.src_filter.dtype)
        src_filter_extent = ceil_div(winograd_conv_api.matrix_n, 16) * 16 * src_filter_extent_params
        src_filter_extent = Expr(src_filter_extent).get()
        dst_extent_params = ceil_div(winograd_conv_api.matrix_m, 16) * 16 * 4 * DTYPE_SIZE[winograd_conv_api.dst.dtype]
        dst_extent = ceil_div(winograd_conv_api.matrix_n, 16) * 16 * dst_extent_params
        dst_extent = Expr(dst_extent).get()
        if winograd_conv_api.is_bias == 0:
            # 0 bias disable
            bias_bit = 0
            dst_acc = "rw"
        else:
            # 1 bias enable
            bias_bit = 1
            dst_acc = "w"
        params = [winograd_conv_api.matrix_m, winograd_conv_api.matrix_k, winograd_conv_api.matrix_n, 0, 0, 1, bias_bit]
        args = type_convert(params)
        with self.new_scope():
            self.scope_attr(tvm.thread_axis("cce"), "coproc_scope", PIPE_M)
            instr = tvm.call_extern(winograd_conv_api.dst.dtype, "winograd_conv",
                                    winograd_conv_api.dst.access_ptr(dst_acc, extent=dst_extent),
                                    winograd_conv_api.src_fm.access_ptr("r", extent=src_fm_extent),
                                    winograd_conv_api.src_filter.access_ptr("r", extent=src_filter_extent), *args)
            # 1 ir is call_extern
            self.emit(instr)
