#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_vecotr_api.py
DESC:     provide vector instructions
CREATED:  2019-08-12 18:53:42
MODIFIED: 2020-12-7 19:17:00
"""
from tbe import tvm
from tbe.tvm.tir.stmt import AttrStmt

from tbe.common.platform import scope_gm
from tbe.common.platform import scope_ubuf
from tbe.common.platform import intrinsic_check_support
from tbe.common.buildcfg import build_config
from tbe.tik.api.tik_tensor import Tensor
from tbe.tik.api.tik_scalar import Scalar
from tbe.tik.common.high_preci_common_util import HighPreciCommonUtil
from tbe.tik.common.common_util import check_address_align
from tbe.tik.common.common_util import vec_template_align
from tbe.tik.common.tik_get_soc_name import is_compatible_mode
from tbe.tik.common.common_nametuple_util import VaddReluParams
from tbe.tik.debug.decorators import high_level_api_debug_decorator
from tbe.tik.tik_lib.tik_expr import Expr
from tbe.tik.tik_lib.tik_api_constants import DTYPE_MAP
from tbe.tik.tik_lib.tik_api_util import set_ctrl_counter_mask
from tbe.tik.tik_lib.tik_api_util import reset_ctrl_value
from tbe.tik.tik_lib.tik_params import gen_api_check_statement
from tbe.tik.tik_lib.tik_params import ONE_BLK_SIZE
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.tik_lib.tik_vector_api.tik_vector_multi_api_ import MultiOp

_ROUND_TO_NEAREST_ENABLE = 0
_MIN_DST_BLK_STRIDE = 1
_BLOCK_LEN = 8


def _check_vector_scalar_tensor_dtype(scalar, src, dst, print_name, name):
    if isinstance(scalar, Scalar):
        TikCheckUtil.check_equality(scalar.dtype, src.dtype,
                                    "Instruction %s's src's dtype should be equal to scalar's dtype" % print_name)
        dtype_str = DTYPE_MAP[dst.dtype] + DTYPE_MAP[src.dtype] + DTYPE_MAP[scalar.dtype]
        dtype_str_err = "src " + src.dtype + " scalar " + scalar.dtype + " dst " + dst.dtype
    else:
        dtype_str = DTYPE_MAP[dst.dtype] + DTYPE_MAP[src.dtype] * 2
        dtype_str_err = "src " + src.dtype + " dst " + dst.dtype
    if name == "vaxpy":
        TikCheckUtil.check_equality(intrinsic_check_support("Intrinsic_" + name, dtype_str), True,
                                    gen_api_check_statement(dtype_str_err, print_name))
    else:
        TikCheckUtil.check_equality(dst.dtype, src.dtype,
                                    "Instruction %s's src's dtype should be equal to dst's dtype" % print_name)
        TikCheckUtil.check_equality(intrinsic_check_support("Intrinsic_" + name, dst.dtype), True,
                                    gen_api_check_statement(dst.dtype, name))


def _calculate_extent(repeat_times, rep_stride, block_count, blk_stride):
    """
    calculate extent

    Parameters
    ----------
    repeat_times : Repeated iterations times
    rep_stride : stride of operator in the same block between repeats
    block_count: block number in one repeat
    blk_stride : stride of operator between different block

    Returns
    -------
    extent
    """
    extent = Expr(((repeat_times - 1) * rep_stride + (block_count - 1) * blk_stride + 1) * ONE_BLK_SIZE)
    return extent.get()


def _check_duplicate_tensor_name(tensors):
    m = set()
    for t in tensors:
        if t is None:
            continue
        if t.name in m:
            raise ValueError("duplicate tensor name %s" % t.name)
        m.add(t.name)


def _is_imm(expr):
    """
    check if input expr is one of python.int, python.float,
    tvm.tir.IntImm, tvm.tir.FloatImm
    """
    if isinstance(expr, (int, float)):
        return True
    expr = tvm.tir.Simplify(expr)
    return isinstance(expr, (tvm.tir.IntImm, tvm.tir.FloatImm, int, float))


def _get_tiling_key(config_map):
    """
    get tiling_key from config_map
    """
    tiling_key = None
    if config_map.get("tiling_key") is not None:
        tiling_key = config_map["tiling_key"].get()
        if not isinstance(tiling_key, tvm.expr.Load):
            raise TypeError("tiling_key should be a Scalar.\n")
        del config_map["tiling_key"]
    return tiling_key


def _generate_input_strides(input_tensor, var_idx, let_var2value, dynamic_stride_var):
    """
    generate strides for input tensors.
    Convert to var if Scalar Expr exists
    """
    strides = [1, ]
    for i in reversed(input_tensor.original_shape):
        if isinstance(i, Expr):
            strides.append(tvm.tir.Simplify(i.get()) * strides[-1])
        else:
            strides.append(i * strides[-1])
    strides = strides[:-1][::-1]
    for counter, stride in enumerate(strides):
        if not _is_imm(stride):
            var_idx = var_idx + 1
            new_var = tvm.var("stride_%s" % var_idx, stride.dtype)
            let_var2value[new_var.name] = [stride, new_var]
            dynamic_stride_var.append(new_var)
            strides[counter] = new_var
    return [strides, var_idx, let_var2value, dynamic_stride_var]


def _generate_input_shape(input_tensor, var_idx, let_var2value, dynamic_shape_var):
    """
    generate shape for input tensors.
    Convert to var if Scalar Expr exists
    """
    shape_new = []
    for i in input_tensor.shape:
        if isinstance(i, Expr):
            i = tvm.tir.Simplify(i.get())
        if not _is_imm(i):
            var_idx = var_idx + 1
            new_var = tvm.var("shape_%s" % var_idx, i.dtype)
            if let_var2value.get(new_var.name) is None:
                let_var2value[new_var.name] = [i, new_var]
            else:
                raise RuntimeError(
                    "duplicate %s in input_dynamic_scalar.\n" % new_var.name)
            dynamic_shape_var.append(new_var)
            shape_new.append(new_var)
        else:
            shape_new.append(i)
    return [shape_new, var_idx, let_var2value, dynamic_shape_var]


def _generate_input_offset(input_tensor, var_idx, let_var2value, dynamic_offset_var):
    """
    generate shape for input tensors.
    Convert to var if Scalar Expr exists
    """
    if isinstance(input_tensor.offset, Expr):
        offset_new = tvm.tir.Simplify(input_tensor.offset.get())
    else:
        offset_new = input_tensor.offset
    if not _is_imm(offset_new):
        var_idx = var_idx + 1
        new_var = tvm.var("offset_%s" % var_idx, input_tensor.offset.dtype)
        let_var2value[new_var.name] = [offset_new, new_var]
        dynamic_offset_var.append(new_var)
        offset_new = new_var
    return [offset_new, var_idx, let_var2value, dynamic_offset_var]


def _generate_output_strides(output_tensor):
    """
    generate strides for output tensors.
    Convert to var if Scalar Expr exists
    """
    strides = [1, ]
    for i in reversed(output_tensor.original_shape):
        if isinstance(i, Expr):
            strides.append(i.get() * strides[-1])
        else:
            strides.append(i * strides[-1])
    strides = strides[:-1][::-1]
    return strides


def _generate_output_shape(output_tensor):
    """
    generate shape for output tensors.
    Convert to var if Scalar Expr exists
    """
    shape_new = []
    for i in output_tensor.shape:
        if isinstance(i, Expr):
            shape_new.append(i.get())
        else:
            shape_new.append(i)
    return shape_new


def _generate_output_offset(output_tensor):
    """
    generate offset for output tensors.
    Convert to var if Scalar Expr exists
    """
    if isinstance(output_tensor.offset, Expr):
        offset_new = output_tensor.offset.get()
    else:
        offset_new = output_tensor.offset
    return offset_new


def _get_map(config_map):
    placeholder_config_map = {}
    build_config_map = {}
    if config_map is None:
        return build_config_map, placeholder_config_map

    if not isinstance(config_map, dict):
        raise TypeError("config_map should be a dict.\n")
    for key in config_map:
        if key == "placeholder_attr":
            if not isinstance(config_map[key], dict):
                raise TypeError("config_map['placeholder_attr'] should be a dict.\n")
            for p_key in config_map[key]:
                placeholder_config_map[p_key] = config_map[key][p_key]
        else:
            build_config_map[key] = config_map[key]
    return build_config_map, placeholder_config_map


class TikVectorApi(HighPreciCommonUtil):
    """
    Vector, Serialization, Spr Operation Api
    """

    # because vecotr gather instruction are here
    def __init__(self):
        super().__init__()
        self.tik_tensor2reuse_count = {}
        self.sync_num = 0

    @staticmethod
    def _check_dtype_str_vsel(dst, src0, src1, name):
        """
        check dtype of instruction vsel

        Parameters
        ----------
        dst : destination operator
        src0 : source operation 1
        src1: source operation 2
        Returns
        -------
        None
        """
        TikCheckUtil.check_equality(dst.dtype, src0.dtype,
                                    "Instruction %s's src0's "
                                    "dtype should be equal "
                                    "to dst's dtype" % name)
        if isinstance(src1, (Scalar, Tensor)):
            TikCheckUtil.check_equality(dst.dtype, src1.dtype,
                                        "Instruction %s's src1's "
                                        "dtype should be equal "
                                        "to dst's dtype" % name)
        TikCheckUtil.check_equality(intrinsic_check_support("Intrinsic_vsel",
                                                            dst.dtype), True,
                                    gen_api_check_statement(
                                        dst.dtype, name))

    def set_sync_num(self, sch):
        """
        in tik tbe hybrid compute
        workspace can be reused between different tbe compute cells
        so we choose the max worksapce number as total worspace number
        """
        if isinstance(sch, list):  # get a schedule list from RL search
            for i in sch:
                self.sync_num = max(self.sync_num, i.get_block_sync_size())
        else:
            self.sync_num = max(self.sync_num, sch.get_block_sync_size())

    def call_module(self, function, input_tensors=None, output_tensors=None, input_params=None, config_map=None):
        """
        generate stmt from schedule
        Parameters
        ----------
        function: functions to generate stmt
        input_tensors: input tensors created by tik
        output_tensors: output tensors created by tik
        input_params: extern variable from tik
        config_map: TBE build config

        Returns
        -------
        no return
        """
        cfg = build_config()
        tiling_key = None

        _check_duplicate_tensor_name(input_tensors)

        build_config_map, placeholder_config_map = _get_map(config_map)

        if build_config_map:
            tiling_key = _get_tiling_key(build_config_map)
            cfg = build_config(**build_config_map)

        # generate map for hybrid dynamic_shape tik.Scalar to tvm.var
        let_var2value = {}
        dynamic_shape_var, dynamic_stride_var, dynamic_offset_var = [], [], []

        # get buffers from input tik tensor
        input_placeholders, input_buffers = [], []

        inc = 0
        var_idx = 1

        for t in input_tensors:
            if t is None:
                input_placeholders.append(None)
                input_buffers.append(None)
                continue

            # add input_tensor strides
            strides, var_idx, let_var2value, dynamic_stride_var = \
                _generate_input_strides(t, var_idx, let_var2value, dynamic_stride_var)

            # add input_tensor shapes
            shape_new, var_idx, let_var2value, dynamic_shape_var = \
                _generate_input_shape(t, var_idx, let_var2value, dynamic_shape_var)

            # add input_tensor offset
            offset_new, var_idx, let_var2value, dynamic_offset_var = \
                _generate_input_offset(t, var_idx, let_var2value, dynamic_offset_var)

            if placeholder_config_map:
                input_placeholder = tvm.placeholder(
                    tuple(shape_new), t.dtype, "input%d" % inc,
                    attrs={"format": placeholder_config_map.get(t.name).get("format"),
                           "ori_shape": tuple(placeholder_config_map.get(t.name).get("ori_shape"))})
            else:
                input_placeholder = tvm.placeholder(tuple(shape_new), t.dtype, "input%d" % inc)

            input_buffer = tvm.decl_buffer(tuple(shape_new), t.dtype,
                                           input_placeholder.name,
                                           strides=tuple(strides),
                                           scope=t.scope,
                                           elem_offset=offset_new)
            input_placeholders.append(input_placeholder)
            input_buffers.append(input_buffer)
            inc += 1
        # generate stmt from input functions
        outputs = function(input_placeholders, input_params)
        if len(outputs) == 2:
            output_compute_nodes, sch = outputs
            tiling_key_list = None
        elif len(outputs) == 3:
            output_compute_nodes, sch, tiling_key_list = outputs
        else:
            raise ValueError("function in call_module() only expected 2 or 3 returns, got %s" % len(outputs))
        self.set_sync_num(sch)

        # if outputs is none, try to get output from sch
        if not output_compute_nodes:
            for output in sch.outputs:
                output_compute_nodes.append(output)
        # create buffers for hybrid outputs
        output_buffers = []
        for p, t in zip(output_tensors, output_compute_nodes):
            # add output_tensor strides
            strides = _generate_output_strides(p)

            # add output_tensor shapes
            shape_new = _generate_output_shape(p)

            # add output_tensor offset
            offset_new = _generate_output_offset(p)

            output_buffer = tvm.decl_buffer(tuple(shape_new), p.dtype, t.name,
                                            strides=tuple(strides),
                                            scope=p.scope,
                                            elem_offset=offset_new)
            output_buffers.append(output_buffer)

        tik_tensors = input_tensors + output_tensors
        dsl_tensors = input_placeholders + output_compute_nodes
        dsl_buffers = input_buffers + output_buffers
        # add tiling_key logic for RL search
        stmt = self.__generate_tiling_key_logic((sch, tiling_key, tiling_key_list, tik_tensors,
                                                 dsl_tensors, dsl_buffers, cfg))
        # generate let command when dynamic shape hybrid programming
        self.__generate_let_command((dynamic_shape_var, dynamic_stride_var,
                                     dynamic_offset_var, let_var2value,
                                     stmt, output_compute_nodes))
        return tiling_key_list

    def vaddrelu(self, mask, dst, src0, src1, repeat_times, dst_blk_stride, src0_blk_stride, src1_blk_stride,
                 dst_rep_stride, src0_rep_stride, src1_rep_stride, stride_unit=0):
        """
        Do addrelu by single element.

        Parameters
        ----------
        mask : Effective operation on element, divided into two model: Continuous and bit by bit.
        dst : destination operator
        src0 : source operation
        src1 : source operation
        repeat_times : Repeated iterations times
        dst_blk_stride : offset of dst operator between different block
        src0_blk_stride : offset of src operator between different block
        src1_blk_stride : offset of src operator between different block
        dst_rep_stride : offset of dst operator in the same block between
        src0_rep_stride : offset of src operator in the same block between
        src1_rep_stride : offset of src operator in the same block between
        stride_unit : address and offset unit both affect it. default = 0

        Returns
        -------
        None
        """
        vadd_relu_params_ins = VaddReluParams("vaddrelu", mask, dst, src0, src1, repeat_times, dst_blk_stride,
                                              src0_blk_stride, src1_blk_stride, dst_rep_stride,
                                              src0_rep_stride, src1_rep_stride, stride_unit)
        vec_add_relu_obj = MultiOp(self, vadd_relu_params_ins)
        vec_add_relu_obj.run_all()

    def vsubrelu(self, mask, dst, src0, src1, repeat_times, dst_blk_stride, src0_blk_stride, src1_blk_stride,
                 dst_rep_stride, src0_rep_stride, src1_rep_stride, stride_unit=0):
        """
        Do subrelu by single element.

        Parameters
        ----------
        mask : Effective operation on element, divided into two model: Continuous and bit by bit.
        dst : destination operator
        src0 : source operation
        src1 : source operation
        repeat_times : Repeated iterations times
        dst_blk_stride : offset of dst operator between different block
        src0_blk_stride : offset of src operator between different block
        src1_blk_stride : offset of src operator between different block
        dst_rep_stride : offset of dst operator in the same block between
        src0_rep_stride : offset of src operator in the same block between
        src1_rep_stride : offset of src operator in the same block between
        stride_unit : address and offset unit both affect it. default = 0

        Returns
        -------
        None
        """
        vsub_relu_params_ins = VaddReluParams("vsubrelu", mask, dst, src0, src1, repeat_times, dst_blk_stride,
                                              src0_blk_stride, src1_blk_stride, dst_rep_stride,
                                              src0_rep_stride, src1_rep_stride, stride_unit)
        vec_sub_relu_obj = MultiOp(self, vsub_relu_params_ins)
        vec_sub_relu_obj.run_all()

    def apply_for_new_alloc(self, params_list, name='tmp_buf', init_value=None, buffer_storage_id=None):
        """
        alloc buffer

        Parameters
        ----------
        params_list: dtype, shape, scope
        -            dtype: tensor's dtype
        -            shape: tensor's shape
        -            scope: gm or ubuf
        name : tensor's name
        init_value : init value
        buffer_storage_id : tensor index for reuse/no_reuse

        Returns
        -------
        buffer
        """
        dtype, shape, scope = params_list
        buf_var = self.allocate((dtype, shape, name), scope=scope,
                                init_value=init_value, buffer_storage_id=buffer_storage_id)
        tmp_buffer = tvm.decl_buffer(shape, buf_var.dtype, name=name, scope=scope, data=buf_var)
        return tmp_buffer

    @high_level_api_debug_decorator
    def vec_sel_(self, vec_sel_obj):
        """
        vec_sel instr for inner
        """
        instr_name = vec_sel_obj.instr_name
        default_blk_stride = 1
        if instr_name is None:
            instr_name = "vec_sel"
        # check mode
        TikCheckUtil.check_type_match(vec_sel_obj.mode, int, "mode should be int.")
        # when mode is 1 or 2, sel type is tensor
        if vec_sel_obj.mode in (1, 2):
            TikCheckUtil.check_type_match(vec_sel_obj.sel, Tensor, "sel should be tensor")
        TikCheckUtil.check_equality(vec_sel_obj.sel.scope, scope_ubuf, "sel's scope must be UB")
        # check UB address 32B align
        sel_align = vec_template_align(vec_sel_obj.sel.dtype)
        check_address_align((vec_sel_obj.sel,), ("sel",), sel_align)
        TikCheckUtil.check_var_in_list(
            vec_sel_obj.sel.dtype, ["uint8", "uint16", "uint32", "uint64"],
            "sel dtype should be uint8, uint16, uint32 or uint64, input: %s" % vec_sel_obj.sel.dtype)
        if (TikSocManager.is_nano_soc() and is_compatible_mode()) or vec_sel_obj.mode != 0:
            sel = vec_sel_obj.sel
        else:
            # change sel to cmpmask
            sel = self.mov_tensor_to_cmpmask(vec_sel_obj.sel)

        return self.vsel(
            vec_sel_obj.mask, vec_sel_obj.mode, vec_sel_obj.dst, sel, vec_sel_obj.src0, vec_sel_obj.src1,
            vec_sel_obj.repeat_times, default_blk_stride, default_blk_stride, default_blk_stride,
            vec_sel_obj.dst_rep_stride, vec_sel_obj.src0_rep_stride, vec_sel_obj.src1_rep_stride,
            instr_name, vec_sel_obj.mask_o)

    def __create_stmt_for_dsl_hybrid(self, params_tuple):
        """
        form body and inject reuse info from schedule
        """
        sch, tik_tensors, dsl_tensors, dsl_buffers, config = params_tuple
        with config:
            sch = sch.normalize()
            bounds = tvm.te.schedule.InferBound(sch)
            stmt = tvm.te.schedule.ScheduleOps(sch, bounds)
        ret = tvm.tir.transform.InjectBufferIndex(sch, stmt, Tensor.BUFFER_STORAGE_COUNT)
        stmt = ret[0]
        Tensor.BUFFER_STORAGE_COUNT = ret[1].value
        # create tik bind tensor pragma
        local_tik2dsl = {}
        for p, t, b in zip(tik_tensors, dsl_tensors, dsl_buffers):
            if p is None:
                continue
            if p.buffer not in local_tik2dsl:
                local_tik2dsl[p.buffer] = []
                local_tik2dsl[p.buffer].append((t, b))
            else:
                local_tik2dsl[p.buffer].append((t, b))

            stmt = AttrStmt([p.buffer, t, b], 'tik_bind_tensor', 1, stmt)
        # add buffer reuse index from tik tensor to dsl tensor
        for p in local_tik2dsl:
            # if tik tensor scope is global, skip create reuse relations
            # codegen will create relation before gm scope tensors
            if p.scope() == scope_gm:
                continue
            # if tik tensor scope is not global,
            # create buffer index and reuse relation for tik tensors in IR

            # create buffer index for tik tensors
            if p not in self.tik_tensor2reuse_count:
                stmt = AttrStmt(p.data, "pragma_buffer_index",
                                tvm.call_extern("int64", "buffer_index", Tensor.BUFFER_STORAGE_COUNT), stmt)
                self.tik_tensor2reuse_count[p] = Tensor.BUFFER_STORAGE_COUNT
                Tensor.BUFFER_STORAGE_COUNT += 1
            # create buffer index for dsl tensors
            tik_reuse_count = self.tik_tensor2reuse_count.get(p)
            dsl_tensors = local_tik2dsl.get(p)
            for dsl_tensor in dsl_tensors:
                stmt = AttrStmt(dsl_tensor[1].data, "pragma_buffer_index",
                                tvm.call_extern("int64", "buffer_index", Tensor.BUFFER_STORAGE_COUNT), stmt)

                # create buffer reuse relation
                stmt = AttrStmt(None, "pragma_buffer_reuse",
                                tvm.call_extern("int64", "buffer_reuse", *[tik_reuse_count,
                                                                           Tensor.BUFFER_STORAGE_COUNT]), stmt)
                Tensor.BUFFER_STORAGE_COUNT += 1
        return stmt

    def __generate_tiling_key_logic(self, params_tuple):
        """
        get a schedule list from RL search.
        Length of sch and length of tiling_key_list must be same.
        So we can create IR:
               if tiling_key equals to tiling_key_list[i]
                   do sch[i]
        :param tiling_key: A Var from tik
        :param sch:              List of Schedule from RL Search
        :param tiling_key_list:  List keys from RL Search
        """
        sch, tiling_key, tiling_key_list, tik_tensors, dsl_tensors, dsl_buffers, cfg = params_tuple
        if isinstance(sch, list):
            if (tiling_key is not None) and (tiling_key_list is not None):
                if len(sch) != len(tiling_key_list):
                    raise RuntimeError("schedule_list size is not equal to tiling_key_list.")

                stmt = self.__get_stmt_for_tiling(params_tuple)
            else:
                # create IR
                stmt = self.__create_stmt_for_dsl_hybrid((sch[0], tik_tensors, dsl_tensors, dsl_buffers, cfg))
        else:
            # create IR
            stmt = self.__create_stmt_for_dsl_hybrid((sch, tik_tensors, dsl_tensors, dsl_buffers, cfg))
        return stmt

    def __get_stmt_for_tiling(self, params_tuple):
        """
        get stmt for tiling
        Parameters
        ----------
        params_tuple :  sch, tiling_key, tiling_key_list, tik_tensors, dsl_tensors, dsl_buffers, cfg

        Returns
        -------
        stmt
        """
        stmt = None
        sch, tiling_key, tiling_key_list, tik_tensors, dsl_tensors, dsl_buffers, cfg = params_tuple
        for counter, value in enumerate(tiling_key_list):
            # create IR
            current_stmt = self.__create_stmt_for_dsl_hybrid((sch[counter], tik_tensors,
                                                              dsl_tensors, dsl_buffers, cfg))
            current_stmt = tvm.tir.IfThenElse(tiling_key == value, current_stmt, None)
            if counter == 0:
                stmt = current_stmt
            else:
                stmt = tvm.tir.SeqStmt([stmt, current_stmt])

        return stmt

    def __generate_let_command(self, params_tuple):
        """
        Create let dynamic_shape_var for scalar from tik.
        Use Scalar to represent dynamic shape in tik.
        Use Var to represent dynamic shape in tbe.
        Create Let Var = Scalar Expr to make connection between
        tbe and tik hybrid dynamic shape.
        """
        dynamic_shape_var, dynamic_stride_var, dynamic_offset_var, let_var2value, stmt, output_compute_nodes = \
            params_tuple
        if dynamic_shape_var is not None:
            for new_var in dynamic_shape_var:
                stmt = tvm.tir.LetStmt(let_var2value[new_var.name][1], let_var2value[new_var.name][0], stmt)
        if dynamic_stride_var is not None:
            for new_var in dynamic_stride_var:
                stmt = tvm.tir.LetStmt(let_var2value[new_var.name][1], let_var2value[new_var.name][0], stmt)
        if dynamic_offset_var is not None:
            for new_var in dynamic_offset_var:
                stmt = tvm.tir.LetStmt(let_var2value[new_var.name][1], let_var2value[new_var.name][0], stmt)
        # create signal for hybrid IR
        stmt = AttrStmt(output_compute_nodes, 'tik_hybrid_stmt', 1, stmt)
        self.emit(stmt)

    def _set_ctrl_counter_mask_counter(self, mask_mode):
        """
        _set_ctrl_counter_mask_counter
        Parameters
        ----------
        mask_mode: if counter mode

        Returns
        -------
        orig_ctrl
        """
        if mask_mode == "counter" and (not TikSocManager.is_v300_610l_soc()):
            orig_ctrl = set_ctrl_counter_mask(self)
        else:
            orig_ctrl = ""
        return orig_ctrl

    def _reset_ctrl_counter_mask_counter(self, mask_mode, orig_ctrl):
        """
        _reset_ctrl_counter_mask_counter
        Parameters
        ----------
        mask_mode: if counter mode

        Returns
        -------
        orig_ctrl
        """
        if (mask_mode == "counter") and (not TikSocManager.is_v300_610l_soc()):
            reset_ctrl_value(self, orig_ctrl)
