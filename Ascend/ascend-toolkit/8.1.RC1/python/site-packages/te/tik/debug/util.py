#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     util.py
DESC:     debug util
CREATED:  2019-7-04 20:12:13
MODIFIED: 2019-7-24 10:54:23
"""
from enum import IntEnum
import re
import numpy as np
from tbe import tvm
from tbe.tvm.tir import FloatImm
from tbe.tvm.tir import IntImm
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.debug_api import is_large_uint
from tbe.tik.tik_lib.tik_expr import is_basic_expr
from tbe.tik.tik_lib.tik_params import ONE_BYTE_BIT_LEN
from tbe.tik.tik_lib.tik_params import MAX_INT64_VALUE
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_check_util import print_error_msg

VEC_DATA_TYPE_ENCODING = {
    'uint8': 0b000, 'uint16': 0b001,
    'uint32': 0b010, 'int8': 0b011,
    'int32': 0b100, 'float16': 0b101,
    'fmix': 0b110, 'float32': 0b111,
    'int16': 0b001
}
_MIN_MASK = 1
_MAX_MASK_N = 128
_MAX_MASK_64 = 64
_MASK_VALUE_ZERO = 0
_MAX_MASK0_VALUE = 2**64 - 1
_MASK1_SHIFT_POS = 64
_MAX_COUNTER_MASK = 2**32 - 1
_BIT_LEN_16 = 16
_BIT_LEN_32 = 32


def tvm_value_to_int(value):
    """
    convert value to int

    Parameters
    ----------
    value : to be converted variable

    Returns
    -------
    value in int type
    """
    if isinstance(value, (tvm.tir.IntImm, tvm.tir.FloatImm, tvm.tir.StringImm)):
        return value.value
    if isinstance(value, (tvm.ir.container.Array, list, tuple)):
        tmp = []
        for tmp_value in value:
            tmp.append(tvm_value_to_int(tmp_value))
        return tmp
    return TikCheckUtil.raise_error("convert value is illegal")


def get_flatten_idx(tensor, context):
    """
    compute the index

    Parameters
    ----------
    tensor : to be computed
    context : context

    Returns
    -------
    the result
    """
    if id(tensor) in context.buffer2static_parameters:
        return context.buffer2static_parameters[id(tensor)]["static_data"]
    return context.evaluate_expr(tensor.offset)


def get_np_dtype_by_name(typename):
    """
    get the type of numpy by name

    Parameters
    ----------
    typename : numpy type name

    Returns
    -------
    np: numpy
    """
    return getattr(np, typename)


def cvt_float_to_uint(dtype, value):
    """
    convert float to uint
    """
    if dtype == "bfloat16":
        import tensorflow as tf
        np_dt = tf.bfloat16.as_numpy_dtype
        dtype = tf.bfloat16.as_numpy_dtype
    else:
        np_dt = getattr(np, dtype)
    d_t = np.dtype(dtype)
    bit_size = d_t.itemsize*ONE_BYTE_BIT_LEN
    target_np = getattr(np, 'uint' + str(bit_size))
    return np_dt(value).view(target_np).item()


_TYPE_REGEX = re.compile('([a-z]*)([0-9]*)')


def get_dtype_bit_width(dtype):
    """
    get the dtype's bit width

    Returns
    -------
    bit_width: dtype bit width
    """
    _, bit_width = _TYPE_REGEX.search(dtype).groups()
    return bit_width


def reinterpret_type(src_type, dst_type, value):
    """
    convert value from src_type to dst_type
    """
    if src_type == dst_type:
        return value
    _, src_bit_len = _TYPE_REGEX.search(src_type).groups()
    dst_type_name, _ = _TYPE_REGEX.search(dst_type).groups()
    tmp_type_name = dst_type_name + src_bit_len
    # reinterpret to same size than cast to type
    tmp_np_type = getattr(np, tmp_type_name)
    dst_np_type = getattr(np, dst_type)
    src_np_type = getattr(np, src_type)
    return src_np_type(value).view(tmp_np_type).astype(dst_np_type).item()


def get_dtype_size(dtype):
    """
    get the dtype's size

    Returns
    -------
    dtype size
    """
    return DTYPE_SIZE[dtype]


def copy_tensor_to_model(context, env, tensor, align=512, access_mode='r'):
    """
    copy tensor to pv model

    Parameters
    ----------
    context : class Context
    env: temp environment
    tensor: tik tensor
    align: align bit len
    check_align: bool, is check align
    require_xt: bool, is require xt reg
    access_mode: buffer read or write mode
    offset: tensor offset

    Returns
    -------
    info of buffer
    """
    return env.copy_tensor_to_model(context, tensor, align, access_mode)


def copy_tensor_to_model_get_addr(context, env, tensor, align, access_mode):
    """
    copy tensor to model to get addr
    """
    env.require_xt = False
    _, addr, _, _ = env.copy_tensor_to_model(context, tensor, align, access_mode)
    dtype_size_ = get_dtype_size(tensor.dtype)
    flatten_idx = get_flatten_idx(tensor, context)
    addr += flatten_idx*dtype_size_

    # restoring require_xt default values True
    env.require_xt = True
    return addr


def copy_tensor_to_model_from_addr(context, env, tensor, data_size, access_mode='r'):
    """
    copy tensoraddrlist to pv model

    Parameters
    ----------
    context : class Context
    env: temp environment
    tensor: tik tensoraddrlist
    data_size: copy data size
    dst_dtype: dst tensor dtype
    align: align bit len
    require_xt: bool, is require xt reg
    access_mode: buffer read or write mode

    Returns
    -------
    info of buffer
    """
    return env.copy_tensor_to_model_from_addr(context, tensor, data_size, access_mode)


def model_with_env(func, env, *args):
    """
    model step with env config

    Parameters
    ----------
    func : function in context.model
    env: temp environment
    args: args of func

    Returns
    -------
    return value of func
    """
    if env.sub_core_id == 0:
        return func(*args, 0)
    else:
        return func(*args)


def check_mask_range(mask_n, tensor_bit_len):
    """
    check mask range

    Parameters
    ----------
    mask_n: mask value
    tensor_bit_len: bit len of tensor

    Returns
    -------
    None
    """
    if tensor_bit_len == _BIT_LEN_16:
        TikCheckUtil.check_in_range_by_dtype(
            mask_n, msg="mask value should be in the range of [%d, %d] for b16 "
            "tensor, input mask: %s" % (_MIN_MASK, _MAX_MASK_N, mask_n), var_range=[_MIN_MASK, _MAX_MASK_N])
    else:
        TikCheckUtil.check_in_range_by_dtype(
            mask_n, msg="mask value should be in the range of [%d, %d] for b32 "
            "tensor, input mask: %s" % (_MIN_MASK, _MAX_MASK_64, mask_n), var_range=[_MIN_MASK, _MAX_MASK_64])


def _get_mask_tmp(mask_n, context, model):
    mask_tmp = []
    is_mask_s64 = False
    for i, mask_value in enumerate(mask_n):
        if is_basic_expr([mask_value]):
            if mask_value.dtype == 'int64':
                is_mask_s64 = True
            mask_value = context.evaluate_expr(mask_value)
        # when mask_value.dtype is s64, we don't check the range of
        # mask_value for using it to express [0, 2**64-1] in u64
        if not is_mask_s64:
            if mask_value < 0 or mask_value > 2 ** 64 - 1:
                print_error_msg("mask value should be in the range "
                                "of [0, 2**64-1], input mask: %s" % mask_value)
        model.write_spr('MASK%s' % str(1 - i), mask_value)
        mask_tmp.append(mask_value)
    return mask_tmp


def set_vector_mask(mask_n, context, mask_mode="normal", tensor_bit_len=_BIT_LEN_16):
    """
    set vector mask
    """
    model = context.model
    # If you import at the top of the file, it causes a loop
    if is_basic_expr([mask_n]):
        mask_n = context.evaluate_expr(mask_n)

    # mask counter mode
    if mask_mode == "counter":
        TikCheckUtil.check_in_range_by_dtype(
            mask_n, msg="In counter_mode, mask value should be in the range of [%d, %d], input mask: %s"
                        % (_MIN_MASK, _MAX_COUNTER_MASK, mask_n), var_range=[_MIN_MASK, _MAX_COUNTER_MASK])
        # low 64 bit
        mask_0 = mask_n & _MAX_MASK0_VALUE
        # high 64 bit
        mask_1 = 0

        model.write_spr('MASK0', mask_0)
        model.write_spr('MASK1', mask_1)
    # mask normal mode
    else:
        if isinstance(mask_n, int):
            check_mask_range(mask_n, tensor_bit_len)
            mask_value = 2**mask_n - 1
            # low 64 bit
            mask_0 = mask_value & _MAX_MASK0_VALUE
            # high 64 bit
            mask_1 = mask_value >> _MASK1_SHIFT_POS

            model.write_spr('MASK0', mask_0)
            model.write_spr('MASK1', mask_1)
        elif isinstance(mask_n, (list, tuple)):
            TikCheckUtil.check_equality(len(mask_n), 2)
            mask_tmp = _get_mask_tmp(mask_n, context, model)
            # mask can not be all zero, also check s64
            TikCheckUtil.check_not_equality(
                mask_tmp, [_MASK_VALUE_ZERO, _MASK_VALUE_ZERO],
                "mask list value can not be [0, 0]")
            # b32, mask_h should be 0
            if tensor_bit_len == _BIT_LEN_32:
                TikCheckUtil.check_equality(
                    mask_tmp[0], _MASK_VALUE_ZERO,
                    "mask_h should be 0 for b32 tensor, input mask_h: "
                    "%s" % mask_tmp[0])


def check_mask_valid_for_debug(mask_n, context, mask_mode="normal", tensor_bit_len=_BIT_LEN_16):
    """
    check mask for tik debug
    mask_n: mask
    context: the stack context
    mask_mode: mode of mask, counter or normal.
    tensor_bit_len: length of tensor.dtype bit

    Returns
    -------
    None
    """
    # If you import at the top of the file, it causes a loop
    if is_basic_expr([mask_n]):
        mask_n = context.evaluate_expr(mask_n)

    # mask counter mode
    if mask_mode == "counter":
        TikCheckUtil.check_in_range_by_dtype(
            mask_n, msg="In counter_mode, mask value should be in the range of [%d, %d], input mask: %s"
                        % (_MIN_MASK, _MAX_COUNTER_MASK, mask_n), var_range=[_MIN_MASK, _MAX_COUNTER_MASK])
    # mask normal mode
    else:
        if isinstance(mask_n, int):
            check_mask_range(mask_n, tensor_bit_len)
        elif isinstance(mask_n, (list, tuple)):
            TikCheckUtil.check_equality(len(mask_n), 2)
            _check_mask_tmp(mask_n, tensor_bit_len, context)


def _check_mask_tmp(mask_n, tensor_bit_len, context):
    """
    check mask tmp

    mask_n: mask
    tensor_bit_len: length of tensor.dtype bit
    context: the stack context

    Returns
    -------
    None
    """
    mask_tmp = []
    is_mask_s64 = False
    for mask_value in mask_n:
        if not is_basic_expr(mask_value):
            mask_tmp.append(mask_value)
            continue
        if mask_value.dtype == 'int64':
            is_mask_s64 = True
        mask_value = context.evaluate_expr(mask_value)
        # when mask_value.dtype is s64, we don't check the range of
        # mask_value for using it to express [0, 2**64-1] in u64
        if not is_mask_s64:
            TikCheckUtil.check_in_range_by_dtype(
                mask_value, msg="mask value should be in the range of [%d, %d], input mask: %s"
                % (_MASK_VALUE_ZERO, _MAX_MASK0_VALUE, mask_n), var_range=[_MASK_VALUE_ZERO, _MAX_MASK0_VALUE])
        mask_tmp.append(mask_value)
    # mask can not be all zero, also check s64
    TikCheckUtil.check_not_equality(mask_tmp, [_MASK_VALUE_ZERO, _MASK_VALUE_ZERO],
                                    "mask list value can not be [0, 0]")
    # b32, mask_h should be 0
    if tensor_bit_len == _BIT_LEN_32:
        TikCheckUtil.check_equality(mask_tmp[0], _MASK_VALUE_ZERO,
                                    "mask_h should be 0 for b32 tensor, input mask_h: %s" % mask_tmp[0])


def make_tvm_imm(dtype, value):
    """
    create the immediately number for tvm

    Parameters
    ----------
    dtype : data type
    value: data value

    Returns
    -------
    data value
    """
    try:
        if 'float' in dtype:
            new_value = FloatImm(dtype, float(value))
        elif dtype.startswith('uint64') and value > MAX_INT64_VALUE:
            from tbe.tvm.runtime import _ffi_node_api
            value = int(value)
            new_value = _ffi_node_api.LargeUIntImm(dtype, value & ((1 << 32) - 1), value >> 32, None)
        elif dtype.startswith('int') or dtype.startswith('uint'):
            new_value = IntImm(dtype, int(value))
        else:
            new_value = None
            TikCheckUtil.raise_error('unsupported dtype %s for value %s' % (dtype, str(value)))
    except (TypeError, ValueError):
        new_value = value

    return new_value


def safe_get_value(var, raise_error=True):
    """
    get var from tvm node
    Parameters
    ----------
    var: tvm var
    raise_error: when cannot get const value, raise error if true, do not raise error but return var if false
    Returns
    -------
    return: result
    """
    return_value = var
    if hasattr(var, "value"):
        return_value = var.value
        if is_large_uint(return_value):
            # large_uint CallNode
            return_value = return_value.args[1].value << 32 | return_value.args[0].value
    elif is_large_uint(var):
        # large_uint CallNode
        return_value = var.args[1].value << 32 | var.args[0].value
    else:
        # raise_error:
        #   True: var should be ImmNode or large_uint CallNode. Else interrupt the process
        #   False: only try to get value. Else return original var
        if raise_error:
            TikCheckUtil.raise_error("can not get value safely!")
    return return_value


def check_scalar_defined(var, context):
    """
    check uninitialized scalar
    """
    TikCheckUtil.raise_error(
        "[Error]: found uninitialized Scalar!\nScalar "
        "define location:\n%s" % context.scalar_location[var])


class VecRegType(IntEnum):
    """
    Vector register Type
    """
    P_REG = 0
    V_REG = 1
    W_REG = 2
    U_REG = 3
    A_REG = 4
    S_REG = 5
    INTEGR_REG = 6
    VA_REG = 7
    NUM_REG = 8


class VecRegTypeV300(IntEnum):
    """
    Vector register Type for v300
    """
    GPR = 0
    SPR = 1
    VA = 2
    VREG = 3
    PREG = 4
    WREG = 5
    SREG = 6
    ULDREG = 7
    USTREG = 8
    FSTREG = 9
    UNDEF = 10
