#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     util.py
DESC:     sim's util file
CREATED:  2019-7-04 20:12:13
MODIFIED: 2020-12-7 19:17:00
"""

from __future__ import print_function
import ctypes
import itertools
import math
import numpy as np

from tbe.common.platform import scope_ubuf
from tbe.common.platform import scope_gm
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.common_util import dma_align_fn
from tbe.tik.common.common_util import check_tensor_addr_list_valid_idx
from tbe.tik.tik_lib.tik_params import MAX_VAREG_ALLOCATED
from tbe.tik.tik_lib.tik_params import MAX_XREG_ALLOCATED
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.debug.util import get_dtype_size
from tbe.tik.debug.util import get_flatten_idx
from tbe.tik.debug.util import model_with_env


class TempEnv:
    """
    the temp environment
    """

    def __init__(self, require_xt=True, is_aic_api=False):
        self.memory_space = {}
        self.x_register_alloc = 0
        self.va_register_alloc = 0
        self.tensor_cache = {}
        self.tensor_offset = {}
        self.tensor_scope = {}
        self.buffer_cache = {}
        self.dst_dtype = None
        self.offset = 0
        self.require_xt = require_xt
        self.check_align = True
        self.sub_core_id = 1
        if (TikSocManager().is_910b_soc() or TikSocManager().is_310b_610l_soc()) and is_aic_api:
            self.sub_core_id = 0

    @staticmethod
    def _get_buf_upper_bound(buf_addr, buffer_size, buf_scope):
        buf_upper_bound = buf_addr + buffer_size
        if buf_scope == scope_gm:
            # 32 is addr align byte nums.
            buf_size_mod = buffer_size % 32
            if buf_size_mod != 0:
                # if not 32B align, increase bound to 32B aligned.
                buf_upper_bound += (32 - buf_size_mod)
        return buf_upper_bound

    @staticmethod
    def _get_xn_addr(context, tensor, buffer_addr, offset=0):
        """
        get xn register align addr

        Parameters
        ----------
        context : stack context
        tensor : the tensor
        dtype_size: tensor dtype size
        buffer_addr: addr of buffer
        offset: buffer offset

        Returns
        -------
        x_n: xn register align addr
        """
        flatten_idx = get_flatten_idx(tensor, context)
        x_n = buffer_addr + (flatten_idx + offset)*get_dtype_size(tensor.dtype)
        x_n = context.evaluate_expr(x_n)
        return x_n, flatten_idx

    def alloc_memory(self, size, scope, align):
        """
        allocate memory

        Parameters
        ----------
        size : memory size
        scope : ub global and so on.
        align: align addr

        Returns
        -------
        the buffer addr
        """
        if scope not in self.memory_space:
            self.memory_space[scope] = 0

        cur_addr = self.memory_space.get(scope)
        aligned_addr = int(math.ceil(cur_addr / float(align))*align)
        self.memory_space[scope] = aligned_addr + size
        return aligned_addr

    def alloc_register(self):
        """
        allocate register

        Returns
        -------
        the result code
        """
        ret = self.x_register_alloc
        if ret >= MAX_XREG_ALLOCATED:
            TikCheckUtil.raise_error("all register exhausted")
        self.x_register_alloc += 1
        return ret

    def alloc_va_register(self, num=1):
        """
        allocate va register.
        If 'num' equals to 2, user is applying 2 successive VA registers

        Parameters
        ----------
        num: the number of VA register

        Returns
        -------
        the result code
        """
        if num not in (1, 2):
            TikCheckUtil.raise_error("Only support 1 or 2 VA for allocation.")

        ret = self.va_register_alloc
        if ret >= MAX_VAREG_ALLOCATED or (num == 2 and (ret + 1 >= MAX_VAREG_ALLOCATED)):
            TikCheckUtil.raise_error("all va register exhausted")

        self.va_register_alloc += num
        return ret if (num == 1) else (ret, ret + 1)

    def get_tensor_addr(self, context, tensor, access_mode):
        """
        get tensor's addr

        Parameters
        ----------
        context : stack context
        tensor : the tensor
        access_mode: buffer read or write mode

        Returns
        -------
        the tensor addr
        """
        # ATTENTION: you must copy tensor to model before you query the addr
        key = str(tensor.buffer) + access_mode
        dtype_size_ = get_dtype_size(tensor.dtype)
        flatten_idx = get_flatten_idx(tensor, context)
        buffer_info = self.tensor_cache.get(key)
        # 1 is index of buffer addr in buffer info list
        return buffer_info[1] + flatten_idx*dtype_size_

    def get_buffer_info(self, context, tensor, align, access_mode):
        """
        get buffer info:splited from function copy_tensor_to_model

        Parameters
        ----------
        context : stack context
        tensor : the tensor
        dtype_size: tensor dtype's size
        align :align addr
        access_mode: buffer rw mode

        Returns
        -------
        info of buffer
        """
        key = str(tensor.buffer) + access_mode
        tensor_buffer = context.tensor_buffer.get_npbuffer_by_tvmbuffer(tensor.buffer).buffer
        dtype = tensor.dtype
        # dtype is just used to get dtype size and numpy cannot recognize "bfloat16", use float16 instead
        if dtype == 'bfloat16':
            import tensorflow as tf
            dtype = tf.bfloat16.as_numpy_dtype
        flatten_np = tensor_buffer.reshape(-1).view(dtype)
        if key in self.tensor_cache:
            buffer_info = self.tensor_cache.get(key)
            tensor_offset = get_flatten_idx(tensor, context) * DTYPE_SIZE.get(tensor.dtype)
            self.tensor_offset.get(key).add(tensor_offset)
        else:
            if tensor.buffer not in self.buffer_cache:
                # need to allocate new memory
                alloc_size = len(flatten_np) * get_dtype_size(tensor.dtype)
                addr = self.alloc_memory(alloc_size, tensor.scope, align)
                model_with_env(context.model.write_memory, self, addr, tensor.scope, flatten_np.ctypes.data, alloc_size)
                # last buffer info is access_valid for check mem access,
                # default False
                tensor_offset = get_flatten_idx(tensor, context) * DTYPE_SIZE[tensor.dtype]
                buffer_info = [tensor.buffer, addr, alloc_size, flatten_np.ctypes.data,
                               access_mode, tensor.name, False]
                self.tensor_cache[key] = buffer_info
                self.tensor_scope[key] = tensor.scope
                self.tensor_offset[key] = {tensor_offset}
                self.buffer_cache[tensor.buffer] = key
            else:
                # don't need allocate memory,
                # just change buffer_info of access_mode
                buffer_info = self.tensor_cache.get(self.buffer_cache.get(tensor.buffer))[:]
                tensor_offset = get_flatten_idx(tensor, context) * DTYPE_SIZE[tensor.dtype]
                # 4 is index of access_mode,
                # if you change code of line 137, you should change this index
                buffer_info[4] = access_mode
                self.tensor_cache[key] = buffer_info
                self.tensor_offset[key] = {tensor_offset}

        return buffer_info

    def get_buffer_info_form_addr(self, context, tensor, data_size, access_mode):
        """
        get buffer info:splited from function copy_tensor_to_model_from_addr

        Parameters
        ----------
        context : stack context
        tensor : the tensoraddrlist
        data_size: copy data size
        access_mode: buffer rw mode

        Returns
        -------
        info of buffer
        """
        key = str(tensor.buffer) + access_mode

        idx, flatten_np = self._get_addr_flatten_np(context, tensor, data_size)

        if tensor.scope == scope_ubuf and tensor.buffer in context.tensor_addr_list_valid_idx.keys():
            check_tensor_addr_list_valid_idx(idx, context.tensor_addr_list_valid_idx.get(tensor.buffer),
                                             tensor.buffer.name)

        if key in self.tensor_cache:
            buffer_info = self.tensor_cache.get(key)
        else:
            if tensor.buffer not in self.buffer_cache:
                # need to allocate new memory
                # TensorAddr only support scope_gm
                addr = self.alloc_memory(data_size, scope_gm, dma_align_fn(tensor))
                context.model.write_memory(addr, scope_gm, flatten_np.ctypes.data, data_size)
                # last buffer info is access_valid for check mem access,
                # default False
                buffer_info = [tensor.buffer, addr, data_size,
                               flatten_np.ctypes.data, access_mode, tensor.name, False]
                self.tensor_cache[key] = buffer_info
                self.buffer_cache[tensor.buffer] = key
                self.tensor_offset[key] = {0}  # tensor addr offset is 0
            else:
                # don't need allocate memory,
                # just change buffer_info of access_mode
                buffer_info = self.tensor_cache.get(self.buffer_cache.get(tensor.buffer))[:]
                # 4 is index of access_mode,
                # if you change code of line 137, you should change this index
                buffer_info[4] = access_mode
                self.tensor_cache[key] = buffer_info
                self.tensor_offset[key] = {0}  # tensor addr offset is 0

        return buffer_info

    def copy_tensor_to_model(self, context, tensor, align, access_mode):
        """
        copy tensor to context.model

        Parameters
        ----------
        context : stack context
        tensor : the tensor
        align : align addr
        check_align : True or False
        require_xt: True or False
        access_mode: buffer rw mode
        offset: tensor offset

        Returns
        -------
        tuple , info of buffer
        """
        buffer_addr, buffer_size, buffer_ptr = self.get_buffer_info(context, tensor, align, access_mode)[1:4]

        x_n, flatten_idx = self._get_xn_addr(context, tensor, buffer_addr, self.offset)
        if self.check_align:
            # is not divisible, then raise error
            if x_n % align != 0:
                TikCheckUtil.raise_error('Address align error! %s is not %s align' % (flatten_idx, align))
        xn_idx = None
        if self.require_xt:
            xn_idx = self.alloc_register()
            model_with_env(context.model.write_gpr, self, xn_idx, x_n)

        #  ATTENTION: here we return the the info of buffer
        #  we are not expected to manipulate the partial buffer directly
        return [xn_idx, buffer_addr, buffer_size, buffer_ptr]

    def copy_tensor_to_model_from_addr(self, context, tensor, data_size, access_mode):
        """
        copy tensoraddrlist to context.model

        Parameters
        ----------
        context : stack context
        tensor : the tensoraddrlist
        data_size: copy data size
        dst_dtype: dst tensor dtype
        align :align addr
        require_xt: True or False
        access_mode: buffer rw mode

        Returns
        -------
        tuple , info of buffer
        """
        # buffer_addr is a real gm addr, which saves the real data
        buffer_addr, buffer_size, buffer_ptr = self.get_buffer_info_form_addr(context, tensor,
                                                                              data_size, access_mode)[1:4]
        xn_idx = self.alloc_register()
        context.model.write_gpr(xn_idx, buffer_addr)

        #  ATTENTION: here we return the the info of buffer
        #  we are not expected to manipulate the partial buffer directly
        return [xn_idx, buffer_addr, buffer_size, buffer_ptr]

    def check_mem_access(self, model, check_read=False, src_tensor_nums=1):
        """
        check memory if access

        Parameters
        ----------
        model : stack context.model
        check_read : need to check src mem access, if set to True, need to check src mem access
        src_tensor_nums: when no_check_read is False, src_tensor_nums is used to indicate src nums
        """
        access_list = model.get_memory_access(check_read, src_tensor_nums)
        for buf, buf_info in self.tensor_cache.items():
            _, buf_addr, _, _, access_mode, _, _ = buf_info
            if check_read is False and access_mode == "r":
                continue

            buf_offset_array = self.tensor_offset.get(buf)
            tensor_scope = self.tensor_scope.get(buf)
            for access_info in access_list:
                for buf_offset in buf_offset_array:
                    buf_start_addr = buf_addr + buf_offset
                    self._check_valid((buf, buf_info, access_info, buf_start_addr, tensor_scope))

    def check_mem_access_depthwise_conv(self, model, dst_store_offset):
        """
        check memory if access

        Parameters
        ----------
        model : stack context.model
        dst_store_offset: for depthewise_conv, first store addr is diff with diff store_high_half

        Returns
        -------
        tuple , info of buffer
        """
        access_list = model.get_memory_access_depthwise_conv()
        for buf, buf_info in self.tensor_cache.items():
            _, buf_addr, _, _, access_mode, _, _ = buf_info
            buf_offset_array = self.tensor_offset.get(buf)
            tensor_scope = self.tensor_scope.get(buf)
            for access_info, buf_offset in itertools.product(access_list, buf_offset_array):
                buf_start_addr = buf_addr + buf_offset
                if access_mode == "w":
                    buf_start_addr += dst_store_offset
                self._check_valid((buf, buf_info, access_info, buf_start_addr, tensor_scope))

    def check_mem_access_vnchwconv(self, model, tensor_nums_list, src_read_offset, dst_store_offset):
        """
        check memory if access

        Parameters
        ----------
        model : stack context.model
        tensor_nums_list: [src_tensor_nums, dst_tensor_nums]
        src_read_offset: src data read offset, calculated by src_high_half
        dst_store_offset: dst data write offset, calculated by dst_high_half

        Returns
        -------
        tuple , info of buffer
        """
        access_list = model.get_memory_access_vnchwconv(tensor_nums_list)
        # when the address is read on the V100 chip, the address with twice the length is used
        is_double_access = False if not TikSocManager.is_v100_soc() else True
        for buf, buf_info in self.tensor_cache.items():
            _, buf_addr, _, _, access_mode, _, _ = buf_info
            buf_offset_array = self.tensor_offset.get(buf)
            tensor_scope = self.tensor_scope.get(buf)
            for access_info, buf_offset in itertools.product(access_list, buf_offset_array):
                buf_start_addr = buf_addr + buf_offset
                if access_mode == "r":
                    buf_start_addr += src_read_offset
                else:
                    buf_start_addr += dst_store_offset
                self._check_valid((buf, buf_info, access_info, buf_start_addr, tensor_scope), is_double_access)

    def _get_addr_flatten_np(self, context, tensor, data_size):
        addr_tensor_buffer = context.tensor_buffer.get_npbuffer_by_tvmbuffer(tensor.buffer).buffer
        addr_flatten_np = addr_tensor_buffer.reshape(-1).view(tensor.dtype)

        idx = context.buffer2static_parameters[id(tensor)]["static_data"]
        addr_offset = context.buffer2static_parameters[id(tensor)]["static_addr_offset"]

        # read data from tensor addr
        tensor_address = int(addr_flatten_np[idx] + addr_offset*DTYPE_SIZE[self.dst_dtype])
        tensor_buffer = (ctypes.c_char*data_size).from_address(tensor_address)
        ele_nums = data_size // DTYPE_SIZE[self.dst_dtype]
        flatten_np = np.ndarray((ele_nums,), dtype=self.dst_dtype, buffer=tensor_buffer).reshape(-1)
        return idx, flatten_np

    def _check_valid(self, access_address_tuple, is_double_access=False):
        """
        check the buffer access is valid by check is overflow access by pv model result
        Parameters
        ----------
        access_address_tuple: buf, buf_info, access_info, buf_start_addr
        is_double_access: whether to use the double address, some interfaces use double addresses

        Returns
        -------

        """
        buf, buf_info, access_info, buf_start_addr, tensor_scope = access_address_tuple
        tvm_buf, buf_addr, buffer_size, _, access_mode, _, _ = buf_info
        buf_scope = tvm_buf.scope()
        if len(access_info) > 0 and access_info[0].addr == buf_start_addr and \
                buf_scope == access_info[0].scope and access_mode in ("rw", access_info[0].mode):
            # set access_valid to False
            self.tensor_cache.get(buf)[-1] = False
            buf_upper_bound = self._get_buf_upper_bound(buf_addr, buffer_size, buf_scope)
            if is_double_access:
                buf_upper_bound *= 2
            for mem_access in access_info:
                if mem_access.scope != tensor_scope:
                    continue
                if buf_addr <= mem_access.addr <= buf_upper_bound and buf_addr <= mem_access.addr + mem_access.size\
                        <= buf_upper_bound:
                    # set access_valid to True
                    self.tensor_cache.get(buf)[-1] = True
                else:
                    # cannot get tensor's dtype, here only show mem addr
                    err_msg = "Access tensor %s overflow, buffer accessible memory addr: [%d, %d] Byte, " \
                              "but accessed memory addr: [%d, %d] Byte" % \
                              (tvm_buf.name, buf_addr, buf_upper_bound,
                               access_info[0].addr,
                               (mem_access.addr + mem_access.size))
                    TikCheckUtil.raise_error(err_msg)
