#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_common_high_preci_debug.py
DESC:     common compute debug for tik high preci api
CREATED:  2021-12-18 14:02:50
MODIFIED: 2020-12-18 14:22:50
"""
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.util import ceil_div
from tbe.tik.tik_lib.tik_params import MASK_LOW_IDX
from tbe.tik.tik_lib.tik_params import MASK_HIGH_IDX
from tbe.tik.common.common_util import vector_max_offset_cal
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.common.common_nametuple_util import VecVconvApi
from tbe.tik.common.common_nametuple_util import Fp162Fp32ComputeDebugApi
from tbe.tik.tik_lib.tik_vector_api.tik_vector_compare_api_ import VconvOpApi
from tbe.tik.debug.tik_vector_ops_debug.tik_vector_compare_debug_ import VconvNew


def _fp162fp32_func_compute_debug(tik_instance, compute_obj):
    """
    fp16 to fp 32 compute debug
    Parameters
    ----------
    tik_instance: tik instance
    compute_obj: compute obj

    Returns
    -------

    """
    tmp_tensor_size = compute_obj.tmp_tensor_size
    if compute_obj.work_tensor.dtype == "float16":
        tmp_src_tensor = compute_obj.work_tensor[0:tmp_tensor_size].reinterpret_cast_to("float32")
        tmp_dst_tensor = compute_obj.work_tensor[tmp_tensor_size: tmp_tensor_size * 2].reinterpret_cast_to("float32")
        tmp_work_tensor = compute_obj.work_tensor[tmp_tensor_size * 2:].reinterpret_cast_to("float32")
        tmp_tensor_size = tmp_tensor_size * DTYPE_SIZE[compute_obj.work_tensor.dtype] // DTYPE_SIZE["float32"]
    else:
        tmp_src_tensor = compute_obj.work_tensor[0:tmp_tensor_size]
        tmp_dst_tensor = compute_obj.work_tensor[tmp_tensor_size:tmp_tensor_size * 2]
        tmp_work_tensor = compute_obj.work_tensor[tmp_tensor_size * 2:]

    vconv_obj = VecVconvApi(compute_obj.name, compute_obj.mask, "none", tmp_src_tensor,
                            compute_obj.src, compute_obj.repeat_times, 1, 1, compute_obj.fp32_rep_stride,
                            compute_obj.src_rep_stride, None, False, 0, None, "vconv")

    eval_conv(compute_obj, tik_instance, vconv_obj)

    params = [compute_obj.mask, tmp_dst_tensor, tmp_src_tensor, tmp_work_tensor,
              compute_obj.repeat_times, compute_obj.fp32_rep_stride, compute_obj.fp32_rep_stride, tmp_tensor_size]
    compute_obj.func(compute_obj.context, params)

    vonv_obj = VecVconvApi(compute_obj.name, compute_obj.mask, "none", compute_obj.dst,
                           tmp_dst_tensor, compute_obj.repeat_times, 1, 1, compute_obj.dst_rep_stride,
                           compute_obj.fp32_rep_stride, None, False, 0, None, "vconv")
    eval_conv(compute_obj, tik_instance, vonv_obj)


def eval_conv(compute_obj, tik_instance, vconv_obj):
    """
    eval vconv, vonv
    Parameters
    ----------
    compute_obj: compute obj
    tik_instance: tik instance
    vconv_obj: vconv obj

    Returns
    -------

    """
    vconv_obj = VconvOpApi(tik_instance, vconv_obj)
    vconv_stmt_src = VconvNew(compute_obj.source_info, vconv_obj, compute_obj.context.tik_debugger)
    vconv_stmt_src.eval_(compute_obj.context)


def _fp162fp32_func_mask_list(tik_instance, fp162fp32_high_preci_params, fp32_rep_stride):
    """
    fp16 to fp32 when mask is list
    Parameters
    ----------
    tik_instance: tik instance
    fp162fp32_high_preci_params: fp16 to fp32 high preci params
    fp32_rep_stride: fp32 repeat stride

    Returns
    -------

    """
    default_start_offset = 64
    low_mask = fp162fp32_high_preci_params.mask[MASK_LOW_IDX]
    high_mask = fp162fp32_high_preci_params.mask[MASK_HIGH_IDX]
    if high_mask > 0:
        tmp_tensor_size = _get_src_extend(
            [0, high_mask], fp162fp32_high_preci_params.repeat_times,
            fp162fp32_high_preci_params.src_rep_stride, fp162fp32_high_preci_params.work_tensor,
            fp162fp32_high_preci_params.size_factor)
        fp162fp32_compute_debug_obj = Fp162Fp32ComputeDebugApi(
            fp162fp32_high_preci_params.source_info, fp162fp32_high_preci_params.context,
            fp162fp32_high_preci_params.func, [0, high_mask],  fp162fp32_high_preci_params.dst[default_start_offset:],
            fp162fp32_high_preci_params.src[default_start_offset:], fp162fp32_high_preci_params.work_tensor,
            fp162fp32_high_preci_params.repeat_times, fp162fp32_high_preci_params.dst_rep_stride,
            fp162fp32_high_preci_params.src_rep_stride, fp32_rep_stride, tmp_tensor_size,
            fp162fp32_high_preci_params.name)

        _fp162fp32_func_compute_debug(tik_instance, fp162fp32_compute_debug_obj)

    tmp_tensor_size = _get_src_extend(
        [0, low_mask], fp162fp32_high_preci_params.repeat_times,
        fp162fp32_high_preci_params.src_rep_stride, fp162fp32_high_preci_params.work_tensor,
        fp162fp32_high_preci_params.size_factor)
    fp162fp32_compute_debug_obj = Fp162Fp32ComputeDebugApi(
        fp162fp32_high_preci_params.source_info, fp162fp32_high_preci_params.context, fp162fp32_high_preci_params.func,
        [0, low_mask], fp162fp32_high_preci_params.dst, fp162fp32_high_preci_params.src,
        fp162fp32_high_preci_params.work_tensor, fp162fp32_high_preci_params.repeat_times,
        fp162fp32_high_preci_params.dst_rep_stride, fp162fp32_high_preci_params.src_rep_stride,
        fp32_rep_stride, tmp_tensor_size, fp162fp32_high_preci_params.name)
    _fp162fp32_func_compute_debug(tik_instance, fp162fp32_compute_debug_obj)


def _fp162fp32_func_mask_imm(tik_instance, fp162fp32_high_preci_params, fp32_rep_stride):
    """
    fp16 to fp32 when mask is imm
    Parameters
    ----------
    tik_instance: tik insatnce
    fp162fp32_high_preci_params: fp162fp32 high preci params
    fp32_rep_stride: fp32 repeat stride

    Returns
    -------

    """
    if fp162fp32_high_preci_params.mask <= 64:
        tmp_tensor_size = _get_src_extend(
            fp162fp32_high_preci_params.mask, fp162fp32_high_preci_params.repeat_times,
            fp162fp32_high_preci_params.src_rep_stride, fp162fp32_high_preci_params.work_tensor,
            fp162fp32_high_preci_params.size_factor)
        fp162fp32_compute_debug_obj = Fp162Fp32ComputeDebugApi(
            fp162fp32_high_preci_params.source_info, fp162fp32_high_preci_params.context,
            fp162fp32_high_preci_params.func, fp162fp32_high_preci_params.mask, fp162fp32_high_preci_params.dst,
            fp162fp32_high_preci_params.src, fp162fp32_high_preci_params.work_tensor,
            fp162fp32_high_preci_params.repeat_times, fp162fp32_high_preci_params.dst_rep_stride,
            fp162fp32_high_preci_params.src_rep_stride, fp32_rep_stride, tmp_tensor_size,
            fp162fp32_high_preci_params.name)
        _fp162fp32_func_compute_debug(tik_instance, fp162fp32_compute_debug_obj)
    else:
        _fp162fp32_func_mask_gt_64(fp162fp32_high_preci_params, tik_instance, fp32_rep_stride)


def _fp162fp32_func_mask_gt_64(fp162fp32_high_preci_params, tik_instance, fp32_rep_stride):
    """
    fp16 to fp32 when mask gather than 64
    Parameters
    ----------
    tik_instance: tik insatnce
    fp162fp32_high_preci_params: fp162fp32 high preci params
    fp32_rep_stride: fp32 repeat stride

    Returns
    -------

    """
    default_start_offset = 64
    low_mask = 64
    high_mask = fp162fp32_high_preci_params.mask - 64
    tmp_tensor_size = _get_src_extend(
        high_mask, fp162fp32_high_preci_params.repeat_times, fp162fp32_high_preci_params.src_rep_stride,
        fp162fp32_high_preci_params.work_tensor, fp162fp32_high_preci_params.size_factor)
    fp162fp32_compute_debug_obj = Fp162Fp32ComputeDebugApi(
        fp162fp32_high_preci_params.source_info, fp162fp32_high_preci_params.context,
        fp162fp32_high_preci_params.func, high_mask, fp162fp32_high_preci_params.dst[default_start_offset:],
        fp162fp32_high_preci_params.src[default_start_offset:], fp162fp32_high_preci_params.work_tensor,
        fp162fp32_high_preci_params.repeat_times, fp162fp32_high_preci_params.dst_rep_stride,
        fp162fp32_high_preci_params.src_rep_stride, fp32_rep_stride, tmp_tensor_size,
        fp162fp32_high_preci_params.name)
    _fp162fp32_func_compute_debug(tik_instance, fp162fp32_compute_debug_obj)

    tmp_tensor_size = _get_src_extend(
        low_mask, fp162fp32_high_preci_params.repeat_times, fp162fp32_high_preci_params.src_rep_stride,
        fp162fp32_high_preci_params.work_tensor, fp162fp32_high_preci_params.size_factor)
    fp162fp32_compute_debug_obj = Fp162Fp32ComputeDebugApi(
        fp162fp32_high_preci_params.source_info, fp162fp32_high_preci_params.context,
        fp162fp32_high_preci_params.func, low_mask, fp162fp32_high_preci_params.dst,
        fp162fp32_high_preci_params.src, fp162fp32_high_preci_params.work_tensor,
        fp162fp32_high_preci_params.repeat_times, fp162fp32_high_preci_params.dst_rep_stride,
        fp162fp32_high_preci_params.src_rep_stride, fp32_rep_stride, tmp_tensor_size,
        fp162fp32_high_preci_params.name)

    _fp162fp32_func_compute_debug(tik_instance, fp162fp32_compute_debug_obj)


def fp162fp32_high_preci_func(tik_instance, fp162fp32_high_preci_params):
    """
    high_preci_func

    Parameters
    ----------
    tik_instance
    fp162fp32_high_preci_params

    Returns
    -------
    None
    """
    fp32_rep_stride = _get_wk_tensor_stride(fp162fp32_high_preci_params.src_rep_stride)
    if isinstance(fp162fp32_high_preci_params.mask, (list, tuple)):
        _fp162fp32_func_mask_list(tik_instance, fp162fp32_high_preci_params, fp32_rep_stride)
    else:
        _fp162fp32_func_mask_imm(tik_instance, fp162fp32_high_preci_params, fp32_rep_stride)


def _get_src_extend(mask, repeat_times, src_rep_stride, work_tensor, size_factor):
    """

    Parameters
    ----------
    mask
    repeat_times
    src_rep_stride
    work_tensor
    size_factor

    Returns
    -------

    """
    default_dtype = "float16"
    block_len = 16
    src_extend = vector_max_offset_cal(
        (mask, default_dtype, block_len, repeat_times, 1, src_rep_stride))
    src_extend = ceil_div(src_extend, block_len) * block_len
    if work_tensor.dtype == "float16":
        tmp_tensor_size = src_extend * 2
    else:
        tmp_tensor_size = src_extend
    needed_tensor_size = tmp_tensor_size * size_factor
    work_tensor_size = work_tensor.size
    # check if int
    TikCheckUtil.check_ge(work_tensor_size, needed_tensor_size,
                          "Input work tensor size(%d) must be more "
                          "than needed size(%d)" %
                          (work_tensor_size, needed_tensor_size))
    return tmp_tensor_size


def _get_wk_tensor_stride(src_rep_stride):
    if src_rep_stride <= 4:
        fp32_rep_stride_1 = src_rep_stride * 2
    else:
        fp32_rep_stride_1 = 8
    return fp32_rep_stride_1
