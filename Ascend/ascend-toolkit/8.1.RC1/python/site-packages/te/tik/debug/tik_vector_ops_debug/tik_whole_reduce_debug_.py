#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_vector_reduce_debug_.py
DESC:     provide params
CREATED:  2021-11-5 18:53:42
MODIFIED: 2021-11-5 19:17:00
"""
from tbe.tik.common.common_util import vec_template_align
from tbe.tik.common.util import get_bit_len
from tbe.tik.debug.statement import STMT
from tbe.tik.debug.simd import _ENCODER
from tbe.tik.debug.simd import VEC_WHOLE_REDUCE_ENCODER_910B
from tbe.tik.debug.simd import VEC_WHOLE_REDUCE_ENCODER
from tbe.tik.debug.simd import _SRC_REPEAT_STRIDE_SHIFT_POS
from tbe.tik.debug.util import copy_tensor_to_model
from tbe.tik.debug.util import reinterpret_type
from tbe.tik.debug.util import set_vector_mask
from tbe.tik.debug.util import VEC_DATA_TYPE_ENCODING
from tbe.tik.debug.util import get_dtype_bit_width
from tbe.tik.debug.sim.util import TempEnv
from tbe.tik.debug.debug_encoder import VEC_DATA_TYPE_ENCODING_V200
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_params import REPEAT_SHIFT_POS
from tbe.tik.tik_lib.tik_params import VREDUCE_DST_ALIGN
from tbe.tik.tik_lib.tik_params import MAXMIN_CNT_INDEX_LEN_1
from tbe.tik.tik_lib.tik_params import MAXMIN_CNT_INDEX_LEN_3
from tbe.tik.tik_lib.tik_params import FOUR_BYTE_VALUE
from tbe.tik.tik_lib.tik_params import CNT_SHIFT_POS
from tbe.tik.tik_lib.tik_params import TWO_BYTE_VALUE
from tbe.tik.tik_lib.tik_params import INDEX_SHIFT_POS
from tbe.tik.tik_lib.tik_params import SRC_BLOCK_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import STRIDE_UNIT_SHIFT_POS
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager


class VecReduce(STMT):
    """
    vector all reduce, group reduce, pair reduce has no difference to the debugger
    """
    def __init__(self, source_info, op_obj):
        super(VecReduce, self).__init__(source_info, op_obj.tik_instance.context.tik_debugger)
        self.op_obj = op_obj
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return

        self.op_obj.dst_tensor_op.set_context(context)
        self.op_obj.src_tensor_op.set_context(context)
        temp_env = TempEnv()
        set_vector_mask(self.op_obj.control_op.mask, context,
                        tensor_bit_len=max(get_bit_len(self.op_obj.dst_tensor_op.tensor_obj.dtype),
                                           get_bit_len(self.op_obj.src_tensor_op.tensor_obj.dtype)))

        dst_align = VREDUCE_DST_ALIGN.get(self.op_obj.name)
        src_align = vec_template_align(self.op_obj.src_tensor_op.tensor_obj.dtype)
        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.op_obj.dst_tensor_op.tensor_obj, dst_align, access_mode='w')
        xn_idx, _, src_alloc_size, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src_tensor_op.tensor_obj, src_align, access_mode='r')

        param = _ENCODER.new_param()
        if "add" in self.op_obj.name or "vcgmin" in self.op_obj.name or "vcgmax" in self.op_obj.name:
            param.type = VEC_DATA_TYPE_ENCODING.get(self.op_obj.src_tensor_op.tensor_obj.dtype)
        else:
            param.type = VEC_DATA_TYPE_ENCODING_V200.get(self.op_obj.src_tensor_op.tensor_obj.dtype)
        param.xt = self.create_gpr_x_t(context, temp_env)
        param.xd = xd_idx
        param.xn = xn_idx

        self.op_obj.src_tensor_op.check_read_mem_out_of_bounds(src_alloc_size, self.op_obj.control_op)
        if self.op_obj.order is not None:
            param.order = self.op_obj.order

        if self.op_obj.name in ("vcmax", "vcmin") and TikSocManager.is_910b_soc():
            instr = VEC_WHOLE_REDUCE_ENCODER_910B.get(self.op_obj.name)(param)
        else:
            instr = VEC_WHOLE_REDUCE_ENCODER.get(self.op_obj.name)(param)

        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

        context.model.read_memory(dst_addr, self.op_obj.dst_tensor_op.tensor_obj.scope, dst_ptr, dst_alloc_size)

        self.update_var_maxmin_cnt(context)

    def update_var_maxmin_cnt(self, context):
        """
        update the var in var table with value recorded in special purpose register 'MAX_MIN_CNT'

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        if self.op_obj.maxmin_cnt_index is not None:
            index_num = len(self.op_obj.maxmin_cnt_index)
            TikCheckUtil.check_in_range_by_dtype(
                index_num, msg="maxmin_cnt_index length must be %s or %s"
                % (MAXMIN_CNT_INDEX_LEN_1, MAXMIN_CNT_INDEX_LEN_3),
                var_range=[MAXMIN_CNT_INDEX_LEN_1, MAXMIN_CNT_INDEX_LEN_3])

            sr_value = context.model.read_spr('MAX_MIN_CNT')
            # maxmin_cnt_index contains maxmin, cnt and index
            # var0 means maxmin
            var0 = self.op_obj.maxmin_cnt_index[0].debug_var
            offset0 = context.evaluate_expr(self.op_obj.maxmin_cnt_index[0].offset)
            val_bit_width = get_dtype_bit_width(var0[offset0].dtype)
            context.update_var(
                var0[offset0], reinterpret_type('uint' + val_bit_width,
                                                var0[offset0].dtype,
                                                sr_value & FOUR_BYTE_VALUE))
            if index_num == MAXMIN_CNT_INDEX_LEN_3:
                # var1 means cnt
                var1 = self.op_obj.maxmin_cnt_index[1].debug_var
                offset1 = context.evaluate_expr(self.op_obj.maxmin_cnt_index[1].offset)
                # var2 means index
                var2 = self.op_obj.maxmin_cnt_index[2].debug_var
                offset2 = context.evaluate_expr(self.op_obj.maxmin_cnt_index[2].offset)
                context.update_var(var1[offset1], (sr_value >> CNT_SHIFT_POS) &
                                   TWO_BYTE_VALUE)
                context.update_var(var2[offset2], (sr_value >> INDEX_SHIFT_POS) &
                                   TWO_BYTE_VALUE)

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        dst_repeat_stride = context.evaluate_expr(self.op_obj.dst_tensor_op.rep_stride)
        src_blk_stride = context.evaluate_expr(self.op_obj.src_tensor_op.blk_stride)
        src_repeat_stride = context.evaluate_expr(self.op_obj.src_tensor_op.rep_stride)
        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)
        stride_unit = context.evaluate_expr(self.op_obj.control_op.stride_unit)

        self.op_obj.reduce_check_obj.check_debug_common_params(context)

        xt_idx = temp_env.alloc_register()
        x_t = dst_repeat_stride
        x_t |= src_blk_stride << SRC_BLOCK_STRIDE_SHIFT_POS
        x_t |= stride_unit << STRIDE_UNIT_SHIFT_POS
        x_t |= repeat << REPEAT_SHIFT_POS
        x_t |= src_repeat_stride << _SRC_REPEAT_STRIDE_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)

        return xt_idx
