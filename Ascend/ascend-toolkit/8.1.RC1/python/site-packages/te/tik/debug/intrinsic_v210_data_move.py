#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     intrinsic_v210_data_move.py
DESC:     v210 data move class
CREATED:  2021-11-25 20:32
MODIFIED: 2021-11-25 20:32
"""

from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.debug.util import get_flatten_idx
from tbe.tik.common.common_util import check_extent_overflow
from tbe.tik.debug.intrinsic_v210_common import DIST_VLD
from tbe.tik.debug.intrinsic_v210_common import DIST_VLD_ALIGN
from tbe.tik.debug.intrinsic_v210_common import DIST_VST
from tbe.tik.debug.intrinsic_v210_common import DIST_VST_ALIGN
from tbe.tik.debug.intrinsic_v210_common import get_mask_bit_len
from tbe.tik.debug.intrinsic_v210_common import gen_vag_instr
from tbe.tik.debug.statement import STMT
from tbe.tik.debug.util import copy_tensor_to_model
from tbe.tik.debug.sim.util import TempEnv
from tbe.tik.debug.util import VecRegType
from tbe.tik.tik_lib.tik_params import MAX_SID
from tbe.tik.common.common_util import check_param_type_range
from tbe.tik.common.common_check_func import check_mvf_data_move_overflow
from tbe.tik.debug.intrinsic_v210_common import SOURCE_REGISTER1
from tbe.tik.debug.intrinsic_v210_common import get_and_write_share_spr
from tbe.tik.debug.intrinsic_v210_common import set_param_loop_vex_num_dtype
from tbe.tik.debug.intrinsic_v210_common import create_vloop_info
from tbe.tik.debug.intrinsic_v210_common import execute_all_instr
from tbe.tik.debug.intrinsic_v210_common import dst_register
from tbe.tik.debug.intrinsic_v210_common import V300_INSTR_OP1_CODE
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.debug.decorators_common import scalar_set_as_fn


class GetVsqzElemCount(STMT):
    """
    Get vsqz Elem_count instruction
    """
    def __init__(self, source_info, src, tik_debugger):
        super(GetVsqzElemCount, self).__init__(source_info, tik_debugger)
        self.src = src
        
    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        ar_count = context.all_sqzn_count
        scalar_set_as_fn(self.src, ar_count)
        for var in self.src.debug_var:
            context.update_var(var, ar_count)
        context.sqzn_count = 0


class MvfDci(STMT):
    """
    DataMove instruction
    """

    def __init__(self, source_info, tik_debugger):
        super(MvfDci, self).__init__(source_info, tik_debugger)
        self.param = None

    def set_param(self, context):
        """
        set param
        Returns
        -------

        """
        self.param = context.encoder.new_vec_param()

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        self.set_param(context)
        instr = context.encoder.gen_mvf_dci(self.param)
        context.model.step(instr)


class MvfMove(STMT):
    """
    DataMove instruction
    """

    def __init__(self, source_info, move_params, tik_debugger):
        super(MvfMove, self).__init__(source_info, tik_debugger)
        self.dst = move_params.dst
        self.src = move_params.src
        self.src_index = move_params.src_index
        self.index_num = move_params.index_num
        self.ele_size = move_params.ele_size
        self.dst_stride = move_params.dst_stride
        self.sid = 0

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        temp_env = TempEnv()
        src_align = 512
        # dst and src_index are 32B align
        align = 32
        xn_idx, _, _, _ = copy_tensor_to_model(
            context, temp_env, self.src_index, align, access_mode='r')
        xm_idx, _, _, _ = copy_tensor_to_model(
            context, temp_env, self.src, src_align, access_mode='r')

        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.dst, align, access_mode='w')

        param = context.encoder.new_vec_param()
        if TikSocManager.is_v300_610l_soc():
            param.isV300 = True

        param.xdIdx = xd_idx
        param.xnIdx = xn_idx
        param.xmIdx = xm_idx
        param.xtIdx = self.create_gpr_x_t(context, temp_env)
        param.type = self.ele_size
        param.itype = 0
        if self.src_index.dtype == "uint32":
            param.itype = 1

        instr = context.encoder.gen_mvf_move(param)

        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

        context.model.read_memory(
            dst_addr, self.dst.scope, dst_ptr, dst_alloc_size)

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        index_num = context.evaluate_expr(self.index_num)
        dst_stride = context.evaluate_expr(self.dst_stride)
        sid = context.evaluate_expr(self.sid)
        check_mvf_data_move_overflow(
            self, index_num, dst_stride, context.evaluate_expr(self.dst.offset),
            context.evaluate_expr(self.src_index.offset))
        xt_idx = temp_env.alloc_register()
        x_t = index_num
        x_t |= dst_stride << 16
        x_t |= sid << 19

        context.model.write_gpr(xt_idx, x_t)

        return xt_idx


class VectorStore(STMT):
    """
    Vector store instruction
    """

    def __init__(self, source_info, store_params, tik_debugger):
        super(VectorStore, self).__init__(source_info, tik_debugger)
        # dst is ub tensor
        self.dst = store_params.dst
        # src is vector register
        if store_params.str_st_mode in ['INTLV_B8', 'INTLV_B16']:
            self.src = store_params.src[0]
            self.src1 = store_params.src[1]
        else:
            self.src = store_params.src
            self.src1 = None
        self.mask = store_params.mask  # None, imm, Scalar, Expr, Preg
        self.str_st_mode = store_params.str_st_mode

    def set_param(self, context, param, instr_list):
        """
        set param
        Parameters
        ----------
        instr_list
        context
        param

        Returns
        -------

        """
        if TikSocManager.is_v300_610l_soc():
            param.smIdx = get_and_write_share_spr(context, 0, "uint32")
        else:
            am_idx = context.alloc_a_register(self.dst)
            param.amIdx = am_idx
            param.loop = 0

        if TikSocManager.is_v210_vec_soc():
            # gen vag instr for vloop
            vag_instr = gen_vag_instr(context, self.dst.dtype)
            instr_list.append(vag_instr)

        if self.src1 is None:
            src_vd_idx = context.alloc_v_register(self.src)
        else:
            src_vd_idx, src1_vd_idx = context.alloc_v_register(self.src, is_even=True)
            context.init_vreg_according_cache(self.src1, src1_vd_idx)
        param.vdIdx = src_vd_idx
        return param, instr_list

    def get_extent(self, context):
        """
        get extent
        Parameters
        ----------
        context

        Returns
        -------

        """
        vl_t = 256
        extent_map = {
            None: vl_t,
            'NORM_B8': vl_t,
            'NORM_B16': vl_t,
            'NORM_B32': vl_t,
            'ONEPT_B8': DTYPE_SIZE.get(self.dst.dtype),
            'ONEPT_B16': DTYPE_SIZE.get(self.dst.dtype),
            'ONEPT_B32': DTYPE_SIZE.get(self.dst.dtype),
            'PK_B16': vl_t // 2,
            'PK_B32': vl_t // 2,
            'INTLV_B8': vl_t * 2,
            'INTLV_B16': vl_t * 2,
        }

        if 'NORM' in self.str_st_mode:
            extent = get_mask_bit_len(context, self.mask, self.src.dtype) * \
                     DTYPE_SIZE.get(self.dst.dtype)
        elif 'PK' in self.str_st_mode:
            extent = get_mask_bit_len(context, self.mask, self.src.dtype) * \
                     DTYPE_SIZE.get(self.dst.dtype) // 2
        else:
            extent = extent_map.get(self.str_st_mode)

        return extent

    def eval_(self, context):
        """
        Vector Store eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        temp_env = TempEnv(require_xt=False)
        param = set_param_loop_vex_num_dtype(context, self.src.dtype, 0, 1)
        instr_list = create_vloop_info(context, param, vst_loop_num=1)

        param.dist = DIST_VST.get(self.str_st_mode)
        align = DIST_VST_ALIGN.get(self.str_st_mode)

        pg_idx = context.alloc_p_register(self.mask, dtype=self.src.dtype)
        param.pgIdx = pg_idx

        # [sn] + Am is UB address, it's need 32B aligned
        offset = get_flatten_idx(self.dst, context)
        _, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.dst, align, access_mode='w')
        extent = self.get_extent(context)

        check_extent_overflow(self.dst, extent, offset, 'dst')
        sn_idx = get_and_write_share_spr(
            context, dst_addr + offset * DTYPE_SIZE.get(self.dst.dtype), "uint32")
        param.snIdx = sn_idx

        param, instr_list = self.set_param(context, param, instr_list)
        if TikSocManager.is_v300_610l_soc():
            instr = context.encoder.gen_vector_store_vsts(param)
        else:
            instr = context.encoder.gen_vector_store(param)

        instr_list.append(instr)
        context.model.step_all(context, instr_list, len(instr_list))

        # check_mem_access failed, cannot find gm
        context.model.read_memory(dst_addr, self.dst.scope, dst_ptr,
                                  dst_alloc_size)
        context.free_all_register()


class VectorStoreUnalignSqzn(STMT):
    """
    Vector store stu/sta instruction
    """
    
    def __init__(self, source_info, unalign_params, tik_debugger):
        super(VectorStoreUnalignSqzn, self).__init__(source_info, tik_debugger)
        # dst is ub tensor
        self.dst = unalign_params.dst
        # src is vector register
        self.src = unalign_params.src
        # ureg is vector alignment register
        self.ureg = unalign_params.ureg

    def set_param(self, context, param, instr_list):
        """
        set param
        Parameters
        ----------
        context
        param
        instr_list

        Returns
        -------

        """
        # current post mode is post-update
        param.post = 1

        # gen vag instr for vloop
        vag_instr = gen_vag_instr(context, self.dst.dtype)
        instr_list.append(vag_instr)

        src_vd_idx = context.alloc_v_register(self.src)
        param.vdIdx = src_vd_idx

        ureg_idx = context.alloc_u_register(self.ureg)
        param.udIdx = ureg_idx
        return param, instr_list

    def eval_(self, context):
        """
        VectorStoreUnalign eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        temp_env = TempEnv(require_xt=False)
        param = set_param_loop_vex_num_dtype(context, self.src.dtype, 0, 1)
        instr_list = create_vloop_info(context, param, vst_loop_num=2)

        # [sn] + ar is UB address, it's need dtype size aligned
        align = DTYPE_SIZE.get(self.dst.dtype)
        offset = get_flatten_idx(self.dst, context)
        _, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.dst, align, access_mode='w')
        check_extent_overflow(self.dst, 256, offset, 'dst')
        sn_idx = get_and_write_share_spr(
            context, dst_addr + offset * align + context.sqzn_count * align, "uint32")

        param.snIdx = sn_idx
        param, instr_list = self.set_param(context, param, instr_list)
        instr_stur = context.encoder.gen_vector_store_stur(param)
        instr_list.append(instr_stur)
        instr_star = context.encoder.gen_vector_store_star(param)
        instr_list.append(instr_star)
        context.model.step_all(context, instr_list, len(instr_list))
        ar_count = context.model.read_spr('VPR_AR') // align
        context.sqzn_count += ar_count
        context.all_sqzn_count += ar_count
        context.model.write_spr('VPR_AR', context.sqzn_count)
        context.model.read_memory(dst_addr, self.dst.scope, dst_ptr,
                                  dst_alloc_size)
        context.free_all_register()


class VectorStoreUnalign(STMT):
    """
    Vector store stu/sta instruction
    """

    def __init__(self, source_info, unalign_params, tik_debugger):
        super(VectorStoreUnalign, self).__init__(source_info, tik_debugger)
        # dst is ub tensor
        self.dst = unalign_params.dst
        # src is vector register
        self.src = unalign_params.src
        # ureg is vector alignment register
        self.ureg = unalign_params.ureg

    def set_param(self, context, param, instr_list):
        """
        set param
        Parameters
        ----------
        context
        param
        instr_list

        Returns
        -------

        """
        if TikSocManager.is_v300_610l_soc():
            sm_offset = int(context.dprofile.get_vector_reg_size())
            param.smIdx = get_and_write_share_spr(context, sm_offset, "uint32")
        else:
            am_idx = context.alloc_a_register(self.dst)
            param.amIdx = am_idx
            # current post mode is post-update by VL
            param.post = 1

            # gen vag instr for vloop
            vag_instr = gen_vag_instr(context, self.dst.dtype)
            instr_list.append(vag_instr)

        src_vd_idx = context.alloc_v_register(self.src)
        param.vdIdx = src_vd_idx

        ureg_idx = context.alloc_u_register(self.ureg)
        param.udIdx = ureg_idx
        return param, instr_list

    def eval_(self, context):
        """
        VectorStoreUnalign eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        temp_env = TempEnv(require_xt=False)
        param = set_param_loop_vex_num_dtype(context, self.src.dtype, 0, 1)
        instr_list = create_vloop_info(context, param, vst_loop_num=2)

        # [sn] + Am is UB address, it's need dtype size aligned
        align = DTYPE_SIZE.get(self.dst.dtype)
        offset = get_flatten_idx(self.dst, context)
        _, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.dst, align, access_mode='w')
        check_extent_overflow(self.dst, 256, offset, 'dst')
        sn_idx = get_and_write_share_spr(
            context, dst_addr + offset * align, "uint32")
        param.snIdx = sn_idx

        param, instr_list = self.set_param(context, param, instr_list)
        if TikSocManager.is_v300_610l_soc():
            instr_stu = context.encoder.gen_vector_store_vstus(param)
            instr_sta = context.encoder.gen_vector_store_vstas(param)
        else:
            instr_stu = context.encoder.gen_vector_store_vstu(param)
            instr_sta = context.encoder.gen_vector_store_vsta(param)
        instr_list.append(instr_stu)
        instr_list.append(instr_sta)

        context.model.step_all(context, instr_list, len(instr_list))

        context.model.read_memory(dst_addr, self.dst.scope, dst_ptr,
                                  dst_alloc_size)
        context.free_all_register()


class VectorLoad(STMT):
    """
    Vector load instruction
    """

    def __init__(self, source_info, load_params, tik_debugger):
        super(VectorLoad, self).__init__(source_info, tik_debugger)
        # dst is vector

        if load_params.str_ld_mode in ["BDINTLV", "DINTLV_B8", "DINTLV_B16"]:

            self.dst = load_params.dst[0]
            self.dst1 = load_params.dst[1]
        else:

            self.dst = load_params.dst
            self.dst1 = None

        # src is ub
        self.src = load_params.src
        self.ld_mode = load_params.str_ld_mode

    def set_param(self, context, param, instr_list):
        """
        set param
        Parameters
        ----------
        instr_list
        context
        param

        Returns
        -------

        """
        if TikSocManager.is_v300_610l_soc():
            sm_idx = get_and_write_share_spr(context, 0, "uint32")
            param.smIdx = sm_idx
        else:
            am_idx = context.alloc_a_register(self.dst)
            param.amIdx = am_idx

            # gen vag instr for vloop
            vag_instr = gen_vag_instr(context, self.dst.dtype)
            instr_list.append(vag_instr)

        dst1_vd_idx = -1
        if self.dst1 is None:
            dst_vd_idx = context.alloc_v_register(self.dst)
        else:
            dst_vd_idx, dst1_vd_idx = context.alloc_v_register(self.dst,
                                                               is_even=True)
            context.init_vreg_according_cache(self.dst1, dst1_vd_idx)
        param.vdIdx = dst_vd_idx

        param.loop = 0
        return param, dst_vd_idx, dst1_vd_idx

    def eval_(self, context):
        """
        Vector Load eval
        Parameters
        ----------
        context: tik context
        Returns
        -------
        no returns
        """
        temp_env = TempEnv(require_xt=False)
        param = set_param_loop_vex_num_dtype(context, self.dst.dtype, 0, 1)
        instr_list = create_vloop_info(context, param, vld_loop_num=1)

        param.dist = DIST_VLD.get(self.ld_mode)
        # [sn] + Am is UB address, it's need aligned according ld_mode
        align = DIST_VLD_ALIGN.get(self.ld_mode)
        offset = get_flatten_idx(self.src, context)
        _, src_addr, _, _ = copy_tensor_to_model(
            context, temp_env, self.src, align, access_mode='r')
        vl_t = 256
        extent_map = {
            None: vl_t,
            'NORM': vl_t,
            'BRC_B8': DTYPE_SIZE.get(self.src.dtype),
            'BRC_B16': DTYPE_SIZE.get(self.src.dtype),
            'BRC_B32': DTYPE_SIZE.get(self.src.dtype),
            'US_B8': vl_t // 2,
            'US_B16': vl_t // 2,
            'DS_B8': vl_t * 2,
            'DS_B16': vl_t * 2,
            'BDINTLV': vl_t * 2,
            'DINTLV_B8': vl_t * 2,
            'DINTLV_B16': vl_t * 2,
            'UNPK_B8': vl_t // 2,
            'UNPK_B16': vl_t // 2,
        }
        check_extent_overflow(self.src, extent_map.get(self.ld_mode), offset, 'src')

        sn_idx = get_and_write_share_spr(
            context, src_addr + offset * DTYPE_SIZE.get(self.src.dtype), "uint32")
        param.snIdx = sn_idx

        param, dst_vd_idx, dst1_vd_idx = self.set_param(context, param, instr_list)
        if TikSocManager.is_v300_610l_soc():
            instr = context.encoder.gen_vector_load_vlds(param)
        else:
            instr = context.encoder.gen_vector_load(param)
        instr_list.append(instr)
        context.model.step_all(context, instr_list, len(instr_list))

        # check_mem_access failed, cannot find gm
        dst_register(context, (self.dst, dst_vd_idx, VecRegType.V_REG), is_merging=False)
        context.set_vector_state(self.dst, is_valid=True)

        if self.dst1 is not None:
            dst_register(context, (self.dst1, dst1_vd_idx, VecRegType.V_REG), is_merging=False)
            context.set_vector_state(self.dst1, is_valid=True)
        context.free_all_register()


class VectorLoadUnalign(STMT):
    """
    Vector load lda/ldu instruction
    """

    def __init__(self, source_info, unalign_params, tik_debugger):
        super(VectorLoadUnalign, self).__init__(source_info, tik_debugger)
        # dst is vector register
        self.dst = unalign_params.dst
        # ureg is alignment vector register
        self.ureg = unalign_params.ureg
        # src is ub
        self.src = unalign_params.src

    def set_param(self, context, param, instr_list):
        """
        set param
        Parameters
        ----------
        context
        param
        instr_list

        Returns
        -------

        """
        am_idx = context.alloc_a_register(self.ureg)
        param.amIdx = am_idx
        if not TikSocManager.is_v300_610l_soc():
            # gen vag instr for vloop
            vag_instr = gen_vag_instr(context, self.dst.dtype)
            instr_list.append(vag_instr)

        st_idx = get_and_write_share_spr(context, 0, "int16")
        param.stIdx = st_idx

        ureg_idx = context.alloc_u_register(self.ureg)
        param.udIdx = ureg_idx
        if TikSocManager.is_v300_610l_soc():
            instr_lda = context.encoder.gen_vector_load_vldas(param)
        else:
            instr_lda = context.encoder.gen_vector_load_vlda(param)
        instr_list.append(instr_lda)

        dst_vd_idx = context.alloc_v_register(self.dst)
        param.vdIdx = dst_vd_idx
        return param, dst_vd_idx

    def eval_(self, context):
        """
        Vector LoadUnalign eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        temp_env = TempEnv(require_xt=False)
        param = set_param_loop_vex_num_dtype(context, self.ureg.dtype, 0, 1)
        instr_list = create_vloop_info(context, param, vld_loop_num=2)

        # [sn] + Am is UB address, it's need not 32B aligned
        align = DTYPE_SIZE.get(self.src.dtype)
        offset = get_flatten_idx(self.src, context)
        _, src_addr, _, _ = copy_tensor_to_model(
            context, temp_env, self.src, align, access_mode='r')
        check_extent_overflow(self.src, 256, offset, 'src')
        sn_idx = get_and_write_share_spr(
            context, src_addr + offset * DTYPE_SIZE.get(self.src.dtype), "uint32")
        param.snIdx = sn_idx

        param, dst_vd_idx = self.set_param(context, param, instr_list)
        if TikSocManager.is_v300_610l_soc():
            instr_ldu = context.encoder.gen_vector_load_vldus(param)
        else:
            instr_ldu = context.encoder.gen_vector_load_vldu(param)
        execute_all_instr(context, instr_list, instr_ldu)
        dst_register(context, (self.dst, dst_vd_idx, VecRegType.V_REG), is_merging=False)
        context.set_vector_state(self.dst, is_valid=True)
        context.free_all_register()


class VectorVmov(STMT):
    """
    Vector vmov instruction
    """

    def __init__(self, source_info, vmov_params, tik_debugger):
        super(VectorVmov, self).__init__(source_info, tik_debugger)
        self.dst = vmov_params.dst
        self.src = vmov_params.src
        self.instr_name = vmov_params.name

    def set_param(self, context, param):
        """
        set param
        Parameters
        ----------
        context
        param

        Returns
        -------

        """
        param.pgIdx = 0
        param.type = 0

        vd_idx = context.alloc_v_register(self.dst)
        param.vdIdx = vd_idx
        vn_idx = context.alloc_v_register(self.src)
        param.vnIdx = vn_idx
        # just use vmIdx to pass param to encoder mode, not real Vm's index
        if not TikSocManager.is_v300_610l_soc():
            param.vmIdx = SOURCE_REGISTER1.get(self.instr_name)
        return param, vd_idx

    def tensor_register(self, context, vd_idx):
        """

        Returns
        -------

        """
        dst_register(context, (self.dst, vd_idx, VecRegType.V_REG), is_merging=False)
        context.set_vector_state(self.dst, is_valid=True)
        context.free_all_register()

    def eval_(self, context):
        """
        Vector Vmov eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        TempEnv()
        param = set_param_loop_vex_num_dtype(context, self.dst.dtype, 0, 1)
        instr_list = create_vloop_info(context, param)
        param, vd_idx = self.set_param(context, param)
        if TikSocManager.is_v300_610l_soc():
            param.op1 = V300_INSTR_OP1_CODE.get(self.instr_name)
        instr = context.encoder.gen_vector_single_elewise(param)
        execute_all_instr(context, instr_list, instr)
        self.tensor_register(context, vd_idx)
