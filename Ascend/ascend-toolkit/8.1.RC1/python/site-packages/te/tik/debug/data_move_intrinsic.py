#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     data_move_intrinsic.py
DESC:     tik data_move related api intrinsic
CREATED:  2021-10-25 14:04:45
MODIFIED: 2021-10-27 14:04:45
"""
from tbe.common.platform import scope_ubuf
from tbe.common.platform import scope_cbuf
from tbe.common.platform import scope_cc
from tbe.common.platform import scope_gm
from tbe.tik.api.tik_tensor import Tensor
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.util import ceil_div
from tbe.tik.common.util import TikUtil
from tbe.tik.common.common_util import vec_template_align
from tbe.tik.common.common_util import is_scalar
from tbe.tik.common.common_util import check_extent_overflow
from tbe.tik.common.common_util import set_tensor_addr_list_valid_idx
from tbe.tik.common.common_util import dma_align_fn
from tbe.tik.common.common_util import is_tensor
from tbe.tik.common.common_util import get_bit_len
from tbe.tik.debug.util import copy_tensor_to_model_from_addr
from tbe.tik.debug.util import copy_tensor_to_model
from tbe.tik.debug.util import model_with_env
from tbe.tik.debug.util import cvt_float_to_uint
from tbe.tik.debug.util import set_vector_mask
from tbe.tik.debug.intrinsic import get_src_mem_id
from tbe.tik.debug.intrinsic import get_dst_mem_id
from tbe.tik.debug.intrinsic import get_src_dst_mem_id
from tbe.tik.debug.intrinsic_v210_common import VEC_TYPE_BITS
from tbe.tik.debug.statement import STMT
from tbe.tik.debug.sim.util import TempEnv
from tbe.tik.debug.simd import set_mask_counter_mode
from tbe.tik.debug.simd import eval_mask
from tbe.tik.tik_lib.tik_params import ONE_BLK_SIZE
from tbe.tik.tik_lib.tik_params import MIN_BURST_LEN
from tbe.tik.tik_lib.tik_params import CONV_F162F32_NO_RELU
from tbe.tik.tik_lib.tik_params import CONV_F322F16_IS_RELU
from tbe.tik.tik_lib.tik_params import CONV_F322F16_NO_RELU
from tbe.tik.tik_lib.tik_params import BYTE_SIZE
from tbe.tik.tik_lib.tik_params import CONV_S322F16_QUANT
from tbe.tik.tik_lib.tik_params import CONV_S322F16_VECTOR_QUANT
from tbe.tik.tik_lib.tik_params import NO_CONV_IS_RELU
from tbe.tik.tik_lib.tik_params import SPR_CONFIG_BIT_LEN
from tbe.tik.tik_lib.tik_params import ALIGNED_ADDR
from tbe.tik.tik_lib.tik_params import CRMODE_DEQSCALE_VDEQ16
from tbe.tik.tik_lib.tik_params import CRMODE_DEQSCALE_DEQ16
from tbe.tik.tik_lib.tik_params import CONV_L0C16_DEQ
from tbe.tik.tik_lib.tik_params import CONV_S322B8_DEQ
from tbe.tik.tik_lib.tik_params import VALUE_BI_1010
from tbe.tik.tik_lib.tik_params import VALUE_BI_1100
from tbe.tik.tik_lib.tik_params import SHIFT_BIT_POS_47
from tbe.tik.tik_lib.tik_params import SHIFT_BIT_POS_2
from tbe.tik.tik_lib.tik_params import SHIFT_BIT_POS_56
from tbe.tik.tik_lib.tik_params import SHIFT_BIT_POS_48
from tbe.tik.tik_lib.tik_params import SRC_BLOCK_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import REPEAT_SHIFT_POS
from tbe.tik.tik_lib.tik_params import DST_REPEAT_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import SRC_REPEAT_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import ND2NZ_ND_NUM_SHIFT_POS
from tbe.tik.tik_lib.tik_params import ND2NZ_ND_N_SHIFT_POS
from tbe.tik.tik_lib.tik_params import ND2NZ_ND_D_SHIFT_POS
from tbe.tik.tik_lib.tik_params import ND2NZ_SRC_ND_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import ND2NZ_DST_C0_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import ND2NZ_DST_N_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import ND2NZ_DST_ND_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.tik_lib.tik_data_move_api.tik_data_move_common import FROM_TENSOR_TO_TENSOR
from tbe.tik.tik_lib.tik_data_move_api.tik_data_move_common import FROM_TENSORADDRLIST_TO_TENSORADDRLIST
from tbe.tik.tik_lib.tik_data_move_api.tik_data_move_common import FROM_TENSORADDRLIST_TO_TENSOR
from tbe.tik.tik_lib.tik_data_move_api.tik_data_move_common import FROM_TENSOR_TO_TENSORADDRLIST


_PAD_VALUE_SHIFT_BIT_POS = 8
_PAD_ITYPE_910B = 15
_PAD_ITYPE_910B_UB = 14
_PAD_ITYPE = 7
_PAD_ITYPE_UB = 6
_PAD_XT_RPADING_BIT = 8
_PAD_XT_DGAP_BIT = 32
_PAD_SPR_PADING_BIT = 32
_PAD_XM_NBURST_BIT = 4
_PAD_XM_BURST_BIT = 16
_PAD_XM_SGAP_BIT = 32
_PAD_XM_DGAP_BIT = 48
_PAD_XM_LPADING_BIT = 48
_PAD_XM_RPADING_BIT = 54
_VALUE_0 = 0
_MOVE_OP1_SHIFT_POS22 = 22
_MOVE_XD_SHIFT_POS17 = 17
_MOVE_XN_SHIFT_POS12 = 12
_MOVE_XM_SHIFT_POS7 = 7
_MOVE_XT_SHIFT_POS3 = 3
_PAD_XT_SHIFT_POS2 = 2

NBURST_SHIFT_BIT_POS = 4
BURST_SHIFT_BIT_POS = 16
SRC_STRIDE_SHIFT_BIT_POS = 32
DST_STRIDE_SHIFT_BIT_POS = 48
_DATA_MOVE_PAD_OUT_TO_UB = 2
_DATA_MOVE_PAD_UB_TO_OUT = 3


_ND2NZ_TYPE_ENCODING = {
    'uint8': 0b00,
    'int8': 0b00,
    'uint16': 0b01,
    'int16': 0b01,
    'float16': 0b01,
    'uint32': 0b10,
    'int32': 0b10,
    'float32': 0b10,
}


def get_data_move_dst_extent(params, dtype, offset, burst_gap_unit=ONE_BLK_SIZE):
    """
    Function for calculate DataMove dst extent list. Save the access list of start and end index of tensor.
    Parameters
    ----------
    params: contains nburst burst gap
    dtype: tensor dtype
    offset: tensor access offset
    burst_gap_unit: burst and gap unit, default is 32Bytes,  data_move_pad is 1Bytes

    Returns
    -------
    [[start1, end1], [start2, end2], ...]
    """
    nburst, burst, gap = params
    access_list = []
    start_index = offset
    burst_ele_nums = ceil_div(burst * burst_gap_unit, DTYPE_SIZE[dtype])
    gap_ele_nums = ceil_div(gap * burst_gap_unit, DTYPE_SIZE[dtype])
    if gap == 0:
        end_index = start_index + nburst * burst_ele_nums
        access_list.append([start_index, end_index])
    else:
        for _ in range(nburst):
            end_index = start_index + burst_ele_nums
            access_list.append([start_index, end_index])
            start_index = end_index + gap_ele_nums
    return access_list


def _generate_instruction(encoder, param):
    """
    generating instruction codes based on chip types.
    """
    if TikSocManager.is_610l_soc():
        instr = encoder.gen_dma_mov_610lite(param)
    elif TikSocManager.is_910b_soc() or TikSocManager.is_310b_soc():
        instr = encoder.gen_dma_mov_910b(param)
    else:
        instr = encoder.gen_dma_mov(param)
    return instr


def _get_value(obj, context, is_tensor_mov=False):
    """
    get param value
    """
    value = {
        "nburst": context.evaluate_expr(obj.dm_obj.nburst),
        "burst_len": context.evaluate_expr(obj.dm_obj.burst),
        "src_stride": context.evaluate_expr(obj.dm_obj.src_stride),
        "dst_stride": context.evaluate_expr(obj.dm_obj.dst_stride)
    }

    if not is_tensor_mov:
        value['sid'] = context.evaluate_expr(obj.dm_obj.sid)
    return value


def _create_gpr_x_m(context, temp_env, params_value):
    """
    create register x_m

    Parameters
    ----------
    context : the stack context
    temp_env : the temp environment
    params_value:

    Returns
    -------
    xm_idx
    """
    xm_idx = temp_env.alloc_register()
    xm_v = _VALUE_0
    xm_v |= params_value.get('sid')
    xm_v |= params_value.get('nburst') << NBURST_SHIFT_BIT_POS
    xm_v |= params_value.get('burst_len') << BURST_SHIFT_BIT_POS
    xm_v |= params_value.get('src_stride') << SRC_STRIDE_SHIFT_BIT_POS
    xm_v |= params_value.get('dst_stride') << DST_STRIDE_SHIFT_BIT_POS
    model_with_env(context.model.write_gpr, temp_env, xm_idx, xm_v)

    return xm_idx


def _create_gpr_xn_xd_memid(dm_obj, context, temp_env):
    """
    create register xn xd ..., used to generate instruction codes.
    Parameters
    ----------
    dm_obj: instruction object
    context: the stack context
    temp_env: TempEnv class object

    Returns
    -------
    xn_idx, xd_idx, dst_addr, dst_alloc_size, dst_ptr, mem_id
    """
    src_align, dst_align = dma_align_fn(dm_obj.src, dm_obj.dst)
    xn_idx, _, _, _ = copy_tensor_to_model(
        context, temp_env, dm_obj.src, src_align, access_mode='r')
    xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
        context, temp_env, dm_obj.dst, dst_align, access_mode='w')
    mem_id = get_src_dst_mem_id(dm_obj.src, dm_obj.dst)[:2]

    return [xn_idx, xd_idx, dst_addr, dst_alloc_size, dst_ptr, mem_id]


def context_append_access_list(context, locked, dst, params, is_mov_pad=False):
    """
    When locked is True, context add access_list

    Parameter
    ---------
    context: the stack context
    locked: data_move's dst is GM buffer, need to lock it
    Returns
    -------
    no return
    """
    if locked is False:  # check output gm info and workspace tensor
        return

    if is_mov_pad:
        gap_unit = MIN_BURST_LEN
    else:
        gap_unit = ONE_BLK_SIZE
    var = context.get_var_by_name("blockIdx.x")  # get the var of block index
    if var is not None:  # var cannot be None, if it's None, evaluate_expr will cannot exit
        block_idx = context.evaluate_expr(var)
        # var_table may be has the var "blockIdx.x", but the var may be cannot evaluate the value
        if isinstance(block_idx, int):
            # according access parameters, calculate the dst access address info
            access_list = get_data_move_dst_extent(params, dst.dtype, context.get_tensor_offset(dst), gap_unit)
            for access in access_list:
                access.append(context.atomic_add_value)
            # save the access info for check multi-core access tread
            context.gm_tensor_access_info[block_idx][dst.buffer.name].append(access_list)


def _release_lock(context, locked):
    if locked is True:
        context.gm_lock.release()  # release the lock


def _get_locked(context, dst):
    locked = False
    # if data_move's dst is GM buffer, need to lock it
    if dst.scope == scope_gm and dst.buffer not in context.placeholders.values():
        # only with multi-core, context.gm_lock is not None
        if context.gm_lock:
            context.gm_lock.acquire()  # get the lock
            locked = True
    return locked


def get_instr_and_xt_code_610l(key):
    if key == "UB L1":
        instr = 0b0111000010
        xt = 0b100
    elif key == "L1 UB":
        instr = 0b0111001000
        xt = 0b001
    else:
        instr = 0b0111000100
        xt = 0b100
    return instr, xt


class DataMove(STMT):
    """
    DataMove instruction
    """

    def __init__(self, source_info, dm_obj):
        super(DataMove, self).__init__(source_info, dm_obj.tik_instance.context.tik_debugger)
        self.dm_obj = dm_obj
        if TikSocManager.is_v300_610l_soc():
            self.source_id = dm_obj.tik_instance.context.debug_source_id

    def check_610lite_instr_mapping(self):
        """
        If ARCH is 610lite, use the data_move_pad's debug
        Parameters
        ----------
        src: src tensor
        dst: dst tensor

        Returns
        -------
        True or False
        """
        src_key_str = TikUtil.get_storage_scope(self.dm_obj.src.scope)
        dst_key_str = TikUtil.get_storage_scope(self.dm_obj.dst.scope)
        key = src_key_str + " " + dst_key_str
        if TikSocManager.is_610l_soc() and key in ("UB OUT", "OUT UB", "L1 OUT"):
            return True
        else:
            return False

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        if self.check_610lite_instr_mapping():
            return
        params_value = _get_value(self, context)
        # check params
        self.dm_obj.check.check_all(params_value)
        TikCheckUtil.check_atomic_add(context.atomic_add_value, self.dm_obj.dst)
        if self.set_source_id(context):
            return
        is_aic_api = self.dm_obj.src.scope in (scope_cbuf, scope_cc) or self.dm_obj.dst.scope in (scope_cbuf, scope_cc)
        temp_env = TempEnv(is_aic_api=is_aic_api)
        locked = False
        try:
            locked = _get_locked(context, self.dm_obj.dst)

            xn_idx, xd_idx, dst_addr, dst_alloc_size, dst_ptr, mem_id = \
                self.create_gpr_xn_xd(context, temp_env, params_value)

            encoder = context.encoder
            param = encoder.new_param()
            param.convRelu = _VALUE_0
            param.pad = _VALUE_0
            param.xd = xd_idx
            param.xn = xn_idx
            if TikSocManager.is_610l_soc():
                self.set_610lite_param(param)
            param.xm = _create_gpr_x_m(context, temp_env, params_value)

            param.srcMemId, param.dstMemId = mem_id
            src_key_str = TikUtil.get_storage_scope(self.dm_obj.src.scope)
            dst_key_str = TikUtil.get_storage_scope(self.dm_obj.dst.scope)
            key = src_key_str + " " + dst_key_str
            if TikSocManager.is_610l_soc() and key in ["UB L1", "L1 UB", "OUT L1"]:
                instr, xt = get_instr_and_xt_code_610l(key)
                instr = instr << _MOVE_OP1_SHIFT_POS22
                instr += param.xd << _MOVE_XD_SHIFT_POS17
                instr += param.xn << _MOVE_XN_SHIFT_POS12
                instr += param.xm << _MOVE_XM_SHIFT_POS7
                instr += xt << _MOVE_XT_SHIFT_POS3
            else:
                instr = _generate_instruction(encoder, param)
            model_with_env(context.model.step, temp_env, instr)
            dst_scope = self._get_dst_scope(temp_env, context)
            model_with_env(context.model.read_memory, temp_env, dst_addr, dst_scope, dst_ptr, dst_alloc_size)
            context_append_access_list(
                context, locked, self.dm_obj.dst, [params_value.get('nburst'),
                                                   params_value.get('burst_len'), params_value.get('dst_stride')])
        finally:
            _release_lock(context, locked)

    def set_source_id(self, context):
        """
        set debug source id for run instruction

        Parameters
        ----------
        context: tik context

        Returns
        -------
        True or False

        """
        if TikSocManager.is_v300_610l_soc() and self.dm_obj.src.scope == scope_ubuf and \
                self.dm_obj.dst.scope == scope_ubuf:
            context.step_next(self.source_id)
            return True
        else:
            return False

    def set_610lite_param(self, param):
        """
        set param's type for 610lite

        Parameters
        ----------
        param: instrction's param

        Returns
        -------
        None

        """
        if DTYPE_SIZE[self.dm_obj.dst.dtype] == 1:
            param_type = 0
        elif DTYPE_SIZE[self.dm_obj.dst.dtype] == 2:
            param_type = 1
        else:
            param_type = 2
        if self.dm_obj.src.scope == scope_gm and self.dm_obj.dst.scope == scope_ubuf:
            param.type += param_type

    def create_gpr_xn_xd(self, context, temp_env, params_value):
        """
        create_gpr_xn_xd
        """
        src_align, dst_align = dma_align_fn(self.dm_obj.src, self.dm_obj.dst)
        if self.dm_obj.data_move_mode == FROM_TENSOR_TO_TENSORADDRLIST:
            xn_idx, _, src_alloc_size, _ = copy_tensor_to_model(
                context, temp_env, self.dm_obj.src, src_align, access_mode='r')
            temp_env.dst_dtype = self.dm_obj.src.dtype
            xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model_from_addr(
                context, temp_env, self.dm_obj.dst, src_alloc_size, access_mode='w')
            mem_id = get_src_mem_id(self.dm_obj.src), get_dst_mem_id(self.dm_obj.dst, is_tensor_addr=True)
        elif self.dm_obj.data_move_mode == FROM_TENSORADDRLIST_TO_TENSOR:
            xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
                context, temp_env, self.dm_obj.dst, dst_align, access_mode='w')
            temp_env.dst_dtype = self.dm_obj.dst.dtype
            xn_idx, _, _, _ = copy_tensor_to_model_from_addr(
                context, temp_env, self.dm_obj.src, dst_alloc_size, access_mode='r')
            mem_id = get_src_mem_id(self.dm_obj.src, is_tensor_addr=True), get_dst_mem_id(self.dm_obj.dst)
        else:
            if self.dm_obj.data_move_mode == FROM_TENSORADDRLIST_TO_TENSORADDRLIST:
                set_tensor_addr_list_valid_idx(context.tensor_addr_list_valid_idx,
                                               context.buffer2static_parameters[id(self.dm_obj.dst)]["static_data"],
                                               self.dm_obj.dst.buffer,
                                               params_value.get('nburst') * params_value.get(
                                                   'burst_len') * ONE_BLK_SIZE)
            xn_idx, xd_idx, dst_addr, dst_alloc_size, dst_ptr, mem_id = \
                _create_gpr_xn_xd_memid(self.dm_obj, context, temp_env)

        return [xn_idx, xd_idx, dst_addr, dst_alloc_size, dst_ptr, mem_id]

    def _get_dst_scope(self, temp_env, context):
        dst_scope = self.dm_obj.dst.scope
        if self.dm_obj.data_move_mode == FROM_TENSOR_TO_TENSORADDRLIST:
            dst_scope = scope_gm
        elif self.dm_obj.data_move_mode in [FROM_TENSORADDRLIST_TO_TENSORADDRLIST, FROM_TENSOR_TO_TENSOR]:
            temp_env.check_mem_access(context.model, True)
        return dst_scope


class DataMoveQuant(STMT):
    """
    DataMoveDeQuant instruction
    """

    def __init__(self, source_info, dmq_obj):
        super(DataMoveQuant, self).__init__(source_info, dmq_obj.tik_instance.context.tik_debugger)
        self.dm_obj = dmq_obj

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        params_value = _get_value(self, context)
        self.dm_obj.check.check_all(params_value)
        temp_env = TempEnv()

        xn_idx, xd_idx, dst_addr, dst_alloc_size, dst_ptr, mem_id = \
            _create_gpr_xn_xd_memid(self.dm_obj, context, temp_env)

        encoder = context.encoder
        param = encoder.new_param()
        param.convRelu = self.get_conv_relu_param(context, temp_env)
        param.pad = _VALUE_0
        param.xd = xd_idx
        param.xn = xn_idx
        param.xm = _create_gpr_x_m(context, temp_env, params_value)
        param.srcMemId, param.dstMemId = mem_id
        context.model.step(_generate_instruction(encoder, param))
        temp_env.check_mem_access(context.model, True)

        context.model.read_memory(dst_addr, self.dm_obj.dst.scope, dst_ptr, dst_alloc_size)

    def get_conv_relu_param(self, context, temp_env):
        """
        get conv_relu_param

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        conv_relu_param
        """
        conv_relu_param = _VALUE_0
        if (self.dm_obj.src.dtype, self.dm_obj.dst.dtype) == ('float32', 'float16'):
            if self.dm_obj.relu_flag:
                conv_relu_param = CONV_F322F16_IS_RELU
            else:
                conv_relu_param = CONV_F322F16_NO_RELU

        elif (self.dm_obj.src.dtype, self.dm_obj.dst.dtype) == ('int32', 'float16'):
            if is_tensor(self.dm_obj.quant_param) is True:
                conv_relu_param = CONV_S322F16_VECTOR_QUANT
                _, deq_addr, _, _ = copy_tensor_to_model(
                    context, temp_env, self.dm_obj.quant_param, ALIGNED_ADDR, access_mode='r')
                # 1  -> 32byte
                deq_spr = deq_addr
                deq_spr = deq_spr // BYTE_SIZE
                if self.dm_obj.relu_flag:
                    deq_spr |= 1 << SPR_CONFIG_BIT_LEN
                context.model.write_spr('DEQSCALE', deq_spr)
            else:
                conv_relu_param = CONV_S322F16_QUANT
                quant_param = context.evaluate_expr(self.dm_obj.quant_param)
                binary_value = cvt_float_to_uint(self.dm_obj.dst.dtype, quant_param)
                context.model.write_spr('DEQSCALE', binary_value)
        elif (self.dm_obj.src.dtype, self.dm_obj.dst.dtype) == ('float16', 'float32'):
            conv_relu_param = CONV_F162F32_NO_RELU
        elif self.dm_obj.src.dtype == self.dm_obj.dst.dtype and self.dm_obj.relu_flag:
            conv_relu_param = NO_CONV_IS_RELU

        return conv_relu_param


class TensorMove(STMT):
    """
    TensorMove instruction
    """

    def __init__(self, source_info, tm_obj):
        super(TensorMove, self).__init__(source_info, tm_obj.tik_instance.context.tik_debugger)
        self.dm_obj = tm_obj
        if TikSocManager.is_v300_610l_soc():
            self.source_id = tm_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        if TikSocManager.is_v300_610l_soc() and self.dm_obj.src.scope == scope_ubuf and \
                self.dm_obj.dst.scope == scope_ubuf:
            context.step_next(self.source_id)
            return True
        src_key_str = TikUtil.get_storage_scope(self.dm_obj.src.scope)
        dst_key_str = TikUtil.get_storage_scope(self.dm_obj.dst.scope)
        key = src_key_str + " " + dst_key_str
        if TikSocManager.is_610l_soc() and key in ("UB OUT", "OUT UB"):
            return True
        src_align, dst_align = dma_align_fn(self.dm_obj.src, self.dm_obj.dst)

        temp_env = TempEnv()

        xn_idx, _, _, _ = copy_tensor_to_model(context, temp_env, self.dm_obj.src, src_align, access_mode='r')

        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.dm_obj.dst, dst_align, access_mode='w')

        encoder = context.encoder
        param = encoder.new_param()

        param.xm, deq_scale_val = self.create_gpr_x_m(context, temp_env, _get_value(self, context, True))

        param.srcMemId, param.dstMemId, src_scope_name = get_src_dst_mem_id(
            self.dm_obj.src, self.dm_obj.dst, self.dm_obj.block_mode)

        param.convRelu = self.get_conv_relu_param(context, temp_env, src_scope_name, deq_scale_val)

        param.pad = self.dm_obj.pad_mode
        param.xd = xd_idx
        param.xn = xn_idx
        self.set_spr_padding(context)
        context.model.step(_generate_instruction(encoder, param))
        temp_env.check_mem_access(context.model, True)

        context.model.read_memory(dst_addr, self.dm_obj.dst.scope, dst_ptr, dst_alloc_size)

    def set_spr_padding(self, context):
        """
        set spr PADDING

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        pad_value = context.evaluate_expr(self.dm_obj.pad_value)
        if self.dm_obj.pad_mode == 1:
            pad_value |= pad_value << _PAD_VALUE_SHIFT_BIT_POS
        context.model.write_spr('PADDING', pad_value)

    def write_deqscale_buffer(self, context, temp_env, deq_scale_val):
        """
        write deqscale buffer

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment
        deq_scale_val: SPR DEQSCALE value

        Returns
        -------
        deq_scale_val
        """
        _, deq_addr, _, _ = copy_tensor_to_model(context, temp_env, self.dm_obj.deqscale, ONE_BLK_SIZE)
        deq_addr += context.evaluate_expr(self.dm_obj.deqscale.offset) * DTYPE_SIZE[self.dm_obj.deqscale.dtype]

        # unit: 32B
        deq_spr = deq_addr // ONE_BLK_SIZE

        deq_spr |= int(self.dm_obj.relu) << SPR_CONFIG_BIT_LEN

        deq_scale_val |= deq_spr
        return deq_scale_val

    def get_conv_relu_param(self, context, temp_env, src_scope_name, deq_scale_val):
        """
        get conv_relu_param

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        conv_relu_param
        """
        if (self.dm_obj.src.dtype, self.dm_obj.dst.dtype) == ('float32', 'float16'):
            if self.dm_obj.relu:
                conv_relu_param = CONV_F322F16_IS_RELU
            else:
                conv_relu_param = CONV_F322F16_NO_RELU

        elif (self.dm_obj.src.dtype, self.dm_obj.dst.dtype) == ('int32', 'float16'):
            if is_tensor(self.dm_obj.deqscale):
                if TikSocManager.is_hisi_sd_cs():
                    conv_relu_param = CRMODE_DEQSCALE_VDEQ16
                else:
                    conv_relu_param = CONV_S322F16_VECTOR_QUANT
                deq_scale_val = self.write_deqscale_buffer(context, temp_env, deq_scale_val)
            else:
                if TikSocManager.is_hisi_sd_cs():
                    conv_relu_param = CRMODE_DEQSCALE_DEQ16
                else:
                    conv_relu_param = CONV_S322F16_QUANT
                quant_param = context.evaluate_expr(self.dm_obj.deqscale)
                binary_value = cvt_float_to_uint(self.dm_obj.dst.dtype, quant_param)
                deq_scale_val |= binary_value
        elif (self.dm_obj.src.dtype, self.dm_obj.dst.dtype) == ('float16', 'float32'):
            conv_relu_param = CONV_F162F32_NO_RELU
        else:
            conv_relu_param, deq_scale_val = self.get_crd_expansion(
                context, temp_env, deq_scale_val, src_scope_name)

        context.model.write_spr('DEQSCALE', deq_scale_val)

        return conv_relu_param

    def get_crd_expansion(self, context, temp_env, deq_scale_val, src_scope_name):
        """
        get conv_relu_param and deq_scale_val based on different src/dst type

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment
        deq_scale_val: DEQSCALE value
        src_scope_name: tranformed src scope name

        Returns
        -------
        conv_relu_param
        deq_scale_val
        """
        conv_relu_param = _VALUE_0
        if self.dm_obj.src.dtype == self.dm_obj.dst.dtype and self.dm_obj.relu:
            conv_relu_param = NO_CONV_IS_RELU
        elif src_scope_name in ('L0C16', 'L0C16V') and self.dm_obj.deqscale is not None:
            conv_relu_param = CONV_L0C16_DEQ
            quant_param = context.evaluate_expr(self.dm_obj.deqscale)
            binary_value = cvt_float_to_uint(self.dm_obj.dst.dtype, quant_param)
            deq_scale_val |= binary_value
        elif self.dm_obj.src.dtype == 'int32' and self.dm_obj.dst.dtype in ('int8', 'uint8'):
            conv_relu_param, deq_scale_val = self.get_crd_param(
                context, temp_env, deq_scale_val, CONV_S322B8_DEQ)
        elif (self.dm_obj.src.dtype, self.dm_obj.dst.dtype) == ('int32', 'float16'):
            conv_relu_param, deq_scale_val = self.get_crd_param(
                context, temp_env, deq_scale_val, VALUE_BI_1010)
        elif (self.dm_obj.src.dtype, self.dm_obj.dst.dtype) == ('int32', 'int16'):
            conv_relu_param, deq_scale_val = self.get_crd_param(
                context, temp_env, deq_scale_val, VALUE_BI_1100)

        return conv_relu_param, deq_scale_val

    def get_crd_param(self, context, temp_env, deq_scale_val, cr_t):
        """
        get conv_relu_param and deq_scale_val

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment
        deq_scale_val: DEQSCALE value
        cr_t: conv relu param tensor
        cr_s: conv relu param scalar/int

        Returns
        -------
        conv_relu_param: conv relu param
        deq_scale_val: new deq_scale_val
        """
        if is_tensor(self.dm_obj.deqscale):
            conv_relu_param = cr_t
            deq_scale_val = self.write_deqscale_buffer(context, temp_env, deq_scale_val)
        elif isinstance(self.dm_obj.deqscale, int) or is_scalar(self.dm_obj.deqscale):
            conv_relu_param = cr_t + 1
            deq_scale_val = context.evaluate_expr(self.dm_obj.deqscale)
            deq_scale_val |= int(self.dm_obj.relu) << SHIFT_BIT_POS_47

        return conv_relu_param, deq_scale_val

    def create_gpr_x_m(self, context, temp_env, params_value):
        """
        get param.xm

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xm_idx
        """
        xm_idx = temp_env.alloc_register()
        self.dm_obj.check.check_all(params_value)
        xm_v = 0
        xm_v |= context.evaluate_expr(self.dm_obj.sid_store_mode)
        if self.dm_obj.src.scope == scope_cc and self.dm_obj.dst.scope == scope_ubuf:
            xm_v |= self.dm_obj.onthefly_mode << SHIFT_BIT_POS_2
        xm_v |= params_value.get('nburst') << NBURST_SHIFT_BIT_POS
        xm_v |= params_value.get('burst_len') << BURST_SHIFT_BIT_POS
        xm_v |= params_value.get('src_stride') << SRC_STRIDE_SHIFT_BIT_POS
        xm_v |= params_value.get('dst_stride') << DST_STRIDE_SHIFT_BIT_POS

        deq_scale_val = _VALUE_0
        if self.dm_obj.src.scope == scope_cc and self.dm_obj.dst.scope == scope_ubuf \
                and self.dm_obj.onthefly_mode > _VALUE_0:
            xm_v |= self.dm_obj.src_onthefly_stride << SHIFT_BIT_POS_56
            # align is 65536 for dst and src_onthefly cannot in the same 64KB
            old_check_align = temp_env.check_align
            temp_env.check_align = False
            _, onthefly_addr, _, _ = copy_tensor_to_model(
                context, temp_env, self.dm_obj.src_onthefly, 65536, access_mode='r')
            temp_env.check_align = old_check_align
            onthefly_addr += context.evaluate_expr(self.dm_obj.src_onthefly.offset) \
                             * DTYPE_SIZE[self.dm_obj.src_onthefly.dtype]
            onthefly_addr = onthefly_addr // ONE_BLK_SIZE
            deq_scale_val |= onthefly_addr << SHIFT_BIT_POS_48

        context.model.write_gpr(xm_idx, xm_v)
        return xm_idx, deq_scale_val


class MovPad(STMT):
    """
    DataMove instruction
    """
    def __init__(self, source_info, dmp_obj):
        super(MovPad, self).__init__(source_info, dmp_obj.tik_instance.context.tik_debugger)
        self.dm_obj = dmp_obj
        self.sid = _VALUE_0
        self.nburst_value = None
        self.burst_value = None
        self.dst_gap_value = None
        self.src_gap_value = None
        self.right_padding_value = None
        self.left_padding_value = None

    def create_gpr_xn_xd(self, context, temp_env, ):
        src_align, dst_align = self._get_src_dst_align()
        if self.dm_obj.data_move_mode == FROM_TENSOR_TO_TENSORADDRLIST:
            xn_idx, _, src_alloc_size, _ = copy_tensor_to_model(
                context, temp_env, self.dm_obj.src, src_align, access_mode='r')
            temp_env.dst_dtype = self.dm_obj.src.dtype
            xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model_from_addr(
                context, temp_env, self.dm_obj.dst, src_alloc_size, access_mode='w')
            mem_id = get_src_mem_id(self.dm_obj.src), get_dst_mem_id(self.dm_obj.dst, is_tensor_addr=True)
        elif self.dm_obj.data_move_mode == FROM_TENSORADDRLIST_TO_TENSOR:
            xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
                context, temp_env, self.dm_obj.dst, dst_align, access_mode='w')
            temp_env.dst_dtype = self.dm_obj.dst.dtype
            xn_idx, _, _, _ = copy_tensor_to_model_from_addr(
                context, temp_env, self.dm_obj.src, dst_alloc_size, access_mode='r')
            mem_id = get_src_mem_id(self.dm_obj.src, is_tensor_addr=True), get_dst_mem_id(self.dm_obj.dst)
        else:
            xn_idx, xd_idx, dst_addr, dst_alloc_size, dst_ptr, mem_id = \
                _create_gpr_xn_xd_memid(self.dm_obj, context, temp_env)
        return [xn_idx, xd_idx, dst_addr, dst_alloc_size, dst_ptr, mem_id]

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        self._set_context_value(context)
        temp_env = TempEnv()

        self._move_pad_check_all(context)

        locked = False
        try:
            locked = _get_locked(context, self.dm_obj.dst)

            xn_idx, xd_idx, dst_addr, dst_alloc_size, dst_ptr, mem_id = \
                self.create_gpr_xn_xd(context, temp_env)
            param = context.encoder.new_vec_param()
            param.xdIdx = xd_idx
            param.xnIdx = xn_idx
            self._set_xm_xt_with_soc(context, param, temp_env)

            self._spr_write_padding_value(context)
            if self.dm_obj.dst.dtype == "int64":
                param.type = VEC_TYPE_BITS["int32"]
            else:
                param.type = VEC_TYPE_BITS[self.dm_obj.dst.dtype]
            src_key_str = TikUtil.get_storage_scope(self.dm_obj.src.scope)
            dst_key_str = TikUtil.get_storage_scope(self.dm_obj.dst.scope)
            key = src_key_str + " " + dst_key_str
            if TikSocManager.is_610l_soc() and key == "L1 OUT":
                param.op1 = 0b110100111
                instr = param.op1 << _MOVE_OP1_SHIFT_POS22
                instr += param.xdIdx << _MOVE_XD_SHIFT_POS17
                instr += param.xnIdx << _MOVE_XN_SHIFT_POS12
                instr += param.xmIdx << _MOVE_XM_SHIFT_POS7
                instr += param.xtIdx << _PAD_XT_SHIFT_POS2
            else:
                instr = context.encoder.gen_data_move_pad(param)
            context.model.step(instr)
            temp_env.check_mem_access(context.model, False)
            context.model.read_memory(dst_addr, self.dm_obj.dst.scope, dst_ptr, dst_alloc_size)
            context_append_access_list(context, locked, self.dm_obj.dst,
                                       [self.nburst_value, self.burst_value, self.dst_gap_value], True)
        finally:
            _release_lock(context, locked)

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        xt_idx = temp_env.alloc_register()
        x_t = self.left_padding_value
        x_t |= self.right_padding_value << _PAD_XT_RPADING_BIT
        context.model.write_gpr(xt_idx, x_t)
        return xt_idx

    def create_gpr_x_t_910b(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        xt_idx = temp_env.alloc_register()
        x_t = self.src_gap_value
        x_t |= self.dst_gap_value << _PAD_XT_DGAP_BIT
        context.model.write_gpr(xt_idx, x_t)
        return xt_idx

    def get_spr_pad_value(self):
        """
        get spr value
        """
        if self.dm_obj.dst.dtype in ["float16", "float32", "bfloat16"]:
            spr_pad_value = cvt_float_to_uint(self.dm_obj.dst.dtype, self.dm_obj.padding_value)
        else:
            spr_pad_value = int(self.dm_obj.padding_value)
            spr_pad_value |= int(self.dm_obj.padding_value) << _PAD_SPR_PADING_BIT
        return spr_pad_value

    def create_gpr_x_m(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        xm_idx = temp_env.alloc_register()
        x_m = self.sid
        x_m |= self.nburst_value << _PAD_XM_NBURST_BIT
        x_m |= self.burst_value << _PAD_XM_BURST_BIT
        x_m |= self.src_gap_value << _PAD_XM_SGAP_BIT
        x_m |= self.dst_gap_value << _PAD_XM_DGAP_BIT

        context.model.write_gpr(xm_idx, x_m)
        return xm_idx

    def create_gpr_x_m_910b(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        xm_idx = temp_env.alloc_register()
        x_m = self.sid
        x_m |= self.nburst_value << _PAD_XM_NBURST_BIT
        x_m |= self.burst_value << _PAD_XM_BURST_BIT
        x_m |= self.left_padding_value << _PAD_XM_LPADING_BIT
        x_m |= self.right_padding_value << _PAD_XM_RPADING_BIT

        context.model.write_gpr(xm_idx, x_m)
        return xm_idx

    def _set_context_value(self, context):
        self.nburst_value = context.evaluate_expr(self.dm_obj.nburst)
        self.burst_value = context.evaluate_expr(self.dm_obj.burst)
        self.dst_gap_value = context.evaluate_expr(self.dm_obj.dst_gap)
        self.src_gap_value = context.evaluate_expr(self.dm_obj.src_gap)
        self.right_padding_value = context.evaluate_expr(self.dm_obj.right_padding)
        self.left_padding_value = context.evaluate_expr(self.dm_obj.left_padding)

    def _get_src_dst_align(self):
        # tensor_stride âˆˆ [0, 2**32-1]
        # if scope is OUT, 1Byte
        src_align = 1
        dst_align = 1
        #  if scope is UB, 32Byte,
        if self.dm_obj.src.scope == scope_ubuf:
            src_align = ONE_BLK_SIZE
        if self.dm_obj.dst.scope == scope_ubuf:
            dst_align = ONE_BLK_SIZE

        return src_align, dst_align

    def _move_pad_check_all(self, context):
        TikCheckUtil.check_atomic_add(context.atomic_add_value, self.dm_obj.dst)

        self.dm_obj.check.check_mov_pad_instr_params([self.nburst_value, self.burst_value,
                                                      self.dst_gap_value, self.src_gap_value,
                                                      self.right_padding_value, self.left_padding_value])
        # The 610lite data move instruction is implemented through the data move pad,
        # and overflow interception is not required.
        if not (TikSocManager.is_610l_soc() and self.dm_obj.name == "data_move"):
            dst_extent = self.dm_obj.get_mov_pad_tensor_extent()
            src_extent = self.dm_obj.get_mov_pad_tensor_extent(is_src=True)
            dst_offset = context.get_tensor_offset(self.dm_obj.dst)
            src_offset = context.get_tensor_offset(self.dm_obj.src)
            if isinstance(self.dm_obj.dst, Tensor):
                check_extent_overflow(self.dm_obj.dst, context.evaluate_expr(dst_extent), dst_offset, "dst",
                                      context.get_tensor_original_shape(self.dm_obj.dst))
            if isinstance(self.dm_obj.src, Tensor):
                check_extent_overflow(self.dm_obj.src, context.evaluate_expr(src_extent), src_offset, "src",
                                      context.get_tensor_original_shape(self.dm_obj.src))

    def _spr_write_padding_value(self, context):
        # write padding_value to SPR
        if self.dm_obj.padding_value is not None:
            context.model.write_spr("MOV_PAD_VAL", self.get_spr_pad_value())

    def _set_xm_xt_with_soc(self, context, param, temp_env):
        if TikSocManager.is_910b_soc():
            param.xmIdx = self.create_gpr_x_m_910b(context, temp_env)
            param.xtIdx = self.create_gpr_x_t_910b(context, temp_env)
            param.itype = _PAD_ITYPE_910B
            if self.dm_obj.dst.scope == scope_ubuf and isinstance(self.dm_obj.dst, Tensor):
                param.itype = _PAD_ITYPE_910B_UB
        elif TikSocManager.is_v300_610l_soc():
            param.isV300 = 1
            if self.dm_obj.dst.scope == scope_ubuf and isinstance(self.dm_obj.dst, Tensor):
                # data move out to ub
                param.path = _DATA_MOVE_PAD_OUT_TO_UB
            else:
                # data move ub to out
                param.path = _DATA_MOVE_PAD_UB_TO_OUT
            param.xmIdx = self.create_gpr_x_m_910b(context, temp_env)
            param.xtIdx = self.create_gpr_x_t_910b(context, temp_env)
        else:
            param.xmIdx = self.create_gpr_x_m(context, temp_env)
            param.xtIdx = self.create_gpr_x_t(context, temp_env)
            param.itype = _PAD_ITYPE
            if self.dm_obj.dst.scope == scope_ubuf and isinstance(self.dm_obj.dst, Tensor):
                param.itype = _PAD_ITYPE_UB


class MovNd2Nz(STMT):
    """
    DataMove instruction
    """
    def __init__(self, source_info, dm_obj):
        super(MovNd2Nz, self).__init__(source_info, dm_obj.tik_instance.context.tik_debugger)
        self.dst = dm_obj.dst
        self.src = dm_obj.src
        self.nd_num = dm_obj.nd_num
        self.nd_n = dm_obj.nd_n
        self.nd_d = dm_obj.nd_d
        self.src_nd_stride = dm_obj.src_nd_stride
        self.src_n_stride = dm_obj.src_n_stride
        self.dst_c0_stride = dm_obj.dst_c0_stride
        self.dst_n_stride = dm_obj.dst_n_stride
        self.dst_nd_stride = dm_obj.dst_nd_stride

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        src_align = 1
        dst_align = vec_template_align(self.dst.dtype)
        temp_env = TempEnv(is_aic_api=True)
        xn_idx, _, _, _ = copy_tensor_to_model(
            context, temp_env, self.src, src_align, access_mode='r')
        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.dst, dst_align, access_mode='w')
        # gen instr encode
        param = context.encoder.new_param()
        param.type = _ND2NZ_TYPE_ENCODING[self.src.dtype]
        param.xd = xd_idx
        param.xn = xn_idx
        param.xm = self.create_gpr_x_m(context, temp_env)
        param.xt = self.create_gpr_x_t(context, temp_env)
        instr = context.encoder.gen_data_move_multi_nd2nz(param)

        model_with_env(context.model.step, temp_env, instr)
        temp_env.check_mem_access(context.model, True)
        model_with_env(context.model.read_memory, temp_env, dst_addr, self.dst.scope, dst_ptr, dst_alloc_size)

    def create_gpr_x_m(self, context, temp_env):
        """
        create general purpose register x_m

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xm_idx
        """
        sid = 0
        nd_num = context.evaluate_expr(self.nd_num)
        nd_n = context.evaluate_expr(self.nd_n)
        nd_d = context.evaluate_expr(self.nd_d)
        src_nd_stride = context.evaluate_expr(self.src_nd_stride)

        xm_idx = temp_env.alloc_register()
        x_m = (sid & 0xF)
        x_m |= (nd_num & 0xFFF) << ND2NZ_ND_NUM_SHIFT_POS
        x_m |= (nd_n & 0xFFFF) << ND2NZ_ND_N_SHIFT_POS
        x_m |= (nd_d & 0xFFFF) << ND2NZ_ND_D_SHIFT_POS
        x_m |= (src_nd_stride & 0xFFFF) << ND2NZ_SRC_ND_STRIDE_SHIFT_POS

        model_with_env(context.model.write_gpr, temp_env, xm_idx, x_m)
        return xm_idx

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        src_n_stride = context.evaluate_expr(self.src_n_stride)
        dst_c0_stride = context.evaluate_expr(self.dst_c0_stride)
        dst_n_stride = context.evaluate_expr(self.dst_n_stride)
        dst_nd_stride = context.evaluate_expr(self.dst_nd_stride)

        xt_idx = temp_env.alloc_register()
        x_t = (src_n_stride & 0xFFFF)
        x_t |= (dst_c0_stride & 0xFFFF) << ND2NZ_DST_C0_STRIDE_SHIFT_POS
        x_t |= (dst_n_stride & 0xFFFF) << ND2NZ_DST_N_STRIDE_SHIFT_POS
        x_t |= (dst_nd_stride & 0xFFFF) << ND2NZ_DST_ND_STRIDE_SHIFT_POS

        model_with_env(context.model.write_gpr, temp_env, xt_idx, x_t)
        return xt_idx


_VCOPY_TYPE_ENCODING = {
    'uint16': 0b001,
    'int16': 0b001,
    'float16': 0b001,
    'uint32': 0b010,
    'int32': 0b010,
    'float32': 0b010,
}


class VectorCopy(STMT):
    """
    this template only have vector
    """

    def __init__(self, source_info, vcopy_obj):
        super(VectorCopy, self).__init__(source_info, vcopy_obj.tik_instance.context.tik_debugger)
        self.obj = vcopy_obj
        self.mask = None
        self.repeat_times = None
        self.dst_blk_stride = None
        self.src_blk_stride = None
        self.dst_rep_stride = None
        self.src_rep_stride = None

        self.check = vcopy_obj.check
        if TikSocManager.is_v300_610l_soc():
            self.source_id = vcopy_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        self.obj.check.context = context
        self.dst_blk_stride = context.evaluate_expr(self.obj.dst_blk_stride)
        self.src_blk_stride = context.evaluate_expr(self.obj.src_blk_stride)
        self.dst_rep_stride = context.evaluate_expr(self.obj.dst_rep_stride)
        self.src_rep_stride = context.evaluate_expr(self.obj.src_rep_stride)
        self.repeat_times = context.evaluate_expr(self.obj.repeat_times)
        # set and check mask
        set_vector_mask(self.obj.mask, context, mask_mode=self.obj.mask_mode,
                        tensor_bit_len=get_bit_len(self.obj.src.dtype))
        self.mask = eval_mask(self.obj.mask, context)

        # when dst_blk_stride is 0, chip default work as it's 1
        if self.dst_blk_stride == 0:
            self.dst_blk_stride = 1

        self.check.set_value([self.mask, self.repeat_times, self.dst_blk_stride, self.src_blk_stride,
                              self.dst_rep_stride, self.src_rep_stride])
        # check strides repeat
        self.check.check_vector_stride_repeat(is_debug=True)

        # check tensor overlapping overflow
        self.obj.check.check_all()
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return
        align = vec_template_align(self.obj.src.dtype)
        temp_env = TempEnv()

        xn_idx, _, _, _ = copy_tensor_to_model(
            context, temp_env, self.obj.src, align, access_mode='r')
        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.obj.dst, align, access_mode='w')

        # gen instr encode
        param = context.encoder.new_param()
        param.type = _VCOPY_TYPE_ENCODING.get(self.obj.src.dtype)
        param.xd = xd_idx
        param.xn = xn_idx
        param.xt = self.create_gpr_x_t(context, temp_env)
        instr = context.encoder.gen_vcopy(param)

        orig_ctrl_value = 0
        if self.obj.mask_mode == "counter":
            orig_ctrl_value = set_mask_counter_mode(context)
        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)
        if self.obj.mask_mode == "counter":
            context.model.write_spr('CTRL', orig_ctrl_value)

        context.model.read_memory(dst_addr, self.obj.dst.scope, dst_ptr, dst_alloc_size)

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        input_params: the input parameters' value

        Returns
        -------
        xt_idx
        """
        dst_rep_high_4bits_pos = 52
        xt_idx = temp_env.alloc_register()
        x_t = self.dst_blk_stride
        x_t |= self.src_blk_stride << SRC_BLOCK_STRIDE_SHIFT_POS
        x_t |= (self.dst_rep_stride & 0xFF) << DST_REPEAT_STRIDE_SHIFT_POS
        x_t |= self.src_rep_stride << SRC_REPEAT_STRIDE_SHIFT_POS
        x_t |= (self.dst_rep_stride >> 8 & 0xF) << dst_rep_high_4bits_pos
        x_t |= self.repeat_times << REPEAT_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)
        return xt_idx
