#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     check_over_high_preci_common.py
DESC:     common check file for tik high preci api
CREATED:  2021-12-18 14:02:50
MODIFIED: 2020-12-18 14:22:50
"""
from collections import namedtuple

from tbe.tik.common.common_util import vector_max_offset_cal
from tbe.tik.tik_lib.tik_vector_api.tik_compute_control import ControlOp
from tbe.tik.tik_lib.tik_vector_api.tik_tensor_op import TensorOp
from tbe.tik.tik_lib.tik_vector_api.vector_common_util import gen_block_list
from tbe.tik.tik_lib.tik_expr import Expr
from tbe.tik.common.util import get_bit_len
from tbe.tik.common.util import TikUtil
from tbe.tik.common.util import ceil_div
from tbe.tik.tik_lib.tik_expr import is_basic_expr
from tbe.tik.tik_lib.tik_params import ONE_REP_BYTE_SIZE
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil

HighOverlapParams = namedtuple('HighOverlapApi', ["mask", "src", "dst", "work_tensor", "dst_extend",
                                                  "src_extend", "dst_offset", "src_offset",
                                                  "work_tensor_offset", "multi_factor", "name"])


def check_over_high_preci(over_high_api):
    """
    check overflow and overlap for high preci instr
    """

    if all(isinstance(value, int) for
           value in (over_high_api.repeat_times, over_high_api.dst_rep_stride, over_high_api.src_rep_stride)):
        # check tensor overflow
        tensor_bit_len = max(get_bit_len(over_high_api.dst.dtype),
                             get_bit_len(over_high_api.src.dtype))
        dst_tensor_op = TensorOp(over_high_api.dst, 1, over_high_api.dst_rep_stride, "dst")
        src_tensor_op = TensorOp(over_high_api.src, 1, over_high_api.src_rep_stride, "src")
        control_op = ControlOp(over_high_api.mask, over_high_api.repeat_times)
        block_list_dst = gen_block_list(tensor_bit_len, over_high_api.dst.dtype)
        block_list_src = gen_block_list(tensor_bit_len, over_high_api.src.dtype)
        dst_tensor_op.check_tensor_op_overflow(over_high_api.name, control_op, block_list_dst)
        src_tensor_op.check_tensor_op_overflow(over_high_api.name, control_op, block_list_src)

        # check work_tensor overflow by !!!core version and dtype!!!
        check_work_tensor_overflow(over_high_api.mask, over_high_api.src, over_high_api.work_tensor,
                                   (over_high_api.repeat_times, over_high_api.src_rep_stride),
                                   over_high_api.multi_factor)
        # check overlap
        src_bit_len = get_bit_len(over_high_api.src.dtype)
        dst_bit_len = get_bit_len(over_high_api.dst.dtype)
        dst_extend = vector_max_offset_cal((over_high_api.mask, over_high_api.dst.dtype,
                                            ONE_REP_BYTE_SIZE // dst_bit_len,
                                            over_high_api.repeat_times, 1, over_high_api.dst_rep_stride))
        src_extend = vector_max_offset_cal((over_high_api.mask, over_high_api.src.dtype,
                                            ONE_REP_BYTE_SIZE // src_bit_len,
                                            over_high_api.repeat_times, 1, over_high_api.src_rep_stride))
        high_over_lap_params = HighOverlapParams(over_high_api.mask, over_high_api.src, over_high_api.dst,
                                                 over_high_api.work_tensor, dst_extend, src_extend,
                                                 over_high_api.dst_offset, over_high_api.src_offset,
                                                 over_high_api.work_tensor_offset, over_high_api.multi_factor,
                                                 over_high_api.name)

        check_high_preci_overlap(high_over_lap_params)


def _high_overlap_dst_src_same_buffer(high_over_lap_params):
    if high_over_lap_params.dst.buffer == high_over_lap_params.src.buffer:
        src_need = Expr(high_over_lap_params.src_extend + high_over_lap_params.src_offset).eval_value()
        dst_need = Expr(high_over_lap_params.dst_extend + high_over_lap_params.dst_offset).eval_value()
        if high_over_lap_params.src_offset <= src_need <= high_over_lap_params.dst_offset or \
                high_over_lap_params.dst_offset <= dst_need <= high_over_lap_params.src_offset:
            pass
        else:
            TikCheckUtil.raise_error(
                "%s doesn't support dst and src address "
                "overlapping fully or partially." % high_over_lap_params.name)


def check_high_preci_overlap(high_over_lap_params):
    """
    check high preci instr overlap
    """

    if is_basic_expr(TikUtil.to_list(high_over_lap_params.mask)):
        return
    offset_range = (high_over_lap_params.dst_offset, high_over_lap_params.src_offset,
                    high_over_lap_params.work_tensor_offset)
    if any(offset is None for offset in offset_range):
        return
    src_bit_len = get_bit_len(high_over_lap_params.src.dtype)
    tensor_size = ceil_div(high_over_lap_params.src_extend,
                           ONE_REP_BYTE_SIZE // src_bit_len) * ONE_REP_BYTE_SIZE // src_bit_len
    _high_overlap_dst_src_same_buffer(high_over_lap_params)
    if high_over_lap_params.src.buffer == high_over_lap_params.work_tensor.buffer:
        src_need = Expr(high_over_lap_params.src_extend + high_over_lap_params.src_offset).eval_value()
        work_need_ele = Expr(
            high_over_lap_params.multi_factor * tensor_size + high_over_lap_params.work_tensor_offset).eval_value()
        if high_over_lap_params.src_offset <= src_need <= high_over_lap_params.work_tensor_offset or \
                high_over_lap_params.work_tensor_offset <= work_need_ele <= high_over_lap_params.src_offset:
            pass
        else:
            TikCheckUtil.raise_error(
                "%s doesn't support src and work_tensor address "
                "overlapping fully or partially." % high_over_lap_params.name)
    if high_over_lap_params.dst.buffer == high_over_lap_params.work_tensor.buffer:
        dst_need = Expr(high_over_lap_params.dst_extend + high_over_lap_params.dst_offset).eval_value()
        work_need_ele = Expr(
            high_over_lap_params.multi_factor * tensor_size + high_over_lap_params.work_tensor_offset).eval_value()
        if high_over_lap_params.dst_offset <= dst_need <= high_over_lap_params.work_tensor_offset or \
                high_over_lap_params.work_tensor_offset <= work_need_ele <= high_over_lap_params.dst_offset:
            pass
        else:
            TikCheckUtil.raise_error(
                "%s doesn't support dst and work_tensor address "
                "overlapping fully or partially." % high_over_lap_params.name)


def check_work_tensor_overflow(mask, src, work_tensor, repeat_list, multi_factor):
    """
    check work tensor space
    """
    repeat_times, src_rep_stride = repeat_list
    if is_basic_expr(TikUtil.to_list(mask)):
        return
    src_bit_len = get_bit_len(src.dtype)
    src_extend = vector_max_offset_cal((mask, src.dtype, ONE_REP_BYTE_SIZE // src_bit_len,
                                        repeat_times, 1, src_rep_stride))
    src_extend = ceil_div(src_extend, ONE_REP_BYTE_SIZE // src_bit_len) * ONE_REP_BYTE_SIZE // src_bit_len
    work_need_ele = Expr(multi_factor * src_extend).eval_value()
    work_tensor_size = Expr(work_tensor.size).eval_value()

    # check work tensor overflow
    if work_need_ele is not None and work_tensor_size is not None:
        # warning: original shape is Scalar
        TikCheckUtil.check_le(
            work_need_ele, work_tensor_size,
            "work_tensor overflow, needed %s but only %s." %
            (work_need_ele, work_tensor_size))
