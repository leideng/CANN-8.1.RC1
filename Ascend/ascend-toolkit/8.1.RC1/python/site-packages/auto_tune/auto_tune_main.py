#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.

Define the main function of auto_tune
"""

import os
import traceback
import json
import fcntl

from auto_tune.config_module.task_config import TaskConfig
from auto_tune.config_module.task_feature import TaskFeature
from auto_tune.config_module.config import FeatureConfig
from auto_tune.config_module.config import RUN_TYPE_TELNET
from auto_tune.common_module.common_util import COST_MAX_VALUE
from auto_tune.common_module.common_util import get_soc_info
from auto_tune.common_module.common_util import TuneOpParam
from auto_tune.common_module.common_util import report_tune_progress
from auto_tune.common_module.common_util import TuneResReport
from auto_tune.auto_tune_log import LOG_INSTANCE
from auto_tune.connect import TelnetJudge
from auto_tune.estimate.python.util import get_kernel_meta_dir
from auto_tune.estimate.python.parallel_run import run_check_soc_version
from auto_tune.tuner_alg.ga_tuner import GATuner
from auto_tune.op_adapter.op_factory import FactoryOperatorAdapter
from auto_tune.file_manager_module.repo_file_manager import check_tune_bank_path_valid
from auto_tune.file_manager_module.repo_file_manager import cube_custom_repo_migrate
from auto_tune.file_manager_module.repo_file_manager import is_repo_shape_tuned
from auto_tune.file_manager_module.repo_file_manager import RepoFileManager
from auto_tune.file_manager_module.tune_show_manager import create_tune_show
from auto_tune.file_manager_module.report_file_manager import TuneResultReport
from auto_tune.util_atc import enable_auto_tune_support
from auto_tune.util_atc import remove_file
from auto_tune.util_atc import create_file
from auto_tune.util_atc import create_dir
from auto_tune.util_atc import FILE_FLAG
from auto_tune.util_atc import FILE_MODE_640
from auto_tune.util_atc import L2_MEMORY_TYPE
from auto_tune.util_atc import get_dict_from_json_file
from auto_tune.get_input_args import get_input_args


# file path
THIS_FILE_NAME = __file__
FILE_PATH = os.path.dirname(os.path.realpath(THIS_FILE_NAME))

# optional env
REPEAT_TUNE = 'REPEAT_TUNE'
SCHEDULE = "Schedule"


def special_env_init(option: dict, run_type: int) -> None:
    """
    init auto_tune env for telnet in some special scenes
    """
    # read tuning config information from config file
    if not option and run_type == RUN_TYPE_TELNET:
        TelnetJudge()


def repeat_tune_flag(case_name: str) -> bool:
    """
    get repeat tune flag
    default is false
    :param case_name: case name
    :return: repeat_tune flag
    """
    env_dict = os.environ
    repeat_tune = False
    if str(env_dict.get(REPEAT_TUNE, None)).lower() == "true":
        repeat_tune = True
        LOG_INSTANCE.debug("REPEAT_TUNE is on, the case %s would be tuned even is already in repository.", case_name)
    return repeat_tune


def get_tune_flag(kernel_name: str, already_in: bool) -> bool:
    """
    get tune_flag param
    """
    repeat_tune = repeat_tune_flag(kernel_name)
    return repeat_tune if repeat_tune else not already_in


def report_tune_result(tune_result_report: TuneResultReport, tuner: GATuner, update_flag: bool) -> None:
    """
    report tune result
    """
    if not tuner.tune_res_report:
        LOG_INSTANCE.warning("tune_res_report is avaliable, can not report tune result.")
        return
    tune_success = bool(tuner.tune_res_report.after_cost < COST_MAX_VALUE
        and tuner.tune_res_report.before_cost < COST_MAX_VALUE)
    tune_res_report = tuner.tune_res_report
    # if tune better than online, but record failed
    if tuner.better_than_online and not update_flag:
        tune_res_report = TuneResReport(
            tune_res_report.before_cost, tune_res_report.after_cost, False, tune_res_report.exist_repository)
    tune_result_report.gen_tune_result_status(tune_res_report, tuner.build_op_name)
    tune_result_report.generate_proc_data(tune_success, SCHEDULE)


def tune_op(input_args: dict, tune_op_params: TuneOpParam,
            feature_config: FeatureConfig, extra_task: dict) -> tuple:
    """
    tune op
    """
    # tune
    # create op_tune_flag for ops
    op_tune_flag = ""
    if not tune_op_params.option:
        op_tune_flag = create_tune_show(input_args, tune_op_params)
    task_config = TaskConfig(input_args, feature_config, op_tune_flag, tune_op_params=tune_op_params)
    task = TaskFeature(input_args, task_config)
    repo_file_manager = extra_task.get("repo_file_manager")
    tune_result_report = extra_task.get("tune_result_report")
    tuner = GATuner(task)
    if not tuner.can_tune:
        report_tune_progress(tune_process_q=tune_op_params.option.get("global_mgr").get("tune_progress_q", None),
                             cbkey=tune_op_params.option.get("cb_struct_key", ""), skip=True)
    if not tuner.can_tune:
        remove_file(op_tune_flag)
        return False, {}
    # start tune
    tuner.tune()
    #save train data
    task_config.save_history_data(tuner.history_record)
    # process after tune
    remove_file(op_tune_flag)
    # if the performance of kernel is already fine, there's no need to update repository!
    # if can't find best tiling, the task name will be wrote into record file of fail task
    if not tuner.better_than_online or tuner.best_individual is None:
        report_tune_result(tune_result_report, tuner, False)
        return False, {}
    # record the best tiling
    task_best_pair = {'shape': input_args.get("shape_args"),
                      'tiling': tuner.best_individual.tiling_entity,
                      'tiling_dict': tuner.best_individual.tiling_dict,
                      'cost_time': tuner.best_individual.measure_result.cost,
                      'origin': tuner.best_individual.origin}
    # transform tiling to dict
    if not repo_file_manager.record_best_tiling(task_best_pair):
        LOG_INSTANCE.error("Save tiling failed, tiling dict: %s", tuner.best_individual.tiling_dict)
        report_tune_result(tune_result_report, tuner, False)
        return False, {}
    report_tune_result(tune_result_report, tuner, True)
    return True, task_best_pair.get('tiling_dict')


def get_tune_result_file(time_stamp: str = None, option: dict = None, input_args: dict = None) -> str:
    """
    get tune result file name
    """
    tune_result_file = ""
    if not option:
        tune_result_file = os.path.join(os.getcwd(), "tune_result_%s.json" % time_stamp)
        create_file(tune_result_file)
        if not input_args:
            LOG_INSTANCE.warning("input_args is empty when get tune_result file.")
            return tune_result_file
        with open(tune_result_file, 'r+') as f_handle:
            fcntl.flock(f_handle.fileno(), fcntl.LOCK_EX)
            tune_result = get_dict_from_json_file(f_handle)
            ori_op_name = input_args.get("topi_args").get('ori_op_name', "")
            if tune_result and ori_op_name in tune_result:
                input_args.get("topi_args")['ori_op_name'] = "{}_{}".format(\
                    ori_op_name, input_args.get('shape_args').get('kernel_name'))
            tune_result.setdefault(input_args.get("topi_args")['ori_op_name'], {})
            f_handle.seek(0)
            f_handle.truncate()
            json.dump(tune_result, f_handle, sort_keys=True, indent=4)
            fcntl.flock(f_handle.fileno(), fcntl.LOCK_UN)
    return tune_result_file


def auto_tune_compile(op_desc: str, data: dict = None, time_stamp: str = None, option: dict = None) -> bool:
    """
    The main function for auto tune

    Parameters
    ----------
    op_desc: storage the operator case
    option:
    None: auto_tune1.0
    not None: auto_tune2.0

    Returns
    -------
    """
    ret, input_args = get_input_args(op_desc, data, option)
    if not ret:
        report_tune_progress(tune_process_q=option.get("global_mgr").get("tune_progress_q", None),
                             cbkey=option.get("cb_struct_key", ""), skip=True)
        LOG_INSTANCE.warning("[Op tune skip] can not get input args, cbkey[%s].", str(option.get("cb_struct_key", "")))
        return False
    kernel_name = str(input_args.get("shape_args").get("kernel_name"))
    # preprocess
    soc_ver_info = get_soc_info()
    feature_config = FeatureConfig(soc_ver_info.soc_version, soc_ver_info.full_soc_version, option.get(
                        "high_perf", False), soc_ver_info.l1_size, input_args.get("shape_args"))
    # if shape is tuned, skip
    if is_repo_shape_tuned(input_args.get("shape_args"), option, feature_config.repo_type):
        report_tune_progress(tune_process_q=option.get("global_mgr").get("tune_progress_q", None),
                            cbkey=option.get("cb_struct_key", ""), skip=True)
        LOG_INSTANCE.warning("[Op tune skip] Op is tuned already, kernel[%s].", kernel_name)
        return False
    op_class_obj = FactoryOperatorAdapter(input_args.get("shape_args").get("op_type"))
    l2_fusion = L2_MEMORY_TYPE in input_args.get("shape_args").get('in_fm_memory_type', [0]) or \
                L2_MEMORY_TYPE in input_args.get("shape_args").get('out_fm_memory_type', [0])
    l1_fusion = input_args.get("topi_args").get("l1_fusion_flag", False)
    # if not repo_file_manager permission
    repo_file_manager = RepoFileManager(feature_config, op_class_obj, l1_fusion, l2_fusion)
    if not repo_file_manager.check_permission():
        LOG_INSTANCE.warning("[Op tune skip] repo file manager permission, kernel[%s].", kernel_name)
        return False
    # special env init for telnet
    special_env_init(option, feature_config.run_type)
    # get tune result file
    tune_result_file = get_tune_result_file(time_stamp, option, input_args)
    # get repeat_tune flag
    already_in_repo, tiling_dict = repo_file_manager.already_in_repository(input_args)
    tune_op_params = TuneOpParam(already_in_repo, tune_result_file, time_stamp, op_class_obj.pass_param_num,
                                 op_class_obj.overhead_opt_tune, option)
    tune_result_report = TuneResultReport(input_args, tune_op_params)
    extra_task = {"repo_file_manager": repo_file_manager, "tune_result_report": tune_result_report}
    # get tune flag: tiling and repeat tune
    if not get_tune_flag(kernel_name, already_in_repo):
        tune_result_report.generate_proc_data(True)
        report_tune_progress(tune_process_q=option.get("global_mgr").get("tune_progress_q", None),
                             cbkey=option.get("cb_struct_key", ""), skip=True)
        LOG_INSTANCE.warning("[Op tune skip] op tiling is already in repo, kernel[%s].", kernel_name)
        return True
    # tune op
    tune_res, tiling_dict = tune_op(input_args, tune_op_params, feature_config, extra_task)
    if not tune_res:
        LOG_INSTANCE.warning("Tuning result is not successful, kernel[%s].", kernel_name)
        return False
    # record
    if tiling_dict and use_core_num(tiling_dict.get("block_dim", [])) < int(soc_ver_info.aicore_num):
        LOG_INSTANCE.warning("This strategy doesn't make use of all cores.")
        record_op_desc(op_desc, option.get("suboptimal_path", ""), kernel_name + ".json")
    return True


def raise_err(err_code:str, reason: str) -> None:
    """
    raise runtime error to report errcode
    """
    err_dict = {}
    err_dict["errCode"] = err_code
    err_dict["reason"] = reason
    raise RuntimeError(err_dict)


def ga_tune_init() -> bool:
    '''
    repo migrate and check_soc_version between atc param and device
    :param: None
    :return: Bool
    '''
    cube_custom_repo_migrate()
    path_check_res = check_tune_bank_path_valid()
    if not path_check_res[0]:
        raise_err("EC0006", path_check_res[1])
    if not run_check_soc_version():
        raise_err("EC0005", "Fail to initialize GATune.")
    return True


def use_core_num(block_dim: list) -> int:
    used_core_num = 1
    for val in block_dim:
        if val > 0:
            used_core_num *= val
    return used_core_num


def record_op_desc(op_desc: str, file_path: str, file_name: str) -> None:
    if file_path == "":
        return
    create_dir(file_path)
    full_file_name = os.path.join(file_path, file_name)
    with os.fdopen(os.open(full_file_name, FILE_FLAG, FILE_MODE_640), 'w') as f_handle:
        json.dump(op_desc, f_handle, sort_keys=True, indent=4)
