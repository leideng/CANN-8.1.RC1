#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2022. Huawei Technologies Co., Ltd. All rights reserved.

Define RepoFileManager Class
"""
import os
import json

from tbe.common.tiling.tiling_api import get_tiling_type
from tbe.common.tiling.tiling_api import set_tiling_type
from tbe.common.tiling.tiling_api import get_tiling
from tbe.common.tiling.op_param_encode.params_encoder import ParamsEncoder
from tbe.common.repository_manager.interface import cann_kb_write
from tbe.common.repository_manager.utils.define import RepoMgrRetStatus
from tbe.common.repository_manager.utils.file_sys_util import FileSysUtil
from tbe.common.repository_manager.utils.file_sys_util import LockedOpen
from auto_tune.config_module.config import REPO_TYPE_GT
from auto_tune.config_module.config import REPO_TYPE_RM
from auto_tune.common_module.common_util import is_zero_tiling
from auto_tune.common_module.common_util import get_soc_info
from auto_tune.common_module.common_util import check_dir_access_valid
from auto_tune.common_module.common_util import check_file_permission
from auto_tune.common_module.common_util import GA_DIR_NAME
from auto_tune.common_module.common_util import BankFilePair
from auto_tune.util_atc import create_file
from auto_tune.util_atc import create_dir
from auto_tune.util_atc import RepoNameParams
from auto_tune.util_atc import create_dir_steply
from auto_tune.util_atc import copy_repo_files
from auto_tune.auto_tune_log import LOG_INSTANCE
from auto_tune.generate_repository import get_bin_from_shape
from auto_tune.generate_repository import transfer_json_to_bin_by_handle
from auto_tune.update_repository import tiling_merge_file
from auto_tune.update_repository import del_redundant_files
from auto_tune.update_repository import read_json_file
from auto_tune.op_adapter.op_factory import FactoryOperatorAdapter


CUSTOMER_HOME_PATH = 'HOME'
CUSTOMER_REPO_PATH = "Ascend/latest/data/aoe/custom/op/"
USR_ASCEND_PATH = "/usr/local/Ascend"
ASCEND_OPP_PATH = "ASCEND_OPP_PATH"
TUNE_BANK_PATH = "TUNE_BANK_PATH"
ASCEND_CACHE_PATH = "ASCEND_CACHE_PATH"
AOE_DATA = "aoe_data/"
ASCEND_HOME_PATH = "ASCEND_HOME_PATH"
OPP_DATA_TILING = "opp/data/tiling/"
ASCEND_DATA_TILING = "data/tiling/"
VENDORS_CUSTOMIZE_TILING = "vendors/customize/data/tiling/"
ATC_DATA_TILING = "atc/data/tiling/"
FWK_DATA_TILING = "fwkacllib/data/tiling/"
AOE_DATA_TILING = "aoe/data"
RWX_PERMISSION = os.R_OK | os.W_OK | os.X_OK
RW_PERMISSION = os.R_OK | os.W_OK
SOC_LOWER = ["Ascend310", "Ascend610", "Ascend910", "BS9SX1A", "BS9SX2A", "MC61AM21A"]


def is_repo_shape_tuned(shape_args: dict, option: dict, repo_type: int) -> bool:
    """
    judge if shape_args already in global_mgr

    Parameters
    ----------
    shape_args: op info_dict
    tuned_shapes: ga_tune_shapes in global_mgr

    Returns
    -------
    True: shape_args is already tuned
    False: shape is not tuned
    """
    shape_str = ""
    if (repo_type == REPO_TYPE_GT):
        shape_str = get_bin_from_shape(shape_args)
    else:
        shape_str = ParamsEncoder.get_kb_query_attr(shape_args)
    is_tuned = False
    with option.get("global_mgr").get("query_lock"):
        if shape_str in option.get("global_mgr").get("ga_tuned_shapes", []):
            LOG_INSTANCE.info("Kernel[%s]'s info dict has been tuned, skip tune." % shape_args.get("kernel_name"))
            is_tuned = True
        else:
            option.get("global_mgr").get("ga_tuned_shapes", []).append(shape_str)
    return is_tuned


def get_default_bank_path() -> str:
    """
    get default_bank_path home/Ascend/latest/data/aoe/custom/op/soc/cube
    """
    customer_tiling_path = os.path.realpath(
        os.path.join(os.environ.get(CUSTOMER_HOME_PATH, ""), CUSTOMER_REPO_PATH))
    bank_path = os.path.join(customer_tiling_path, get_soc_info().full_soc_version, GA_DIR_NAME)
    return bank_path


def check_tune_bank_path_valid() -> tuple:
    """
    check if TUNE_BANK_PATH is available, if not check ASCEND_CACHE_PATH instead.
    """
    tune_bank_path = os.getenv(TUNE_BANK_PATH, "")
    if tune_bank_path:
        real_path = os.path.realpath(tune_bank_path)
        if not os.path.isdir(real_path):
            LOG_INSTANCE.warning("TUNE_BANK_PATH:%s does not exist, check ASCEND_CACHE_PATH instead.", \
                tune_bank_path)
            return False, "Directory [{}] does not exist".format(tune_bank_path)
        if not os.access(real_path, RWX_PERMISSION):
            LOG_INSTANCE.warning("No permission for directory: %s, check ASCEND_CACHE_PATH instead." % (tune_bank_path))
            return False, "No permission for directory [{}]".format(tune_bank_path)
    else:
        return check_ascend_cache_path_valid()
    return True, None


def check_ascend_cache_path_valid() -> tuple:
    """
    check if ASCEND_CACHE_PATH is available
    """
    ascend_cache_path = os.getenv(ASCEND_CACHE_PATH, "")
    if ascend_cache_path:
        ascend_cache_path = os.path.realpath(ascend_cache_path)
        if not os.path.isdir(ascend_cache_path):
            LOG_INSTANCE.error("ASCEND_CACHE_PATH:%s does not exist, please check!" % (ascend_cache_path))
            return False, "Directory [{}] does not exist".format(ascend_cache_path)
        ascend_cache_path = os.path.realpath(os.path.join(ascend_cache_path, AOE_DATA))
        create_dir_steply(ascend_cache_path)
        if not os.access(ascend_cache_path, RWX_PERMISSION):
            LOG_INSTANCE.error("No permission for directory: %s, please check!" % (ascend_cache_path))
            return False, "No permission for directory [{}]".format(ascend_cache_path)
    return True, None


def get_previous_cube_repo_dirs() -> list:
    """
    get default cube repository dirs from previous cann version
    """
    old_usr_ascend_path = USR_ASCEND_PATH
    home_path = os.path.realpath(os.environ.get(CUSTOMER_HOME_PATH, ""))
    if not home_path:
        LOG_INSTANCE.warning("Home path in environmental variable is not set!")
    home_path = os.path.join(home_path, "Ascend")
    ascend_home_path = os.path.realpath(os.environ.get(ASCEND_HOME_PATH, ""))
    if not ascend_home_path:
        LOG_INSTANCE.warning("ASCEND_HOME_PATH in environmental variable is not set!")
    vendors_customize_tiling_path = os.path.join(os.environ.get(ASCEND_OPP_PATH, ""), VENDORS_CUSTOMIZE_TILING)
    old_ascend_opp_data_path = os.path.join(os.environ.get(ASCEND_OPP_PATH, ""), ASCEND_DATA_TILING)
    old_home_opp_data_path = os.path.join(home_path, OPP_DATA_TILING)
    old_ascend_home_opp_data_path = os.path.join(ascend_home_path, OPP_DATA_TILING)
    old_ascend_atc_data_path = os.path.join(old_usr_ascend_path, ATC_DATA_TILING)
    old_home_atc_data_path = os.path.join(home_path, ATC_DATA_TILING)
    old_ascend_home_atc_data_path = os.path.join(ascend_home_path, ATC_DATA_TILING)
    old_ascend_fwk_data_path = os.path.join(old_usr_ascend_path, FWK_DATA_TILING)
    old_home_fwk_data_path = os.path.join(home_path, FWK_DATA_TILING)
    old_ascend_home_fwk_data_path = os.path.join(ascend_home_path, FWK_DATA_TILING)
    old_ascend_aoe_data_path = os.path.join(old_usr_ascend_path, AOE_DATA_TILING)
    old_home_aoe_data_path = os.path.join(home_path, AOE_DATA_TILING)
    old_ascend_home_aoe_data_path = os.path.join(ascend_home_path, AOE_DATA_TILING)

    return [old_ascend_home_aoe_data_path, old_ascend_aoe_data_path, old_home_aoe_data_path,
        old_ascend_home_opp_data_path, vendors_customize_tiling_path, old_ascend_opp_data_path, old_home_opp_data_path,
        old_ascend_home_atc_data_path, old_ascend_home_fwk_data_path,
        old_ascend_atc_data_path, old_ascend_fwk_data_path, old_home_atc_data_path, old_home_fwk_data_path]


def migrate_cube_repo_dir(ga_data_path: str, customer_repo_path: str) -> bool:
    """
    copy files under ga_data_path to customer_repo_path
    """
    if not check_dir_access_valid(ga_data_path, RWX_PERMISSION):
        LOG_INSTANCE.warning("Current user doesn't have rwx permission for dir[%s], "
            "please copy cube repo files to dir[%s] manually!", ga_data_path, customer_repo_path)
        return True

    if not os.listdir(ga_data_path):
        return False

    create_dir_steply(customer_repo_path)
    LOG_INSTANCE.info("Try to copy repository files under dir[%s] to customer path.", ga_data_path)
    try:
        copy_repo_files(ga_data_path, customer_repo_path)
        LOG_INSTANCE.info("Copy repository files under dir[%s] to customer path[%s] success.",
            ga_data_path, customer_repo_path)
    except OSError as err_msg:
        LOG_INSTANCE.warning("Failed to copy src_path[%s] to dst_path[%s]. "
            "Error is %s. Please copy cube repo files manually!", ga_data_path, customer_repo_path, err_msg)
    finally:
        pass
    return True


def cube_custom_repo_migrate() -> None:
    '''
    custom repo migrate to user home path
    :param: None
    :return: None
    '''
    tune_bank_path = os.getenv(TUNE_BANK_PATH, "")
    ascend_cache_aoe_path = os.getenv(ASCEND_CACHE_PATH, "")
    if tune_bank_path or ascend_cache_aoe_path:
        LOG_INSTANCE.info("TUNE_BANK_PATH or ASCEND_CACHE_PATH has been set,"
            "default cube customer repository files won't be migrated.")
        return
    customer_repo_path = get_default_bank_path()
    if check_dir_access_valid(customer_repo_path, RWX_PERMISSION) and \
        os.listdir(customer_repo_path):
        LOG_INSTANCE.info("The repo files already exists in customer repo path[%s] and won't be migrated.",
            customer_repo_path)
        return

    old_cube_data_paths = get_previous_cube_repo_dirs()
    soc_version = get_soc_info().soc_version
    for path in old_cube_data_paths:
        custom_path_str = "" if "vendors/customize" in path else "custom"
        if "aoe" in path:
            ga_data_path = os.path.realpath(os.path.join(path, soc_version, GA_DIR_NAME))
        elif soc_version in SOC_LOWER:
            ga_data_path = os.path.realpath(os.path.join(path, soc_version.lower(), custom_path_str))
        else:
            ga_data_path = os.path.realpath(os.path.join(path, soc_version, custom_path_str))
        if not os.path.exists(ga_data_path) or not os.path.isdir(ga_data_path):
            LOG_INSTANCE.debug("cube repo dir[%s] does not exist.", ga_data_path)
            continue
        if migrate_cube_repo_dir(ga_data_path, customer_repo_path):
            return
    LOG_INSTANCE.info("No qualified cube repository files need to be migrated.")


class RepoFileManager():
    """
    Base class for tuners
    Parameters
    ----------
    task: autotvm.task.Task Tuning Task
    """
    def __init__(self, feature_config: object, op_class_obj: object, l1_fusion: bool = False, l2_fusion: bool = False):
        self.feature_config = feature_config
        self.op_class_obj = op_class_obj
        self.l1_fusion = l1_fusion
        self.l2_fusion = l2_fusion
        self.bin_bank, self.json_bank = self.get_bank_file() # already realpath
        self.repo_type = feature_config.repo_type

    @staticmethod
    def make_bank_file_name(dir_path: str, default_file_name: str, op_class_obj: FactoryOperatorAdapter,
                            l1_fusion: bool = False, l2_fusion: bool = False) -> str:
        """
        make_bank_file_name: make bank file name from input params
        """
        full_soc_version = get_soc_info().full_soc_version
        aicore_num = get_soc_info().aicore_num
        l1_size = get_soc_info().l1_size
        bank_file = os.path.join(os.path.realpath(dir_path), default_file_name)
        repo_name_params = RepoNameParams(bank_file, full_soc_version, aicore_num, l1_size, l2_fusion, l1_fusion)
        bank_file = op_class_obj.record_till_file_name(repo_name_params)
        return bank_file

    @staticmethod
    def already_in_repository(input_args: dict) -> tuple:
        """
        judge whether the tiling is already in repository or not
        Parameters:
        ----------
        input_args: input_args
        """
        # get tiling from tiling_query under repository_tiling
        tiling_type = get_tiling_type()
        set_tiling_type("repository_tiling")
        shape_args = input_args.get("shape_args")
        tiling = get_tiling(shape_args)
        set_tiling_type(tiling_type)

        # judge whether the tiling is already in repository
        if is_zero_tiling(tiling):
            return False, tiling
        LOG_INSTANCE.debug("The kernel %s is already in repository.", shape_args.get("kernel_name", ""))
        return True, tiling

    @staticmethod
    def check_directory_exist(file_path: str) -> str:
        """
        check whether the directory of file or directoryis exist
        Parameters
        ----------
        param: file_path  the instance to check

        Returns
        -------
        file_dir : The directory of file or input directory.
        """
        # check the input is string
        if not isinstance(file_path, str):
            raise TypeError("the input is invalid, the input must be string")
        # check the input is directory
        if os.path.isfile(os.path.realpath(file_path)):
            LOG_INSTANCE.debug("the input isn't a directory, the input is %s.", str(os.path.realpath(file_path)))
            file_dir = os.path.dirname(os.path.realpath(file_path))
        else:
            file_dir = os.path.realpath(file_path)
        # if the directory is not exist, create the directory
        if not os.path.exists(file_dir):
            if '.' not in os.path.split(file_dir)[-1]:
                LOG_INSTANCE.debug("the input directory doesn't exist, then create the directory, the input is %s.",
                    str(file_dir))
                create_dir(os.path.realpath(file_dir))

        return file_dir

    @staticmethod
    def check_dir_permission(file_path: str) -> tuple:
        """
        check_dir_permission: check the rwx permission of the file_path's dir
        """
        idx = file_path[:-1].rfind(os.sep)
        dir_path = file_path[:idx]
        del_redundant_files(dir_path)
        if os.access(dir_path, RWX_PERMISSION):
            return dir_path, True
        return dir_path, False

    @staticmethod
    def check_json_file_content(file_name: str) -> bool:
        """
        check json content is valid or not.
        """
        ret = True
        try:
            with open(file_name, "r") as fp:
                fp.seek(0)
                _, _ = read_json_file(fp)
        except (ValueError, TypeError, IOError, OSError) as e:
            LOG_INSTANCE.warning("Check bank file [%s] meets something, ret: %s." % (file_name, str(e)))
            ret = False
        finally:
            pass
        return ret

    @staticmethod
    def file_recovery(tmp_name: str, file_name: str) -> bool:
        """
        recovery file by using tmp_name
        return True if oprator succ
        """
        if not FileSysUtil.rename_file(tmp_name, file_name):
            LOG_INSTANCE.error("Recover knowledge bank file failed, the original file is most likely corrupted, "
                "please be sure to restore the knowledge bank file manually via renaming [%s] to [%s].",
                tmp_name, file_name)
            return False
        return True

    @staticmethod
    def remove_backup_file(tmp_json: str, tmp_bin: str) -> None:
        """
        remove backup file
        """
        if os.path.isfile(tmp_json) and not FileSysUtil.remove_file(tmp_json):
            LOG_INSTANCE.warning("Can not remove backup file [%s]." % str(tmp_json))
        if os.path.isfile(tmp_bin) and not FileSysUtil.remove_file(tmp_bin):
            LOG_INSTANCE.warning("Can not remove backup file [%s]." % str(tmp_bin))

    def update_bin_file_by_json_file(self) -> bool:
        ret = True
        try:
            with open(self.json_bank, "r") as json_handle, open(self.bin_bank, "r+") as bin_handle:
                transfer_json_to_bin_by_handle(json_handle, bin_handle)
                bin_handle.flush()
        except (OSError, IOError) as e:
            ret = False
            LOG_INSTANCE.warning("Can not transfer json [%s] to bin, ret: %s." % (self.json_bank, str(e)))
        finally:
            pass
        return ret

    def check_and_choose_repo_file(self, bank_name_tmp: BankFilePair) -> RepoMgrRetStatus:
        """
        check and choose repo file:
        Determine if the file is useble, otherwise replace it with an alternate file
        """
        # origin file is valid, return succ
        if self.check_json_file_content(self.json_bank):
            return RepoMgrRetStatus.SUCCESS
        # origin file is invalid and no backup file return fail
        if not os.path.isfile(bank_name_tmp.json):
            LOG_INSTANCE.error("Load bank file [%s] failed before backup file." % self.json_bank)
            return RepoMgrRetStatus.FILE_LOAD_FAIL
        # origin file is invalid and backup file is invalid, return fail
        if not self.check_json_file_content(bank_name_tmp.json):
            LOG_INSTANCE.error("Check bank file [%s] failed while backup repo file." % self.json_bank)
            FileSysUtil.remove_file(bank_name_tmp.json)
            return RepoMgrRetStatus.FILE_LOAD_FAIL_USE_ALT_FAIL
        # origin file is invalid and copy backup file failed, return fail
        if not FileSysUtil.copy_file(bank_name_tmp.json, self.json_bank):
            LOG_INSTANCE.error("Copy backup file [%s] to bank file [%s] failed while checking file."
                % (bank_name_tmp.json, self.json_bank))
            return RepoMgrRetStatus.FILE_LOAD_FAIL_USE_ALT_FAIL
        # origin file is invalid and copy backup file succ, backup bin_bank
        if not self.update_bin_file_by_json_file():
            LOG_INSTANCE.error("Transfer json bank file [%s] bin failed while backup repo file." % self.json_bank)
            return RepoMgrRetStatus.FILE_LOAD_FAIL_USE_ALT_FAIL
        LOG_INSTANCE.event(
            "Bank file [%s] is available, and use the backup file successfully." % self.json_bank)
        return RepoMgrRetStatus.FILE_LOAD_FAIL_USE_ALT_SUCC

    def backup_repo_file(self, bank_name_tmp: BankFilePair) -> RepoMgrRetStatus:
        """
        backup repo file: copy original file with ".aoe"
        """
        #check file
        check_ret = self.check_and_choose_repo_file(bank_name_tmp)
        if check_ret != RepoMgrRetStatus.SUCCESS and check_ret != RepoMgrRetStatus.FILE_LOAD_FAIL_USE_ALT_SUCC:
            LOG_INSTANCE.error("Check and choose repo file [%s] failed." % self.json_bank)
            return check_ret
        # copy backup file
        if not FileSysUtil.copy_file(self.json_bank, bank_name_tmp.json):
            LOG_INSTANCE.error("Copy knowledge bank file [%s] to backup file failed." % self.json_bank)
            return RepoMgrRetStatus.FILE_COPY_FAIL
        if not FileSysUtil.copy_file(self.bin_bank, bank_name_tmp.bin):
            FileSysUtil.remove_file(bank_name_tmp.json)
            LOG_INSTANCE.error("Copy knowledge bank file [%s] to backup file failed." % self.bin_bank)
            return RepoMgrRetStatus.FILE_COPY_FAIL

        LOG_INSTANCE.info("Copy knowledge bank file [%s] to backup file successful." % self.json_bank)
        return RepoMgrRetStatus.SUCCESS

    def write_bank_file_with_backup_file(self, bank_name_tmp: BankFilePair, best_individual: dict) -> RepoMgrRetStatus:
        """
        write bank file, if faile, recovery file by backupfile
        """
        ret = RepoMgrRetStatus.SUCCESS
        try:
            with open(self.json_bank, 'r+') as json_handle, open(self.bin_bank, 'ab') as bin_handle:
                tiling_merge_file(json_handle, best_individual)
                transfer_json_to_bin_by_handle(json_handle, bin_handle)
                json_handle.flush()
                bin_handle.flush()
                # check bank file
                json_handle.seek(0)
                _, _ = read_json_file(json_handle)
        except (ValueError, TypeError, IOError, OSError) as e:
            LOG_INSTANCE.warning(
                "Write bank file failed, ret: %s, start to recovery bank file: %s" % (str(e), self.json_bank))
            ret_json = self.file_recovery(bank_name_tmp.json, self.json_bank)
            ret_bin = self.file_recovery(bank_name_tmp.bin, self.bin_bank)
            if not ret_json or not ret_bin:
                ret = RepoMgrRetStatus.FILE_RECOVERY_FAIL
        finally:
            pass
        return ret

    def get_bank_file(self) -> tuple:
        """
        get_bank_file: get bank file path: bin file path and json file path
        """
        soc_version =  self.feature_config.full_soc_version
        tune_bank_path = os.getenv(TUNE_BANK_PATH, "")
        ascend_cache_path = os.getenv(ASCEND_CACHE_PATH, "")
        if tune_bank_path:
            repo_dir = os.path.realpath(os.path.join(tune_bank_path, soc_version, GA_DIR_NAME))
        elif ascend_cache_path:
            repo_dir = os.path.realpath(os.path.join(ascend_cache_path, AOE_DATA, soc_version, GA_DIR_NAME))
        else:
            repo_dir = os.path.realpath(get_default_bank_path())
        create_dir_steply(repo_dir)
        bin_bank = self.make_bank_file_name(
            repo_dir, "repository.bin", self.op_class_obj, self.l1_fusion, self.l2_fusion)
        json_bank = self.make_bank_file_name(
            repo_dir, "repository.json", self.op_class_obj, self.l1_fusion, self.l2_fusion)
        LOG_INSTANCE.event("auto tune get bank path json_bank is %s", json_bank)
        return os.path.realpath(bin_bank), os.path.realpath(json_bank)

    def record_json_bin_file_repository(self, best_individual: dict) -> None:
        """
        process tuning result
        Parameters
        ----------
        op_class_obj: FactoryOperatorAdapter object
        tiling_dict: json dict
        Returns
        -------
        """
        # check the directory of customer tiling
        self.check_directory_exist(self.bin_bank)
        create_file(self.json_bank)
        create_file(self.bin_bank)
        tmp_json = os.path.join(self.json_bank + ".aoe")
        tmp_bin = os.path.join(self.bin_bank + ".aoe")
        LOG_INSTANCE.event(
            "Start writing repository json_bank = {}, bin_bank = {}".format(self.json_bank, self.bin_bank))
        with LockedOpen(self.json_bank, mode="a+"), LockedOpen(self.bin_bank, mode="a+"):
            bank_name_tmp = BankFilePair(tmp_json, tmp_bin)
            # 1. backup bank file
            ret = self.backup_repo_file(bank_name_tmp)
            if ret != RepoMgrRetStatus.SUCCESS:
                LOG_INSTANCE.error("Backup bank file [%s] failed, ret: %s." % (str(self.json_bank), ret))
                return ret
            # 2. write bank file: if recovery failed, keep the backup file and return
            ret = self.write_bank_file_with_backup_file(bank_name_tmp, best_individual)
            if ret == RepoMgrRetStatus.FILE_RECOVERY_FAIL:
                return ret
            # 3. remove backup file
            self.remove_backup_file(tmp_json, tmp_bin)
        LOG_INSTANCE.event(
            "Finished writing repository json_bank = {}, bin_bank = {}".format(self.json_bank, self.bin_bank))
        return RepoMgrRetStatus.SUCCESS

    def record_best_tiling(self, best_individual: dict) -> bool:
        """
        record the best tiling to repository
        Parameters
        ----------
        best_individual: best individual including shape, tiling and cost_time
        -------
        """
        ret = RepoMgrRetStatus.SUCCESS
        if self.repo_type == REPO_TYPE_RM:
            write_config = {"op_type": best_individual.get('shape').get('op_type'),
                            "cost_time": best_individual.get("cost_time"),
                            "origin": best_individual.get("origin", "UNKNOWN")}
            shape_kb_str = ParamsEncoder.get_kb_query_attr(best_individual.get('shape'))
            info_dict = json.loads(shape_kb_str)
            info_dict.pop("extra_param", "extra_param doesn't exist in info_dict")
            shape_kb_str = json.dumps(info_dict)
            ret = cann_kb_write(shape_kb_str, best_individual.get("tiling_dict"), write_config, flush=True, option={})
        elif self.repo_type == REPO_TYPE_GT:
            repo_merge_dict = {
                'shape': best_individual.get("shape"),
                'tiling': best_individual.get("tiling"),
                'cost_time': best_individual.get("cost_time")
            }
            ret = self.record_json_bin_file_repository(repo_merge_dict)

        if ret == RepoMgrRetStatus.FILE_LOAD_FAIL_USE_ALT_FAIL or ret == RepoMgrRetStatus.FILE_RECOVERY_FAIL:
            LOG_INSTANCE.error("Save tiling failed, ret: %s", ret)
            raise RuntimeError(
                {"errCode": 'EG0011', "reason": "The bank file is corrupted, please restore files manually."})
        if ret != RepoMgrRetStatus.SUCCESS:
            LOG_INSTANCE.error("Save tiling failed, ret: %s", ret)
            return False
        return True

    def check_permission(self) -> bool:
        """
        check_permission: check the permission of the files' dir and files: bin_path, json_path
        """
        dir_path, flag = self.check_dir_permission(self.bin_bank)
        if not flag:
            LOG_INSTANCE.error("The current user doesn't have the r+w+x permission of %s.", dir_path)
            return False
        flag = check_file_permission(self.bin_bank, RW_PERMISSION) and \
               check_file_permission(self.json_bank, RW_PERMISSION)
        if not flag:
            LOG_INSTANCE.error("The current user doesn't have the r+w permission of %s or %s.",
                self.bin_bank, self.json_bank)
            return False
        return True
