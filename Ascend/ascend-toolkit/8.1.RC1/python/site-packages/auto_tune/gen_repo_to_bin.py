#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2021. Huawei Technologies Co., Ltd. All rights reserved.

Define shape to bin and tiling to bin functions for generate repository
"""

import sys
import math

from copy import deepcopy
from collections import namedtuple

from auto_tune.offline_util import encode_memory_type
from auto_tune.gen_repo_utils import num_2_bin
from auto_tune.gen_repo_utils import str_2_bin
from auto_tune.gen_repo_utils import get_check_sum
from auto_tune.gen_repo_utils import check_tiling
from auto_tune.gen_repo_utils import get_al0_bl0_matrix

from auto_tune.gen_repo_utils import OP_TAG_ENCODE
from auto_tune.gen_repo_utils import INPUT_DATA_BYTE_WIDTH
from auto_tune.gen_repo_utils import MAX_VALUE_8_BIT
from auto_tune.gen_repo_utils import MAX_VALUE_16_BIT
from auto_tune.gen_repo_utils import BIT_LEN_128
from auto_tune.gen_repo_utils import BIT_LEN_64
from auto_tune.gen_repo_utils import BIT_LEN_32
from auto_tune.gen_repo_utils import BIT_LEN_16
from auto_tune.gen_repo_utils import BIT_LEN_12
from auto_tune.gen_repo_utils import BIT_LEN_8
from auto_tune.gen_repo_utils import ZERO
from auto_tune.gen_repo_utils import ONE
from auto_tune.gen_repo_utils import DEFAULT_VALUE
from auto_tune.gen_repo_utils import L1_NO_FUSION

# define the type of L1 fusion
FLAG_ENCODE = {False: 0, True: 1}
# Define the occupied memory of input data type
# Define the level of fm valid size
# according to the convention, fm_l1_valid_size should be 1/2, 3/4, 1 times fm_shape
# the level of fm valid size is designed as 1\2\3
INPUT_DATA_LEVAL = {1: 1, 0.75: 2, 0.5: 3}
Conv2DParam = namedtuple("Conv2DParam", ["wa", "wc", "wa_high", "wc_high", "group_low",
    "group_high", "fusion_type_low", "fusion_type_high", "fused_double_operand_num"])


def head_2_bin(all_bin: list, case_num: int) -> list:
    """
    transfer tablehead to binary
    all_bin: list of all binary data
    tiling_set: shape of a case
    return: list of shape and tiling
    """
    # headconfig info
    check_sum = 1031
    head_length = 64
    hardware_platform = 'AaZ'
    repository_length = case_num
    version = 'version7.7'
    base_address = 'addr64' # address
    repository_resereved = 'repores'
    reserved = 'res'
    table_head = []
    table_head.append("num") # date type of head_length
    table_head.append("str") # date type of hardware_platform
    table_head.append("num") # date type of repository_length
    table_head.append("str") # date type of version
    table_head.append("str") # date type of base_address
    table_head.append("str") # date type of repository_resereved_fields
    table_head.append("str") # date type of reserved_fields
    table_head.append(head_length)
    table_head.append(hardware_platform)
    table_head.append(repository_length)
    table_head.append(version)
    table_head.append(base_address)
    table_head.append(repository_resereved)
    table_head.append(reserved)
    # head_length occupies 32 bits
    table_head.append(BIT_LEN_32)
    # hardware_platform occupies 32 bits
    table_head.append(BIT_LEN_32)
    # repository_length occupies 32 bits
    table_head.append(BIT_LEN_32)
    # version occupies 128 bits
    table_head.append(BIT_LEN_128)
    # base_address occupies 64 bits
    table_head.append(BIT_LEN_64)
    # repository_resereved_fields occupies 64 bits
    table_head.append(BIT_LEN_64)
    # reserved_fields occupies 128 bits
    table_head.append(BIT_LEN_128)
    check_sum = get_check_sum(table_head, BIT_LEN_32)
    # check_sum occupies 32 bits
    all_bin = num_2_bin(all_bin, check_sum, BIT_LEN_32)
    # head_length occupies 32 bits
    all_bin = num_2_bin(all_bin, head_length, BIT_LEN_32)
    # hardware_platform occupies 32 bits
    all_bin = str_2_bin(all_bin, hardware_platform, BIT_LEN_32)
    # repository_length occupies 32 bits
    all_bin = num_2_bin(all_bin, repository_length, BIT_LEN_32)
    # version occupies 128 bits
    all_bin = str_2_bin(all_bin, version, BIT_LEN_128)
    # base_address occupies 64 bits
    all_bin = str_2_bin(all_bin, base_address, BIT_LEN_64)
    # repository_resereved_fields occupies 64 bits
    all_bin = str_2_bin(all_bin, repository_resereved, BIT_LEN_64)
    # reserved_fields occupies 128 bits
    all_bin = str_2_bin(all_bin, reserved, BIT_LEN_128)
    return all_bin


def prepare_l1_fusion_shape_2_bin(shape: dict) -> None:
    """
    prepare shape for l1_fusion_shape_2_bin
    """
    # check the fm_l1_valid_size whether is legal
    shape['fm_l1_valid_size'] = shape.get('fm_l1_valid_size', DEFAULT_VALUE)
    if shape.get('fm_l1_valid_size') != DEFAULT_VALUE:
        # according to the use_c04_mode, align the channel
        use_c04_mode = shape.get('special_mode', {}).get('use_c04_mode', ZERO)
        a_shape = deepcopy(shape.get('a_shape'))
        if use_c04_mode == 1 and a_shape[4] == 4:
            a_shape[4] = 16
        # with group conv scene, the fm_shape is shape of placehold tensor
        if shape.get('group') != ONE:
            a_shape = shape.get('placeholder_fmap_5hd_shape')
        fm_shape_size = INPUT_DATA_BYTE_WIDTH.get(shape.get('a_dtype'))
        for elt in a_shape:
            fm_shape_size *= elt
        input_data_level = shape.get('fm_l1_valid_size') / fm_shape_size
        if input_data_level not in INPUT_DATA_LEVAL.keys():
            raise ValueError("the fm_l1_valid_size must be 1/2, 3/4, 1 times fm_shape_size, \
                but fm_l1_valid_size is %s, fm_shape_size is %s" % (shape.get('fm_l1_valid_size'), fm_shape_size))
        shape['fm_l1_valid_size_level'] = input_data_level
    else:
        shape['fm_l1_valid_size_level'] = ZERO

    # endocde the value of fm_l1_valid_size_level
    if shape.get('fm_l1_valid_size_level') != ZERO:
        raw_fm_l1_valid_size_level = shape.get('fm_l1_valid_size_level')
        shape['fm_l1_valid_size_level'] = INPUT_DATA_LEVAL.get(raw_fm_l1_valid_size_level)

    # 2 represent L1_no_fusion
    if shape.get("l1_fusion_type") == DEFAULT_VALUE:
        shape["l1_fusion_type"] = L1_NO_FUSION


def l1_fusion_shape_2_bin(all_bin: list, shape: dict) -> list:
    """
    transfer l1 fusion shape to binary
    all_bin: list of all binary data
    shape: shape of a case
    return: new all_bin
    """
    if not shape["c_shape"]:
        shape["c_shape"] = [0, 0, 0, 0]
    # encode the memory type
    in_fm_memory_type_encode = encode_memory_type("in", shape.get('in_fm_memory_type'))
    out_fm_memory_type_encode = encode_memory_type("out", shape.get('out_fm_memory_type'))
    # process the input params
    group_low = shape.get("group") & MAX_VALUE_8_BIT
    group_high = (shape.get("group") >> 8) & MAX_VALUE_16_BIT

    prepare_l1_fusion_shape_2_bin(shape)
    # get batch_a from A_shape dimension 0, batch_a occupies 64 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[0], BIT_LEN_64)
    # get batch_b from B_shape dimension 0, batch_b occupies 64 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[0], BIT_LEN_64)
    # get cb from B_shape dimension 0 times dimension 4, cb occupies 64 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[1] * shape.get("b_shape")[4], BIT_LEN_64)
    # get ca1 from A_shape dimension 1, ca1 occupies 64 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[1], BIT_LEN_64)
    # get ha from A_shape dimension 2, ha occupies 64 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[2], BIT_LEN_64)
    # get wa from A_shape dimension 3, wa occupies 64 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[3], BIT_LEN_64)
    # get hb from B_shape dimension 2, hb occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[2], BIT_LEN_16)
    # get wb from B_shape dimension 3, wb occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[3], BIT_LEN_16)
    # get l1_fusion_input_memory_type
    all_bin = num_2_bin(all_bin, in_fm_memory_type_encode, BIT_LEN_32)
    # get hc from C_shape dimension 2, hc occupies 64 bits
    all_bin = num_2_bin(all_bin, shape.get("c_shape")[2], BIT_LEN_64)
    # get wc from C_shape dimension 3, wc occupies 64 bits
    all_bin = num_2_bin(all_bin, shape.get("c_shape")[3], BIT_LEN_64)
    # get fusionType from shape,
    # fusionType occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("fusion_type"), BIT_LEN_32)
    # get fused_ub_cl0 from shape,
    # fused_ub_cl0 occupies 16 bits
    all_bin = num_2_bin(all_bin, math.ceil(shape.get('fused_ub_cl0', 0) * 1000 / 10), BIT_LEN_16)
    # get ca0 from A_shape dimension 4, ca0 occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[4], BIT_LEN_8)
    # get a_type from shape, a_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("a_dtype"), BIT_LEN_8)
    # get b_type from shape, b_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("b_dtype"), BIT_LEN_8)
    # get c_type from shape, c_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("c_dtype"), BIT_LEN_8)
    # get mad_type from shape, mad_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("mad_dtype"), BIT_LEN_8)
    # blank 8 bits, original pad field
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_8)
    # blank 16 bits, original pad field
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_16)
    # blank 8 bits, original pad field
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_8)
    # get stride_h from shape, stride_h occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("stride")[0], BIT_LEN_8)
    # get stride_w from shape, stride_w occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("stride")[1], BIT_LEN_8)
    # get dilation_h from shape, dilation_h occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("dilation")[0], BIT_LEN_8)
    # get dilation_w from shape, dilation_w occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("dilation")[1], BIT_LEN_8)
    # get group from shape, group_low occupies 8 bits
    all_bin = num_2_bin(all_bin, group_low, BIT_LEN_8)
    # get op_tag from shape, op_tag occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("l1_fusion_type"), BIT_LEN_8)
    # get outputMemoryType from shape, get bias_flag from shape
    all_bin = num_2_bin(all_bin, out_fm_memory_type_encode, BIT_LEN_8)
    # get bias_flag from shape occupies 1 bit,
    # fm_l1_valid_size_level occupies 7 bits
    all_bin = num_2_bin(all_bin, int(shape.get("fm_l1_valid_size_level") * 2 + shape.get("bias_flag")), BIT_LEN_8)
    # pooling_shape_H occupies 4 bits, pooling_shape_W occupies 4 bits
    all_bin = num_2_bin(all_bin, shape.get('pooling_shape', [0, 0])[0] + \
                    shape.get('pooling_shape', [0, 0])[1] * 2**4, BIT_LEN_8)
    # pooling_stride_H occupies 4 bits, pooling_stride_W occupies 4 bits
    all_bin = num_2_bin(all_bin, shape.get('pooling_stride', [0, 0])[0] + \
                    shape.get('pooling_stride', [0, 0])[1] * 2**4, BIT_LEN_8)
    # blank 8 bits
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_8)
    # get group from shape, group_high occupies 16 bits
    all_bin = num_2_bin(all_bin, group_high, BIT_LEN_16)
    # reserved 352 bits
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_32)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)

    return all_bin


def prepare_conv2d_shape_2_bin(shape: dict) -> Conv2DParam:
    """
    prepare params for conv2d_shape_2_bin
    """
    if not shape["c_shape"]:
        shape["c_shape"] = [0, 0, 0, 0]
    # process the input params
    wa = shape.get("a_shape")[3] & MAX_VALUE_16_BIT
    wa_high = (shape.get("a_shape")[3]  >> 16) & MAX_VALUE_16_BIT
    wc = shape.get("c_shape")[3] & MAX_VALUE_16_BIT
    wc_high = (shape.get("c_shape")[3]  >> 16) & MAX_VALUE_16_BIT
    fused_double_operand_num = shape.get("fused_coefficient")[2]
    group_low = shape.get("group") & MAX_VALUE_8_BIT
    group_high = (shape.get("group") >> 8) & MAX_VALUE_16_BIT
    # split the fusion_type to high 16-bits and low 16-bits
    fusion_type_low = shape.get("fusion_type") & MAX_VALUE_16_BIT
    fusion_type_high = (shape.get("fusion_type") >> 16) & MAX_VALUE_16_BIT
    conv2d_param = Conv2DParam(wa, wc, wa_high, wc_high, group_low, group_high,
        fusion_type_low, fusion_type_high, fused_double_operand_num)
    return conv2d_param


def conv2d_shape_2_bin(all_bin: list, shape: dict) -> list:
    """
    transfer l1 fusion shape to binary
    all_bin: list of all binary data
    shape: shape of a case

    return: new all_bin
    """
    conv2d_param = prepare_conv2d_shape_2_bin(shape)
    # get batch_a from A_shape dimension 0, batch_a occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[0], BIT_LEN_32)
    # get batch_b from B_shape dimension 0, batch_b occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[0], BIT_LEN_32)
    # get cb from B_shape dimension 0 times dimension 4,
    # cb occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[1] * shape.get("b_shape")[4], BIT_LEN_32)
    # get ca1 from A_shape dimension 1, ca1 occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[1], BIT_LEN_32)
    # get ha from A_shape dimension 2, ha occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[2], BIT_LEN_16)
    # get wa from A_shape dimension 3, wa occupies 16 bits
    all_bin = num_2_bin(all_bin, conv2d_param.wa, BIT_LEN_16)
    # get hb from B_shape dimension 2, hb occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[2], BIT_LEN_16)
    # get wb from B_shape dimension 3, wb occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[3], BIT_LEN_16)
    # get hc from C_shape dimension 2, hc occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("c_shape")[2], BIT_LEN_16)
    # get wc from C_shape dimension 3, wc occupies 16 bits
    all_bin = num_2_bin(all_bin, conv2d_param.wc, BIT_LEN_16)
    # get fused_double_operand_num from shape,
    # fused_double_operand_num occupies 16 bits
    all_bin = num_2_bin(all_bin, math.ceil(conv2d_param.fused_double_operand_num * 1000 / 10), BIT_LEN_16)
    # get ca0 from A_shape dimension 4, ca0 occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[4], BIT_LEN_8)
    # get a_type from shape, a_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("a_dtype"), BIT_LEN_8)
    # get b_type from shape, b_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("b_dtype"), BIT_LEN_8)
    # get c_type from shape, c_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("c_dtype"), BIT_LEN_8)
    # get mad_type from shape, mad_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("mad_dtype"), BIT_LEN_8)
    # get padl from shape, padl occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("pad")[0], BIT_LEN_8)
    # get padr from shape, padr occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("pad")[1], BIT_LEN_8)
    # get padu from shape, padu occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("pad")[2], BIT_LEN_8)
    # get padd from shape, padd occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("pad")[3], BIT_LEN_8)
    # get stride_h from shape, stride_h occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("stride")[0], BIT_LEN_8)
    # get stride_w from shape, stride_w occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("stride")[1], BIT_LEN_8)
    # get fusion_type from shape, fusion_type_low occupies 16 bits
    all_bin = num_2_bin(all_bin, conv2d_param.fusion_type_low, BIT_LEN_16)
    # get dilation_h from shape, dilation_h occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("dilation")[0], BIT_LEN_8)
    # get dilation_w from shape, dilation_w occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("dilation")[1], BIT_LEN_8)
    # get group from shape, group_low occupies 8 bits
    all_bin = num_2_bin(all_bin, conv2d_param.group_low, BIT_LEN_8)
    # get op_tag from shape, op_tag occupies 8 bits
    if shape.get("op_type") not in OP_TAG_ENCODE.keys():
        raise ValueError("not support op_type: %s" % str(shape.get("op_type")))
    all_bin = str_2_bin(all_bin, shape.get("op_type"), BIT_LEN_8)
    # bias_flag quant_pre_flag relu_pre_flag each occupies 1 bit, 5bit reserved
    data = shape.get("bias_flag")
    if 'fixpipe_fusion_flag_dict' in shape:
        data = data | shape['fixpipe_fusion_flag_dict'].get("quant_pre_flag") << 1 | \
               shape['fixpipe_fusion_flag_dict'].get("relu_pre_flag") << 2
    if 'special_mode' in shape and 'high_performance_mode' in shape['special_mode']:
        data = data | shape['special_mode']['high_performance_mode'] << 4
    all_bin = num_2_bin(all_bin, data, BIT_LEN_8)

    # pooling_shape_H occupies 4 bits, pooling_shape_W occupies 4 bits
    all_bin = num_2_bin(all_bin, shape.get('pooling_shape', [0, 0])[0] + \
                    shape.get('pooling_shape', [0, 0])[1] * 2**4, BIT_LEN_8)
    # pooling_stride_H occupies 4 bits, pooling_stride_W occupies 4 bits
    all_bin = num_2_bin(all_bin, shape.get('pooling_stride', [0, 0])[0] + \
                    shape.get('pooling_stride', [0, 0])[1] * 2**4, BIT_LEN_8)
    # wa_high occupies 16 bits
    all_bin = num_2_bin(all_bin, conv2d_param.wa_high, BIT_LEN_16)
    # wc_high occupies 16 bits
    all_bin = num_2_bin(all_bin, conv2d_param.wc_high, BIT_LEN_16)
    # get fused_ub_cl0 from shape,
    # fused_ub_cl0 occupies 16 bits
    all_bin = num_2_bin(all_bin, math.ceil(shape.get('fused_ub_cl0', 0) * 1000 / 10), BIT_LEN_16)
    # fusion_type_high occupies 16 bits
    all_bin = num_2_bin(all_bin, conv2d_param.fusion_type_high, BIT_LEN_16)
    # group_high occupies 16 bits
    all_bin = num_2_bin(all_bin, conv2d_param.group_high, BIT_LEN_16)
    # reserved 32 bits
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_32)

    return all_bin


def conv_param_shape_2_bin(all_bin: list, shape: dict, group_low: int) -> list:
    """
    trans some conv param in shape to bin
    """
    # get ca0 from A_shape dimension 4, ca0 occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("A_shape")[4], BIT_LEN_8)
    # get a_type from shape, a_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("A_dtype"), BIT_LEN_8)
    # get b_type from shape, b_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("B_dtype"), BIT_LEN_8)
    # get c_type from shape, c_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("C_dtype"), BIT_LEN_8)
    # get mad_type from shape, mad_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("mad_dtype"), BIT_LEN_8)
    if shape.get("op_type") == "conv2d_backprop_input" or shape.get("op_type") == "conv2d_backprop_filter":
        # get padl from shape, padl occupies 8 bits
        all_bin = num_2_bin(all_bin, shape.get("padl") & MAX_VALUE_8_BIT, BIT_LEN_8)
        # get padr from shape, padr occupies 8 bits
        all_bin = num_2_bin(all_bin, shape.get("padr") & MAX_VALUE_8_BIT, BIT_LEN_8)
        # get padu from shape, padu occupies 8 bits
        all_bin = num_2_bin(all_bin, shape.get("padu") & MAX_VALUE_8_BIT, BIT_LEN_8)
        # get padd from shape, padd occupies 8 bits
        all_bin = num_2_bin(all_bin, shape.get("padd") & MAX_VALUE_8_BIT, BIT_LEN_8)
        # get stride_h from shape, stride_h occupies 8 bits
        all_bin = num_2_bin(all_bin, shape.get("strideH") & MAX_VALUE_8_BIT, BIT_LEN_8)
        # get stride_w from shape, stride_w occupies 8 bits
        all_bin = num_2_bin(all_bin, shape.get("strideW") & MAX_VALUE_8_BIT, BIT_LEN_8)
    else:
        # get padl from shape, padl occupies 8 bits
        all_bin = num_2_bin(all_bin, shape.get("padl"), BIT_LEN_8)
        # get padr from shape, padr occupies 8 bits
        all_bin = num_2_bin(all_bin, shape.get("padr"), BIT_LEN_8)
        # get padu from shape, padu occupies 8 bits
        all_bin = num_2_bin(all_bin, shape.get("padu"), BIT_LEN_8)
        # get padd from shape, padd occupies 8 bits
        all_bin = num_2_bin(all_bin, shape.get("padd"), BIT_LEN_8)
        # get stride_h from shape, stride_h occupies 8 bits
        all_bin = num_2_bin(all_bin, shape.get("strideH"), BIT_LEN_8)
        # get stride_w from shape, stride_w occupies 8 bits
        all_bin = num_2_bin(all_bin, shape.get("strideW"), BIT_LEN_8)
    # get stride_h_expand from shape, stride_h_expand occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("strideH_expand"), BIT_LEN_8)
    # get stride_w_expand from shape, stride_w_expand occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("strideW_expand"), BIT_LEN_8)
    # get dilation_h from shape, dilation_h occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("dilationH"), BIT_LEN_8)
    # get dilation_w from shape, dilation_w occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("dilationW"), BIT_LEN_8)
    # get group from shape, group occupies 8 bits
    all_bin = num_2_bin(all_bin, group_low, BIT_LEN_8)
    return all_bin


def dx_l1_fusion_shape_2_bin(all_bin: list, shape: dict) -> list:
    """
    transfer dx l1 fusion shape to binary
    all_bin: list of all binary data
    shape: case shape
    Returns:list, new all_bin
    """
    c_shape = shape.get("C_shape", None)
    shape["C_shape"] = ([0, 0, 0, 0] if c_shape is None else c_shape)

    group_low = shape.get("group") & MAX_VALUE_8_BIT
    group_high = (shape.get("group") >> 8) & MAX_VALUE_16_BIT

    # encode memory type
    in_fm_memory_type_encode = encode_memory_type("in", shape.get("in_fm_memory_type"))
    out_fm_memory_type_encode = encode_memory_type("out", shape.get("out_fm_memory_type"))

    if shape.get("l1_fusion_type") == DEFAULT_VALUE:
        shape["l1_fusion_type"] = L1_NO_FUSION

    # process input params
    # the order is same as TBEConv2dL1FusionTilingArgs
    all_bin = num_2_bin(all_bin, shape.get("A_shape")[0], BIT_LEN_64)  # batch_a
    all_bin = num_2_bin(all_bin, shape.get("B_shape")[0], BIT_LEN_64)  # batch_b
    all_bin = num_2_bin(all_bin, shape.get("B_shape")[1] * shape.get("B_shape")[4], BIT_LEN_64)  # cb
    all_bin = num_2_bin(all_bin, shape.get("A_shape")[1], BIT_LEN_64)  # ca1
    all_bin = num_2_bin(all_bin, in_fm_memory_type_encode,  BIT_LEN_32)
    # blank 32 bits
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_32)
    all_bin = num_2_bin(all_bin, shape.get("A_shape")[2], BIT_LEN_64)  # ha
    all_bin = num_2_bin(all_bin, shape.get("A_shape")[3], BIT_LEN_64)  # wa
    all_bin = num_2_bin(all_bin, shape.get("B_shape")[2], BIT_LEN_64)  # hb
    all_bin = num_2_bin(all_bin, shape.get("B_shape")[3], BIT_LEN_64)  # wb
    all_bin = num_2_bin(all_bin, shape.get("C_shape")[2], BIT_LEN_64)  # hc
    all_bin = num_2_bin(all_bin, shape.get("C_shape")[3], BIT_LEN_64)  # wc
    all_bin = num_2_bin(all_bin, shape.get("fusion_type"), BIT_LEN_16)
    all_bin = conv_param_shape_2_bin(all_bin, shape, group_low)
    all_bin = num_2_bin(all_bin, shape.get("l1_fusion_type"), BIT_LEN_8)
    all_bin = num_2_bin(all_bin, out_fm_memory_type_encode, BIT_LEN_8)
    all_bin = num_2_bin(all_bin, ZERO * 2 + shape.get("bias_flag"), BIT_LEN_8)

    # reserved 88 bits for occupying 64 Bytes in total
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_8)
    all_bin = num_2_bin(all_bin, group_high, BIT_LEN_16)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_32)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_32)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)

    return all_bin


def depthwise_l1_param_shap_2_bin(all_bin: list, shape: dict) -> list:
    """
    trans some depthwise l1 params from shape to bin
    """
    # blank 32 bits
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_32)
    # get ha from A_shape dimension 2, ha occupies 64 bits
    all_bin = num_2_bin(all_bin, shape["A_shape"][2], BIT_LEN_64)
    # get wa from A_shape dimension 3, wa occupies 64 bits
    all_bin = num_2_bin(all_bin, shape["A_shape"][3], BIT_LEN_64)
    # get hb from B_shape dimension 2, hb occupies 16 bits
    all_bin = num_2_bin(all_bin, shape["B_shape"][2], BIT_LEN_16)
    # get wb from B_shape dimension 3, wb occupies 16 bits
    all_bin = num_2_bin(all_bin, shape["B_shape"][3], BIT_LEN_16)
    # blank 32 bits
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_32)
    # get hc from C_shape dimension 2, hc occupies 64 bits
    all_bin = num_2_bin(all_bin, shape["C_shape"][2], BIT_LEN_64)
    # get wc from C_shape dimension 3, wc occupies 64 bits
    all_bin = num_2_bin(all_bin, shape["C_shape"][3], BIT_LEN_64)
    all_bin = num_2_bin(all_bin, shape['fusion_type'], BIT_LEN_16)
    # get ca0 from A_shape dimension 4, ca0 occupies 8 bits
    all_bin = num_2_bin(all_bin, shape["A_shape"][4], BIT_LEN_8)
    all_bin = str_2_bin(all_bin, shape["A_dtype"], BIT_LEN_8)
    all_bin = str_2_bin(all_bin, shape["B_dtype"], BIT_LEN_8)
    all_bin = str_2_bin(all_bin, shape["C_dtype"], BIT_LEN_8)
    all_bin = str_2_bin(all_bin, shape["mad_dtype"], BIT_LEN_8)
    all_bin = num_2_bin(all_bin, shape["padl"], BIT_LEN_8)
    all_bin = num_2_bin(all_bin, shape["padr"], BIT_LEN_8)
    all_bin = num_2_bin(all_bin, shape["padu"], BIT_LEN_8)
    all_bin = num_2_bin(all_bin, shape["padd"], BIT_LEN_8)
    all_bin = num_2_bin(all_bin, shape["strideH"], BIT_LEN_8)
    all_bin = num_2_bin(all_bin, shape["strideW"], BIT_LEN_8)
    all_bin = num_2_bin(all_bin, shape["dilationH"], BIT_LEN_8)
    all_bin = num_2_bin(all_bin, shape["dilationW"], BIT_LEN_8)
    all_bin = num_2_bin(all_bin, shape["group"], BIT_LEN_8)
    # get op_tag from shape, op_tag occupies 8 bits
    all_bin = num_2_bin(all_bin, shape["l1_fusion_type"], BIT_LEN_8)
    return all_bin


def depthwise_l1_fusion_shape_2_bin(all_bin: list, shape: dict) -> list:
    """
    transfer l1 fusion shape to binary
    all_bin: list of all binary data
    shape: shape of a case
    return: new all_bin
    """
    if not shape["C_shape"]:
        shape["C_shape"] = [0, 0, 0, 0]
    # encode the memory type
    in_fm_memory_type_encode = encode_memory_type("in", shape.get('in_fm_memory_type'))
    out_fm_memory_type_encode = encode_memory_type("out", shape.get('out_fm_memory_type'))

    # check the fm_l1_valid_size whether is legal
    shape['fm_l1_valid_size'] = shape.get('fm_l1_valid_size', DEFAULT_VALUE)
    if shape.get('fm_l1_valid_size') != DEFAULT_VALUE:
        fm_shape_size = INPUT_DATA_BYTE_WIDTH.get(shape.get('A_dtype'))
        for _, elt in enumerate(shape.get('A_shape')):
            fm_shape_size *= elt
        input_data_level = shape.get('fm_l1_valid_size') / fm_shape_size
        if input_data_level not in INPUT_DATA_LEVAL.keys():
            raise ValueError("the fm_l1_valid_size must be 1/2, 3/4, 1 times fm_shape_size, but fm_l1_valid_size \
                is %s, fm_shape_size is %s" % (shape.get('fm_l1_valid_size'), fm_shape_size))
        shape['fm_l1_valid_size_level'] = input_data_level
    else:
        shape['fm_l1_valid_size_level'] = ZERO

    # endocde the value of fm_l1_valid_size_level
    if shape.get('fm_l1_valid_size_level') != ZERO:
        raw_fm_l1_valid_size_level = shape.get('fm_l1_valid_size_level')
        shape['fm_l1_valid_size_level'] = INPUT_DATA_LEVAL.get(raw_fm_l1_valid_size_level)

    # 2 represent L1_no_fusion
    if shape["l1_fusion_type"] == DEFAULT_VALUE:
        shape["l1_fusion_type"] = L1_NO_FUSION
    # get batch_a from A_shape dimension 0, batch_a occupies 64 bits
    all_bin = num_2_bin(all_bin, shape["A_shape"][0], BIT_LEN_64)
    # get batch_b from B_shape dimension 0, batch_b occupies 64 bits
    all_bin = num_2_bin(all_bin, shape["B_shape"][0], BIT_LEN_64)
    # get cb from B_shape dimension 0 times dimension 4, cb occupies 64 bits
    all_bin = num_2_bin(all_bin, shape["B_shape"][1] * shape["B_shape"][4], BIT_LEN_64)
    # get ca1 from A_shape dimension 1, ca1 occupies 64 bits
    all_bin = num_2_bin(all_bin, shape["A_shape"][1], BIT_LEN_64)
    # get l1_fusion_input_memory_type
    all_bin = num_2_bin(all_bin, in_fm_memory_type_encode, BIT_LEN_32)

    all_bin = depthwise_l1_param_shap_2_bin(all_bin, shape)

    # get outputMemoryType from shape
    all_bin = num_2_bin(all_bin, out_fm_memory_type_encode, BIT_LEN_8)
    # get bias_flag from shape occupies 1 bit,
    # fm_l1_valid_size_level occupies 7 bits
    all_bin = num_2_bin(all_bin, int(shape["fm_l1_valid_size_level"] * 2 + shape['bias_flag']), BIT_LEN_8)
    # reserved 424 bits
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_8)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_32)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)
    all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_64)

    return all_bin


def prepare_conv3d_shape_2_bin(shape: dict) -> None:
    """
    prepare shape for transformation from conv3d shape to bin
    """
    if "A_shape" in shape:
        shape["a_shape"] = shape.get("A_shape")
        shape["b_shape"] = shape.get("B_shape")
        shape["c_shape"] = shape.get("C_shape")

        shape["a_dtype"] = shape.get("A_dtype")
        shape["b_dtype"] = shape.get("B_dtype")
        shape["c_dtype"] = shape.get("C_dtype")

        shape["fused_coefficient"] = [0, 0, shape.get("fused_double_operand_num")]
        shape["stride"] = [shape.get("strideD"), shape.get("strideH"), shape.get("strideW")]
        shape["dilation"] = [1, shape.get("dilationH"), shape.get("dilationW")]
        shape["strideh_expand"] = shape.get("strideH_expand")
        shape["stridew_expand"] = shape.get("strideW_expand")
        shape["pad"] = [shape.get("padf"), shape.get("padb"), shape.get("padu"),
                        shape.get("padd"), shape.get("padl"), shape.get("padr")]
    if not shape["c_shape"]:
        shape["c_shape"] = [0, 0, 0, 0]


def conv3d_shape_2_bin(all_bin: list, shape: dict) -> list:
    """
    transfer conv3d shape to binary
    all_bin: list of all binary data
    shape: shape of a case
    return: new all_bin
    """
    prepare_conv3d_shape_2_bin(shape)

    # get batch_a from a_shape dimension 0, batch_a occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[0], BIT_LEN_32)
    # get batch_b from b_shape dimension 0, batch_b occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[0], BIT_LEN_32)
    # get cb from b_shape dimension 2, dimension 5, cb occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[2] * shape.get("b_shape")[5], BIT_LEN_32)
    # get ca1 from a_shape dimension 2, ca1 occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[2], BIT_LEN_32)
    # get ha from a_shape dimension 3, ha occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[3], BIT_LEN_16)
    # get wa from a_shape dimension 4, wa occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[4], BIT_LEN_16)
    # get hb from b_shape dimension 3, hb occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[3], BIT_LEN_16)
    # get wb from b_shape dimension 4, wb occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[4], BIT_LEN_16)
    # get hc from c_shape dimension 2, hc occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("c_shape")[2], BIT_LEN_16)
    # get wc from c_shape dimension 3, wc occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("c_shape")[3], BIT_LEN_16)
    # get fused_double_operand_num from shape,
    # fused_double_operand_num occupies 16 bits
    all_bin = num_2_bin(all_bin, math.ceil(
            ((shape.get("fused_coefficient")[0]) << BIT_LEN_12) + shape.get("fused_coefficient")[2] * 100), BIT_LEN_16)
    # get ca0 from a_shape dimension 5, ca0 occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("a_shape")[5], BIT_LEN_8)

    # get a_type from shape, a_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("a_dtype"), BIT_LEN_8)
    # get b_type from shape, b_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("b_dtype"), BIT_LEN_8)
    # get c_type from shape, c_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("c_dtype"), BIT_LEN_8)
    # get mad_type from shape, mad_type occupies 8 bits
    all_bin = str_2_bin(all_bin, shape.get("mad_dtype"), BIT_LEN_8)
    # get padl from shape, padl occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("pad")[4], BIT_LEN_8)
    # get padr from shape, padr occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("pad")[5], BIT_LEN_8)
    # get padu from shape, padu occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("pad")[2], BIT_LEN_8)
    # get padd from shape, padd occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("pad")[3], BIT_LEN_8)
    # get stride_h from shape, stride_h occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("stride")[1], BIT_LEN_8)
    # get stride_w from shape, stride_w occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("stride")[2], BIT_LEN_8)
    # get stride_h_expand from shape, stride_h_expand occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("strideh_expand"), BIT_LEN_8)
    # get stride_w_expand from shape, stride_w_expand occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("stridew_expand"), BIT_LEN_8)
    # get dilation_h from shape, dilation_h occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("dilation")[1], BIT_LEN_8)
    # get dilation_w from shape, dilation_w occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("dilation")[2], BIT_LEN_8)
    group_low_val = shape.get("group") & MAX_VALUE_8_BIT
    group_high_val = (shape.get("group") >> BIT_LEN_8) & MAX_VALUE_16_BIT
    # get group_low_val from group, group_low_val occupies 8 bits
    all_bin = num_2_bin(all_bin, group_low_val, BIT_LEN_8)
    # get op_tag from shape, op_tag occupies 8 bits
    if shape.get("op_type") not in OP_TAG_ENCODE.keys():
        raise ValueError("not support op_type: %s" % str(shape.get("op_type")))
    all_bin = str_2_bin(all_bin, shape.get("op_type"), BIT_LEN_8)
    # get platform from shape, get bias_flag from shape
    # plat_form occupies 7 bit, bias_flag occupies 1 bit
    all_bin = num_2_bin(all_bin, shape.get("platform") * 2 + shape.get("bias_flag"), BIT_LEN_8)

    # add conv3d items
    if sys.byteorder == 'little':
        # get da from shape, da occupies 16 bits
        all_bin = num_2_bin(all_bin, shape.get("a_shape")[1], BIT_LEN_16)
        # get group_high_val from group, group_high_val occupies 16 bits
        all_bin = num_2_bin(all_bin, group_high_val, BIT_LEN_16)
    elif sys.byteorder == 'big':
        # get group_high_val from group, group_high_val occupies 16 bits
        all_bin = num_2_bin(all_bin, group_high_val, BIT_LEN_16)
        # get da from shape, da occupies 16 bits
        all_bin = num_2_bin(all_bin, shape.get("a_shape")[1], BIT_LEN_16)
    # get db from shape, db occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("b_shape")[1], BIT_LEN_32)
    # get padf from shape, padf occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("pad")[0], BIT_LEN_8)
    # get padb from shape, padb occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("pad")[1], BIT_LEN_8)
    # get strideD from shape, strideD occupies 8 bits
    all_bin = num_2_bin(all_bin, shape.get("stride")[0], BIT_LEN_8)
    all_bin = num_2_bin(all_bin, shape.get("dilation")[0], BIT_LEN_8)

    if shape.get("op_type") == 'conv3d_backprop_input' or shape.get("op_type") == 'conv3d_backprop_filter':
        # get dc from shape, dc occupies 32 bits
        all_bin = num_2_bin(all_bin, shape.get("c_shape")[1], BIT_LEN_32)

    return all_bin


def shape_2_bin(all_bin: list, shape: dict) -> list:
    """
    transfer shape to binary
    all_bin: list of all binary data
    shape: shape of a case
    return: new all_bin
    """
    if not shape["C_shape"]:
        shape["C_shape"] = [0, 0, 0, 0]

    group_low = shape.get("group") & MAX_VALUE_8_BIT
    group_high = (shape.get("group") >> 8) & MAX_VALUE_16_BIT
    padl_high = (shape.get("padl") >> 8) & MAX_VALUE_8_BIT
    padr_high = (shape.get("padr") >> 8) & MAX_VALUE_8_BIT
    padu_high = (shape.get("padu") >> 8) & MAX_VALUE_8_BIT
    padd_high = (shape.get("padd") >> 8) & MAX_VALUE_8_BIT
    strideh_high = (shape.get("strideH") >> 8) & MAX_VALUE_8_BIT
    stridew_high = (shape.get("strideW") >> 8) & MAX_VALUE_8_BIT

    # get batch_a from A_shape dimension 0, batch_a occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("A_shape")[0], BIT_LEN_32)
    # get batch_b from B_shape dimension 0, batch_b occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("B_shape")[0], BIT_LEN_32)
    # get cb from B_shape dimension 0 times dimension 4,
    # cb occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("B_shape")[1] * shape.get("B_shape")[4], BIT_LEN_32)
    # get ca1 from A_shape dimension 1, ca1 occupies 32 bits
    all_bin = num_2_bin(all_bin, shape.get("A_shape")[1], BIT_LEN_32)
    # get ha from A_shape dimension 2, ha occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("A_shape")[2], BIT_LEN_16)
    # get wa from A_shape dimension 3, wa occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("A_shape")[3] & MAX_VALUE_16_BIT, BIT_LEN_16)
    # get hb from B_shape dimension 2, hb occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("B_shape")[2], BIT_LEN_16)
    # get wb from B_shape dimension 3, wb occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("B_shape")[3] & MAX_VALUE_16_BIT, BIT_LEN_16)
    # get hc from C_shape dimension 2, hc occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("C_shape")[2], BIT_LEN_16)
    # get wc from C_shape dimension 3, wc occupies 16 bits
    all_bin = num_2_bin(all_bin, shape.get("C_shape")[3] & MAX_VALUE_16_BIT, BIT_LEN_16)
    # get fused_double_operand_num from shape,
    # fused_double_operand_num occupies 16 bits
    all_bin = num_2_bin(all_bin, math.ceil(shape.get("fused_double_operand_num") * 1000 / 10), BIT_LEN_16)
    all_bin = conv_param_shape_2_bin(all_bin, shape, group_low)
    # get op_tag from shape, op_tag occupies 8 bits
    if shape.get("op_type") not in OP_TAG_ENCODE.keys():
        raise ValueError("not support op_type: %s" % str(shape.get("op_type")))
    all_bin = str_2_bin(all_bin, shape.get("op_type"), BIT_LEN_8)
    # get platform from shape, get bias_flag from shape
    # plat_form occupies 7 bit, bias_flag occupies 1 bit
    all_bin = num_2_bin(all_bin, shape.get("platform") * 2 + shape.get("bias_flag"), BIT_LEN_8)

    if shape.get("op_type") == "conv2d_backprop_input" or shape.get("op_type") == "conv2d_backprop_filter":
        if shape.get("op_type") == "conv2d_backprop_input":
            fusion_type = shape.get("fusion_type", ZERO)
        else:
            fusion_type = ZERO

        all_bin = num_2_bin(all_bin, shape.get("A_shape")[3] >> 16, BIT_LEN_16)
        all_bin = num_2_bin(all_bin, shape.get("B_shape")[3] >> 16, BIT_LEN_16)
        all_bin = num_2_bin(all_bin, shape.get("C_shape")[3] >> 16, BIT_LEN_16)
        all_bin = num_2_bin(all_bin, fusion_type, BIT_LEN_16)
        all_bin = num_2_bin(all_bin, group_high, BIT_LEN_16)
        all_bin = num_2_bin(all_bin, padl_high, BIT_LEN_8)
        all_bin = num_2_bin(all_bin, padr_high, BIT_LEN_8)
        all_bin = num_2_bin(all_bin, padu_high, BIT_LEN_8)
        all_bin = num_2_bin(all_bin, padd_high, BIT_LEN_8)
        all_bin = num_2_bin(all_bin, strideh_high, BIT_LEN_8)
        all_bin = num_2_bin(all_bin, stridew_high, BIT_LEN_8)
    else:
        all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_16)
        all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_16)
        all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_16)
        all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_16)
        all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_32)
        all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_32)

    return all_bin


def tiling_2_bin_second(all_bin: list, tiling: list) -> list:
    """
    second part of transfer tiling to binary
    all_bin: list of all binary data
    shape: shape of a case
    tiling: tiling of a case
    return: new all_bin
    """
    # process specific dims of tiling
    n_bef_group_flag = ZERO
    batch_bef_group_flag = ZERO

    # get bub_ping_pong_buffer from tiling dimension 21
    # get aub_ping_pong_buffer from tiling dimension 9
    # bub_ping_pong_buffer and aub_ping_pong_buffer occupies 8 bits
    all_bin = num_2_bin(all_bin, tiling[21] * (2**4) + tiling[9], BIT_LEN_8)
    # get bl1_ping_pong_buffer from tiling dimension 14
    # get al1_ping_pong_buffer from tiling dimension 0
    # bl1_ping_pong_buffer and al1_ping_pong_buffer occupies 8 bits
    all_bin = num_2_bin(all_bin, tiling[14] * (2**4) + tiling[0], BIT_LEN_8)
    # get bl0_ping_pong_buffer from tiling dimension 31
    # get al0_ping_pong_buffer from tiling dimension 26
    # bl0_ping_pong_buffer and al0_ping_pong_buffer 8 bits
    all_bin = num_2_bin(all_bin, tiling[31] * (2**4) + tiling[26], BIT_LEN_8)
    # get cub_ping_pong_buffer from tiling dimension 41
    # get cl0_ping_pong_buffer from tiling dimension 36
    # cub_ping_pong_buffer and cl0_ping_pong_buffer occupies 8 bits
    all_bin = num_2_bin(all_bin, tiling[41] * (2**4) + tiling[36], BIT_LEN_8)
    # if count of dims of tiling is 50, the tiling is old tiling
    # if the num is 51, the cub_channel_wise_flag has added in tiling
    if len(tiling) >= 51:
        cub_channel_wise_flag = bool(tiling[46] and (tiling[46] != 0))
        # get ubg_ping_pong_buffer from tiling dimension 47
        # get nBefBatchFlag from tiling dimension 48
        # n_bef_group_flag fix 0
        # batch_bef_group_flag fix 0
        # get aOverHeadOptFlag from tiling dimension 1
        # 5 fields occupy 8 bits
        data = FLAG_ENCODE.get(tiling[48]) * (2 ** 4)
        data += n_bef_group_flag * (2 ** 5)
        data += batch_bef_group_flag * (2 ** 6)
        data += FLAG_ENCODE.get(tiling[1]) * (2 ** 7)
        data += tiling[47]
        all_bin = num_2_bin(all_bin, data, BIT_LEN_8)
        # get bOverHeadOptFlag from tiling dimension 15
        # get cubChannelWiseFlag from tiling dimension 46
        if len(tiling) == 53:
            all_bin = num_2_bin(all_bin, FLAG_ENCODE.get(tiling[15]) +
                FLAG_ENCODE.get(cub_channel_wise_flag) * 2 + tiling[52]*4, BIT_LEN_8)
        else:
            all_bin = num_2_bin(all_bin, FLAG_ENCODE.get(tiling[15]) +
                FLAG_ENCODE.get(cub_channel_wise_flag) * 2, BIT_LEN_8)
    else:
        # get ubg_ping_pong_buffer from tiling dimension 46
        # get nBefBatchFlag from tiling dimension 47
        # n_bef_group_flag fix 0
        # batch_bef_group_flag fix 0
        # get aOverHeadOptFlag from tiling dimension 1
        # 5 fields occupy 8 bits
        data = FLAG_ENCODE.get(tiling[47]) * (2 ** 4)
        data += n_bef_group_flag * (2 ** 5)
        data += batch_bef_group_flag * (2 ** 6)
        data += FLAG_ENCODE.get(tiling[1]) * (2 ** 7)
        data += tiling[46]
        all_bin = num_2_bin(all_bin, data, BIT_LEN_8)
        # get bOverHeadOptFlag from tiling dimension 15
        all_bin = num_2_bin(all_bin, FLAG_ENCODE.get(tiling[15]), BIT_LEN_8)

    if len(tiling) >= 52:
        all_bin = num_2_bin(all_bin, tiling[51], BIT_LEN_16)
    else:
        all_bin = num_2_bin(all_bin, ZERO, BIT_LEN_16) # blank

    return all_bin


def tiling_2_bin(all_bin: list, shape: dict, tiling: list) -> list:
    """
    transfer tiling to binary
    all_bin: list of all binary data
    shape: shape of a case
    tiling: tiling of a case
    return: new all_bin
    """
    # check tiling info
    tiling = check_tiling(tiling)
    al0_matrix3, bl0_matrix3 = get_al0_bl0_matrix(shape)
    # get al1_shape0 from tiling dimension 5, al1_shape0 occupies 32 bits
    all_bin = num_2_bin(all_bin, tiling[5], BIT_LEN_32)
    # get bl1_shape0 from tiling dimension 17, bl1_shape0 occupies 32 bits
    all_bin = num_2_bin(all_bin, tiling[17], BIT_LEN_32)

    # get al1_shape1 from tiling dimension 6, al1_shape1 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[6], BIT_LEN_16)
    # get al1_shape2 from tiling dimension 7, al1_shape2 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[7], BIT_LEN_16)
    # get al1_shape3 from tiling dimension 8, al1_shape3 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[8], BIT_LEN_16)

    # get bl1_shape1 from tiling dimension 18, bl1_shape1 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[18], BIT_LEN_16)
    # get bl1_shape2 from tiling dimension 19, bl1_shape2 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[19], BIT_LEN_16)
    # get bl1_shape3 from tiling dimension 20, bl1_shape3 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[20], BIT_LEN_16)

    # get al0_matrix0 from tiling dimension 27, al0_matrix0 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[27], BIT_LEN_16)
    # get al0_matrix1 from tiling dimension 28, al0_matrix1 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[28], BIT_LEN_16)
    # fix 16, al0_matrix2 occupies 8 bits
    all_bin = num_2_bin(all_bin, 16, BIT_LEN_8)
    # if B_dtype is float16, al0_matrix3 is 16, else al0_matrix3 is 32
    # al0_matrix3 occupies 8 bits
    all_bin = num_2_bin(all_bin, al0_matrix3, BIT_LEN_8)
    # get al0_matrix4 from tiling dimension 29, al0_matrix4 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[29], BIT_LEN_16)
    # get al0_matrix5 from tiling dimension 30, al0_matrix5 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[30], BIT_LEN_16)
    # get bl0_matrix0 from tiling dimension 32, bl0_matrix0 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[32], BIT_LEN_16)
    # get bl0_matrix1 from tiling dimension 33, bl0_matrix1 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[33], BIT_LEN_16)
    # fix 16, bl0_matrix2 occupies 8 bits
    all_bin = num_2_bin(all_bin, 16, BIT_LEN_8)
    # if B_dtype is float16, bl0_matrix3 is 16, else bl0_matrix3 is 32
    # bl0_matrix3 occupies 8 bits
    all_bin = num_2_bin(all_bin, bl0_matrix3, BIT_LEN_8)
    # get bl0_matrix4 from tiling dimension 34, bl0_matrix4 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[34], BIT_LEN_16)
    # get bl0_matrix5 from tiling dimension 35, bl0_matrix5 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[35], BIT_LEN_16)

    # get cl0_matrix0 from tiling dimension 38, cl0_matrix0 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[38], BIT_LEN_16)
    # get cl0_matrix1 from tiling dimension 37, cl0_matrix1 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[37], BIT_LEN_16)
    # fix 16, cl0_matrix2 occupies 8 bits
    all_bin = num_2_bin(all_bin, 16, BIT_LEN_8)
    # fix 16, cl0_matrix3 occupies 8 bits
    all_bin = num_2_bin(all_bin, 16, BIT_LEN_8)
    # get cl0_matrix4 from tiling dimension 39, cl0_matrix4 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[39], BIT_LEN_16)
    # get cl0_matrix5 from tiling dimension 40, cl0_matrix5 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[40], BIT_LEN_16)

    # get cub_matrix0 from tiling dimension 42, cub_matrix0 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[42], BIT_LEN_16)
    # get cub_matrix1 from tiling dimension 43, cub_matrix1 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[43], BIT_LEN_16)
    # fix 16, cub_matrix2 occupies 8 bits
    all_bin = num_2_bin(all_bin, 16, BIT_LEN_8)
    # fix 16, cub_matrix3 occupies 8 bits
    all_bin = num_2_bin(all_bin, 16, BIT_LEN_8)
    # get cub_matrix4 from tiling dimension 44, cub_matrix4 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[44], BIT_LEN_16)
    # get cub_matrix5 from tiling dimension 45, cub_matrix5 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[45], BIT_LEN_16)

    # get aub_shape0 from tiling dimension 10, aub_shape0 occupies 32 bits
    all_bin = num_2_bin(all_bin, tiling[10], BIT_LEN_32)
    # get bub_shape0 from tiling dimension 22, bub_shape0 occupies 32 bits
    all_bin = num_2_bin(all_bin, tiling[22], BIT_LEN_32)

    # get aub_shape1 from tiling dimension 11, aub_shape1 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[11], BIT_LEN_16)
    # get aub_shape2 from tiling dimension 12, aub_shape2 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[12], BIT_LEN_16)
    # get aub_shape3 from tiling dimension 13, aub_shape3 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[13], BIT_LEN_16)

    # get bub_shape1 from tiling dimension 23, bub_shape1 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[23], BIT_LEN_16)
    # get bub_shape2 from tiling dimension 24, bub_shape2 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[24], BIT_LEN_16)
    # get bub_shape3 from tiling dimension 25, bub_shape3 occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[25], BIT_LEN_16)

    # get batch_dim from tiling dimension 2, batch_dim occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[2], BIT_LEN_16)
    # get n_dim from tiling dimension 16, n_dim occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[16], BIT_LEN_16)
    # get m_dim from tiling dimension 3, m_dim occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[3], BIT_LEN_16)
    # get group_Dim from tiling dimension 4, group_Dim occupies 16 bits
    all_bin = num_2_bin(all_bin, tiling[4], BIT_LEN_16)
    return tiling_2_bin_second(all_bin, tiling)
