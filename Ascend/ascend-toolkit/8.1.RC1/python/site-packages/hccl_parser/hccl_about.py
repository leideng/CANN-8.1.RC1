#!/usr/bin/env python
# coding=utf-8

# Copyright (c) Huawei Technologies Co., Ltd. 2021-2021. All rights reserved.
# description: hccl_bin文件相关
# Create: 2021-9-17

import os
import re
import struct

role_dict = {0: 'dst', 1: 'src'}
op_dict = {0: 'SUM', 1: 'PROD', 2: 'MAX', 3: 'MIN'}
dtype_dict = {0: 'INT8', 1: 'INT16', 2: 'INT32', 3: 'FP16', 4: 'FP32', 5: 'INT64', 6: 'UINT64'}
link_type_dict = {0: 'OnChip', 1: 'HCCS', 2: 'PCIe', 3: 'RoCE'}
transport_type_dict = {0: 'SDMA', 1: 'RDMA', 2: 'LOCAL'}
RDMA_type_dict = {0: 'RDMASendNotify', 1: 'RDMASendPayload', 2: 'NONE'}
MAX_TASKID = 65536

def getkey(op_elem):
    return int(op_elem['tag'].split('_')[2])

def get_sidtid_from_ops(ops, ar_op):
    stid_list = []
    end_stid_list = []
    ops.sort(key=getkey)

    for op_elem in ops:
        if ar_op.lower() in op_elem['tag'].lower() or ar_op == 'all':
            op_list = []
            end_op_list = []
            stream_nums = len(op_elem['streams'])
            for stream in op_elem['streams']:
                for task in stream['tasks']:
                    if 'stage' in task['name']:
                        continue
                    sid = stream['stream_id']
                    tid = task['args']['task_id']
                    batch_id = task['args']['batch_id']

                    stid = [sid, tid, batch_id]
                    op_list.append(stid)
                    break
                for i in range(len(stream['tasks']) - 1, -1, -1):
                    if 'stage' in stream['tasks'][i]['name']:
                        continue
                    sid = stream['stream_id']
                    tid = stream['tasks'][i]['args']['task_id']
                    batch_id = stream['tasks'][i]['args']['batch_id']

                    stid = [sid, tid, batch_id]
                    end_op_list.append(stid)
                    break
            stid_list.append([op_list, 0, stream_nums, op_elem['tag']])
            end_stid_list.append([end_op_list, 0])
    return stid_list, end_stid_list


# ops_process, 功能：删除task序列中 stage0-step1这种task，方便MI的人解析
# 参数描述： ops->hccl_process得到的结构体
class DeviceData:

    __slots__ = ('device_id', 'stream')

    def __init__(self, device_id):
        self.device_id = device_id
        self.stream = []

    def add_stream(self, stream):
        self.stream.append(stream)


class Stream:

    __slots__ = ('stream_id', 'stream_type', 'stream_info', 'task')

    def __init__(self, stream_id, stream_info=None):
        self.stream_id = stream_id
        self.stream_type = 'HCCL'
        self.stream_info = stream_info
        self.task = []

    def add_task(self, task):
        self.task.append(task)


class Task:

    __slots__ = (
    'task_type', 'task_id', 'stage', 'step', 'src', 'dst', \
    'notify_id', 'plane_id', 'datasize', \
    'channel_type', 'op_type', 'task_record', 'name', \
    'src_rank', 'dst_rank', 'transport_type', 'batch_id')

    def __init__(self, task_type, task_id=None, stage=None, step=None, \
                 src=None, dst=None, notify_id=None,\
                 plane_id=None, channel_type='NULL', datasize=None, \
                 op_type=None, name=None, src_rank=None,\
                 dst_rank=None, transport_type=None, batch_id=None):
        self.task_type = task_type
        self.task_id = task_id
        self.plane_id = plane_id
        self.stage = stage
        self.step = step
        self.src = src
        self.dst = dst
        self.notify_id = notify_id
        self.datasize = datasize
        self.channel_type = channel_type
        self.op_type = op_type
        self.task_record = []
        self.name = name
        self.src_rank = src_rank
        self.dst_rank = dst_rank
        self.transport_type = transport_type
        self.batch_id = batch_id

    def add_task_record(self, task_record):
        self.task_record.append(task_record)

def ops_process(deviceid, local_rankid, ops):

    devicedata = DeviceData(deviceid)
    op_elem = ops[0]
    optag = op_elem['tag']
    end_index = optag.rfind('_')
    optype = optag[len('hcom_'):end_index]

    for streamindex in op_elem['streams']:
        stream_id = streamindex['stream_id']
        planeid = streamindex['plane_id']
        stream_info = str(planeid)
        tmpstream = Stream(stream_id, stream_info)
        taskslist = streamindex['tasks']
        for taskindex in taskslist:
            taskname = taskindex['name']
            if "stage" in taskname:
                continue
            args = taskindex['args']


            local_rank = local_rankid
            remote_rank = args['remote_rank']
            srcrank = local_rank
            dstrank = remote_rank

            if args['role'] == 'dst':
                srcrank = remote_rank
                dstrank = local_rank
            if args['role'] == 'src':
                srcrank = local_rank
                dstrank = remote_rank
            if args['task_type'] == 5 or args['task_type'] == 0 or\
                            args['task_type'] == 16:
                tmptask = Task(taskindex['name'], task_id=args['task_id'],\
                               stage=args['stage'], step=args['step'], \
                               src=args['src'], dst=args['dst'], \
                               channel_type=args['link_type'],\
                               datasize=args['size'], notify_id=0, \
                               plane_id=planeid, op_type=optype, \
                               name=taskname, src_rank=srcrank, \
                               dst_rank=dstrank, \
                               transport_type=args['transport_type'],
                               batch_id=args['batch_id'])
            elif args['task_type'] == 14 or args['task_type'] == 15:
                tmptask = Task(taskindex['name'], task_id=args['task_id'],\
                               stage=args['stage'], step=args['step'],\
                               notify_id=args['notify_id'], plane_id=planeid,\
                               op_type=optype, name=taskname, \
                               src_rank=srcrank, dst_rank=dstrank, \
                               transport_type=args['transport_type'],
                               batch_id=args['batch_id'])
            else:
                tmptask = Task(taskindex['name'], task_id=args['task_id'],
                               stage=args['stage'], step=args['step'], \
                               src='NULL', dst='NULL', channel_type='Null', \
                               datasize='NULL', notify_id=args['notify_id'], \
                               plane_id=planeid, op_type=optype, \
                               name=taskname, batch_id=args['batch_id'])

            tmpstream.add_task(tmptask)

        devicedata.add_stream(tmpstream)
    return devicedata

def get_allreduce_tag(file_name):
    tag_name = file_name.split('/')[-1].split('.')[1]
    return tag_name


def bin_file_merge(file_path, ar_op):
    name_list = []

    if os.path.exists(file_path):

        files = os.listdir(file_path)
        for file_name in files:
            if ar_op in file_name and not file_name.endswith('done'):
                name_list.append(file_name)

    file_bin_name = file_path + os.sep + '%s' % ar_op
    name_list.sort(key=lambda x: int(x.split('_')[-1]))

    if os.path.exists(file_bin_name):
        os.remove(file_bin_name)
    with open(file_bin_name, 'ab+') as bin_data:
        for i in name_list:
            file_path_ = file_path + os.sep + i
            with open(file_path_, 'rb') as txt:
                bin_data.write(txt.read())

    return file_bin_name

def bin_parser(file_path):
    file_list = []
    if os.path.exists(file_path):
        files = os.listdir(file_path)
        for file_name in files:
            if file_name.split('.')[0] == 'HCCL' and file_name.split('.')[-1] != 'done' \
                and file_name.split('.')[1] != 'hash_dic':
                file_list.append(file_path + os.sep + file_name)
        allreduce_tag_set = set()

        for eachfile in file_list:
            allreduce_tag_set.add(get_allreduce_tag(eachfile))
        bin_list = []

        for ar_op in allreduce_tag_set:
            return_path = bin_file_merge(file_path, ar_op)
            bin_list.append(return_path)

        if not bin_list:
            raise FileNotFoundError("[ERROR] No matched any HCCL file.")

        return bin_list


def get_stage_by_name(task_item=None):
    segments = task_item['name'].split('-')
    stages = re.findall(r'stage\d+', segments[0])
    return stages[0][len('stage'):]


def get_step_by_name(task_item=None):
    segments = task_item['name'].split('-')
    steps = re.findall(r'step\d+', segments[1])
    return steps[0][len('step'):]


def get_plane_id(stream=None):
    return stream['plane_id']


def get_stream_id(stream=None):
    return stream['stream_id']

def get_localrank_and_workflow_mode(h_file):

    with open(h_file, 'rb') as hccl_data:
        _line = hccl_data.read(104)

    local_rank, workflow_mode = struct.unpack('II', _line[56:64])

    return local_rank, workflow_mode


def type_parse(part):
    b = []
    for i in part:
        if i == b'\x00':
            break
        else:
            b.append(i.decode())

    name = "".join(b)

    return name.strip('"')


def end_parse(_line, log_type):
    plane_id, device_id, stream_id = struct.unpack('III', _line[4:16])
    ts = struct.unpack('d', _line[16:24])[0]
    hccl_trace = {'plane_id': plane_id, 'device_id': device_id, 'stream_id': -1, 'ts': ts, 'name': log_type}

    return hccl_trace


def flag_parse(_line, log_type):
    ccl_tag_hash, group_name_hash = struct.unpack('QQ', _line[40:56])
    local_rank, workflow_mode = struct.unpack('II', _line[56:64])
    ccl_tag, group_name = ccl_tag_hash, group_name_hash
    hccl_trace = {'name': log_type,
                  'args': {'ccl_tag': ccl_tag, 'group_name': group_name, 'localRank': local_rank,
                           'workFlowMode': workflow_mode}}

    return hccl_trace


def stage_parse(_line, log_type):
    plane_id, device_id, stream_id = struct.unpack('III', _line[4:16])
    ts = struct.unpack('d', _line[16:24])[0]
    rank, rank_size = struct.unpack('II', _line[40:48])
    hccl_trace = {'plane_id': plane_id, 'device_id': device_id, 'stream_id': stream_id, 'ts': ts, 'name': log_type,
                  'args': {'rank': rank, 'rank_size': rank_size}}

    return hccl_trace


def memcpy_parse(_line, log_type):
    plane_id, device_id, stream_id = struct.unpack('III', _line[4:16])
    ts = struct.unpack('d', _line[16:24])[0]
    task_id = struct.unpack('I', _line[40:44])[0]
    src, dst, size, notify_id = struct.unpack('QQQQ', _line[44:76])
    link_type, remote_rank, transport_type, role = struct.unpack('IIII', _line[76:92])
    duration_estimated = struct.unpack('d', _line[92:100])[0]
    hccl_trace = {'plane_id': plane_id, 'device_id': device_id, 'stream_id': stream_id, 'ts': ts, 'name': log_type,
                  'args': {'task_id': task_id, 'src': src, 'dst': dst, 'size': size, 'notify_id': notify_id,
                           'link_type': link_type_dict[link_type], 'remote_rank': remote_rank,
                           'transport_type': transport_type_dict[transport_type],
                           'role': role_dict[role],
                           'duration_estimated': duration_estimated}}

    return hccl_trace


def rdma_parse(_line, log_type):
    plane_id, device_id, stream_id = struct.unpack('III', _line[4:16])
    ts = struct.unpack('d', _line[16:24])[0]
    task_id = struct.unpack('I', _line[40:44])[0]
    src, dst, size, notify_id = struct.unpack('QQQQ', _line[44:76])
    link_type, remote_rank, transport_type, role, type = struct.unpack('IIIII', _line[76:96])
    duration_estimated = struct.unpack('d', _line[96:104])[0]
    hccl_trace = {'plane_id': plane_id, 'device_id': device_id, 'stream_id': stream_id, 'ts': ts, 'name': log_type,
                  'args': {'task_id': task_id, 'src': src, 'dst': dst, 'size': size, 'notify_id': notify_id,
                           'link_type': link_type_dict[link_type], 'remote_rank': remote_rank,
                           'transport_type': transport_type_dict[transport_type],
                           'role': role_dict[role],
                           'type': RDMA_type_dict[type], 'duration_estimated': duration_estimated}}
    return hccl_trace


def reduce_parse(_line, log_type):
    plane_id, device_id, stream_id = struct.unpack('III', _line[4:16])
    ts = struct.unpack('d', _line[16:24])[0]
    task_id = struct.unpack('I', _line[40:44])[0]
    src, dst, size = struct.unpack('QQQ', _line[44:68])
    op, data_type, link_type, remote_rank, transport_type, role = struct.unpack('IIIIII', _line[68:92])
    duration_estimated = struct.unpack('d', _line[92:100])[0]

    hccl_trace = {'plane_id': plane_id, 'device_id': device_id, 'stream_id': stream_id, 'ts': ts, 'name': log_type,
                  'args': {'task_id': task_id, 'src': src, 'dst': dst, 'size': size, 'op': op_dict[op],
                           'data_type': dtype_dict[data_type], 'link_type': link_type_dict[link_type],
                           'remote_rank': remote_rank, 'transport_type': transport_type_dict[transport_type],
                           'role': role_dict[role],
                           'duration_estimated': duration_estimated}}

    return hccl_trace


def notify_parse(_line, log_type):
    plane_id, device_id, stream_id = struct.unpack('III', _line[4:16])
    ts = struct.unpack('d', _line[16:24])[0]
    task_id = struct.unpack('I', _line[40:44])[0]
    notify_id = struct.unpack('Q', _line[44:52])[0]
    stage, remote_rank, transport_type, role = struct.unpack('IIII', _line[52:68])
    duration_estimated = struct.unpack('d', _line[68:76])[0]

    hccl_trace = {'plane_id': plane_id, 'device_id': device_id, 'stream_id': stream_id, 'ts': ts, 'name': log_type,
                  'args': {'task_id': task_id, 'notify_id': notify_id, 'stage': stage, 'remote_rank': remote_rank,
                           'transport_type': transport_type_dict[transport_type], 'role': role_dict[role],
                           'duration_estimated': duration_estimated}}

    return hccl_trace


def get_taskinfo_from_bin(_line):
    log_type = type_parse(struct.unpack('cccccccccccccccc', _line[24:40]))

    if(log_type.startswith("end")):
        current_hccl = end_parse(_line, log_type)
        return False, current_hccl
    elif(log_type.startswith("Flag")):
        current_hccl = flag_parse(_line, log_type)
        return False, current_hccl
    elif(log_type.startswith("stage")):
        current_hccl = stage_parse(_line, log_type)
    elif(log_type.startswith("Memcpy")):
        current_hccl = memcpy_parse(_line, log_type)
    elif(log_type.startswith("RDMASend")):
        current_hccl = rdma_parse(_line, log_type)
    elif(log_type.startswith("Reduce")):
        current_hccl = reduce_parse(_line, log_type)
    elif(log_type.startswith("Notify")):
        current_hccl = notify_parse(_line, log_type)
    else:
        print('[ERROR] log_type parse wrong:', log_type)


    return True, current_hccl


def post_process(op_dict):
    for stream in op_dict['streams']:
        op_dict['task_total'] += len(stream['tasks'])
        for task in stream['tasks']:
            if 'stage' not in task['name']:
                op_dict['task_total_runtime'] += 1

    op_dict['streams'].sort(key=get_plane_id)
    op_dict['streams'].sort(key=get_stream_id)
    op_dict['main_stream'] = op_dict['streams'][-1]
    stream_index = 0
    while stream_index < len(op_dict['stream_ids']):
        op_dict['stream_ids'][stream_index] = op_dict['streams'][stream_index]['stream_id']
        stream_index += 1

    return op_dict


def get_new_stream(stream_id, op_dict):
    if stream_id not in op_dict['stream_ids']:
        stream = {
            'plane_id': None,
            'stream_id': stream_id,
            'task_cnt': 0,
            'task_total': 0,
            'tasks': [],
            'steps': [],
            'current_stage': 0,
            'current_step': 0
        }
        op_dict['streams'].append(stream)
        op_dict['stream_ids'].append(stream_id)

    return op_dict

def get_new_info(stream_id, current_hccl, op_dict):
    stream_index = op_dict['stream_ids'].index(stream_id)
    task_dict = {
        'tid': current_hccl['plane_id'],
        'name': current_hccl['name'],
        'args': current_hccl['args']
    }

    current_sta = op_dict['streams'][stream_index]['current_stage']
    current_step = op_dict['streams'][stream_index]['current_step']

    if 'stage' not in current_hccl['name']:
        if 'stage' in current_hccl['args']:
            if current_hccl['args']['stage'] != '0xffffffff':
                current_sta = current_hccl['args']['stage']
                current_step = 9 * 10 + current_hccl['args']['stage']
        task_dict['args']['bandwidth(GB/s)'] = 0
        task_dict['args']['stream_id'] = stream_id
        task_dict['args']['task_id'] = current_hccl['args']['task_id']
        task_type_dict = {"AI core": 0, "Reduce Inline": 5, \
                          "Memcpy": 5, "Reduce TBE": 5, \
                          "Notify Wait": 14,
                          "Notify Record": 15, "RDMASend": 16}

        task_dict['args']['task_type'] = task_type_dict[current_hccl['name']]
    else:
        op_dict['streams'][stream_index]['current_stage'] = \
            get_stage_by_name(current_hccl)
        op_dict['streams'][stream_index]['current_step'] = \
            get_step_by_name(current_hccl)
        op_dict['streams'][stream_index]['rank_id'] = \
            current_hccl['args']['rank']
        op_dict['streams'][stream_index]['rank_size'] = \
            current_hccl['args']['rank_size']

    task_dict['args']['stage'] = current_sta
    task_dict['args']['step'] = current_step

    op_dict['device_id'] = current_hccl['device_id']
    op_dict['streams'][stream_index]['plane_id'] = task_dict['tid']
    op_dict['streams'][stream_index]['tasks'].append(task_dict)
    op_dict['streams'][stream_index]['task_total'] += 1
    op_dict['streams'][stream_index]['task_cnt'] += 1

    return op_dict


def hccl_process(json_list):
    ops = []

    for file_full_name in json_list:
        with open(file_full_name, "rb") as hccl_task_trace:
            op_dict = {
                'device_id': 0,
                'tag': file_full_name.split('\\')[-1].split('/')[-1],
                'iteration_cnt': 0,
                'iterations': [],
                'streams': [],
                'stream_ids': [],
                'task_cnt': 0,
                'task_total': 0,
                'task_total_runtime': 0,
                'timestamp-first': 0,
                'timestamp-last': 0,
                'main_stream': None
            }

            while 1:
                _line = hccl_task_trace.read(104)
                if not _line:
                    break

                if not _line.strip():
                    continue
                is_continue, current_hccl = get_taskinfo_from_bin(_line)
                if 'stage' in current_hccl['name']:
                    continue
                if "Flag" in current_hccl['name']:
                    continue
                if 'End' in current_hccl['name']:
                    continue
                if not is_continue:
                    continue

                stream_id = current_hccl['stream_id']
                op_dict = get_new_stream(stream_id, op_dict)
                op_dict = get_new_info(stream_id, current_hccl, op_dict)
            if len(op_dict.get('streams')) == 0:
                print('[WARN] HCCL streams is not exist.')
            else:
                op_dict = post_process(op_dict)
                ops.append(op_dict)

        # remove中间文件
        os.remove(file_full_name)
    ops = sort_taski(ops)
    return ops


def sort_taski(ops):
    # 对集合通信taskid不取余
    stream_sort_dict = {}

    for op in ops:
        for streams in op['streams']:
            if stream_sort_dict.get(streams['stream_id']) is None:
                stream_sort_dict[streams['stream_id']] = []
            stream_sort_dict[streams['stream_id']].extend(streams['tasks'])

    for stream in stream_sort_dict:
        stream_sort_dict[stream] = sorted( stream_sort_dict[stream], key=lambda x:x['args']['task_id'])
        last_taskid = -1
        batch_id = 0
        for task in stream_sort_dict[stream]:
            task_id = task['args']['task_id'] % 65536
            if last_taskid == -1:
                last_taskid = task_id

            elif task_id < last_taskid:
                last_taskid = task_id
                batch_id += 1
            else:
                last_taskid = task_id
            task['args']['task_id'] = task_id
            task['args']['batch_id'] = batch_id
    return ops




