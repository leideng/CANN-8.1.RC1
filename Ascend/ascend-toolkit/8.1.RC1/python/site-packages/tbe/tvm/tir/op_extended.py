#!/usr/bin/env python
# -*- coding: UTF-8 -*-
# Copyright 2022 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""extended Operator"""
# pylint: disable=invalid-name
import struct
import numpy as np

from tvm._ffi.base import string_types
from tvm.runtime import convert, const
from tvm.ir import Array, Op
from tvm.error_mgr import raise_tbe_python_err, TBE_DEFAULT_PYTHON_ERROR_CODE
from .op import call_pure_extern, if_then_else, comm_reducer, call_intrin
from .expr import Call, StringImm, Not, PrimExprWithOp, Select
from . import _ffi_api

int64 = "int64"


def call_cce_pure_intrin(dtype, name, *args, span=None):
    """Build expression by calling a pure cce intrinsic function

    Parameters
    ----------
    dtype : str
       The data type of the result.

    name : str
       The name of the llvm intrinsic function.

    args : list
       Poistional arguments.

    span : Optional[Span]
        The location of this operator in the source code.

    Returns
    -------
    call : PrimExpr
        The call expression.
    """
    return call_intrin(
        dtype, Op.get("tir.call_llvm_pure_intrin"), StringImm(name), *args, span=span,
    )


def call_cce_intrin(dtype, name, *args, span=None):
    """Build expression by calling a cce intrinsic function

    Parameters
    ----------
    dtype : str
       The data type of the result.

    name : str
       The name of the llvm intrinsic function.

    args : list
       Poistional arguments.

    span : Optional[Span]
        The location of this operator in the source code.

    Returns
    -------
    call : PrimExpr
        The call expression.
    """
    return call_intrin(
        dtype, Op.get("tir.call_llvm_intrin"), StringImm(name), *args, span=span
    )


def negate(*args):
    """Create a new experssion of the not of all conditions in the arguments

    Parameters
    ----------
    args : list
        List of symbolic boolean expressions

    Returns
    -------
    expr: Expr
        Expression
    """
    if len(args) != 1:
        raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                             "Not must take at 1 argument")
    ret = Not(args[0])
    return ret


def fixpipe_op(src, dst_dtype, pre_conv_param=None, pre_relu_param=None, pre_clip_relu_param=None,
               post_eltwise_src=None, post_anti_quant_scale=None, post_anti_quant_offset=None,
               post_clip_relu_param=None, post_quant_param=None, post_relu_param=None,
               pre_clip_relu_min_param=None, op_dict={}):
    """fixpipe intrin for v220 and v300

    Parameters
    -------
    src : tensor
        src in L0C.
    dst_dtype : string
        type of dst result
    pre_conv_param : tensor(vector), imm(scalar)
        quant_pre parameter: used for both scalar and vector relu mode
    pre_relu_param : tensor(vector), imm(scalar)
        pre-relu parameter: used for both scalar and vector relu mode
    pre_clip_relu_param : imm
        pre-clip relu parameter
    post_eltwise_src : tensor
        eltwise-op src in L1
    post_anti_quant_scale : imm
        scale parameter for eltwise op.
    post_anti_quant_offset : imm
        offset parameter for eltwise op.
    post_clip_relu_param : imm
        post-clip relu parameter
    post_quant_param : tensor(vector), imm(scalar)
        quant_post parameter: used for both scalar and vector relu mode
    pre_clip_relu_min_param : Is the lower bound in Clip ReLU for nano
    post_relu_param : tensor(vector), imm(scalar)
        post-relu paramter: used for both scalar and vector relu mode
    op_dict : dictionary
        'pre_conv': 'F322F16', 'F322B8', 'F322S4', 'F322BF16', 'S322F16', 'S322B8', 'S322S4'
                    'VF322B8', 'VF322S4', 'VF322BF16', 'VS322F16', 'VS322B8', 'VS322S4'
        'pre_activation': 'NORMAL_RELU', 'SCALAR_RELU', 'VECTOR_RELU'
                          'SIGMOID', 'TANH', 'ELU'(nano LUT activation mode)
        'post_anti_quant': 'S4', 'S8'
        'post_eltwise': 'ADD', 'SUB'
        'post_activation': 'NORMAL_RELU', 'SCALAR_RELU', 'VECTOR_RELU'
        'post_quant': 'F162S4', 'F162B8', 'VF162S4', 'VF162B8'
        'post_transform': 'NZ2ND', 'WINO_POST'

    Returns
    -------
    res : Expr
        The result.
    """

    def __pre_process_arg(arg):
        return "fixpipe_op_default_arg" if arg is None else arg

    from tbe.common.testing.testing import is_debug_mode
    if is_debug_mode():
        raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                             "fixpipe_op() is not supported on CPU. Try to write compute instead.")
    else:
        args = [src, pre_conv_param, pre_relu_param, pre_clip_relu_param, post_eltwise_src,
                post_anti_quant_scale, post_anti_quant_offset, post_clip_relu_param,
                post_quant_param,
                post_relu_param, pre_clip_relu_min_param]
        args = [__pre_process_arg(arg) for arg in args]
        call_name = "fixpipe_op"
        if not op_dict:
            return call_cce_pure_intrin(dst_dtype, call_name, *args)
        else:
            # convert type of values in op_dict into StringImm
            for k, val in op_dict.items():
                if isinstance(val, string_types):
                    op_dict[k] = StringImm(val)

            return Call(
                dst_dtype, Op.get("tir.call_llvm_pure_intrin"),
                convert([StringImm(call_name), ] + args),
                None, op_dict)


def vdeq_cast(x, y, dtype, do_relu=False):
    """s32 to f16/s8/u8/s16 vector dequantilization

    Parameters
    ----------
    x : Expr
        Input argument.
    y : Expr
        1*16 dequantilization vector. Each element is 64 bits in v200, 16bits in v100.
    dtype :
        type of the final destination result
    do_relu : Bool
        perform RELU to the final destination result

    Returns
    -------
    res : Expr
        The result.
    """
    from tbe.common.testing.testing import is_debug_mode
    if is_debug_mode():
        raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                             "vdeq_cast() is not supported on CPU. Try to write compute instead.")
    else:
        return call_intrin(dtype, "tir.vdeq_cast", x, y, do_relu)


def mad_sp_(x, y):
    """Take mad_sp  of input x and y
     Parameters
     ----------
     x : Expr
         fmap.
     y : Expr
         dense_weight.
     Returns
     -------
     res : Expr
         res data.
    """
    return call_intrin(x.dtype, "tir.mad_sp", x, y)


def load_sparse(x, y):
    """Take load_sparse  of input x and y
     Parameters
     ----------
     x : Expr
         weight data.
     y : Expr
         index data.
     Returns
     -------
     res : Expr
         The res data.
    """
    return call_intrin(x.dtype, "tir.load_sparse", x, y)


def conv_op(x, y, bias, fmap_w=None, fmap_h=None, fmap_c=None, filter_w=None, filter_h=None,
            filter_co=None, stride_w=None, stride_h=None, dilate_w=None, dilate_h=None,
            padding_top=None, padding_bottom=None, padding_left=None, padding_right=None,
            pad_value=None, dst_dtype=None, op_dict=None):
    def __pre_process_arg(arg):
        return "conv_op_default_arg" if arg is None else arg

    from tbe.common.testing.testing import is_debug_mode
    if is_debug_mode():
        raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                             "conv_op() is not supported on CPU. Try to write compute instead.")
    else:
        args = [x, y, bias, fmap_w, fmap_h, fmap_c, filter_w, filter_h, filter_co, stride_w,
                stride_h, dilate_w, dilate_h, padding_top, padding_bottom, padding_left,
                padding_right, pad_value]
        args = [__pre_process_arg(arg) for arg in args]
        call_name = "conv_op"
        if not op_dict:
            return call_intrin(dst_dtype, call_name, *args)
        else:
            for k, val in op_dict.items():
                if isinstance(val, string_types):
                    op_dict[k] = StringImm(val)

            return Call(
                dst_dtype, Op.get("tir.call_llvm_pure_intrin"), convert([StringImm(call_name), ] + args), None, op_dict)


def matmul_op(x, y, bias, dst_dtype=None, op_dict=None):
    def __pre_process_arg(arg):
        return "matmul_op_default_arg" if arg is None else arg

    from tbe.common.testing.testing import is_debug_mode
    if is_debug_mode():
        raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                             "matmul_op() is not supported on CPU. Try to write compute instead.")
    else:
        args = [x, y, bias]
        args = [__pre_process_arg(arg) for arg in args]
        call_name = "matmul_op"
        if not op_dict:
            return call_intrin(dst_dtype, call_name, *args)
        else:
            for k, val in op_dict.items():
                if isinstance(val, string_types):
                    op_dict[k] = StringImm(val)

            return Call(
                dst_dtype, Op.get("tir.call_llvm_pure_intrin"), convert([StringImm(call_name), ] + args), None, op_dict)


def unzip(x, y):
    """Unzip y according to index table x.

     Parameters
     ----------
     x : Expr
         unzip index table.
     y : Expr
         zipped data.

     Returns
     -------
     res : Expr
         The unzipped data.
    """
    return call_intrin(y.dtype, "tir.unzip", x, y)


def quant_cast(src, scale, offset, dtype):
    """f32 to b8/s4 scalar quantilization

    Parameters
    ----------
    src : Expr
        Input argument.
    scale : Expr
        Quant scale.
    offset : Expr
        Quant offset.
    dtype : Output data type.

    Returns
    -------
    res : Expr
        the result.
    """
    from tbe.common.testing.testing import is_debug_mode
    if is_debug_mode():
        raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                             "deq_cast() is not supported on CPU. Try to write compute instead.")
    else:
        return call_intrin(dtype, "tir.quant_cast", src, scale, offset)


def relu(x):
    """Take relu func of input x.

    Parameters
    ----------
    x : Expr
        Input argument.

    Returns
    -------
    y : Expr
        The result.
    """
    return call_intrin(x.dtype, "tir.relu", x)


def elu(x):
    """Take elu func of input x.

    Parameters
    ----------
    x : Expr
        Input argument.

    Returns
    -------
    y : Expr
        The result.
    """
    return call_intrin(x.dtype, "tir.elu", x)


def lrelu(x, scalar):
    """Take relu func of input x and scalar.

    Parameters
    ----------
    x : Expr
        Input argument.
    scalar : Expr
        Input tvm const.

    Returns
    -------
    res : Expr
        The result.
    """
    from tbe.common.testing.testing import is_debug_mode
    if is_debug_mode():
        return if_then_else(x >= 0, x, x * scalar)
    else:
        return call_intrin(x.dtype, "tir.lrelu", x, scalar)


def conv_vdeq(x, y):
    """s16 to s8/u8 vector dequantilization

    Parameters
    ----------
    x : Expr
        Input argument.
    y : Expr
        n*1*16 dequantilization vector. Each element is 64 bits in v200.

    Returns
    -------
    res : Expr
        The result.
    """
    from tbe.common.testing.testing import is_debug_mode
    if is_debug_mode():
        raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                             "conv_vdeq() is not supported on CPU. Try to write compute instead.")
    else:
        return call_intrin(x.dtype, "tir.conv_vdeq", x, y)


def deq_cast(x, y, dtype):
    """s32 to f16/s8/u8/s16 or f16 to f16 scalar dequantilization

    Parameters
    ----------
    x : Expr
        Input argument.
    y : Expr
        set DEQSCALE SPR, 64 bits in v200, 16bits in v100. please set every bit according to the ISA.

    Returns
    -------
    res : Expr
        The result.
    """
    from tbe.common.testing.testing import is_debug_mode
    if is_debug_mode():
        raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                             "deq_cast() is not supported on CPU. Try to write compute instead.")
    else:
        return call_intrin(dtype, "tir.deq_cast", x, y)


def rec(x):
    """Take reciprocal of input x.

    Parameters
    ----------
    x : Expr
        Input argument.

    Returns
    -------
    y : Expr
        The result.
    """
    from tbe.common.testing.testing import is_debug_mode
    if is_debug_mode():
        return tvm.tir.div(tvm.tir.FloatImm(x.dtype, 1), x)
    else:
        return call_intrin(x.dtype, "tir.rec", x)


def maddrelu(x, y, z):
    """Take maddrelu of input x, y, z.

    Parameters
    ----------
    x : Expr
        Input argument.
    y : Expr
        Input argument.
    z : Expr
        Input argument.

    Returns
    -------
    res : Expr
        The result.
    """
    from tbe.common.testing.testing import is_debug_mode
    if is_debug_mode():
        return call_intrin(x.dtype, "tir.relu", x * z + y)
    else:
        return call_intrin(x.dtype, "tir.maddrelu", x, y, z)


def muladd(x, y, z, dtype):
    """Take muladd of input x, y, z.

     Parameters
     ----------
     x : Expr
         Input argument.
     y : Expr
         Input argument.
     z : Expr
         Input argument.
     dtype: str
         Input dtype.
     Returns
     -------
     res : Expr
         The result.
    """
    from tbe.common.testing.testing import is_debug_mode
    if is_debug_mode():
        if not (x.dtype == dtype and y.dtype == dtype and z.dtype == dtype):
            raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                                 ("muladd args' dtype are not ", dtype))
        return (x * y) + z
    else:
        return call_intrin(dtype, "tir.muladd", x, y, z)


def mod(x, y):
    """Take mod  cast of input x and y

    Parameters
    ----------
    x : Expr
        Input argument.
    y : Expr
        Input argument.

    Returns
    -------
    y : Expr
        The result.
    """
    from tbe.common.testing.testing import is_debug_mode
    if is_debug_mode():
        return _ffi_api._OpMod(x, y)
    else:
        return call_intrin(x.dtype, "tir.mod", x, y)


def keep_old_value(dtype):
    """Create a Call node named keep_old_value, use in select when false value is empty.
    Parameters
    ----------
    dtype : str
        Input argument.

    Returns
    -------
    y : Expr
        The tvm.expr.Call node named keep_old_value with the return type as dtype.
    """
    return call_pure_extern(dtype, "keep_old_value")


def select(cond, t, f=None):
    """Construct a select branch.

    Parameters
    ----------
    cond : Expr
        The condition

    t : Expr
        The result expression if cond is true.

    f : Expr, optional
        The result expression if cond is false.

    Returns
    -------
    node : Node
    The tvm.expr.Select node
    """

    if isinstance(t, PrimExprWithOp):
        if str(t.dtype) == int64 and isinstance(f, int):
            f = const(f, int64)
    if isinstance(f, PrimExprWithOp):
        if str(f.dtype) == int64 and isinstance(t, int):
            t = const(t, int64)
    if isinstance(f, type(None)):
        f = keep_old_value(t.dtype)
    return Select(convert(cond), convert(t), convert(f))


def true_value(dtype, span=None):
    """true value of dtype

    Parameters
    ----------
    dtype : str
        The data type.

    span : Optional[Span]
        The location of this operator in the source code.

    Returns
    -------
    value : tvm.Expr
        The true value of dtype.
    """
    return _ffi_api.true_value(dtype, span)  # type: ignore


def false_value(dtype, span=None):
    """false value of dtype

    Parameters
    ----------
    dtype : str
        The data type.

    span : Optional[Span]
        The location of this operator in the source code.

    Returns
    -------
    value : tvm.Expr
        The false value of dtype.
    """
    return _ffi_api.false_value(dtype, span)  # type: ignore


def tbepower(x, y, span=None):
    """x power y in ascend compiler

    Parameters
    ----------
    x : PrimExpr
    The first Input argument.

    y : PrimExpr
    The second Input argument.

    z : PrimExpr
        The final result.
    """
    return _ffi_api._OpTbePow(convert(x), convert(y), span)


def gcd(x, y, span=None):
    """calc x and y greatest common divisor

    Parameters
    ----------
    x : PrimExpr
        The first Input argument.

    y : PrimExpr
        The second Input argument.

    span : Optional[Span]
        The location of this operator in the source code.

    Returns
    -------
    z : PrimExpr
        The result.
    """
    return _ffi_api._OpGCD(convert(x), convert(y), span)


def sign_bit(x, span=None):
    """sign bit of value

    Parameters
    ----------
    x : PrimExpr
        The Input Tensor.

    span : Optional[Span]
        The location of this operator in the source code.

    Returns
    -------
    value : PrimExpr
        The sign bit of the input, 0 for positive, 1 for negative.
    """
    return _ffi_api.sign_bit(x, span)


def real(x, span=None):
    """get real part of complex input x

    Parameters
    ----------
    x : PrimExpr
        The first Input argument. Data type is complex.

    span : Optional[Span]
        The location of this operator in the source code.

    Returns
    -------
    z : PrimExpr
        The result.
    """
    if x.dtype != "complex32" and x.dtype != "complex64":
        raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE, "op tvm.real() support complex datatype only")

    dtype = "float16" if x.dtype == "complex32" else "float32"
    return call_intrin(dtype, "tir.real", x, span=span)


def complex(x, y, span=None):
    """combine complex with two float tensor

    Parameters
    ----------
    x : PrimExpr
        The first Input argument. Data type is float.
    y : PrimExpr
        The first Input argument. Data type is float.
    span : Optional[Span]
        The location of this operator in the source code.

    Returns
    -------
    z : PrimExpr
        The result.
    """
    if x.dtype != y.dtype or (x.dtype != "float16" and y.dtype != "float32"):
        raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                             "dtype of input x and y should be both float16 or both float32,\
                             current x.dtype is %s, y.dtype is %s " % (x.dtype, y.dtype))

    dtype = "complex32" if x.dtype == "float16" else "complex64"
    offset = 16 if x.dtype == "float16" else 32

    if isinstance(x, np.float16):
        if not isinstance(y, np.float16):
            raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                                 "input x, y must be both numpy type or tensor \
                                 current type(x) is %s, type(y) is %s " % (type(x), type(y)))
        res = struct.unpack('!H', struct.pack('!e', x))[0] << offset | struct.unpack('!H', struct.pack('!e', y))[0]
        combined = const(res, "int32")
        return call_intrin(dtype, "tir.complex", combined, 0, span=span)

    if isinstance(x, np.float32):
        if not isinstance(y, np.float32):
            raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                                 "input x, y must be both numpy type or tensor \
                                 current type(x) is %s, type(y) is %s " % (type(x), type(y)))
        res = struct.unpack('!I', struct.pack('!f', x))[0] << offset | struct.unpack('!I', struct.pack('!f', y))[0]
        combined = const(res, "int64")
        return call_intrin(dtype, "tir.complex", combined, 0, span=span)

    return call_intrin(dtype, "tir.complex", x, y, span=span)


def vector_reduce(x, y, span=None):
    """
    calc vreduce x with y as mask

    NEXTNEXT: only support vreduce int64, and this is for ut test.
    Delete this part of the code if it is possible in the futrue
    Parameters
    ----------
    x : PrimExpr
        The first Input argument.

    y : PrimExpr
        The second Input argument.

    span : Optional[Span]
        The location of this operator in the source code.

    Returns
    -------
    z : PrimExpr
        The result.
    """
    if x.dtype != "int64":
        raise_tbe_python_err(TBE_DEFAULT_PYTHON_ERROR_CODE,
                             "reduce with input mask should have int64 dtype of input x,\
                             current x.dtype is %s " % (x.dtype))
    return _ffi_api._OpVreduce(convert(x), convert(y), span)


mad_sp = comm_reducer(lambda x, y: mad_sp_(
    x, y), lambda t: const(0, dtype=t), name="madsp")
prod = comm_reducer(lambda x, y: x * y,
                    lambda t: const(1, dtype=t), name="prod")
bit = comm_reducer(lambda x, y: _ffi_api.bitwise_and(
    x, y, None), lambda t: const(0, dtype=t), name='bit')
reduce_all = comm_reducer(lambda x, y: x & y, true_value, name="reduce_all")
reduce_any = comm_reducer(lambda x, y: x | y, false_value, name="reduce_any")
