#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2022 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
conv util
"""
import math

from tbe.common.utils import para_check
from tbe.common.utils.const import BIT_RATIO_DICT
from tbe.common.utils.errormgr import error_manager_cube
from tbe.common.utils.errormgr import error_manager_util

# the max size is 2**63-1
DATA_SIZE_MAX = 9223372036854775807

RANGE_DIM_LEN = 2


def get_shape_axis_value(shape, axis, shape_format):
    if not shape or not shape_format:
        return None

    if len(shape) != len(shape_format):
        return None

    idx = shape_format.lower().find(axis.lower())
    if idx != -1:
        return shape[idx]
    return None


def trip_strides(strides, data_format):
    """
    if the strides is 4D, convert it to 2D
    if the strides is 5D, convert it to 3D
    """
    d_index = data_format.find("D")
    h_index = data_format.find("H")
    w_index = data_format.find("W")
    if len(strides) == 5:
        strides = [strides[d_index], strides[h_index], strides[w_index]]
    elif len(strides) == 4:
        strides = [strides[h_index], strides[w_index]]
    return strides


def lcm(value, factor):
    '''
    get the lowest common multiple for value and factor
    '''
    return (value * factor) // math.gcd(value, factor)


class CubeChecker:
    """
    class of cube checker
    """

    def __init__(self, op_type):
        self._op_type = op_type

    @staticmethod
    def check_kernel_name(kernel_name):
        """
        check kernel_name
        """
        para_check.check_kernel_name(kernel_name)

    def check_type(self, name, shape_type, type_set):
        """
        check type
        """
        if not isinstance(shape_type, type_set):
            error_manager_cube.raise_err_specific(self._op_type, f"type of {name} should in {type_set}")

    def check_format(self, name, src_format, format_set):
        """
        check format
        """
        if src_format not in format_set:
            error_manager_cube.raise_err_specific_user(self._op_type, f"format of {name} should in {format_set}")

    def check_dims(self, name, shape, dimension):
        """
        check dimension
        """
        if len(shape) != dimension:
            error_manager_cube.raise_err_specific_user(self._op_type, f"{name} should be {dimension}d list")

    def check_value_range(self, name, value, attr_min=0, attr_max=DATA_SIZE_MAX):
        """
        check whether the value is whthin the range
        """
        if value is None:
            return
        if (not isinstance(value, int)) or value > attr_max or value < attr_min:
            error_manager_cube.raise_err_attr_range_invalid(self._op_type, [attr_min, attr_max], name, str(value))

    def check_equal(self, lhs, rhs, lhs_name, rhs_name):
        """
        check whether is the same as rhs
        """
        if lhs != rhs:
            error_manager_cube.raise_err_scene_equal_limitation(self._op_type, lhs_name, rhs_name)

    def check_multiple(self, lhs, rhs, lhs_name, rhs_name):
        """
        check whether the lhs is an integer multiple of rhs
        """
        if lhs % rhs != 0:
            error_manager_cube.raise_err_specific_user(self._op_type, f"{lhs_name} must be a multiple of {rhs_name}")

    def check_valid_input(self, name, value, valid_set):
        """
        check whether the valie is in the valid_set
        """
        if value not in valid_set:
            error_manager_cube.raise_err_specific_user(self._op_type,
                                                       f"{name} should in {valid_set}, but input {value}")

    def check_64bits_limitation(self, attr_name, attr_value, dtype):
        """
        check whether the attr_value exceeds the upper limit of 64bits
        """
        if dtype:
            bit_ratio = BIT_RATIO_DICT.get(dtype)
        else:
            bit_ratio = BIT_RATIO_DICT.get("float16")
        if attr_value * bit_ratio > DATA_SIZE_MAX:
            error_manager_cube.raise_err_specific_user(
                self._op_type, f"{attr_name} must be less than {DATA_SIZE_MAX}, but it is {attr_value * bit_ratio}.")

    def check_variable_range(self, name, range_i, mini=1, maxi=DATA_SIZE_MAX):
        """
        check variable range

        """
        if not isinstance(range_i, (tuple, list)):
            error_manager_cube.raise_err_specific_user(self._op_type, "type of range must be tuple or list.")
        if len(range_i) != RANGE_DIM_LEN:
            error_manager_cube.raise_err_specific_user(self._op_type, "each dimension of range must be 2.")
        if not isinstance(range_i[0], int):
            error_manager_cube.raise_err_specific_user(self._op_type, "The lower limit of the range must be Int.")
        if range_i[1] and (not isinstance(range_i[1], int)):
            error_manager_cube.raise_err_specific_user(self._op_type,
                                                       "The upper limit of the range must be Int or None.")
        if range_i[0] < mini or range_i[0] > maxi:
            error_manager_cube.raise_err_attr_range_invalid(self._op_type, [mini, maxi], name, range_i[0])
        if range_i[1] and (range_i[1] < mini or range_i[1] > maxi):
            error_manager_cube.raise_err_attr_range_invalid(self._op_type, [mini, maxi], name, range_i[1])

    def check_shape_dims_positive(self, name, shape, allow_zero=False):
        """
        check if shape dims are positive numbers
        """
        axis_index = 0
        dict_args = {}
        dict_args["errCode"] = "E64004"
        dict_args["op_name"] = self._op_type
        dict_args["param_name"] = name
        dict_args["axis_rule"] = "int and >= 0" if allow_zero else "int and > 0"
        for dim_x in shape:
            if (not isinstance(dim_x, int)) or ((dim_x < 0) if allow_zero else (dim_x <= 0)):
                dict_args["wrong_axis"] = str(axis_index)
                dict_args["actual_value"] = str(dim_x)
                error_manager_util.raise_runtime_error(dict_args)
            axis_index = axis_index + 1


class CubeConstantConfig:
    CONV2D_BACKPROP_FILTER_D_OP_NAME = "conv2d_backprop_filter_d"
    CONV2D_BACKPROP_FILTER_OP_NAME = "conv2d_backprop_filter"
    CONV3D_BACKPROP_FILTER_D_OP_NAME = "conv3d_backprop_filter_d"
    CONV3D_BACKPROP_FILTER_OP_NAME = "conv3d_backprop_filter"

    BLOCK_SIZE = 16
    C04_SIZE = 4
    C0_SIZE = 16

    # the dim of ori shape in conv_backprop must be 4
    CONV_BACKPROP_SHAPE_DIM = 4
    NC1HWC0_SHAPE_LEN = 5
    # the dim of ori shape in conv3d_backprop
    CONV3D_BACKPROP_FZ_DIM = 4
    CONV3D_BACKPROP_SHAPE_DIM = 5
    CONV3D_BACKPROP_PAD_DIM = 6
    NDC1HWC0_SHAPE_LEN = 6
    FROMAT_TO_FIX_DIMS = {"NCHW": CONV_BACKPROP_SHAPE_DIM, "NHWC": CONV_BACKPROP_SHAPE_DIM,
                          "HWCN": CONV_BACKPROP_SHAPE_DIM, "FRACTAL_Z": CONV_BACKPROP_SHAPE_DIM,
                          "NC1HWC0": NC1HWC0_SHAPE_LEN, "NCDHW": CONV3D_BACKPROP_SHAPE_DIM,
                          "DHWCN": CONV3D_BACKPROP_SHAPE_DIM, "FRACTAL_Z_3D": CONV3D_BACKPROP_FZ_DIM,
                          "NDHWC": CONV3D_BACKPROP_SHAPE_DIM, "NDC1HWC0": NDC1HWC0_SHAPE_LEN}
    # the dim of strides in conv_backprop must be 2
    STRIDES_SHAPE_DIM = 2

    # L1Fusion mode, 2 meas support fullload and reuse
    L1FUSION_INPUT_CTR = 2

    # dynamic
    DYNAMIC_FLAG = -1
    DYNAMIC_RANK_SHAPE = [-2]
    NO_RANGE = [1, None]


class ConvFeatureMap:

    def __init__(self, fmap_dict) -> None:
        self.name = "featureMap"
        self.ori_info = fmap_dict
        self.shape = fmap_dict.get("shape")
        self.ori_shape = fmap_dict.get("ori_shape")
        self.dtype = fmap_dict.get("dtype")
        self.format = fmap_dict.get("format")
        self.ori_format = fmap_dict.get("ori_format")
        self.fmap_batch = get_shape_axis_value(self.ori_shape, "N", self.ori_format)
        self.fmap_h = get_shape_axis_value(self.ori_shape, "H", self.ori_format)
        self.fmap_w = get_shape_axis_value(self.ori_shape, "W", self.ori_format)
        self.fmap_c = get_shape_axis_value(self.ori_shape, "C", self.ori_format)
        self.fmap_d = get_shape_axis_value(self.ori_shape, "D", self.ori_format)
        self.tag = fmap_dict.get("tag")

    def get_nchw_shape(self):
        return [self.fmap_batch, self.fmap_c, self.fmap_h, self.fmap_w]

    def get_ncdhw_shape(self):
        return [self.fmap_batch, self.fmap_c, self.fmap_d, self.fmap_h, self.fmap_w]


class ConvKernel:

    def __init__(self, kernel_dict) -> None:
        self.name = "kernel"
        self.ori_info = kernel_dict
        self.shape = kernel_dict.get("shape")
        self.ori_shape = kernel_dict.get("ori_shape")
        self.dtype = kernel_dict.get("dtype")
        self.format = kernel_dict.get("format")
        self.ori_format = kernel_dict.get("ori_format")
        self.kernel_cout = get_shape_axis_value(self.ori_shape, "N", self.ori_format)
        self.kernel_c = get_shape_axis_value(self.ori_shape, "C", self.ori_format)
        self.kernel_h = get_shape_axis_value(self.ori_shape, "H", self.ori_format)
        self.kernel_w = get_shape_axis_value(self.ori_shape, "W", self.ori_format)
        self.kernel_d = get_shape_axis_value(self.ori_shape, "D", self.ori_format)

    def get_nchw_shape(self):
        return [self.kernel_cout, self.kernel_c, self.kernel_h, self.kernel_w]

    def get_ncdhw_shape(self):
        return [self.kernel_cout, self.kernel_c, self.kernel_d, self.kernel_h, self.kernel_w]


class ConvFilterSize:

    def __init__(self, filter_size, data_format) -> None:
        self.name = "filter_size"
        self.ori_info = filter_size
        if isinstance(filter_size, (list, tuple)):
            self.filter_size = list(filter_size)
            self.shape = [len(filter_size)]
            self.dtype = "int32"
        else:  # filter_size is dict
            self.filter_size = filter_size.get("const_value")
            self.shape = filter_size.get("shape")
            self.dtype = filter_size.get("dtype")
        self.data_format = data_format
        self.fs_n = get_shape_axis_value(self.filter_size, "N", self.data_format)
        self.fs_c = get_shape_axis_value(self.filter_size, "C", self.data_format)
        self.fs_h = get_shape_axis_value(self.filter_size, "H", self.data_format)
        self.fs_w = get_shape_axis_value(self.filter_size, "W", self.data_format)
        self.fs_d = get_shape_axis_value(self.filter_size, "D", self.data_format)

    def get_nchw_shape(self):
        return [self.fs_n, self.fs_c, self.fs_h, self.fs_w]

    def get_ncdhw_shape(self):
        return [self.fs_n, self.fs_c, self.fs_d, self.fs_h, self.fs_w]


class ConvGrads:

    def __init__(self, grads_dict) -> None:
        self.name = "out_backprop"
        self.ori_info = grads_dict
        self.shape = grads_dict.get("shape")
        self.ori_shape = grads_dict.get("ori_shape")
        self.dtype = grads_dict.get("dtype")
        self.format = grads_dict.get("format")
        self.ori_format = grads_dict.get("ori_format")
        self.grads_batch = get_shape_axis_value(self.ori_shape, "N", self.ori_format)
        self.grads_c = get_shape_axis_value(self.ori_shape, "C", self.ori_format)
        self.grads_h = get_shape_axis_value(self.ori_shape, "H", self.ori_format)
        self.grads_w = get_shape_axis_value(self.ori_shape, "W", self.ori_format)
        self.grads_d = get_shape_axis_value(self.ori_shape, "D", self.ori_format)

    def get_nchw_shape(self):
        return [self.grads_batch, self.grads_c, self.grads_h, self.grads_w]

    def get_ncdhw_shape(self):
        return [self.grads_batch, self.grads_c, self.grads_d, self.grads_h, self.grads_w]


class ConvStrides:

    def __init__(self, strides_shape, data_format) -> None:
        self.name = "strides"
        self.data_format = data_format
        self.stride_d = get_shape_axis_value(strides_shape, "D", data_format)
        self.stride_h = get_shape_axis_value(strides_shape, "H", data_format)
        self.stride_w = get_shape_axis_value(strides_shape, "W", data_format)
        self.strides = trip_strides(strides_shape, data_format)

    def get_nchw_shape(self):
        return [1, 1, self.stride_h, self.stride_w]

    def get_ncdhw_shape(self):
        return [1, 1, self.stride_d, self.stride_h, self.stride_w]


class ConvPads:

    def __init__(self, pads_shape) -> None:
        self.name = "pads"
        self.pads = pads_shape
        self.pad_f, self.pad_b, self.pad_u, self.pad_d, self.pad_l, self.pad_r = self.convert_pad_to_6d()

    def convert_pad_to_6d(self):
        """
        if the pads is 4D, convert it to 6d, pads -> [0, 0] + pads
        """
        pad_shape = list(self.pads)
        if len(self.pads) == 4:
            pad_shape = [0, 0] + pad_shape
        return pad_shape


class ConvDilations:

    def __init__(self, dilations_shape, data_format) -> None:
        self.name = "dilation"
        self.dilations = dilations_shape
        self.data_format = data_format
        self.dilation_n = get_shape_axis_value(dilations_shape, "N", data_format)
        self.dilation_c = get_shape_axis_value(dilations_shape, "C", data_format)
        self.dilation_h = get_shape_axis_value(dilations_shape, "H", data_format)
        self.dilation_w = get_shape_axis_value(dilations_shape, "W", data_format)
        self.dilation_d = get_shape_axis_value(dilations_shape, "D", data_format)

    def get_nchw_shape(self):
        return [self.dilation_n, self.dilation_c, self.dilation_h, self.dilation_w]

    def get_ncdhw_shape(self):
        return [self.dilation_n, self.dilation_c, self.dilation_d, self.dilation_h, self.dilation_w]
