#!/usr/bin/env python
# -*- coding: UTF-8 -*-
# Copyright 2019-2020 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
TBE operator param encoder
"""
import math
import json
from copy import deepcopy
from tbe.common.platform import CUBE_MKN
from tbe.common.utils.errormgr.error_manager_cube import raise_err_message_cube
from tbe.common.tiling.op_param_encode.operator_params_encoder import BaseClassParamsEncoder
from tbe.common.tiling.tiling_api_internal_use import is_support_fixpipe_flatform

C04 = 4
# define the type of memory
DDR_MEMORY = 0
L1_MEMORY = 1
L2_MEMORY = 2
EMPTY_MEMORY = 3

# define the type of L1 fusion
DEFAULT_VALUE = -1
L1_DEPTH_FUSION = 0
L1_BREADTH_FUSION = 1
L1_NO_FUSION = 2
L2_FUSION = 3
L2_NO_FUSION = 2

# define the const value
CONST_VALUE0 = 0
CONST_VALUE1 = 1

# length of shape
SHAPE_LENGTH2 = 2
SHAPE_LENGTH3 = 3
SHAPE_LENGTH4 = 4
SHAPE_LENGTH5 = 5
SHAPE_LENGTH6 = 6

MAX_UINT32 = 4294967295
MAX_UINT16 = 65535


def decode_for_dynamic(tiling: list, input_args: dict) -> list:
    """
    encode the input params to NDArray

    Parameters
    ----------
    input_args: input params

    Returns
    ----------
    NDArray: tvm.nd.array
    """
    # dynamic shape tiling
    tiling_result = []
    for tiling_res in tiling:
        c_shape = deepcopy(input_args["c_shape"])
        if input_args.get("tiling_type") == "cost_model_tiling":
            tiling_res["A_shape"] = deepcopy(input_args["a_shape"])
            tiling_res["B_shape"] = deepcopy(input_args["b_shape"])
        elif input_args.get("tiling_type") is None:
            c_shape[1] = tiling_res["C_shape"][0]
            c_shape[2] = tiling_res["C_shape"][1]
            c_shape[3] = tiling_res["C_shape"][2]
            if c_shape[0] == -1:
                c_shape[0] = tiling_res["A_shape"][0]
        tiling_res["C_shape"] = c_shape
        tiling_result.append(tiling_res)
    return tiling_result


class Conv3dParamsEncoder(BaseClassParamsEncoder):
    """
    Child class for conv3d Params Encoder
    """

    def __init__(self):
        '''
        init the super class
        '''
        super(Conv3dParamsEncoder, self).__init__()
        self.input_args = {}
        self.flag_new_tiling = False

    @staticmethod
    def get_kb_query_attr(info_dict):
        """
        get typical key for repository query

        Parameters
        ----------
        info_dict: input params

        Returns
        ----------
        attr_dict: input params string
        """
        attr_dict = {
            "op_type": "convolution_3d",
            "a_shape": [],
            "b_shape": [],
            "c_shape": [],
            "a_dtype": 'float16',
            "b_dtype": 'float16',
            "c_dtype": 'float16',
            "mad_dtype": 'float32',
            "pad": [0, 0, 0, 0, 0, 0],
            "stride": [1, 1, 1],
            "dilation": [1, 1, 1],
            "bias_flag": None,
            "fused_coefficient": [0, 0, 0],
            "group": 1,
        }
        for key, value in info_dict.items():
            if key in attr_dict:
                attr_dict[key] = value
        if "bias_dtype" in info_dict:
            attr_dict.update({"bias_dtype": info_dict.get("bias_dtype")})
        if "fixpipe_flag" in info_dict:
            attr_dict.update({"fixpipe_flag": info_dict.get("fixpipe_flag")})
        return json.dumps(attr_dict)

    def encode_array(self, input_args: list) -> str:
        """
        encode the input params to tvm.nd.array

        Parameters
        ----------
        input_args: the input params

        Returns
        -------
        tvm.nd.array: the NDArray
        """
        self.flag_new_tiling = is_support_fixpipe_flatform(input_args.get("op_type"))
        params_in = deepcopy(input_args)
        self.input_args = params_in
        # first: check the params from the interface
        self.check_info_dict(params_in)
        # second: preprocess the params from the interface
        self.preprocess_info_dict(params_in)

        # third: encode the params to tvm.nd.array
        return self.encode(params_in)

    def decode(self, tiling_encode: str) -> list:
        """
        encode the input params to tvm.nd.array
        Parameters
        ----------
        input_args: the input params
        Returns
        -------
        tvm.nd.array: the NDArray
        """
        if not self.input_args["dynamic_shape_flag"] and not tiling_encode:
            raise_err_message_cube("only support legal tiling, "
                "but the return value of tiling is [%s]." % tiling_encode)

        if self.input_args["dynamic_shape_flag"] and not tiling_encode:
            return []

        tiling = json.loads(tiling_encode)
        if isinstance(tiling, list):
            tiling = decode_for_dynamic(tiling, self.input_args)
        return tiling

    def set_default_value(self, params_in: dict) -> None:
        """
        set default value

        Parameters
        ----------
        params_in: dict of params, include all information of shape

        Returns
        -------
        None
        """
        params_in['c_shape'] = params_in.get('c_shape', [0, 0, 0, 0, 0])
        params_in['strideh_expand'] = params_in.get('strideh_expand', 1)
        params_in['stridew_expand'] = params_in.get('stridew_expand', 1)
        params_in['dilation'] = params_in.get('dilation', [1, 1, 1])
        params_in['group'] = params_in.get('group', 1)
        params_in['bias_flag'] = params_in.get('bias_flag', False)
        params_in["dynamic_shape_flag"] = \
            params_in.get("dynamic_shape_flag", False)
        params_in['fused_coefficient'] = \
            params_in.get('fused_coefficient', [0, 0, 0])
        params_in['fused_channel_wise'] = \
            params_in.get('fused_channel_wise', [0, 0, 0])

        params_in['fusion_type'] = params_in.get('fusion_type', CONST_VALUE0)
        params_in['l1_fusion_type'] = params_in.get('l1_fusion_type', DEFAULT_VALUE)
        params_in['l2_fusion_type'] = params_in.get('l2_fusion_type', DEFAULT_VALUE)
        # transform the value of -1 to 0 for fm_l1_valid_size
        if params_in.get('fm_l1_valid_size', DEFAULT_VALUE) == DEFAULT_VALUE:
            params_in['fm_l1_valid_size'] = CONST_VALUE0
        # endocde the value of fm_l1_valid_size_level
        params_in['fm_l1_valid_size_level'] = \
            params_in.get('fm_l1_valid_size_level', CONST_VALUE0)
        raw_fm_l1_valid_size_level = params_in.get('fm_l1_valid_size_level',
                                                   CONST_VALUE0)
        if raw_fm_l1_valid_size_level != CONST_VALUE0:
            params_in['fm_l1_valid_size_level'] = \
                self.input_data_level[raw_fm_l1_valid_size_level]

    def check_info_dict(self, params_in: dict) -> None:
        """
        check the input params

        Parameters
        ----------
        params_in: the input params

        Returns
        -------
        None
        """
        self.set_default_value(params_in)

        # preprocess the param

        # check the type of param
        self.check_param_type(params_in, [dict])
        self.check_param_type(params_in.get('a_shape'), [list])
        self.check_param_type(params_in.get('b_shape'), [list])
        self.check_param_type(params_in.get('c_shape'), [list])
        self.check_param_type(params_in.get('a_dtype'), [str])
        self.check_param_type(params_in.get('b_dtype'), [str])
        self.check_param_type(params_in.get('c_dtype'), [str])
        self.check_param_type(params_in.get('mad_dtype'), [str])
        self.check_param_type(params_in.get('pad'), [list, tuple])
        self.check_param_type(params_in.get('stride'), [list, tuple])
        self.check_param_type(params_in.get('dilation'), [list, tuple])
        self.check_param_type(params_in.get('fused_coefficient'), [list])
        self.check_param_type(params_in.get('fused_channel_wise'), [list])
        self.check_param_type(params_in.get('group'), [int])
        self.check_param_type(params_in.get('strideh_expand'), [int])
        self.check_param_type(params_in.get('strideh_expand'), [int])
        self.check_param_type(params_in.get('bias_flag'), [bool, int])
        self.check_param_type(params_in.get('op_type'), [str])
        self.check_param_type(params_in.get('kernel_name'), [str])
        self.check_param_type(params_in.get('bias_dtype', 'float16'), [str])

        # check the length of param
        self.check_param_length(params_in.get('a_shape'), [SHAPE_LENGTH6])
        self.check_param_length(params_in.get('b_shape'), [SHAPE_LENGTH6])
        self.check_param_length(params_in.get('c_shape'), [SHAPE_LENGTH5])
        self.check_param_length(params_in.get('pad'), [SHAPE_LENGTH6])
        self.check_param_length(params_in.get('stride'), [SHAPE_LENGTH3])
        self.check_param_length(params_in.get('dilation'), [SHAPE_LENGTH3])
        self.check_param_length(params_in.get('fused_coefficient'), [SHAPE_LENGTH3])
        self.check_param_length(params_in.get('fused_channel_wise'), [SHAPE_LENGTH3])

        # check the support range of param
        self.check_support_range(params_in.get('a_dtype'), self.dtype_dict)
        self.check_support_range(params_in.get('b_dtype'), self.dtype_dict)
        self.check_support_range(params_in.get('c_dtype'), self.dtype_dict)
        self.check_support_range(params_in.get('mad_dtype'), self.dtype_dict)
        self.check_support_range(params_in.get('bias_dtype', 'float16'), self.dtype_dict)
        self.check_support_range(params_in.get('op_type'), self.op_type_dict)

    def preprocess_info_dict(self, params_in: dict) -> None:
        """
        encode the information of shape to the list of uint32 digit

        Parameters
        ----------
        params_in: dict of params, include all information of shape

        Returns
        -------
        None
        """
        # set the default value of these params
        op_type = params_in.get('op_type', 'convolution_3d')
        a_dtype = params_in.get('a_dtype', 'float16')
        b_dtype = params_in.get('b_dtype', 'float16')
        c_dtype = params_in.get('c_dtype', 'float16')
        mad_dtype = params_in.get('mad_dtype', 'float16')
        bias_flag = params_in.get('bias_flag')
        bias_flag = (1 if bias_flag else 0)

        # the channel align to unit of cube
        _ca0 = params_in["b_shape"][5]
        if _ca0 != C04:
            config = CUBE_MKN[params_in["b_dtype"]]
            _ca0 = config['mac'][1]

        a_shape = params_in.get('a_shape')
        a_shape[2] = (a_shape[2] * a_shape[5] + _ca0 - 1) // _ca0
        a_shape[5] = _ca0
        b_shape = params_in.get('b_shape')
        b_shape[2] = (b_shape[2] * b_shape[5] + _ca0 - 1) // _ca0
        b_shape[5] = _ca0

        # processing fixed-point number
        fused_coefficient = params_in.get('fused_coefficient')
        fused_coefficient = [math.ceil(100 * elt) for elt in fused_coefficient]
        fused_channel_wise = params_in.get('fused_channel_wise')
        fused_channel_wise = [math.ceil(100 * elt) for elt in fused_channel_wise]

        params_in['in_fm_memory_type'] = params_in.get('in_fm_memory_type', DDR_MEMORY)
        params_in['out_fm_memory_type'] = params_in.get('out_fm_memory_type', DDR_MEMORY)

        # processed params
        params_in['a_shape'] = a_shape
        params_in['b_shape'] = b_shape
        params_in['a_dtype'] = self.dtype_dict.get(a_dtype)
        params_in['b_dtype'] = self.dtype_dict.get(b_dtype)
        params_in['c_dtype'] = self.dtype_dict.get(c_dtype)
        params_in['mad_dtype'] = self.dtype_dict.get(mad_dtype)
        params_in['bias_flag'] = bias_flag

        if params_in.get("bias_dtype"):
            params_in['bias_dtype'] = self.dtype_dict.get(params_in.get("bias_dtype"))

        if self.flag_new_tiling:
            params_in["op_type"] = op_type
        else:
            params_in["op_type"] = self.op_type_dict.get(op_type)
        # the fused_channel_wise and fused_coefficient are fixed-point number
        # account to two decimal places
        params_in['fused_coefficient'] = fused_coefficient
        params_in['fused_channel_wise'] = fused_channel_wise