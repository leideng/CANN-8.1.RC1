#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2019-2020 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
CceConv2dBackpropInputOp
"""
from tbe.common.platform import platform_info as tbe_platform_info
from tbe.common.utils.errormgr import error_manager_util
from tbe.common.platform import get_cube_mkn
from tbe.dsl.static_schedule.gemm_integrated_schedule_util import copy_attrs
from tbe.dsl.static_schedule.conv_util import print_ir_conv


NC1HWC0_C1_INDEX = -4
NC1HWC0_H_INDEX = -3
NC1HWC0_W_INDEX = -2
NC1HWC0_C0_INDEX = -1


class CceConv2dBackpropInputUbOp:
    """
    The class of conv2d backprop input

    Parameters
    ----------
    scope : cal buffer like local.UB

    need_tensorize : if need to doing tensorize when using calculate

    need_pragma : if need to doing pragma when using calculate

    Returns
    -------
    CceConv2dBackpropInputOp_instance : instance of CceConv2dBackpropInputOp
    """

    def __init__(self):
        self._res_tensor = None
        self._spec_node_list = None
        self._compute_tensor = None
        self._placeholder_tensor = None
        self._sch = None
        self._tiling = None
        self._param_map = None
        self._attach_axis = {}
        self._split_m = False
        self._split_k = False
        self._split_n = False
        self._fifo_fusion_flag = False
        self._deq_pre_channel_flag = False
        self._need_prepad = False

    def schedule(self, res, spec_node_list, sch_list, tiling_case=None, var_range=None):
        """
        auto_schedule for cce AI-CORE.

        Parameters
        ----------
        res : tvm.te.tensor

        spec_node_list : same as other template in cce_schedule

        sch_list: use sch_list[0] to return conv schedule

        tiling_case: fix tiling for dynamic shape

        var_range: var range for dynamic shape

        Returns
        -------
        True for sucess, False for no schedule
        """
        self._res_tensor = res
        self._spec_node_list = spec_node_list
        self._compute_tensor, self._placeholder_tensor = tiling_case.get("tensor_list")
        self._param_map = tiling_case.get("param_map")
        self._tiling = tiling_case.get("tiling_strategy")
        self._need_prepad = self._param_map.get("conv_param").get("need_prepad")
        self._sch = sch_list[0]
        self._config_scope()
        self._cache_read()
        self._get_split_flag()
        self._do_buffer_align()
        self._do_compute_inline()
        if self._fifo_fusion_flag:
            self._do_compute_with()
        self._do_split()
        self._do_order()
        self._do_compute_at()
        self._do_double_buffer()
        self._do_emit_insn()
        return self._sch

    def _config_scope(self):
        """
        Config tensor scope.

        Returns
        -------
        tensor_param: dict
            Tensors those set scope.
        """
        for tensor_name, tensor in self._compute_tensor.items():
            if tensor != self._res_tensor and tensor_name != "fwc_res":
                self._sch[tensor].set_scope(tbe_platform_info.scope_ubuf)

    def _cache_read(self):
        dy_filling = self._compute_tensor.get("dy_filling")
        if self._param_map.get("fifo_fusion_flag", None) is not None:
            # _placeholder_tensor name generated by fusion_util
            weight = self._placeholder_tensor.get("params_3")
            tensor_bias = self._placeholder_tensor.get("params_4")
            deq = self._placeholder_tensor.get("params_5")
            fifo_res = self._compute_tensor.get("fwc_res")
            fifo_in = fifo_res.op.input_tensors[1]
            clean_cache = fifo_res.op.input_tensors[0]
            clean_cache_ub = self._sch.cache_read(clean_cache, tbe_platform_info.scope_ubuf, [fifo_res])
            fifo_res_ub_write = self._sch.cache_write(fifo_res, tbe_platform_info.scope_ubuf)
            fifo_res_ub_read = self._sch.cache_read(fifo_res, tbe_platform_info.scope_ubuf, [dy_filling])
            self._compute_tensor["fifo_res_ub_read"] = fifo_res_ub_read
            self._compute_tensor["fifo_res_ub_write"] = fifo_res_ub_write
            self._compute_tensor["fifo_in"] = fifo_in
            self._compute_tensor["clean_cache_ub"] = clean_cache_ub
            self._sch[fifo_res_ub_write].reused_by(fifo_res_ub_read)
            self._sch[fifo_in].reused_by(fifo_res)
            n, c1, h, w, c0 = fifo_in.shape
            frame_size = n * c1 * h * w * c0
            self._sch[fifo_res].bind_buffer(fifo_res.op.axis[-1], 0, frame_size)
            self._fifo_fusion_flag = True
        else:
            # _placeholder_tensor name generated by fusion_util
            weight = self._placeholder_tensor.get("params_2")
            tensor_bias = self._placeholder_tensor.get("params_3")
            deq = self._placeholder_tensor.get("params_4")
        if self._need_prepad:
            offset_tensor = self._compute_tensor.get("offset_tensor")
            self._sch[dy_filling].reused_by(offset_tensor)
        conv_res = self._compute_tensor.get("conv_res")
        fixpipe = self._compute_tensor.get("fixpipe")
        weight = self._sch.cache_read(weight, tbe_platform_info.scope_ubuf, [conv_res])
        bias = self._sch.cache_read(tensor_bias, tbe_platform_info.scope_ubuf, [conv_res])
        res_ub = self._sch.cache_write(self._res_tensor, tbe_platform_info.scope_ubuf)
        self._compute_tensor["weight"] = weight
        self._compute_tensor["bias"] = bias
        self._compute_tensor["res_ub"] = res_ub
        if deq is not None:
            self._deq_pre_channel_flag = True
            deq_fb = self._sch.cache_read(deq, tbe_platform_info.scope_fb, fixpipe)
            deq_ub = self._sch.cache_read(deq, tbe_platform_info.scope_ubuf, deq_fb)
            self._compute_tensor["deq_fb"] = deq_fb
            self._compute_tensor["deq_ub"] = deq_ub

    def _get_split_flag(self):
        res_c_factor, res_h_factor, res_w_factor = self._tiling.get("Cub_shape")[1:]
        dy_filling = self._compute_tensor.get("dy_filling")
        res_ub = self._compute_tensor.get("res_ub")
        self._split_k = self._tiling.get("split_k_flag") and not self._fifo_fusion_flag
        if (res_h_factor, res_w_factor) != (res_ub.shape[NC1HWC0_H_INDEX], res_ub.shape[NC1HWC0_W_INDEX]):
            self._split_m = True
        if res_c_factor != res_ub.shape[NC1HWC0_C1_INDEX]:
            self._split_n = True

    def _do_compute_with(self):
        fifo_res = self._compute_tensor.get("fwc_res")
        self._sch.compute_with([fifo_res, self._res_tensor], 1)

    def _do_buffer_align(self):
        weight = self._compute_tensor["weight"]
        _, k0_align_weight, n0_align = get_cube_mkn(weight.dtype)
        self._sch[weight].buffer_align((1, 1), (1, 1), (n0_align, n0_align), (k0_align_weight, k0_align_weight))

    def _do_compute_inline(self):
        conv_res = self._compute_tensor.get("conv_res")
        fixpipe_op = self._compute_tensor.get("fixpipe", None)
        fixpipe_channel_merge_split = None
        for tensor in self._compute_tensor.values():
            if tensor.op.tag == "fixpipe_reform" and tensor.op.name != "fixpipe_reform.local.UB":
                fixpipe_channel_merge_split = tensor
                break
        if fixpipe_op is not None:
            self._sch[conv_res].compute_inline(instant=True)
        if fixpipe_channel_merge_split is not None:
            copy_attrs(fixpipe_op, fixpipe_channel_merge_split)
            self._sch[fixpipe_op].compute_inline(instant=True)

    def _do_split(self):
        fmap_c_factor = self._tiling.get("Aub_shape")[1]
        weight_h_factor, weight_w_factor = self._tiling.get("Bub_shape")
        res_batch_factor, res_c_factor, res_h_factor, res_w_factor = self._tiling.get("Cub_shape")
        conv_res = self._compute_tensor.get("conv_res")
        res_ub = self._compute_tensor.get("res_ub")
        res = self._res_tensor
        # -5 means batch axis
        res_batch_outer, res_batch_inner = self._sch[res].split(res.op.axis[-5], res_batch_factor)
        # -4 means c1 axis
        res_c_outer, res_c_inner = self._sch[res].split(res.op.axis[-4], res_c_factor)
        # -3 means h axis
        res_h_outer, res_h_inner = self._sch[res].split(res.op.axis[-3], res_h_factor)
        # -2 means w axis
        res_w_outer, res_w_inner = self._sch[res].split(res.op.axis[-2], res_w_factor)
        # -5 means batch axis
        res_ub_batch_outer, res_ub_batch_inner = self._sch[res_ub].split(res_ub.op.axis[-5], res_batch_factor)
        # -4 means c1 axis
        res_ub_c_outer, res_ub_c_inner = self._sch[res_ub].split(res_ub.op.axis[-4], res_c_factor)
        # -3 means h axis
        res_ub_h_outer, res_ub_h_inner = self._sch[res_ub].split(res_ub.op.axis[-3], res_h_factor)
        # -2 means w axis
        res_ub_w_outer, res_ub_w_inner = self._sch[res_ub].split(res_ub.op.axis[-2], res_w_factor)
        if self._split_k:
            conv_res_c_outer, conv_res_c_inner = self._sch[res_ub].split(self._sch[res_ub].op.reduce_axis[0],
                                                                         fmap_c_factor)
        else:
            conv_res_c_outer, conv_res_c_inner = None, None
        self._attach_axis["res_batch_axis"] = (res_batch_outer, res_batch_inner)
        self._attach_axis["res_cout_axis"] = (res_c_outer, res_c_inner)
        self._attach_axis["res_h_axis"] = (res_h_outer, res_h_inner)
        self._attach_axis["res_w_axis"] = (res_w_outer, res_w_inner)
        self._attach_axis["res_cin_axis"] = (conv_res_c_outer, conv_res_c_inner)
        self._attach_axis["res_ub_batch_axis"] = (res_ub_batch_outer, res_ub_batch_inner)
        self._attach_axis["res_ub_c_axis"] = (res_ub_c_outer, res_ub_c_inner)
        self._attach_axis["res_ub_h_axis"] = (res_ub_h_outer, res_ub_h_inner)
        self._attach_axis["res_ub_w_axis"] = (res_ub_w_outer, res_ub_w_inner)

    def _do_order(self):
        res = self._res_tensor
        axes = self._attach_axis
        res_ub = self._compute_tensor["res_ub"]
        if self._tiling.get("reorder_mn_flag"):
            res_ub_mn_outer = [axes.get("res_ub_h_axis")[0], axes.get("res_ub_w_axis")[0],
                               axes.get("res_ub_c_axis")[0]]
            res_mn_outer = [axes.get("res_h_axis")[0], axes.get("res_w_axis")[0],
                            axes.get("res_cout_axis")[0]]
        else:
            res_ub_mn_outer = [axes.get("res_ub_c_axis")[0], axes.get("res_ub_h_axis")[0],
                               axes.get("res_ub_w_axis")[0]]
            res_mn_outer = [axes.get("res_cout_axis")[0], axes.get("res_h_axis")[0], axes.get("res_w_axis")[0]]
        if self._split_k:
            self._sch[res_ub].reorder(axes.get("res_ub_batch_axis")[0], *res_ub_mn_outer, axes.get("res_cin_axis")[0],
                axes.get("res_ub_batch_axis")[1], axes.get("res_ub_c_axis")[1], axes.get("res_ub_h_axis")[1],
                axes.get("res_ub_w_axis")[1], res_ub.op.axis[NC1HWC0_C0_INDEX])
        else:
            self._sch[res_ub].reorder(axes.get("res_ub_batch_axis")[0], *res_ub_mn_outer,
                axes.get("res_ub_batch_axis")[1], axes.get("res_ub_c_axis")[1], axes.get("res_ub_h_axis")[1],
                axes.get("res_ub_w_axis")[1], res_ub.op.axis[NC1HWC0_C0_INDEX])
        self._sch[res].reorder(axes.get("res_batch_axis")[0], *res_mn_outer, axes.get("res_batch_axis")[1],
            axes.get("res_cout_axis")[1], axes.get("res_h_axis")[1],
            axes.get("res_w_axis")[1], res.op.axis[NC1HWC0_C0_INDEX])

    def _do_compute_at(self):
        if self._need_prepad:
            offset_tensor = self._compute_tensor.get("offset_tensor")
        dy_filling = self._compute_tensor.get("dy_filling")
        weight = self._compute_tensor.get("weight")
        bias = self._compute_tensor.get("bias")
        res_ub = self._compute_tensor.get("res_ub")
        res = self._res_tensor

        fifo_attach_axis = self._attach_axis.get("res_batch_axis")[0]
        attach_tensor = res
        offset_tensor_attach_axis = self._attach_axis.get("res_batch_axis")[0]
        dy_filling_attach_axis = self._attach_axis.get("res_batch_axis")[0]
        weight_attach_axis = self._attach_axis.get("res_batch_axis")[0]
        if self._split_m:
            offset_tensor_attach_axis = self._attach_axis.get("res_w_axis")[0]
            dy_filling_attach_axis = self._attach_axis.get("res_w_axis")[0]
        if self._split_n:
            weight_attach_axis = self._attach_axis.get("res_cout_axis")[0]
        if self._split_k:
            attach_tensor = res_ub
            offset_tensor_attach_axis = self._attach_axis.get("res_cin_axis")[0]
            dy_filling_attach_axis = self._attach_axis.get("res_cin_axis")[0]
            weight_attach_axis = self._attach_axis.get("res_cin_axis")[0]
        bias_attach_axis = self._attach_axis.get("res_cout_axis")[0]
        res_ub_attach_axis = self._attach_axis.get("res_batch_axis")[1]

        if self._fifo_fusion_flag:
            fifo_res_ub_read = self._compute_tensor.get("fifo_res_ub_read")
            fifo_res_ub_write = self._compute_tensor.get("fifo_res_ub_write")
            self._sch[fifo_res_ub_read].compute_at(self._sch[res], fifo_attach_axis)
            self._sch[fifo_res_ub_write].compute_at(self._sch[res], fifo_attach_axis)
        if self._need_prepad:
            self._sch[offset_tensor].compute_at(self._sch[attach_tensor], offset_tensor_attach_axis)
        self._sch[dy_filling].compute_at(self._sch[attach_tensor], dy_filling_attach_axis)
        self._sch[weight].compute_at(self._sch[attach_tensor], weight_attach_axis)
        self._sch[bias].compute_at(self._sch[res], bias_attach_axis)
        self._sch[res_ub].compute_at(self._sch[res], res_ub_attach_axis)
        if self._deq_pre_channel_flag:
            deq_fb = self._compute_tensor.get("deq_fb")
            deq_ub = self._compute_tensor.get("deq_ub")
            self._sch[deq_fb].compute_at(self._sch[res], res_ub_attach_axis)
            self._sch[deq_ub].compute_at(self._sch[res], res_ub_attach_axis)


    def _do_double_buffer(self):
        double_buffer_flag = self._tiling.get("manual_pingpong_buffer")
        if double_buffer_flag.get("AUB_pbuffer") == 2:
            if self._need_prepad:
                offset_tensor = self._compute_tensor.get("offset_tensor")
                self._sch[offset_tensor].double_buffer()
            dy_filling = self._compute_tensor.get("dy_filling")
            self._sch[dy_filling].double_buffer()
        if double_buffer_flag.get("BUB_pbuffer") == 2:
            weight = self._compute_tensor.get("weight")
            self._sch[weight].double_buffer()
        if double_buffer_flag.get("CUB_pbuffer") == 2:
            res_ub = self._compute_tensor.get("res_ub")
            self._sch[res_ub].double_buffer()
            if self._tiling.get("split_cout_flag"):
                bias = self._compute_tensor.get("bias")
                self._sch[bias].double_buffer()
                if self._deq_pre_channel_flag:
                    deq_fb = self._compute_tensor.get("deq_fb")
                    deq_ub = self._compute_tensor.get("deq_ub")
                    self._sch[deq_fb].double_buffer()
                    self._sch[deq_ub].double_buffer()

    def _do_emit_insn(self):
        if self._need_prepad:
            offset_tensor = self._compute_tensor.get("offset_tensor")
            self._sch[offset_tensor].emit_insn(offset_tensor.op.axis[0], "vector_dup")
        dy_filling = self._compute_tensor.get("dy_filling")
        weight = self._compute_tensor.get("weight")
        bias = self._compute_tensor.get("bias")
        conv_res = self._compute_tensor.get("conv_res")
        res_ub = self._compute_tensor.get("res_ub")
        res = self._res_tensor
        self._sch[dy_filling].emit_insn(dy_filling.op.axis[-1], "dma_copy")
        self._sch[weight].emit_insn(weight.op.axis[0], "dma_copy")
        self._sch[bias].emit_insn(bias.op.axis[0], "dma_copy")
        self._sch[conv_res].emit_insn(conv_res.op.axis[0], "conv")
        if self._deq_pre_channel_flag:
            deq_fb = self._compute_tensor.get("deq_fb")
            deq_ub = self._compute_tensor.get("deq_ub")
            self._sch[deq_fb].emit_insn(deq_fb.op.axis[0], "dma_copy")
            self._sch[deq_ub].emit_insn(deq_ub.op.axis[0], "dma_copy")
        if self._split_k:
            self._sch[res_ub].emit_insn(self._attach_axis["res_ub_batch_axis"][1], "fixpipe_op",
                attrs={"k_outer": self._attach_axis["res_cin_axis"][0]})
        else:
            self._sch[res_ub].emit_insn(self._attach_axis["res_ub_batch_axis"][1], "fixpipe_op")
        if self._fifo_fusion_flag:
            clean_cache_ub = self._compute_tensor.get("clean_cache_ub")
            fifo_res = self._compute_tensor.get("fwc_res")
            fifo_res_ub_write = self._compute_tensor.get("fifo_res_ub_write")
            fifo_res_ub_read = self._compute_tensor.get("fifo_res_ub_read")
            self._sch[clean_cache_ub].emit_insn(clean_cache_ub.op.axis[0], "dma_copy")
            self._sch[fifo_res_ub_write].emit_insn(fifo_res_ub_write.op.axis[0], "dma_copy",
                attrs={"clean_cache_value": conv_res.op.attrs.get("offset_x")})
            self._sch[fifo_res].emit_insn(fifo_res.op.axis[1], "dma_copy")
            self._sch[fifo_res_ub_read].emit_insn(fifo_res_ub_read.op.axis[0], "phony_insn")
        self._sch[res].emit_insn(self._attach_axis["res_h_axis"][1], "dma_copy")
