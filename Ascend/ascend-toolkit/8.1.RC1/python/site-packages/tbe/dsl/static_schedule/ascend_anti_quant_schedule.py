#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright (c) Huawei Technologies Co., Ltd. 2020. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
ascend_anti_quant schedule
"""
from tbe import tvm
from tbe.common.platform.platform_info import get_soc_spec
from tbe.common.platform import scope_ubuf
from tbe.common.utils import shape_to_list
from tbe.dsl.base import operation
from tbe.tvm import Tensor
from typing import Any
from typing import Dict
from typing import Iterable
from typing import Optional
from tbe.tvm import PlaceholderOp
from typing import List
from typing import Set
from typing import Tuple
from typing import Union
from typing import Callable
from .ascend_quant_schedule import _round_emit_insn

INPUT_NAME = "anti_quant_input_ub"
# define the map of dtype size
DTYPE_BYTE_MAPPING = {"int8": 1,
                      "float16": 2,
                      "float32": 4}

class QuantTilingCase:
    def __init__(self):
        self.block_tiling_axis = None
        self.ub_tiling_axis = None
        self.multi_core = True
        self.is_split_ub = None
        self.block_factor = None
        self.ub_factor = None
        self.is_fuse_block = None

    def __repr__(self):
        return "QUANT:" + "b_axis=" + str(self.block_tiling_axis) + ",u_axis=" + str(self.ub_tiling_axis) + \
               ",is_split_ub=" + str(self.is_split_ub) + ",b_factor=" + str(self.block_factor) + \
               ",u_factor=" + str(self.ub_factor) + ",is_fuse_block=" + str(self.is_fuse_block)

    def __hash__(self):
        return hash((self.block_tiling_axis, self.block_factor, self.ub_tiling_axis, self.ub_factor, self.multi_core))

    def __eq__(self, other):
        condition1 = other.block_tiling_axis == self.block_tiling_axis
        condition2 = other.block_factor == self.block_factor
        condition3 = other.ub_tiling_axis == self.ub_tiling_axis
        condition4 = other.ub_factor == self.ub_factor
        condition5 = other.multi_core == self.multi_core
        return type(other) == type(self) and condition1 and condition2 and condition3 and condition4 and condition5

    def __ne__(self, other):
        condition1 = other.block_tiling_axis != self.block_tiling_axis
        condition2 = other.block_factor != self.block_factor
        condition3 = other.ub_tiling_axis != self.ub_tiling_axis
        condition4 = other.ub_factor != self.ub_factor
        condition5 = other.multi_core != self.multi_core
        return type(other) != type(self) or condition1 or condition2 or condition3 or condition4 or condition5


def _get_block_num():
    """
    get the core number
    """
    core_num = get_soc_spec("CORE_NUM")
    return core_num


def ascend_anti_quant_schedule(res, input_tensors):
    """
    ascend_anti_quant schedule
    """
    return AscendAntiQuantSchedule(res, input_tensors).do_schedule()


class AscendAntiQuantSchedule:
    def __init__(self, outs, input_tensors):
        self._scope = scope_ubuf
        self._schedule = None
        self._res = outs
        self._ub_split_result = []
        self._tiling_case = QuantTilingCase()
        x = input_tensors[0]
        self.input_shape = shape_to_list(x.shape)

        self._tensor_map = set()
        self._max_ub_size : Optional[int] = None
        self._quant_input_ub = set()
        self._quant_reorder_ub = set()
        self._buffer_align_tensors = set()
        self._compute_inline_tensors = set()
        self._out_ub_tensors = set()

        self.quant_fuse = False
        self.elewise_fuse = False
        self.elewise_tensor_set = set()
        self.quant_tensor_set: Set[Tensor] = set()
        output_tensors = list(outs) if isinstance(outs, (list, tuple)) else [outs]
        self.output_tensor_set: Optional[Set[Tensor]] = set(output_tensors)
        self.tensor_consumers_map: Optional[Dict[Tensor, Set[Tensor]]] = None
        self.tensor_producers_map: Optional[Dict[Tensor, Set[Tensor]]] = None
        self.tensor_list: Optional[List[Tensor]] = None
        self.broadcast_tensor_set: Set[Tensor] = set()
        self.mid_output_tensor_set: Set[Tensor] = set()

        self.input_tensor_set: Set[Tensor] = set()
        self.non_gm_input_tensor_set: Set[Tensor] = set()

    def gen_fuse_flag(self):
        if self.quant_tensor_set:
            self.quant_fuse = True
        if self.elewise_tensor_set:
            self.elewise_fuse = True

    def gen_quant_tensor_set(self):
        for tensor in self.tensor_list:
            # quant compute inline
            if tensor.op.tag in ["input_ub"]:
                self._quant_input_ub.add(tensor)
            # antiquant buffer align
            if tensor.op.tag in ["anti_quant_input_ub", "anti_quant_cast_f16_ub"]:
                self._buffer_align_tensors.add(tensor)
            # quant reorder
            if tensor.op.tag in ["anti_quant_reform_by_vmuls", "reform_by_vmuls", "reform_by_vadds"]:
                self._quant_reorder_ub.add(tensor)

    def init_max_ub_count(self):
        soc_ub_size = get_soc_spec("UB_SIZE")
        soc_ub_size = soc_ub_size // 2

        total_width = 2
        max_bound = total_width * 128
        max_ub_count = int(soc_ub_size // max_bound * 128)

        self._max_ub_size = max_ub_count

    def gen_mid_tensor_sets(self):
        # mid_output_tensor_set
        for tensor in self.tensor_list:
            if tensor in self.output_tensor_set and self.tensor_consumers_map.get(tensor):
                # Tensor in output and has consumers is middle_out_tensor
                self.mid_output_tensor_set.add(tensor)
                self._tensor_map.add(tensor)
            elif tensor not in self.output_tensor_set | self.input_tensor_set | self.non_gm_input_tensor_set:
                self._tensor_map.add(tensor)

    @staticmethod
    def dfs_compute_graph(root_tensor: Union[Iterable[Tensor], Tensor],
                          hooks: Tuple[Tuple[Callable[[Tensor], bool],
                                             Callable[[Tensor], Any],
                                             Callable[[Tensor], Any]], ...]):
        def recursive_func(_root_tensor: Tensor,
                           _visited_list: Set[Tensor],
                           _tensor_consumers_map: Dict[Tensor, Union[Set[Tensor]]],
                           _tensor_producers_map: Dict[Tensor, Union[Set[Tensor]]],
                           _hooks: Tuple[Tuple[Callable[[Tensor], bool],
                                               Callable[[Tensor], Any],
                                               Callable[[Tensor], Any]], ...]):
            _visited_list.add(_root_tensor)
            _tensor_producers_map.setdefault(_root_tensor, set())
            _tensor_consumers_map.setdefault(_root_tensor, set())

            for hook in hooks:
                if hook[0](_root_tensor):
                    hook[1](_root_tensor)
                else:
                    hook[2](_root_tensor)

            for in_tensor in _root_tensor.op.input_tensors:
                _tensor_consumers_map.setdefault(in_tensor, set())
                _tensor_consumers_map[in_tensor].add(_root_tensor)
                _tensor_producers_map[_root_tensor].add(in_tensor)
                recursive_func(in_tensor,
                               _visited_list,
                               _tensor_consumers_map,
                               _tensor_producers_map,
                               _hooks)

        visited_list = set()
        tensor_consumers_map = {}
        tensor_producers_map = {}
        if isinstance(root_tensor, (list, tuple, set)):
            for tensor in root_tensor:
                recursive_func(tensor,
                               visited_list,
                               tensor_consumers_map,
                               tensor_producers_map,
                               hooks)
        elif isinstance(root_tensor, Tensor):
            recursive_func(root_tensor,
                           visited_list,
                           tensor_consumers_map,
                           tensor_producers_map,
                           hooks)
        else:
            raise RuntimeError("dfs_compute_graph supports [list,tuple,Tensor]. Received %s" % str(type(root_tensor)))
        return list(visited_list), tensor_consumers_map, tensor_producers_map

    def collect_info(self):
        self.tensor_list, self.tensor_consumers_map, self.tensor_producers_map = \
            self.dfs_compute_graph(self.output_tensor_set,
                                   (  # self.input_tensor_set hook
                                       (lambda _tensor: isinstance(_tensor.op, PlaceholderOp),
                                        lambda _tensor: self.input_tensor_set.add(_tensor),
                                        lambda _tensor: self.non_gm_input_tensor_set.add(_tensor)
                                        if not _tensor.op.input_tensors else None),

                                       # self.quant_tensor_set hook
                                       (lambda _tensor: _tensor.op.tag == "quant",
                                        lambda _tensor: self.quant_tensor_set.add(_tensor),
                                        lambda _tensor: None),

                                       # self.broadcast_tensor_set hook
                                       (lambda _tensor: _tensor.op.tag.find("broadcast") != -1,
                                        lambda _tensor: self.broadcast_tensor_set.add(_tensor),
                                        lambda _tensor: None),

                                       # self.elewise_tensor_set hook
                                       (lambda _tensor: _tensor.op.tag.find("elewise") != -1,
                                        lambda _tensor: self.elewise_tensor_set.add(_tensor),
                                        lambda _tensor: None)
                                   ))

        self.gen_mid_tensor_sets()

        self.gen_quant_tensor_set()

    def _do_cache_write(self):
        if self.elewise_fuse and not self.quant_fuse:
            for output_tensor in self.output_tensor_set:
                output_tensor_stage = self._schedule.cache_write(output_tensor, self._scope)
                self._out_ub_tensors.add(output_tensor_stage)

    def _set_buffer_align(self):
        for tensor in self._buffer_align_tensors:
            self._schedule[tensor].buffer_align((1, 1),
                                                (1, 1),
                                                (1, 1),
                                                (32, 32))

    def _set_buffer_scope(self):
        """
        set the scope for tensors
        """
        for value in self._tensor_map | self._out_ub_tensors:
            self._schedule[value].set_scope(self._scope)

    def _do_storage_bound(self):
        for stage in self._tensor_map | self._out_ub_tensors:
            storage_bound = self._max_ub_size // DTYPE_BYTE_MAPPING[stage.dtype]
            self._schedule[stage].set_buffer_size(storage_bound)

    def _cal_compute_inline(self):
        for tensor in self._quant_input_ub:
            c_out = tensor.op.attrs['c_out'].value
            c1_transform = tensor.op.attrs['c1_transform'].value
            if c_out % c1_transform == 0:
                self._compute_inline_tensors.add(tensor)

    def _do_compute_inline(self):
        for tensor in self._compute_inline_tensors:
            self._schedule[tensor].compute_inline()

    def _reorder_buffer(self):
        """
        reorder all tensors to the same shape
        """
        factor = 2
        for tensor in self._quant_reorder_ub:
            self._schedule[tensor].split(tensor.op.axis[1], factor)

    def _tilling_ub(self, block_tiling_axis, block_factor, out_shape):
        ub_size = 1
        self._tiling_case.ub_tiling_axis = 0
        ub_outer = 1
        self._tiling_case.ub_factor = 1
        is_need_split_block_factor = True
        _max_ub_size = self._max_ub_size // 16

        for j in range(len(out_shape) - 1, block_tiling_axis, -1):
            ub_size *= out_shape[j]
            if ub_size > _max_ub_size:
                self._tiling_case.ub_tiling_axis = j
                if ub_size % _max_ub_size == 0:
                    ub_outer = ub_size // _max_ub_size
                else:
                    ub_outer = (ub_size + _max_ub_size - 1) // _max_ub_size
                
                if out_shape[j] % ub_outer == 0:
                    self._tiling_case.ub_factor = out_shape[j] // ub_outer
                else:
                    self._tiling_case.ub_factor = (out_shape[j] + ub_outer - 1) // ub_outer

                is_need_split_block_factor = False
                break
        if is_need_split_block_factor:
            block_factor = 1
            ub_size *= block_factor
            self._tiling_case.ub_tiling_axis = block_tiling_axis
            if ub_size > _max_ub_size:
                if ub_size % _max_ub_size == 0:
                    ub_outer = ub_size // _max_ub_size
                else:
                    ub_outer = (ub_size + _max_ub_size - 1) // _max_ub_size
            if block_factor % ub_outer == 0:
                self._tiling_case.ub_factor = block_factor // ub_outer
            else:
                self._tiling_case.ub_factor = (block_factor + ub_outer - 1) // ub_outer
        if self._tiling_case.ub_tiling_axis == block_tiling_axis:
            self._tiling_case.is_split_ub = False
        else:
            self._tiling_case.is_split_ub = True

    def _tilling_axis(self):
        """
        get the split axis and factor by ub size

        Parameters
        ----------
        shape: the shape of input
        dtype_size: the dtype size
        tensor_num: the number of tensor size

        Returns
        -------
        split_axis and split_factor
        """
        out_shape = self.input_shape
        core_limit = len(out_shape) - 2
        block_tiling_axis = core_limit - 1
        block_factor = 1
        n_parts = out_shape[core_limit - 1]
        core_size = 1
        core_num = _get_block_num()
        is_fuse_block = 1
        for i in range(0, core_limit):
            core_size *= out_shape[i]
            if out_shape[i] >= core_num and i == 1:
                is_fuse_block = 0
                block_tiling_axis = i
                n_parts = core_num
                block_factor = (out_shape[i] + core_num - 1) // core_num
                break
            if core_size >= core_num:
                left_block_dim = core_size // out_shape[i]
                cur_block_dim = core_num // left_block_dim
                cur_block_factor = (out_shape[i] + cur_block_dim - 1) // cur_block_dim
                n_parts = cur_block_dim
                block_tiling_axis = i
                block_factor = cur_block_factor
                break

        self._tiling_case.block_tiling_axis = block_tiling_axis
        self._tiling_case.is_fuse_block = is_fuse_block
        self._tiling_case.block_factor = n_parts

        self._tilling_ub(block_tiling_axis, block_factor, out_shape)

    def _do_tiling(self):
        case = self._tiling_case
        res = self._res
        sch = self._schedule

        # get tiling axis
        block_tiling_axis = case.block_tiling_axis
        ub_tiling_axis = case.ub_tiling_axis

        # get tiling params
        block_inner_factor = case.block_factor
        ub_inner_factor = case.ub_factor

        # block tiling
        block_outer, block_inner = sch[res].split(res.op.axis[block_tiling_axis],
                                                  nparts=block_inner_factor)
        if case.is_split_ub:
            ub_outer, ub_inner = sch[res].split(res.op.axis[ub_tiling_axis],
                                                factor=ub_inner_factor)
        else:
            ub_outer, ub_inner = sch[res].split(block_inner, factor=ub_inner_factor)
        self._ub_split_result = [ub_outer, ub_inner]

        if case.is_fuse_block:
            fuse_axis_list = [sch[res].op.axis[i] for i in range(block_tiling_axis)]
            fuse_axis_list.append(block_outer)
            if len(fuse_axis_list) > 1:
                multi_core_bind_axis = sch[res].fuse(*fuse_axis_list)
            else:
                multi_core_bind_axis = fuse_axis_list[0]
        else:
            multi_core_bind_axis = block_outer

        if case.multi_core:
            block = tvm.thread_axis("blockIdx.x")
            sch[res].bind(multi_core_bind_axis, block)

    def _set_buffer_compute_at(self):
        """
        set the compute axis for tensors
        """
        ub_outer = self._ub_split_result[0]
        res = self._res
        sch = self._schedule

        for value in self._tensor_map | self._out_ub_tensors - self._compute_inline_tensors:
            sch[value].compute_at(sch[res], ub_outer)

    def _do_double_buffer(self):
        sch = self._schedule
        for value in self._tensor_map | self._out_ub_tensors:
            sch[value].double_buffer()

    def _set_buffer_emit_insn(self):
        """
        instruction mapping
        """
        res = self._res
        sch = self._schedule
        tensor_map = self._tensor_map
        ub_inner = self._ub_split_result[1]

        for tensor in tensor_map | self._out_ub_tensors - self._compute_inline_tensors:
            if tensor.op.tag == INPUT_NAME:
                sch[tensor].emit_insn(tensor.op.axis[0], 'dma_copy')
            elif tensor.op.tag == "input_ub":
                sch[tensor].emit_insn(tensor.op.axis[0], 'dma_padding')
            elif tensor.op.tag == "cast_i8_ub":
                round_mode = 'Round'
                if self._res.op.attrs:
                    round_mode = self._res.op.attrs['round_mode']
                sch[tensor].emit_insn(tensor.op.axis[0], _round_emit_insn(round_mode))
            else:
                sch[tensor].emit_insn(tensor.op.axis[0], 'vector_auto')

        sch[res].emit_insn(ub_inner, 'dma_copy')

    def do_schedule(self):
        """
        auto_schedule for cce AI-CORE
        """
        self._schedule = tvm.create_schedule(self._res.op)
        self.collect_info()
        self.gen_fuse_flag()
        self.init_max_ub_count()
        self._do_cache_write()

        self._set_buffer_align()

        self._set_buffer_scope()

        self._do_storage_bound()

        self._cal_compute_inline()

        self._do_compute_inline()

        self._reorder_buffer()
        self._tilling_axis()
        self._do_tiling()

        self._set_buffer_compute_at()

        self._do_double_buffer()

        self._set_buffer_emit_insn()

        return self._schedule
 