#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2019-2022 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
common function for cube schedule
"""
from tbe import tvm
from tbe.common import platform as tbe_platform
from tbe.common.buildcfg import build_config
from tbe.common.platform import platform_info as tbe_platform_info
from tbe.common.utils.const import SplitAxisMode
from tbe.common.utils.const import QUANT_DTYPES
from tbe.dsl.base.operation import get_te_var
from tbe.dsl.boost_schedule_kit import Compare
from tbe.dsl.boost_schedule_kit.schedule_agent import SplitParam
from tbe.dsl.compute import cube_util
from tbe.dsl.compute.conv2d_backprop_input_compute import DynamicConv2dBpInputParams
from tbe.dsl.static_schedule.util import get_precision_mode

from tbe.dsl.base.operation import get_context
from tbe.dsl.base.operation import is_unify

FIXPIPE_SCOPE_MAP = {
    "quant_scale_0": "local.FB0",
    "relu_weight_0": "local.FB1",
    "relu_weight_1": "local.FB2",
    "quant_scale_1": "local.FB3"
}


def get_all_tensors(res):
    """
    get all tensor
    :param res: tensor
    :return: list
    """

    all_tensor = {}
    leaf_tensor = {}

    def get(tensor):
        """
        find all tensor
        :param tensor: c_gm
        :return: all tensor
        """
        tensor_list = tensor.op.input_tensors
        for one_tensor in tensor_list:
            if not one_tensor.op.input_tensors:
                leaf_tensor[one_tensor.op.name] = tensor
            # check which tensor has not been checked
            if one_tensor.op.name not in all_tensor:
                all_tensor[one_tensor.op.name] = one_tensor
                if one_tensor.op.tag in ("conv2d_backprop_input", "conv2d_backprop_input_opti"):
                    continue
                get(one_tensor)

    get(res)
    return all_tensor, leaf_tensor


def print_ir_conv(process, sch, debug_mode):
    """
    print ir for input sch

    Parameter:
    --------------------------------------------------------------
    :param process: tag
    :param sch: schedule
    :return: IR process
    ---------------------------------------------------------------
    """
    if debug_mode and "debug" in process:
        with build_config():
            start = process + " IR start"
            end = process + " IR end\n"
            sch = sch.normalize()
            print(start)
            bounds = tvm.schedule.InferBound(sch)
            stmt = tvm.ScheduleOps(sch, bounds, True)
            print(stmt)
            print(end)


def set_intrinsic_support(tensor_attr):
    """
    get intrinsic support to tensor_attr
    """
    tensor_attr["support_l0c_to_out"] = tbe_platform.intrinsic_check_support("Intrinsic_fix_pipe_l0c2out")
    tensor_attr["support_l1_to_bt"] = tbe_platform.intrinsic_check_support("Intrinsic_data_move_l12bt")
    tensor_attr["support_ub_to_l1"] = tbe_platform.intrinsic_check_support("Intrinsic_data_move_ub2l1")
    tensor_attr["support_fixpipe"] = (tbe_platform.intrinsic_check_support("Intrinsic_fix_pipe_l0c2out") or
                                      tbe_platform.intrinsic_check_support("Intrinsic_fix_pipe_l0c2ub"))
    tensor_attr["support_l0c_to_ub"] = (tbe_platform.intrinsic_check_support("Intrinsic_fix_pipe_l0c2ub") or
                                        tbe_platform.intrinsic_check_support("Intrinsic_data_move_l0c2ub"))
    tensor_attr["support_out_to_l1_nd_to_nz"] = tbe_platform.intrinsic_check_support("Intrinsic_data_move_out2l1_nd2nz")
    tensor_attr["l0a_layout_is_zN"] = tbe_platform_info.get_soc_spec("L0A_LAYOUT_IS_zN")


def fetch_fixpipe_tensor(sch, all_tensor, tensor_map):
    """
    get fixpipe tensor to tensor map and fix inline
    """
    tensor_map, fixpipe_tensor, tensor_gm = get_fixpipe_tensor(all_tensor, tensor_map)

    if len(tensor_map.get("double_out_tensor", [])) == 2:
        c_ddr_out = False
        for out_tensor in tensor_map.get("double_out_tensor", []):
            if out_tensor.op.tag == "fixpipe_reform":
                fixpipe_tensor = out_tensor.op.input_tensors[0]
                tensor_gm_clone = sch.cache_clone(tensor_gm, tbe_platform.scope_gm, [fixpipe_tensor])
                sch[tensor_gm_clone].compute_inline()
                sch[fixpipe_tensor].compute_inline()
            else:
                c_ddr_out = True
        if not c_ddr_out:
            sch[tensor_gm].compute_inline()
        return sch, tensor_map

    if fixpipe_tensor is not None:
        sch[fixpipe_tensor].compute_inline()
        sch[tensor_gm].compute_inline()

    return sch, tensor_map


def get_fixpipe_tensor(all_tensor, tensor_map):
    """
    get fixpipe tensor to tensor map
    """
    if isinstance(all_tensor, list):
        # conv3d all_tensor type is list
        all_tensor_info = []
        for tensor_info in all_tensor:
            all_tensor_info.append(tensor_info.get("dst_buffer"))
    else:
        all_tensor_info = all_tensor.values()
    fixpipe_tensor = None
    tensor_gm = None
    for tensor in all_tensor_info:
        if tensor.op.tag == "fixpipe":
            fixpipe_tensor = tensor
            tensor_map["fixpipe_tensor"] = fixpipe_tensor
        elif tensor.op.tag == "fixpipe_reform":
            tensor_map["fixpipe_output"] = tensor
        elif tensor.op.tag == "conv2d_backprop_input":
            tensor_gm = tensor
            tensor_map["tensor_dx_gm"] = tensor_gm
        elif tensor.op.tag == "conv3d_C":
            tensor_gm = tensor
            tensor_map["tensor_conv3d_gm"] = tensor_gm
        elif tensor.op.tag == "conv3d_backprop_input_dx_ddr":
            tensor_gm = tensor
            tensor_map["tensor_conv3ddx_gm"] = tensor_gm
    return tensor_map, fixpipe_tensor, tensor_gm


def fetch_requant_fusion_ub_info(sch, tensor_map, tensor_attr):
    """
    get ub info with dx + requant fusion
    """
    # l0c->ub->ddr->ub->data_transfer->res
    tensor_attr["quant_fuse"] = True
    tensor_map["data_transfer"] = tensor_map.get("deconv_res").op.input_tensors[0]
    tensor_map["c_ub"] = tensor_map.get("data_transfer").op.input_tensors[0]
    tensor_map["deq"] = tensor_map.get("c_ub").op.input_tensors[1]
    c_ub_ddr = tensor_map.get("c_ub").op.input_tensors[0]
    c_ub = c_ub_ddr.op.input_tensors[0]
    sch[c_ub_ddr].compute_inline()
    sch[c_ub].compute_inline()
    sch[c_ub_ddr].buffer_align((1, 1), (1, 1), (1, 16), (1, 16))
    return sch, tensor_map, tensor_attr


def fetch_elewise_fusion_ub_info(sch, tensor_map, tensor_attr):
    """
    get ub info with dx + elewise fusion
    """
    deconv_res = tensor_map.get("deconv_res")
    all_tensor, leaf_tensor = get_all_tensors(deconv_res)
    ub_list = []
    input_tensor_list = []
    c_ub_res = sch.cache_write(deconv_res, tbe_platform_info.scope_ubuf)
    for key, value in all_tensor.items():
        if value.op.tag == "conv2d_backprop_input":
            continue
        elif value.op.input_tensors:
            ub_list.append(value)
        else:
            if leaf_tensor.get(key) == deconv_res:
                input_tensor_list.append([value, c_ub_res])
            else:
                input_tensor_list.append([value, leaf_tensor.get(key)])
    ub_list.append(c_ub_res)
    tensor_attr["elewise_fuse"] = True
    tensor_map["ub_list"] = ub_list
    tensor_map["input_tensor_list"] = input_tensor_list
    c_ub = tensor_map.get("tensor_dx_gm")
    if not tensor_attr.get("support_l0c_to_out"):
        c_ub = c_ub.op.input_tensors[0]

    if c_ub.op.name == "bias_add_vector":
        tensor_map["bias_add_vector"] = c_ub
        c_ub = c_ub.op.input_tensors[0]
    tensor_map["c_ub"] = c_ub
    return sch, tensor_map, tensor_attr


def _get_tensors_vadd_three_inputs(tensor_vadd_res, tensor_map):
    """
    get vadd tensor with therr inputs
    """
    all_tensors, _ = get_all_tensors(tensor_vadd_res)
    c_ub, tensor_vadd, tensor_vadd_1, tensor_inter_add_compute = None, None, None, None
    if len(all_tensors) == 2:
        c_ub, tensor_vadd = _get_tensors_vadd(tensor_vadd_res)
    elif len(all_tensors) == 4:
        placeholder_tensors = []
        for one_tensor in all_tensors.values():
            if isinstance(one_tensor.op, tvm.PlaceholderOp):
                placeholder_tensors.append(one_tensor)
            elif one_tensor.op.tag == "conv2d_backprop_input":
                c_ub = one_tensor
            elif one_tensor.op.tag == "elewise_binary_add":
                tensor_inter_add_compute = one_tensor
        tensor_vadd = placeholder_tensors[1]
        tensor_vadd_1 = placeholder_tensors[0]
    tensor_map["tensor_vadd"] = tensor_vadd
    tensor_map["tensor_vadd_1"] = tensor_vadd_1
    tensor_map["tensor_inter_add_compute"] = tensor_inter_add_compute
    return c_ub, tensor_map


def _get_tensors_vadd(tensor_vadd_res):
    """
    get vadd tensor
    return c_ub, vadd_tensor
    """
    tensor_left = tensor_vadd_res.op.input_tensors[0]
    tensor_right = tensor_vadd_res.op.input_tensors[1]
    if tensor_left.op.tag == "conv2d_backprop_input":
        return tensor_left, tensor_right
    return tensor_right, tensor_left


def fetch_relugard_fusion_ub_info(sch, tensor_map, tensor_attr):
    """
    get ub info with dx + relugrad fusion
    """
    deconv_res = tensor_map.get("deconv_res")
    tensor_mask = deconv_res.op.input_tensors[0]
    c_ub = deconv_res.op.input_tensors[1]
    if len(deconv_res.op.input_tensors) > 2:
        tensor_map["tensor_broadcast"] = deconv_res.op.input_tensors[2]
    if "elewise_binary_add" in deconv_res.op.input_tensors[1].op.tag:
        vadd_res = deconv_res.op.input_tensors[1]
        c_ub, tensor_map = _get_tensors_vadd_three_inputs(vadd_res, tensor_map)
        tensor_map["vadd_res"] = vadd_res
    if not tensor_attr.get("support_l0c_to_out"):
        c_ub = c_ub.op.input_tensors[0]
    tensor_map["c_ub"] = c_ub
    tensor_map["mask"] = tensor_mask
    return sch, tensor_map


def get_c_add_bias_tensor(tensor_map):
    """
    get c_add_bias tensor
    """
    tensor_dx_gm = tensor_map.get("tensor_dx_gm")
    all_tensor, _ = get_all_tensors(tensor_dx_gm.op.input_tensors[0])
    for tensor in all_tensor.values():
        if tensor.name == "c_add_bias":
            return tensor
    return None


def get_tensor_workspace(sch, tensor_map, tensor_attr):
    """
    get workspace tensor
    """
    tensor_ub_write = tensor_map.get("c_ub_drelu")
    if tensor_map.get("vadd_res") is not None:
        tensor_ub_write = tensor_map.get("vadd_res")
        if tensor_map.get("tensor_inter_add_compute") is not None:
            tensor_ub_write = tensor_map.get("tensor_inter_add_compute")

    c_ub = tensor_map.get("c_ub")
    tensor_map["tensor_workspace_list"] = [c_ub]
    tensor_map["tensor_workspace_ub"] = sch.cache_read(c_ub, tbe_platform_info.scope_ubuf, [tensor_ub_write])
    tensor_map["c_ub"] = tensor_map["tensor_workspace_ub"]
    return sch, tensor_map


def get_mix_ratio():
    """
    get the ratio of AIC and AIV for mix l2 fusion
    """
    aic_num = int(tbe_platform_info.get_soc_spec("CUBE_CORE_CNT"))
    aiv_num = int(tbe_platform_info.get_soc_spec("VECTOR_CORE_CNT"))
    multiple_of_aiv_to_aic = aiv_num // aic_num
    return multiple_of_aiv_to_aic


def get_fixpipe_flag(fixpipe_tensor):
    """ encode fixpipe flag
    """
    fixpipe_flag = 0
    if "vector_params" not in fixpipe_tensor.op.attrs:
        return fixpipe_flag
    for fixpipe_input in fixpipe_tensor.op.attrs["vector_params"]:
        if fixpipe_input == "eltwise_src":
            # 16 is 2**4, 2 means exponent base, the index of fixpipe add is 4
            fixpipe_flag += 16
        fixpipe_scope = FIXPIPE_SCOPE_MAP.get(fixpipe_input)
        if fixpipe_scope is not None:
            # 2 means exponent base
            fixpipe_flag += int(2 ** int(fixpipe_scope[-1]))
    return fixpipe_flag


def update_info_dict(support_l0c_to_out, fixpipe_tensor, bias_l1_tensor, info_dict, special_params=None):
    """ add fixpipe_flag and bias_dtype to info_dict
    """
    if not support_l0c_to_out:
        return
    if fixpipe_tensor is not None:
        info_dict.update({"fixpipe_flag": get_fixpipe_flag(fixpipe_tensor)})
    if bias_l1_tensor is not None:
        info_dict.update({"bias_dtype": bias_l1_tensor.dtype})
    if special_params is not None:
        if special_params.get("sparse_4to2_flag"):
            info_dict.update({"4To2_structured_sparsity": True})


def _bf16_to_f16(input_dtype):
    """
    transform bfloat16 to float16
    """
    if input_dtype == "bfloat16":
        input_dtype = "float16"
    return input_dtype


def get_inout_dtype(a_ddr, b_ddr, c_ddr, op_type):
    """
    get the input dtypes, output dtype and mmad dtype of tiling info
    """
    a_dtype, b_dtype, c_dtype = _bf16_to_f16(a_ddr.dtype), _bf16_to_f16(b_ddr.dtype), _bf16_to_f16(c_ddr.dtype)
    mad_type = "float32"
    if b_dtype in QUANT_DTYPES:
        mad_type = "int32"
    if b_dtype == "float32" and get_precision_mode(op_type) == "enable_hi_float_32_execution":
        mad_type = "hfloat32"
    return [a_dtype, b_dtype, c_dtype, mad_type]


class DxDynamicUtil():
    """
    DxDynamic custom schedule method
    """
    def __init__(self, tiling_case, var_range, tensor_attr=None) -> None:
        self.tiling_case = tiling_case
        self.var_range = var_range
        self.dynamic_mode = None
        self.format_a = "NC1HWC0"
        self.tiling_vars = {}
        self.shape_vars = {}
        if tensor_attr is not None:
            self.shape_vars = {"dy_c1_extend": tensor_attr["group_dict"]["dy_c1_extend"]}
        self.stride_expand = False
        self.status = {}
        self.attach_flag = {}
        self.range_const = {
            "range_one": (1, 1),
            "range_pad": (0, 255),
            "range_stride": (1, 63),
            "range_dilation": (1, 255),
            "range_shape_modify": (-255, 0),
            "range_block_dim": (1, 32),
            "range_64": (1, 64),
            "range_255": (1, 255),
            "range_256": (1, 256),
            "range_1024": (1, 1024),
            "range_4096": (1, 4096),
            "range_max": (1, 2147483647),
            "range_ub_bound": (256, 262144),
            "range_l1_bound": (256, 1048576),
            "load3d_special": (1, 2),
            "bias_flag": (0, 1)
        }
        self.shape_var_names = ('batch_n', 'dedy_h', 'dedy_w', 'dx_h', 'dx_w', 'dx_c', 'dx_c1', 'dy_c',
                                'kernel_h', 'kernel_w', 'padt', 'padb', 'padl', 'padr', 'stride_h', 'stride_w',
                                'dilation_h', 'dilation_w', 'g_extend', 'multiple_extend',
                                'dx_c1_extend', 'filter_ci1hw', 'pad_up_before',
                                'pad_left_before', 'pad_down_after', 'pad_right_after', "load3d_special",
                                'shape_up_modify', 'shape_left_modify', 'shape_down_modify', 'shape_right_modify',
                                "bias_flag")
        self.tiling_var_names = ('group_dim', 'batch_dim', 'n_dim', 'm_dim', 'batch_single_core', 'm_al1', 'n_bl1',
                                 'k_div_max_kl1', 'max_kl1_div_min_kl1', 'min_kl1_div_kl0', 'k_aub', 'm_aub', 'wo_aub',
                                 'm_l0', 'n_l0_div_ub', 'n_ub', 'k_l0', 'al1_bound', 'bl1_bound', 'aub_bound',
                                 'bias_table_bound')
        self.status_ori_dict_dx = {0: Compare.EQUAL, 1: Compare.LESS_EQ, 2: Compare.LESS_EQ, 3: Compare.LESS_EQ}
        self.status_dict_dx = {0: Compare.EQUAL, 1: Compare.EQUAL, 2: Compare.LESS_EQ, 3: Compare.GREATE_EQ}
        self.g_dim = (0,)
        self.al1_khw_dim = (2, 3, 4)
        dim_offset = int(self.tiling_case is not None
                         and self.tiling_case.get("split_axis_mode") == SplitAxisMode.split_w.value)
        self.ddr_gnm_dim = (0, 2, 3 + dim_offset)
        self.cl0_mn0_dim = (3 + dim_offset, 4 + dim_offset)
        self.cl0_n1m_dim = (2 + dim_offset, 3 + dim_offset)


    @staticmethod
    def _get_optional_te_var(var_name):
        return None if not get_te_var(var_name) else get_te_var(var_name).get_tvm_var()

    def get_ceil_mode(self, affine_shape=None, factor_ceil_dim=None, split_ceil_dim=None):
        """
        calculate factor with factor_ceil_mode in schedule_agent, split with split_ceil_mode in schedule_agent/
        False for divisible scene, default is True
        """
        factor_ceil_mode = True
        split_ceil_mode = True
        if self.dynamic_mode == "binary" and affine_shape:
            factor_ceil_mode = [False] * len(affine_shape)
            split_ceil_mode = [False] * len(affine_shape)
            if factor_ceil_dim:
                for dim in factor_ceil_dim:
                    factor_ceil_mode[dim] = True
            if split_ceil_dim:
                for dim in split_ceil_dim:
                    split_ceil_mode[dim] = True
        return {"factor_ceil_mode": factor_ceil_mode, "split_ceil_mode": split_ceil_mode}

    def set_dynamic_scene(self):
        """
        identify dynamic scene and set relevant members
        """
        if not is_unify():
            # static scene
            return

        for name in self.shape_var_names:
            self.shape_vars[name] = self._get_optional_te_var(name)

        if self.shape_vars.get("kernel_h") is None:
            self.dynamic_mode = "dynamic_nhw"
            return

        self.dynamic_mode = "binary"
        self.attach_flag = self.tiling_case.get("attach_at_flag", {})
        for name in self.tiling_var_names:
            self.tiling_vars[name] = self._get_optional_te_var(name)

    def set_spec_var_range(self, sch, dim_var_range, is_conv1d_situation):
        """
        set var range for all variables
        """
        if self.dynamic_mode == "dynamic_nhw":
            for var_name, var_range in dim_var_range.items():
                sch.set_var_range(self.shape_vars.get(var_name), *var_range)
        elif self.dynamic_mode == "binary":
            shape_var_range, tiling_var_range = self._get_binary_range()

            for var_name, var_range in shape_var_range.items():
                var = self.shape_vars.get(var_name)
                if isinstance(var, tvm.Var):
                    sch.set_var_range(var, *var_range)

            for var_name, var_range in tiling_var_range.items():
                var = self.tiling_vars.get(var_name)
                if isinstance(var, tvm.Var):
                    sch.set_var_range(var, *var_range)

            # Use set_var_value to avoid parallel compilation failures
            if is_conv1d_situation:
                sch.set_var_value(self.shape_vars.get("dedy_h"), 1)
                sch.set_var_value(self.shape_vars.get("dx_h"), 1)
                sch.set_var_value(self.shape_vars.get("kernel_h"), 1)
                sch.set_var_value(self.shape_vars.get("padt"), 0)
                sch.set_var_value(self.shape_vars.get("padb"), 0)
                sch.set_var_value(self.shape_vars.get("pad_up_before"), 0)
                sch.set_var_value(self.shape_vars.get("pad_down_after"), 0)
                sch.set_var_value(self.shape_vars.get("shape_up_modify"), 0)
                sch.set_var_value(self.shape_vars.get("shape_down_modify"), 0)
                sch.set_var_value(self.shape_vars.get("stride_h"), 1)
                sch.set_var_value(self.tiling_vars.get("m_aub"), 1)

            if self.attach_flag.get('abkl1_attach_flag') == 0:
                sch.set_var_value(self.tiling_vars.get('max_kl1_div_min_kl1'), 1)

    def set_spec_var_value(self, sch, b_col):
        """
        set variable's value by const or expr
        """
        if self.dynamic_mode != "binary":
            return

        # if al1 attach at cl0, m_al1 should be one
        if self.attach_flag.get("al1_attach_flag") in (1, 2):
            sch.set_var_value(self.tiling_vars.get("m_al1"), 1)
        # if bl1 attach at cl0, n_bl1 should be one
        if self.attach_flag.get("bl1_attach_flag") in (1, 2):
            sch.set_var_value(self.tiling_vars.get("n_bl1"), 1)

        if self.attach_flag.get("min_kl1_div_kl0_is_1_flag") == 1:
            sch.set_var_value(self.tiling_vars.get("min_kl1_div_kl0"), 1)

        kernel_h = self.shape_vars.get("kernel_h")
        kernel_w = self.shape_vars.get("kernel_w")
        co1g_factor = 2 if b_col.dtype == "float32" else 1
        if self.tiling_case.get("co1g_ci1g_is_1") == 0:
            sch.set_var_value(self.shape_vars.get('dy_c1_extend'),
                tvm.div(self.tiling_vars.get('k_div_max_kl1') * self.tiling_vars.get('max_kl1_div_min_kl1') *
                self.tiling_vars.get('min_kl1_div_kl0') * self.tiling_vars.get("k_l0"),
                kernel_h * kernel_w * co1g_factor))
        sch.set_constraint((
            ((self.shape_vars.get('dy_c1_extend') * kernel_h * kernel_w * co1g_factor) %
             self.tiling_vars.get("k_l0") == 0)).asobject())

        if self.tiling_case.get("simply_loop_mn_from_sc_to_l0_is_1") == 1:
            n_ub = self.tiling_vars.get("n_ub")
            n_l0_div_ub = self.tiling_vars.get("n_l0_div_ub")
            n_dim = self.tiling_vars.get("n_dim")
            dx_c1_extend = self.shape_vars.get("dx_c1_extend")
            sch.set_constraint((tvm.floordiv(tvm.floordiv(tvm.floordiv(
                dx_c1_extend-1, n_ub), n_l0_div_ub), n_dim) + 1 == 1).asobject())

            dx_h = self.shape_vars.get("dx_h")
            dx_w = self.shape_vars.get("dx_w")
            m_l0 = self.tiling_vars.get("m_l0")
            m_dim = self.tiling_vars.get("m_dim")
            sch.set_constraint((tvm.floordiv(tvm.floordiv(
                dx_h * dx_w - 1, m_l0 * 16), m_dim) + 1 == 1).asobject())

            if self.tiling_case.get("co1g_ci1g_is_1") == 1:
                dy_c1_extend = self.shape_vars.get("dy_c1_extend")

                sch.set_var_value(dy_c1_extend, 1)
                sch.set_var_value(dx_c1_extend, 1)

        if isinstance(self.shape_vars.get("filter_ci1hw"), tvm.Var):
            sch.set_var_value(
                self.shape_vars.get("filter_ci1hw"),
                self.shape_vars.get("g_extend") * self.shape_vars.get("dx_c1_extend") * kernel_h * kernel_w)

    def get_buffer_status(self):
        """
        get attach status on L0/L1/UB buffer
        """
        if self.dynamic_mode != "binary":
            return
        cub_attach_flag = self.attach_flag.get("cub_attach_flag")
        cl0_attach_flag = self.attach_flag.get("cl0_attach_flag")
        al0_attach_flag = self.attach_flag.get("al0_attach_flag")
        bl0_attach_flag = self.attach_flag.get("bl0_attach_flag")
        aub_attach_flag = self.attach_flag.get("aub_attach_flag")
        al1_attach_flag = self.attach_flag.get("al1_attach_flag")
        bl1_attach_flag = self.attach_flag.get("bl1_attach_flag")
        self.status = {
            "cub_status_ori": self.status_ori_dict_dx.get(cub_attach_flag),
            "cub_status": self.status_dict_dx.get(cub_attach_flag),
            "cl0_status_ori": self.status_ori_dict_dx.get(cl0_attach_flag),
            "cl0_status": self.status_dict_dx.get(cl0_attach_flag),
            "al0_status_ori": self.status_ori_dict_dx.get(al0_attach_flag),
            "al0_status": self.status_dict_dx.get(al0_attach_flag),
            "bl0_status_ori": self.status_ori_dict_dx.get(bl0_attach_flag),
            "bl0_status": self.status_dict_dx.get(bl0_attach_flag),
            "aub_status_ori":  self.status_ori_dict_dx.get(aub_attach_flag),
            "aub_status": self.status_dict_dx.get(aub_attach_flag),
            "al1_status_ori":  self.status_ori_dict_dx.get(al1_attach_flag),
            "al1_status": self.status_dict_dx.get(al1_attach_flag),
            "bl1_status_ori":  self.status_ori_dict_dx.get(bl1_attach_flag),
            "bl1_status": self.status_dict_dx.get(bl1_attach_flag),
        }

    def l1_full_load(self, c_ddr, sch, tensor_map, tensor_attr):
        """
        handle l1 full load
        """
        if self.dynamic_mode != "binary":
            return
        a_l1 = tensor_map.get('a_l1')
        b_l1 = tensor_map.get('b_l1')
        if self.attach_flag.get("al1_attach_flag") == 0:
            sch[a_l1].compute_at(sch[c_ddr], sch[c_ddr].leaf_iter_vars[5])
            if tensor_attr.get("support_l0c_to_out") and 'a_zero' in tensor_map:
                sch[tensor_map.get('dy_vn')].compute_at(sch[c_ddr], sch[c_ddr].leaf_iter_vars[5])
                sch[tensor_map.get('a_zero')].compute_at(sch[c_ddr], sch[c_ddr].leaf_iter_vars[5])
                sch[tensor_map.get('a_filling')].compute_at(sch[c_ddr], sch[c_ddr].leaf_iter_vars[5])
        if self.attach_flag.get("bl1_attach_flag") == 0:
            # the value of n_bl1 does not affect buffer size when full load
            sch.set_var_value(self.tiling_vars.get('n_bl1'), 1)
            sch[b_l1].compute_at(sch[c_ddr], sch[c_ddr].leaf_iter_vars[5])
            if DynamicConv2dBpInputParams.binary_mode == cube_util.BinaryMode.NC1HWC0:
                sch[b_l1].compute_at(sch[c_ddr], sch[c_ddr].leaf_iter_vars[3])

    def _get_binary_range(self):
        range_pad = self.range_const.get("range_pad")
        range_shape_modify = self.range_const.get("range_shape_modify")
        range_block_dim = self.range_const.get("range_block_dim")
        range_64 = self.range_const.get("range_64")
        range_255 = self.range_const.get("range_255")
        range_256 = self.range_const.get("range_256")
        range_1024 = self.range_const.get("range_1024")
        range_4096 = self.range_const.get("range_4096")
        range_max = self.range_const.get("range_max")
        range_stride = self.range_const.get("range_stride")
        range_dilation = self.range_const.get("range_dilation")
        range_load3d_special = self.range_const.get("load3d_special")
        range_bias_flag = self.range_const.get("bias_flag")

        shape_var_range = {
            "dedy_h": range_4096, "dedy_w": range_max, "dx_h": range_4096, "dx_w": range_max,
            "kernel_h": range_255, "kernel_w": range_255, "dx_c": range_4096, "dx_c1": range_256,
            "padt": range_pad, "padb": range_pad, "padl": range_pad, "padr": range_pad,
            "dx_c1_extend": range_256,  "g_extend": range_max, "multiple_extend": range_max,
            "pad_up_before": range_pad, "pad_left_before": range_pad,
            "pad_down_after": range_pad, "pad_right_after": range_pad,
            "shape_up_modify": range_shape_modify, "shape_left_modify": range_shape_modify,
            "shape_down_modify": range_shape_modify, "shape_right_modify": range_shape_modify,
            "stride_h": range_stride, "stride_w": range_stride, "load3d_special": range_load3d_special,
            "dilation_h": range_dilation, "dilation_w": range_dilation, "bias_flag": range_bias_flag
        }

        tiling_var_range = {
            "batch_dim": range_block_dim, "n_dim": range_block_dim, "m_dim": range_block_dim,
            "k_div_max_kl1": range_1024, "max_kl1_div_min_kl1": range_1024, "min_kl1_div_kl0": range_1024,
            "m_al1": range_1024, "n_bl1": range_1024, "n_ub": range_64, "m_l0": range_64, "k_l0": range_64,
            "n_l0_div_ub": range_64, "m_aub": range_256, "wo_aub": range_max, "k_aub": range_1024,
            "aub_bound": self.range_const.get("range_ub_bound"),
            "al1_bound": self.range_const.get("range_l1_bound"),
            "bl1_bound": self.range_const.get("range_l1_bound"),
            "bias_table_bound": range_256
        }
        return shape_var_range, tiling_var_range


class BinaryUtil():
    """
    binary public const
    """
    TILING_RANGE = {
        "range_block_dim": (1, 32),
        "range_l0_ub_param": (1, 64),
        "range_outer_axis": (1, 1024),
        "range_shape": (1, 4096),
        "range_l1": (256, 1048576),
        "range_bt": (0, 1024),
        "range_pad": (0, 511),
        "range_stride": (1, 63),
        "range_kernel": (1, 511),
        "range_dilation": (1, 255),
        "range_load3d_special": (1, 2),
        "range_kl1_times": (1, 2048),
        "range_c": (1, 65536 * 16),
        "range_c1": (1, 65536),
        "range_max": (1, 2147483647),
        "range_bool": (0, 1)
    }

    TILING_UTILS = {
        "attach_full_load": 0,
        "attach_equal": 1,
        "attach_less": 2,
        "no_attach": 3
    }


class ConvBpFilterBinaryDynamic:
    """
    special for dynamic binary
    """
    def __init__(self, sch, binary_mode, flag_load3d_w_split_case, flag_all_one_case):
        self.tiling_utils = BinaryUtil.TILING_UTILS
        self._tiling_range = BinaryUtil.TILING_RANGE
        self.sch = sch
        self.cache_tiling = {}
        self.binary_nparts = {}
        self.block_reduce = 16
        self.binary_mode = binary_mode
        self._binary_tiling_data = None
        self.k_full_load_list = (self.tiling_utils.get("attach_full_load"), self.tiling_utils.get("attach_equal"))
        self.ub_tensor_list = ["input_ub_td", "input_ub_pad", "input_ub_vn"]
        if binary_mode == cube_util.BinaryMode.NCHW:
            self.ub_tensor_list.append("transpose_hw_c0")
        else:
            self.ub_tensor_list.append("transpose_hw_c1")
        self.k_expr = None
        self.k_expr_single_core = None
        self.emit_insn_dict = {
            "input_ub_td": "dma_copy",
            "input_ub_pad": "vector_dup",
            "input_ub_vn": "phony_insn",
            "transpose_hw_c1": "vector_or",
            "transpose_hw_c0": "vnchwconv"
        }
        self.split_tail_strategy = "round_up" if binary_mode else "guard_with_if"
        self.split_nofactor_tail_strategy = "guard_with_if"
        self.split_params = SplitParam(tail_strategy=self.split_tail_strategy)
        self.split_nofactor_params = SplitParam(tail_strategy=self.split_nofactor_tail_strategy)
        self.dma_insn_dict = {"map_policy":"2d"} if binary_mode else {}
        self.bl1_attach_ins_flag = 0
        self.axis_merge_ins_flag = 0
        self.flag_load3d_w_split_case = flag_load3d_w_split_case
        self.flag_all_one_case = flag_all_one_case

    @staticmethod
    def _get_optional_te_var(var_name):
        """get optional te var"""
        return None if not get_te_var(var_name) else get_te_var(var_name).get_tvm_var()

    def set_shape_var_range(self):
        """
        set var range for cache tiling vars and shape vars
        """
        range_shape = self._tiling_range.get("range_shape")
        range_pad = self._tiling_range.get("range_pad")
        range_stride = self._tiling_range.get("range_stride")
        range_kernel = self._tiling_range.get("range_kernel")
        range_dilation = self._tiling_range.get("range_dilation")
        range_c = self._tiling_range.get("range_c")
        range_c1 = self._tiling_range.get("range_c1")
        range_max = self._tiling_range.get("range_max")
        shape_var_range = {
            "batch": range_shape,
            "dedy_h": range_shape,
            "dedy_w": range_max,
            "fmap_h": range_shape,
            "fmap_w": range_max,
            "padt": range_pad,
            "padb": range_pad,
            "padl": range_pad,
            "padr": range_pad,
            "stride_h": range_stride,
            "stride_w": range_stride,
            "kernel_h": range_kernel,
            "kernel_w": range_kernel,
            "dilation_h": range_dilation,
            "dilation_w": range_dilation,
            "fmap_c": range_c,
            "dedy_c": range_c,
            "fmap_c1": range_c1,
            "dedy_c1": range_c1,
            "groups": range_shape,
            "cout1_g": range_c1,
            "cin1_g": range_c1,
            "real_g": range_shape
        }
        for var, var_range in shape_var_range.items():
            self.sch.set_var_range(get_te_var(var).get_tvm_var(), *var_range)

    def set_tiling_var_range(self):
        """set tiling var range"""
        range_shape = self._tiling_range.get("range_shape")
        range_outer_axis = self._tiling_range.get("range_outer_axis")
        range_max = self._tiling_range.get("range_max")
        range_l0_ub_param = self._tiling_range.get("range_l0_ub_param")
        range_l1 = self._tiling_range.get("range_l1")
        range_block_dim = self._tiling_range.get("range_block_dim")
        tiling_var_range = {
            "group_dim": range_block_dim,
            "batch_dim": range_block_dim,
            "n_dim": range_block_dim,
            "m_dim": range_block_dim,
            "k_dim": range_block_dim,
            "batch_single_core": range_shape,
            "m_single_core": range_shape,
            "n_single_core": range_outer_axis,
            "m_al1": range_outer_axis,
            "n_bl1": range_outer_axis,
            "cub_n1": range_l0_ub_param,
            "m_l0": range_l0_ub_param,
            "k_l0": range_l0_ub_param,
            "n_ub_l0_time": range_l0_ub_param,
            "kal1_factor": range_outer_axis,
            "kbl1_factor": range_outer_axis,
            "kal0_factor": range_outer_axis,
            "kbl0_factor": range_outer_axis,
            "bl1_bound": range_l1,
            "m_aub": range_l0_ub_param,
            "k_aub": range_l0_ub_param,
            "k_bub": range_l0_ub_param,
            "n_bub": range_l0_ub_param,
            "wi_bub": range_max,
            "multi_n_ub_l1": range_l0_ub_param,
            "multi_m_ub_l1": range_l0_ub_param,
            "multi_k_aub_l1": range_l0_ub_param,
            "multi_k_bub_l1": range_l0_ub_param,
            "kl1_times": self._tiling_range.get("range_kl1_times"),
            "ho_bL1": range_shape,
            "load3d_special": self._tiling_range.get("range_load3d_special"),
            "is_bf16": self._tiling_range.get("range_bool")
            }
        if get_te_var("al1_pb"):
            tiling_var_range["al1_pb"] = self._tiling_range.get("range_bool")
        if get_te_var("bl1_pb"):
            tiling_var_range["bl1_pb"] = self._tiling_range.get("range_bool")
        if get_te_var("l0c_pb"):
            tiling_var_range["l0c_pb"] = self._tiling_range.get("range_bool")

        for var, var_range in tiling_var_range.items():
            self.sch.set_var_range(get_te_var(var).get_tvm_var(), *var_range)

    def update_tiling_nparts(self):
        """
        get tiling_nparts in binary dynamic scene
        """
        nparts_dict = {
            "batch_dim_factor": self.cache_tiling.get("batch_single_core"),
            "dw_tiling_nparts": [self.binary_nparts.get("n_bL0"), self.binary_nparts.get("m_aL0")],
            "grads_l1_tiling_nparts": [self.binary_nparts.get("k_aL1"), self.binary_nparts.get("m_aL1")],
            "fmap_l1_tiling_nparts": [self.binary_nparts.get("k_bL1"), self.binary_nparts.get("n_bL1")],
            "dw_ub_tiling_nparts": [self.cache_tiling.get("n_ub_l0_time"), 1],
            "dw_tiling_factor": [self.cache_tiling.get("n_ub_l0_time") * self.cache_tiling.get("cub_n1"),
                                 self.cache_tiling.get("m_l0")],
            "dw_ub_tiling_factor": [self.cache_tiling.get("cub_n1"), self.cache_tiling.get("m_l0")],
            "dw_k": self.cache_tiling.get("k_al0"),
        }
        return nparts_dict

    def config_cache_tiling(self, tiling):
        """
        config base tiling information for cache tiling
        """
        if not self.binary_mode:
            return

        self._binary_tiling_data = tiling.get("binary_tiling_data")
        self._get_cache_tiling()
        self.binary_nparts["m_aL1"] = self.cache_tiling.get("m_single_core")
        self.binary_nparts["n_bL1"] = self.cache_tiling.get("n_single_core")
        self.binary_nparts["m_aL0"] = self.cache_tiling.get("m_single_core") * self.cache_tiling.get("m_al1")
        self.binary_nparts["n_bL0"] = self.cache_tiling.get("n_single_core") * self.cache_tiling.get("n_bl1")
        # al1 and bl1 full load
        if tiling.get("attach_at_flag").get("al1_attach_flag") == self.tiling_utils.get("attach_full_load"):
            self.sch.set_var_value(self.cache_tiling.get("m_single_core"), 1)
        if tiling.get("attach_at_flag").get("bl1_attach_flag") == self.tiling_utils.get("attach_full_load"):
            self.sch.set_var_value(self.cache_tiling.get("n_single_core"), 1)
        # al1 compute at l0c
        if tiling.get("attach_at_flag").get("al1_attach_flag") == self.tiling_utils.get("attach_less"):
            self.sch.set_var_value(self.cache_tiling.get("m_al1"), 1)
        # bl1 compute at l0c
        if tiling.get("attach_at_flag").get("bl1_attach_flag") == self.tiling_utils.get("attach_less"):
            self.sch.set_var_value(self.cache_tiling.get("n_bl1"), 1)
        abkl1_attach_flag = tiling.get("attach_at_flag").get("abkl1_attach_flag")
        self.sch.set_var_value(get_te_var("load3d_special").get_tvm_var(), tiling.get("load3d_special_flag") + 1)
        if abkl1_attach_flag == 0:
            self.sch.set_var_value(self.cache_tiling.get("kl1_times"), 1)
            self._norange_kal1_kbl1_equal(tiling)
        elif abkl1_attach_flag == 1:
            self._norange_kal1(tiling)
        else:
            self._norange_kbl1(tiling)
        if abkl1_attach_flag == 1 or tiling.get("attach_at_flag").get("min_kl1_cmp_kl0") == 1 or tiling.get(
                "attach_at_flag").get("db_bl1") == 1:
            self.axis_merge_ins_flag = 1
        self._tiling_infer_norange(tiling)

    def binary_simplify(self, conv1d_flag, linear_embedding_opti_flag):
        if not self.binary_mode:
            return
        if self.binary_mode != cube_util.BinaryMode.NC1HWC0:
            self.sch.set_var_value(get_te_var("cout1_g").get_tvm_var(),
                get_te_var("m_dim").get_tvm_var() * get_te_var("m_single_core").get_tvm_var() *
                get_te_var("m_al1").get_tvm_var() * get_te_var("m_l0").get_tvm_var())
        self.sch.set_constraint(
            get_te_var("padl").get_tvm_var() < get_te_var("kernel_w").get_tvm_var())
        if self.flag_all_one_case:
            self.sch.set_var_value(get_te_var("kernel_h").get_tvm_var(), 1)
            self.sch.set_var_value(get_te_var("kernel_w").get_tvm_var(), 1)
            self.sch.set_var_value(get_te_var("stride_h").get_tvm_var(), 1)
            self.sch.set_var_value(get_te_var("stride_w").get_tvm_var(), 1)
            self.sch.set_var_value(get_te_var("padt").get_tvm_var(), 0)
            self.sch.set_var_value(get_te_var("padb").get_tvm_var(), 0)
            self.sch.set_var_value(get_te_var("padl").get_tvm_var(), 0)
            self.sch.set_var_value(get_te_var("padr").get_tvm_var(), 0)
        if conv1d_flag:
            self.sch.set_var_value(get_te_var("fmap_h").get_tvm_var(), 1)
            self.sch.set_var_value(get_te_var("kernel_h").get_tvm_var(), 1)
            self.sch.set_var_value(get_te_var("dedy_h").get_tvm_var(), 1)
            self.sch.set_var_value(get_te_var("stride_h").get_tvm_var(), 1)
            self.sch.set_var_value(get_te_var("padt").get_tvm_var(), 0)
            self.sch.set_var_value(get_te_var("padb").get_tvm_var(), 0)
        if linear_embedding_opti_flag:
            # Linear_embedding_opti only let go of the scene below
            self.sch.set_var_value(get_te_var("padt").get_tvm_var(), 0)
            self.sch.set_var_value(get_te_var("padb").get_tvm_var(), 0)
            self.sch.set_var_value(get_te_var("padl").get_tvm_var(), 0)
            self.sch.set_var_value(get_te_var("padr").get_tvm_var(), 0)
            self.sch.set_var_value(get_te_var("dilation_h").get_tvm_var(), 1)
            self.sch.set_var_value(get_te_var("dilation_w").get_tvm_var(), 1)
            self.sch.set_var_value(get_te_var("kernel_h").get_tvm_var(), 32)
            self.sch.set_var_value(get_te_var("kernel_w").get_tvm_var(), 32)
            self.sch.set_var_value(get_te_var("stride_h").get_tvm_var(), 32)
            self.sch.set_var_value(get_te_var("stride_w").get_tvm_var(), 32)
            self.sch.set_var_value(get_te_var("fmap_h").get_tvm_var(), 224)
            self.sch.set_var_value(get_te_var("fmap_w").get_tvm_var(), 224)
            self.sch.set_var_value(get_te_var("dedy_h").get_tvm_var(), 7)
            self.sch.set_var_value(get_te_var("dedy_w").get_tvm_var(), 7)

        self._binary_constant()
        get_context().get_current_compute().get_current_schedule().add("_build_config",
                                                                      {"enable_branch_eliminator_else_case": False})

    def _binary_constant(self):
        if not self._binary_tiling_data:
            return
        for var_name, var_value in self._binary_tiling_data.items():
            self.sch.set_var_range(get_te_var(var_name).get_tvm_var(), var_value, var_value)

    def _get_cache_tiling(self):
        """
        get cache_tiling
        """
        self.cache_tiling = {
            "group_dim": get_te_var("group_dim").get_tvm_var(),
            "batch_dim": get_te_var("batch_dim").get_tvm_var(),
            "k_dim": get_te_var("k_dim").get_tvm_var(),
            "batch_single_core": get_te_var("batch_single_core").get_tvm_var(),
            "n_single_core": get_te_var("n_single_core").get_tvm_var(),
            "n_dim": get_te_var("n_dim").get_tvm_var(),
            "n_bl1": get_te_var("n_bl1").get_tvm_var(),
            "n_ub_l0_time": get_te_var("n_ub_l0_time").get_tvm_var(),
            "cub_n1": get_te_var("cub_n1").get_tvm_var(),
            "m_dim": get_te_var("m_dim").get_tvm_var(),
            "m_single_core": get_te_var("m_single_core").get_tvm_var(),
            "m_al1": get_te_var("m_al1").get_tvm_var(),
            "m_l0": get_te_var("m_l0").get_tvm_var(),
            "k_l0": get_te_var("k_l0").get_tvm_var(),
            "k_al0": get_te_var("k_l0").get_tvm_var(),
            "k_bl0": get_te_var("k_l0").get_tvm_var(),
            "kal1_factor": get_te_var("kal1_factor").get_tvm_var(),
            "kbl1_factor": get_te_var("kbl1_factor").get_tvm_var(),
            "kal0_factor": get_te_var("kal0_factor").get_tvm_var(),
            "kbl0_factor": get_te_var("kbl0_factor").get_tvm_var(),
            "kal1_16": self._get_optional_te_var("kal1_16"),
            "kbl1_16": self._get_optional_te_var("kbl1_16"),
            "kl1_times": get_te_var("kl1_times").get_tvm_var(),
            "bl1_bound": get_te_var("bl1_bound").get_tvm_var(),
            "ho_bL1": get_te_var("ho_bL1").get_tvm_var(),
            "m_aub": self._get_optional_te_var("m_aub"),
            "n_bub": self._get_optional_te_var("n_bub"),
            "k_aub": self._get_optional_te_var("k_aub"),
            "k_bub": self._get_optional_te_var("k_bub"),
            "wi_bub": self._get_optional_te_var("wi_bub"),
            "multi_n_ub_l1": self._get_optional_te_var("multi_n_ub_l1"),
            "multi_m_ub_l1": self._get_optional_te_var("multi_m_ub_l1"),
            "multi_k_aub_l1": self._get_optional_te_var("multi_k_aub_l1"),
            "multi_k_bub_l1": self._get_optional_te_var("multi_k_bub_l1"),
            "a_align_value": self._get_optional_te_var("a_align_value"),
            "b_align_value": self._get_optional_te_var("b_align_value"),
            "aub_align_bound": self._get_optional_te_var("aub_align_bound"),
            "bub_align_bound": self._get_optional_te_var("bub_align_bound"),
        }
        self.cache_tiling["kal1_16"] = self.cache_tiling.get("kal0_factor") * self.cache_tiling.get("k_l0")
        self.cache_tiling["kbl1_16"] = self.cache_tiling.get("kbl0_factor") * self.cache_tiling.get("k_l0")
        if get_te_var("al1_pb"):
            self.cache_tiling["al1_pb"] = get_te_var("al1_pb").get_tvm_var()
        if get_te_var("bl1_pb"):
            self.cache_tiling["bl1_pb"] = get_te_var("bl1_pb").get_tvm_var()
        if get_te_var("l0c_pb"):
            self.cache_tiling["l0c_pb"] = get_te_var("l0c_pb").get_tvm_var()

    def _norange_kal1_kbl1_equal(self, tiling):
        """
        config k related tiling variable when kal1 equals kbl1
        """
        kal0_factor = self.cache_tiling.get("kal0_factor")
        kal1_factor = self.cache_tiling.get("kal1_factor")
        self.binary_nparts["k_aL1"] = kal1_factor
        self.binary_nparts["k_bL1"] = kal1_factor
        self.binary_nparts["k_aL0"] = kal1_factor * kal0_factor
        self.binary_nparts["k_bL0"] = kal1_factor * kal0_factor
        k_l0 = self.cache_tiling.get("k_l0")
        # min(akl1, bkl1) equal whith kl0
        if not tiling["attach_at_flag"].get("min_kl1_cmp_kl0"):
            self.sch.set_var_value(kal0_factor, 1)
        # kal1 full load
        if tiling["attach_at_flag"].get("al1_attach_flag") in self.k_full_load_list:
            self.sch.set_var_value(kal1_factor, 1)
        self.cache_tiling["kal1_16"] = kal0_factor * k_l0
        self.cache_tiling["kbl1_16"] = kal0_factor * k_l0
        self.k_expr_single_core = kal1_factor * kal0_factor
        if not self.flag_load3d_w_split_case:
            self.k_expr_single_core = self.k_expr_single_core * k_l0
        self.k_expr = self.cache_tiling.get("k_dim") * self.k_expr_single_core


    def _norange_kal1(self, tiling):
        """
        config k related tiling variable when kal1 large than kbl1
        """
        kbl0_factor = self.cache_tiling.get("kbl0_factor")
        k_l0 = self.cache_tiling.get("k_l0")
        kl1_times = self.cache_tiling.get("kl1_times")
        k_dim = self.cache_tiling.get("k_dim")
        kal1_factor = self.cache_tiling.get("kal1_factor")
        self.binary_nparts["k_aL1"] = kal1_factor
        self.binary_nparts["k_bL1"] = kal1_factor * kl1_times
        self.binary_nparts["k_aL0"] = kal1_factor * kl1_times * kbl0_factor
        self.binary_nparts["k_bL0"] = kal1_factor * kl1_times * kbl0_factor
        # min(akl1, bkl1) equal whith kl0
        if not tiling["attach_at_flag"].get("min_kl1_cmp_kl0"):
            self.sch.set_var_value(kbl0_factor, 1)
        # kbl1 full load
        if tiling["attach_at_flag"].get("al1_attach_flag") in self.k_full_load_list:
            self.sch.set_var_value(kal1_factor, 1)
        else:
            self.cache_tiling["kal1_16"] = kl1_times * kbl0_factor * k_l0
        self.k_expr_single_core = kal1_factor * kl1_times * kbl0_factor
        if not self.flag_load3d_w_split_case:
            self.k_expr_single_core = self.k_expr_single_core * k_l0
        self.k_expr = k_dim * self.k_expr_single_core

    def _norange_kbl1(self, tiling):
        """
        config k related tiling variable when kal1 smaller than kbl1
        """
        kal0_factor = self.cache_tiling.get("kal0_factor")
        k_l0 = self.cache_tiling.get("k_l0")
        kl1_times = self.cache_tiling.get("kl1_times")
        kbl1_factor = self.cache_tiling.get("kbl1_factor")
        k_dim = self.cache_tiling.get("k_dim")
        self.binary_nparts["k_aL1"] = kbl1_factor * kl1_times
        self.binary_nparts["k_bL1"] = kbl1_factor
        self.binary_nparts["k_aL0"] = kbl1_factor * kl1_times * kal0_factor
        self.binary_nparts["k_bL0"] = kbl1_factor * kl1_times * kal0_factor
        if tiling.get("attach_at_flag").get("min_kl1_cmp_kl0") == 0:
            self.sch.set_var_value(kal0_factor, 1)
        if tiling.get("attach_at_flag").get("bl1_attach_flag") in self.k_full_load_list:
            self.sch.set_var_value(kbl1_factor, 1)
        else:
            self.cache_tiling["kbl1_16"] = kl1_times * kal0_factor * k_l0
        self.k_expr_single_core = kbl1_factor * kl1_times * kal0_factor
        if not self.flag_load3d_w_split_case:
            self.k_expr_single_core = self.k_expr_single_core * k_l0
        self.k_expr = k_dim * self.k_expr_single_core

    def _tiling_infer_norange(self, tiling):
        """
        config tiling variable for cache tiling
        """
        tiling['block_dim'] = [self.cache_tiling.get('batch_dim'),
                               self.cache_tiling.get("n_dim"),
                               self.cache_tiling.get("m_dim"),
                               self.cache_tiling.get("group_dim"), 1]
        tiling.get('AL1_shape')[0] = self.cache_tiling.get("kal1_16") * tiling.get('AL0_matrix')[3]
        tiling.get('AL1_shape')[1] = self.cache_tiling.get("m_al1")
        tiling.get('BL1_shape')[0] = self.cache_tiling.get("kbl1_16") * tiling.get('BL0_matrix')[3]
        tiling.get('BL1_shape')[1] = self.cache_tiling.get("n_bl1")
        tiling.get('AL0_matrix')[0] = self.cache_tiling.get("m_l0")
        tiling.get('CL0_matrix')[1] = self.cache_tiling.get("m_l0")
        tiling.get('L0C_OUTPUT_matrix')[1] = self.cache_tiling.get("m_l0")
        tiling.get('L0C_OUTPUT_matrix')[0] = self.cache_tiling.get("cub_n1")
        tiling.get('AL0_matrix')[1] = self.cache_tiling.get("k_al0")
        tiling.get('BL0_matrix')[0] = self.cache_tiling.get("k_bl0")
        tiling.get('BL0_matrix')[1] = self.cache_tiling.get("n_ub_l0_time") * self.cache_tiling.get("cub_n1")
        tiling.get('CL0_matrix')[0] = tiling.get('BL0_matrix')[1]
        tiling.get('AUB_shape')[0] = None
        if self.cache_tiling.get('k_aub') is not None:
            tiling.get('AUB_shape')[0] = self.cache_tiling.get('k_aub') * self.block_reduce
        tiling.get('AUB_shape')[1] = self.cache_tiling.get('m_aub')
        tiling.get('BUB_shape')[0] = self.cache_tiling.get('k_bub')
        tiling.get('BUB_shape')[1] = self.cache_tiling.get('n_bub')
        tiling.get('BUB_shape')[2] = self.cache_tiling.get('wi_bub')