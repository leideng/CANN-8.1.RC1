#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2024 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
from te.platform import cce_params
from tbe.common.utils.op_util.op_util_conv2d import Conv2dTensorName
from tbe.common.utils.op_util.op_util_conv2d import BIT_RATIO_MAP

SCALE_UB = "scale_ub"
SCALE_UB_ZERO = "scale_ub_zero"
SCALE_5HD_UB = "scale_5hd_ub"
SCALE_L1 = "scale_l1"
SCALE_L1_ZERO = "scale_l1_zero"
SCALE_L1_VIR_ADD = "scale_l1_vir_add"
DMA_COPY = "dma_copy"
PHONY_INSN = "phony_insn"
SET_2D = "set_2d"
ND2NZ = "nd2nz"
LAYOUT_TRANSFORM = "layout_transform"
BIAS_L0C = "bias_l0c"
L0C_BIAS_ADD = "l0c_bias_add"
CL0_PBUFFER = "CL0_pbuffer"
INIT_BIAS = "init_bias"

DOUBLE_BUFFER_DISABLED = 1
DOUBLE_BUFFER_ENABLED = 2
ND2NZ_ALIGN_BYTE = 32


class QuantConv2dSchedule:

    def __init__(self, sch, tensor_map):
        self.sch = sch
        self.tensor_map = tensor_map
        self.scale_ub = self.tensor_map.get(SCALE_UB)
        self.scale_ub_zero = self.tensor_map.get(SCALE_UB_ZERO)
        self.scale_5hd_ub = self.tensor_map.get(SCALE_5HD_UB)
        self.bias_l0c = self.tensor_map.get(Conv2dTensorName.BIAS_L0C)
        self.l0c_bias_add = self.tensor_map.get(Conv2dTensorName.L0C_BIAS_ADD)
        # milan
        self.scale_l1 = self.tensor_map.get(SCALE_L1)
        self.scale_l1_zero = self.tensor_map.get(SCALE_L1_ZERO)
        self.scale_l1_vir_add = self.tensor_map.get(SCALE_L1_VIR_ADD)

    @staticmethod
    def transform_pingpong_buffer_to_static_format(pingpong_buffer, conv_param):
        rang_map = conv_param.option_dict.get("CONST_BINARY_TILING_DATA", dict())
        for k, v in pingpong_buffer.items():
            # [0,0] is to close db and [1,1] is to open db in CONST_BINARY_TILING_DATA
            v = rang_map.get(k.lower(), None)
            if not v:
                continue
            v = DOUBLE_BUFFER_ENABLED if v == [1, 1] else DOUBLE_BUFFER_DISABLED
            pingpong_buffer[k] = v

    def config_bias_l0c(self):
        if self.bias_l0c is None:
            return

        self.sch[self.bias_l0c].set_scope(cce_params.scope_cc)
        self.sch[self.l0c_bias_add].set_scope(cce_params.scope_cc)

    def config_scale_ub(self):
        if self.scale_ub is None:
            return

        self.sch[self.scale_ub].set_scope(cce_params.scope_ubuf)
        self.sch[self.scale_ub_zero].set_scope(cce_params.scope_ubuf)
        self.sch[self.scale_5hd_ub].set_scope(cce_params.scope_ubuf)

    def config_scale_l1(self):
        if self.scale_l1 is None:
            return

        self.sch[self.scale_l1].set_scope(cce_params.scope_cbuf)
        self.sch[self.scale_l1_zero].set_scope(cce_params.scope_cbuf)
        self.sch[self.scale_l1_vir_add].set_scope(cce_params.scope_cbuf)

    def config_scope(self):
        self.config_bias_l0c()
        self.config_scale_ub()
        self.config_scale_l1()

    def bias_l0c_compute_at(self, res, cl0_at_res_axis):
        if self.bias_l0c is None:
            return

        self.sch[self.bias_l0c].compute_at(self.sch[res], cl0_at_res_axis)
        self.sch[self.l0c_bias_add].compute_at(self.sch[res], cl0_at_res_axis)

    def scale_ub_compute_at(self, res, scale_attach_axis):
        if self.scale_ub is None:
            return

        self.sch[self.scale_ub].compute_at(self.sch[res], scale_attach_axis)
        self.sch[self.scale_ub_zero].compute_at(self.sch[res], scale_attach_axis)
        self.sch[self.scale_5hd_ub].compute_at(self.sch[res], scale_attach_axis)

    def scale_l1_compute_at(self, res, scale_l1_attach_axis):
        if self.scale_l1 is None:
            return

        # Constraints from Pass.
        # The innermost loop of the nd2nz instruction must be 32B,
        # so the number of inner loops is calculated based on the data type.
        scale_l1_factor = ND2NZ_ALIGN_BYTE / BIT_RATIO_MAP.get(self.scale_l1.dtype)
        self.sch[self.scale_l1].split(self.scale_l1.op.axis[-1], factor=scale_l1_factor)
        self.sch[self.scale_l1].compute_at(self.sch[res], scale_l1_attach_axis)
        self.sch[self.scale_l1_zero].compute_at(self.sch[res], scale_l1_attach_axis)
        self.sch[self.scale_l1_vir_add].compute_at(self.sch[res], scale_l1_attach_axis)

    def compute_at(self, res, cl0_at_res_axis, scale_attach_axis, scale_l1_attach_axis):
        self.bias_l0c_compute_at(res, cl0_at_res_axis)
        self.scale_ub_compute_at(res, scale_attach_axis)
        self.scale_l1_compute_at(res, scale_l1_attach_axis)

    def bias_l0c_emit_insn(self, cl0):
        if self.bias_l0c is None:
            return

        self.sch[self.bias_l0c].reused_by(self.l0c_bias_add, cl0)
        self.sch[self.bias_l0c].emit_insn(self.bias_l0c.op.axis[0], DMA_COPY)
        self.sch[self.l0c_bias_add].emit_insn(self.l0c_bias_add.op.axis[0], PHONY_INSN)

    def scale_ub_emit_insn(self):
        if self.scale_ub is None:
            return

        self.sch[self.scale_ub].emit_insn(self.scale_ub.op.axis[0], DMA_COPY)
        self.sch[self.scale_ub_zero].emit_insn(self.scale_ub_zero.op.axis[0], DMA_COPY)
        self.sch[self.scale_5hd_ub].emit_insn(self.scale_5hd_ub.op.axis[0], PHONY_INSN)
        self.sch[self.scale_5hd_ub].reused_by(self.scale_ub_zero, self.scale_ub)

    def scale_l1_emit_insn(self):
        if self.scale_l1 is None:
            return

        self.sch[self.scale_l1].emit_insn(
            self.scale_l1.op.axis[0], DMA_COPY, attrs={LAYOUT_TRANSFORM: ND2NZ})
        self.sch[self.scale_l1_zero].emit_insn(self.scale_l1_zero.op.axis[0], SET_2D)
        self.sch[self.scale_l1_vir_add].reused_by(self.scale_l1, self.scale_l1_zero)
        self.sch[self.scale_l1_vir_add].emit_insn(self.scale_l1_vir_add.op.axis[0], PHONY_INSN)

    def emit_insn(self, cl0):
        self.bias_l0c_emit_insn(cl0)
        self.scale_ub_emit_insn()
        self.scale_l1_emit_insn()

    def update_pingpong_map_for_bias_l0c(self, pingpong_map):
        if self.bias_l0c is None:
            return

        cl0_pbuffer_list = pingpong_map.get(CL0_PBUFFER, list())
        if not isinstance(cl0_pbuffer_list, list):
            cl0_pbuffer_list = [cl0_pbuffer_list]

        cl0_pbuffer_list.append(self.bias_l0c)
        cl0_pbuffer_list.append(self.l0c_bias_add)
        pingpong_map[CL0_PBUFFER] = cl0_pbuffer_list

    def update_mad_dict_for_bias_l0c(self, mad_dict):
        if self.bias_l0c is None:
            return

        mad_dict[INIT_BIAS] = 1

    def l0c_bias_add_align(self, block_m0):
        if self.l0c_bias_add is None or self.bias_l0c is None:
            return

        l0c_bias_add_axis_buffer_aligns = list()
        l0c_bias_add_total_axis = len(self.l0c_bias_add.shape)
        for i in range(l0c_bias_add_total_axis):
            l0c_bias_add_axis_buffer_aligns.append((1, 1))
        _, _, _, m_idx, _ = range(l0c_bias_add_total_axis)
        l0c_bias_add_axis_buffer_aligns[m_idx] = (1, block_m0)
        self.sch[self.l0c_bias_add].buffer_align(*l0c_bias_add_axis_buffer_aligns)
