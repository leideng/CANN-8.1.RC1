#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2022-2023 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================

import collections
from functools import reduce
from tbe.common.platform import platform_info
from tbe.dsl.compute.util import shape_to_list
from tbe.dsl.compute.util import get_value
from tbe.dsl.static_schedule.conv_util import print_ir_conv
from tbe.dsl.static_schedule.gemm_integrated_schedule_util import copy_attrs
from tbe.dsl.static_schedule.util import ceil
from tbe.dsl.static_schedule.util import FIXPIPE_SCOPE_MAP
from tbe.dsl.unify_schedule.constants import DTYPE_BYTE_MAPPING


BATCH_MATMUL_LEN_NZ = 5
MATMUL_LEN_NZ = 4
BATCH_MATMUL_LEN_ND = 3


class GemmUbSchedule():
    """
    GemmUbSchedule: schedule definition of matmul for plate_form that only has UB

    Functions
    ----------
    __init__ : initialization

    schedule : schedule definition of matmul

    """
    def __init__(self, res, sch_list, tilingcases):
        """
        initialization

        Parameters:
        ----------
        res : the output tensor of matmul

        sch_list: schedule function

        tilingcases : A list of dict which contains tensors tiling and param_map

        Returns
        -------
        None
        """
        self.res = res
        self.sch = sch_list[0]
        self.tilingcases = tilingcases
        self.compute_tensor, self.placeholder_tensor = tilingcases.get("tensor_list")
        self.tiling = tilingcases.get("tiling_strategy")
        self.param_map = tilingcases.get("param_map")
        self.tensor_a_list = []
        self.tensor_b_list = []
        self.tensor_c_list = []
        self.fixpipe_ub = []
        self.fixpipe_fb = []
        self.is_out_nz = len(self.res.shape) in [MATMUL_LEN_NZ, BATCH_MATMUL_LEN_NZ]
        self.is_batch_matmul = len(self.res.shape) in [BATCH_MATMUL_LEN_ND, BATCH_MATMUL_LEN_NZ]
        self.k_full_load = self.tiling.get("attach_at_flag").get("k_bub_full_load") and \
                           self.tiling.get("attach_at_flag").get("k_aub_full_load")
        self.m_vnchw_align = 16
        self.block_res_c0 = 8
        if self.res.dtype == "int8":
            self.block_res_c0 = 16
        self.a_batch_need_broadcast = False
        self.b_batch_need_broadcast = False
        self.bm_fusion_flag = self.compute_tensor.get("matmul_op").op.attrs.get("bm_fusion_flag", False)
        self.bm_fusion_db = False
        self.fifo_fusion_flag = self.param_map.get("fifo_fusion_flag")


    def schedule(self):
        self._set_tensor_lay_out()
        self._fifo_set_lay_out()
        self._set_tensor_compute_inline()
        self._set_broadcast_flag()
        bloc_dim_axis, single_core_axis = self._split_block_dim()
        tensor_attach_res_axis = self._split_res_bmn(single_core_axis)
        tensor_attach_matmul_op_axis, k_outer = self._split_cub_k()
        self._do_attach(tensor_attach_res_axis, tensor_attach_matmul_op_axis)
        self._set_tensor_bound()
        self._double_buffer()
        self._do_emit_insn(k_outer)
        print_ir_conv("matmul", self.sch, False)

    def _fifo_set_lay_out(self):
        # 1 means input_fifo, 2 means weight_fifo, 0 means no fifo
        if self.fifo_fusion_flag == 0:
            return
        tensor_x_ub = self.compute_tensor.get("tensor_x_ub")
        fifo_tensor = self.compute_tensor.get("fifo_tensor")
        fwc_res = self.compute_tensor.get("fwc_res")
        fifo_in = tensor_x_ub.op.input_tensors[0]
        clean_cache = fifo_tensor.op.input_tensors[0]
        clean_cache_ub = self.sch.cache_read(clean_cache, platform_info.scope_ubuf, [fifo_tensor])
        fifo_res_ub_write = self.sch.cache_write(fwc_res, platform_info.scope_ubuf)
        x_reshape_tensor = self.compute_tensor.get("x_reshape_tensor")
        x_tranpose_tensor = self.compute_tensor.get("x_tranpose_tensor")
        fifo_transpose_tensor = self.compute_tensor.get("fifo_transpose_tensor")
        fifo_trans_reshape_tensor = self.compute_tensor.get("fifo_trans_reshape_tensor")
        fifo_not_align_tensor_list = [x_reshape_tensor, x_tranpose_tensor, fifo_transpose_tensor,
                                      fifo_trans_reshape_tensor]
        # 1 means input_fifo, 2 means weight_fifo,
        # 3 means input_fifo not align, 4 means weight_fifo not align, 0 means no fifo
        if self.fifo_fusion_flag == 1 or self.fifo_fusion_flag == 3:
            tensor_a = self.compute_tensor.get("tensor_a_nz")
            if self.param_map.get("trans_a"):
                tensor_a = self.compute_tensor.get("tensor_a_ub")
            fifo_res_ub_read = self.sch.cache_read(fwc_res, platform_info.scope_ubuf, [tensor_a])
            self.tensor_a_list.extend([tensor_x_ub, fifo_tensor, fifo_res_ub_read, fifo_res_ub_write, fwc_res])
            if fifo_trans_reshape_tensor is not None:
                self.tensor_a_list.extend(fifo_not_align_tensor_list)
        else:
            tensor_b = self.compute_tensor.get("tensor_b_ub")
            if self.param_map.get("trans_b"):
                tensor_b = self.compute_tensor.get("tensor_b_zn")
            fifo_res_ub_read = self.sch.cache_read(fwc_res, platform_info.scope_ubuf, [tensor_b])
            self.tensor_b_list.extend([tensor_x_ub, fifo_tensor, fifo_res_ub_read, fifo_res_ub_write, fwc_res])
            if fifo_trans_reshape_tensor is not None:
                self.tensor_b_list.extend(fifo_not_align_tensor_list)
        self.compute_tensor["clean_cache_ub"] = clean_cache_ub
        self.compute_tensor["fifo_res_ub_write"] = fifo_res_ub_write
        self.compute_tensor["fifo_res_ub_read"] = fifo_res_ub_read
        self.sch[fifo_res_ub_write].reused_by(fifo_res_ub_read)
        self.sch[fifo_in].reused_by(fwc_res)
        frame_size = reduce(lambda x, y: x * y, list(fifo_in.shape))
        self.sch[fwc_res].bind_buffer(fwc_res.op.axis[-1], 0, frame_size)


    def _set_tensor_lay_out(self):
        """
        set scope for tensor except placeholder_tensor and res
        """
        block_a_k0 = self.param_map.get("block_dict").get("block_a_k0")
        block_n0 = self.param_map.get("block_dict").get("block_n0")
        temp_align = ((1, 1),)
        if self.res.op.name in ("matmul_op", "fixpipe_channel_merge_split", "fixpipe_channel_merge_split_res"):
            tensor_before_res = self.sch.cache_write(self.res, platform_info.scope_ubuf)
            self.compute_tensor[self.res.op.name] = tensor_before_res
            self.tensor_c_list.append(tensor_before_res)
        for tensor_name, tensor in self.compute_tensor.items():
            if self.placeholder_tensor.get(tensor_name, None) is None and tensor != self.res and \
                tensor_name != "fwc_res":
                self.sch[tensor].set_scope(platform_info.scope_ubuf)
            if tensor_name in ["tensor_a_ub", "tensor_a_nz", "tensor_a_align"]:
                temp_num = len(tensor.shape) - 1
                self.tensor_a_list.append(tensor)
                self.sch[tensor].buffer_align(*(temp_align * temp_num), (1, block_a_k0))
            if tensor_name in ["tensor_b_ub", "tensor_b_zn"]:
                temp_num = len(tensor.shape) - 2
                self.tensor_b_list.append(tensor)
                self.sch[tensor].buffer_align(*(temp_align * temp_num), (1, block_n0), (1, block_n0))
            if tensor_name in ["tensor_bias_align", "matmul_op", "fixpipe", "tensor_bias_int32"]:
                self.tensor_c_list.append(tensor)
            if self.bm_fusion_flag and tensor_name in ["fixpipe_channel_merge_split", "fixpipe_res"]:
                self.tensor_c_list.append(tensor)
        if self.param_map.get("fixpipe_vector_params", None) is not None:
            self._fixpipe_cache_read()

    def _fixpipe_cache_read(self):
        fixpipe_op = self.compute_tensor.get("fixpipe")
        for fixpipe_input in self.param_map.get("fixpipe_vector_tensors"):
            fixpipe_scope_name = platform_info.scope_fb
            if fixpipe_scope_name:
                fixpipe_input_ub = self.sch.cache_read(fixpipe_input, platform_info.scope_ubuf, [fixpipe_op])
                fixpipe_input_fb = self.sch.cache_read(fixpipe_input_ub, fixpipe_scope_name, [fixpipe_op])
                self.fixpipe_ub.append(fixpipe_input_ub)
                self.fixpipe_fb.append(fixpipe_input_fb)
            else:
                # if elewise input is 5HD, trans to Nz on L1, else cache_read directly
                if self.compute_tensor.get("fixpipe_trans_eltwise") is not None:
                    self.fixpipe_ub.append(self.compute_tensor.get("fixpipe_trans_eltwise"))
                else:
                    fixpipe_input_ub = self.sch.cache_read(
                        fixpipe_input, platform_info.scope_ubuf, [fixpipe_op]
                        )
                    self.fixpipe_ub.append(fixpipe_input_ub)

    def _set_broadcast_flag(self):
        tensor_a_nz = self.compute_tensor.get("tensor_a_nz", None)
        tensor_b_zn = self.compute_tensor.get("tensor_b_zn", None)
        self.a_batch_need_broadcast = len(tensor_a_nz.shape) < len(tensor_b_zn.shape)
        self.b_batch_need_broadcast = len(tensor_a_nz.shape) > len(tensor_b_zn.shape)
        if len(tensor_a_nz.shape) == len(tensor_b_zn.shape):
            if tensor_a_nz.shape[0] == 1 and tensor_b_zn.shape[0] != 1:
                self.a_batch_need_broadcast = True
            if tensor_b_zn.shape[0] == 1 and tensor_a_nz.shape[0] != 1:
                self.b_batch_need_broadcast = True

    def _set_tensor_compute_inline(self):
        fixpipe_op = self.compute_tensor.get("fixpipe", None)
        matmul_op = self.compute_tensor.get("matmul_op")
        fixpipe_channel_merge_split = self.compute_tensor.get("fixpipe_channel_merge_split", None)
        if fixpipe_op is not None:
            self.sch[matmul_op].compute_inline(instant=True)
            self.compute_tensor["matmul_op"] = fixpipe_op
            self.tensor_c_list.remove(matmul_op)
        if fixpipe_channel_merge_split is not None:
            copy_attrs(fixpipe_op, fixpipe_channel_merge_split)
            self.sch[fixpipe_op].compute_inline(instant=True)
            self.compute_tensor["matmul_op"] = fixpipe_channel_merge_split
            self.compute_tensor["fixpipe"] = fixpipe_channel_merge_split
            self.tensor_c_list.remove(fixpipe_op)

    def _split_block_dim(self):
        # nz shape lenth is 4 or 5
        m_axis_idx = -3 if self.is_out_nz else -2
        n_axis_idx = -4 if self.is_out_nz else -1
        block_dim_batch, block_dim_n, block_dim_m = self.tiling.get("block_dim")
        one_core_factor_m = ceil(shape_to_list(self.res.shape)[m_axis_idx], block_dim_m)
        one_core_factor_n = ceil(shape_to_list(self.res.shape)[n_axis_idx], block_dim_n)
        n_outer, n_core_inner = self.sch[self.res].split(self.res.op.axis[n_axis_idx], one_core_factor_n)
        m_outer, m_core_inner = self.sch[self.res].split(self.res.op.axis[m_axis_idx], one_core_factor_m)
        self.sch[self.res].reorder(n_outer, m_outer, n_core_inner, m_core_inner)
        bloc_dim_axis = [n_outer, m_outer]
        single_core_axis = [n_core_inner, m_core_inner]
        if self.is_batch_matmul:
            batch_axis_idx = -5 if self.is_out_nz else -3
            one_core_factor_batch = ceil(shape_to_list(self.res.shape)[batch_axis_idx], block_dim_batch)
            batch_outer, batch_core_inner = self.sch[self.res].split(self.res.op.axis[batch_axis_idx],
                                                                     one_core_factor_batch,
                                                                     tail_strategy="shift_inwards")
            self.sch[self.res].reorder(batch_outer, n_outer, m_outer, batch_core_inner, n_core_inner, m_core_inner)
            bloc_dim_axis.insert(0, batch_outer)
            single_core_axis.insert(0, batch_core_inner)
        return bloc_dim_axis, single_core_axis

    def _update_tiling(self):
        """
        change tiling_value
        return tiling factors of m_axis and n_axis of res
        """
        k_bub_full_load = self.tiling.get("attach_at_flag").get("k_bub_full_load")
        k_aub_full_load = self.tiling.get("attach_at_flag").get("k_aub_full_load")
        m_aub_factor = self.tiling.get("aub_matrix")[1]
        m_mmad_factor = self.tiling.get("cub_matrix")[1]
        n_bub_factor = self.tiling.get("bub_matrix")[1]
        n_mmad_factor = self.tiling.get("cub_matrix")[0]
        if not self.is_out_nz:
            # res mn axis is n1*n0 and m1*m0
            m_aub_factor = m_aub_factor * self.tiling.get("aub_matrix")[2]
            m_mmad_factor = m_mmad_factor * self.tiling.get("cub_matrix")[2]
            n_bub_factor = n_bub_factor * self.tiling.get("bub_matrix")[2]
            n_mmad_factor = n_mmad_factor * self.tiling.get("cub_matrix")[3]
        # res shape is [n1, m1, m0, n0], for int32, n0 is 16, for other dtype n0 is 16/dtype_size
        elif self.res.dtype != "int32":
            # n0 of res may not equal with n0 of matmul, example: res is int16, n0 of res is 8, and n0 of matmul is 16
            n_bub_factor = n_bub_factor * self.tiling.get("bub_matrix")[2] // self.block_res_c0
            n_mmad_factor = n_mmad_factor * self.tiling.get("cub_matrix")[3] // self.block_res_c0
            tensor_a_align = self.compute_tensor.get("tensor_a_align", None)
        if not k_bub_full_load:
            n_bub_factor = n_mmad_factor
        if not k_aub_full_load:
            m_aub_factor = m_mmad_factor
        TilingFactor = collections.namedtuple("TilingFactor", "m_aub_factor m_mmad_factor n_bub_factor n_mmad_factor")
        return TilingFactor(m_aub_factor, m_mmad_factor, n_bub_factor, n_mmad_factor)

    def _get_batch_factor(self):
        cub_matrix = "cub_matrix"
        batch_factor = self.tiling.get(cub_matrix)[-1]
        if self.bm_fusion_flag:
            batch_factor = self.tiling.get(cub_matrix)[1]
            #  batch_factor >= 4 keep matmul_m_dim divided by 2 at least greater than 2
            if batch_factor >= 4 and self.fifo_fusion_flag == 0:
                self.bm_fusion_db = True
                # divided by 2 on doublebuffer
                batch_factor = self.tiling.get(cub_matrix)[1] // 2
        return batch_factor

    def _split_res_bmn(self, single_core_axis):
        """
        split mn axis of res according tiling
        return a dict about tensor compute at axis
        """

        n_inner, m_inner = single_core_axis[-2:]
        tensor_attach_res_axis = {}
        tiling_factor = self._update_tiling()
        attach_at_flag = self.tiling.get("attach_at_flag")
        reorder_mn_flag = attach_at_flag.get("reorder_mn_flag")

        m_aub_outer, m_inner = self.sch[self.res].split(m_inner, tiling_factor.m_aub_factor)
        n_bub_outer, n_inner = self.sch[self.res].split(n_inner, tiling_factor.n_bub_factor)
        m_cub_outer, m_inner = self.sch[self.res].split(m_inner, tiling_factor.m_mmad_factor)
        n_cub_outer, n_inner = self.sch[self.res].split(n_inner, tiling_factor.n_mmad_factor)
        outer_axis = [n_bub_outer, m_aub_outer, n_cub_outer, m_cub_outer]
        inner_axis = [m_inner, n_inner]
        if reorder_mn_flag:
            outer_axis = [m_aub_outer, n_bub_outer, n_cub_outer, m_cub_outer]

        tensor_attach_res_axis["tensor_a"] = m_aub_outer
        tensor_attach_res_axis["tensor_b"] = n_bub_outer
        tensor_attach_res_axis["matmul_op"] = m_cub_outer

        if self.is_batch_matmul:
            batch_inner = single_core_axis[0]
            batch_factor = self._get_batch_factor()
            batch_ub_outer, batch_inner = self.sch[self.res].split(batch_inner,
                                                                   batch_factor,
                                                                   tail_strategy="shift_inwards")
            k_bub_full_load = attach_at_flag.get("k_bub_full_load")
            k_aub_full_load = attach_at_flag.get("k_aub_full_load")
            if k_aub_full_load and k_bub_full_load:
                if self.b_batch_need_broadcast:
                    outer_axis.insert(2, batch_ub_outer)
                    tensor_attach_res_axis["tensor_a"] = batch_ub_outer
                elif self.a_batch_need_broadcast:
                    outer_axis.insert(2, batch_ub_outer)
                    tensor_attach_res_axis["tensor_b"] = batch_ub_outer
                else:
                    outer_axis.insert(0, batch_ub_outer)
            else:
                outer_axis.insert(0, batch_ub_outer)
            inner_axis.insert(0, batch_inner)
        self.sch[self.res].reorder(*outer_axis, *inner_axis)
        return tensor_attach_res_axis

    def _split_cub_k(self):
        """
        split k axis of matmul according tiling
        return a dict about tensor compute at axis
        """
        tensor_attach_matmul_op_axis = {}
        matmul_op = self.compute_tensor.get("matmul_op")
        k_bub_full_load = self.tiling.get("attach_at_flag").get("k_bub_full_load")
        k_aub_full_load = self.tiling.get("attach_at_flag").get("k_aub_full_load")
        a_b_kub_compare = self.tiling.get("attach_at_flag").get("a_b_kub_compare")
        k_aub_factor = self.tiling.get("aub_matrix")[0]
        k_bub_factor = self.tiling.get("bub_matrix")[0]
        k_axis = self.sch[matmul_op].op.reduce_axis[0]
        k_outer = []
        if k_aub_full_load and k_bub_full_load:
            return tensor_attach_matmul_op_axis, k_outer
        elif k_aub_full_load and not k_bub_full_load:
            k_bub_outer, _ = self.sch[matmul_op].split(k_axis, k_bub_factor)
            tensor_attach_matmul_op_axis["tensor_b"] = k_bub_outer
            self.sch[matmul_op].reorder(k_bub_outer, *self.sch[matmul_op].op.axis)
            k_outer = [k_bub_outer, ]
        elif not k_aub_full_load and k_bub_full_load:
            k_aub_outer, _ = self.sch[matmul_op].split(k_axis, k_aub_factor)
            tensor_attach_matmul_op_axis["tensor_a"] = k_aub_outer
            self.sch[matmul_op].reorder(k_aub_outer, *self.sch[matmul_op].op.axis)
            k_outer = [k_aub_outer, ]
        # k_aub > k_bub
        elif a_b_kub_compare:
            k_aub_outer, k_inner = self.sch[matmul_op].split(k_axis, k_aub_factor)
            k_bub_outer, k_inner = self.sch[matmul_op].split(k_inner, k_bub_factor)
            tensor_attach_matmul_op_axis["tensor_a"] = k_aub_outer
            tensor_attach_matmul_op_axis["tensor_b"] = k_bub_outer
            self.sch[matmul_op].reorder(k_aub_outer, k_bub_outer, *self.sch[matmul_op].op.axis)
            k_outer = [k_aub_outer, k_bub_outer]
        else:
            k_bub_outer, k_inner = self.sch[matmul_op].split(k_axis, k_bub_factor)
            k_aub_outer, k_inner = self.sch[matmul_op].split(k_inner, k_aub_factor)
            tensor_attach_matmul_op_axis["tensor_a"] = k_aub_outer
            tensor_attach_matmul_op_axis["tensor_b"] = k_bub_outer
            self.sch[matmul_op].reorder(k_bub_outer, k_aub_outer, *self.sch[matmul_op].op.axis)
            k_outer = [k_bub_outer, k_aub_outer]
        return tensor_attach_matmul_op_axis, k_outer

    def _do_attach(self, tensor_attach_res_axis, tensor_attach_matmul_op_axis):
        """
        do attach for compute_tensor
        tensor_a/tensor_b compute at cub or res according to whether k_axis is full load
        """
        matmul_op = self.compute_tensor.get("matmul_op")
        if self.tiling.get("attach_at_flag").get("k_aub_full_load"):
            tensor_a_attach_node = self.res
            tensor_a_attach_axis = tensor_attach_res_axis.get("tensor_a")
        else:
            tensor_a_attach_node = matmul_op
            tensor_a_attach_axis = tensor_attach_matmul_op_axis.get("tensor_a")
        for tensor in self.tensor_a_list:
            self.sch[tensor].compute_at(self.sch[tensor_a_attach_node], tensor_a_attach_axis)
        if self.tiling.get("attach_at_flag").get("k_bub_full_load"):
            tensor_b_attach_node = self.res
            tensor_b_attach_axis = tensor_attach_res_axis.get("tensor_b")
        else:
            tensor_b_attach_node = matmul_op
            tensor_b_attach_axis = tensor_attach_matmul_op_axis.get("tensor_b")
        for tensor in self.tensor_b_list:
            self.sch[tensor].compute_at(self.sch[tensor_b_attach_node], tensor_b_attach_axis)
        for tensor in self.tensor_c_list + self.fixpipe_fb + self.fixpipe_ub:
            self.sch[tensor].compute_at(self.sch[self.res], tensor_attach_res_axis.get("matmul_op"))

    def _double_buffer(self):
        double_buffer_flag = self.tiling.get("manual_pingpong_buffer")
        if double_buffer_flag.get("AUB_pbuffer") == 2 or self.bm_fusion_db:
            for tensor in self.tensor_a_list:
                self.sch[tensor].double_buffer()
        if double_buffer_flag.get("BUB_pbuffer") == 2:
            for tensor in self.tensor_b_list:
                self.sch[tensor].double_buffer()
        if (double_buffer_flag.get("CUB_pbuffer") == 2 and self.k_full_load) or self.bm_fusion_db:
            for tensor in self.tensor_c_list + self.fixpipe_fb + self.fixpipe_ub:
                self.sch[tensor].double_buffer()

    def _do_fifo_emit_insn(self):
        dma_copy = "dma_copy"
        tensor_x_ub = self.compute_tensor.get("tensor_x_ub")
        fifo_tensor = self.compute_tensor.get("fifo_tensor")
        fwc_res = self.compute_tensor.get("fwc_res")
        clean_cache_ub = self.compute_tensor.get("clean_cache_ub")
        fifo_res_ub_write = self.compute_tensor.get("fifo_res_ub_write")
        fifo_res_ub_read = self.compute_tensor.get("fifo_res_ub_read")

        x_reshape_tensor = self.compute_tensor.get("x_reshape_tensor")
        x_tranpose_tensor = self.compute_tensor.get("x_tranpose_tensor")
        fifo_transpose_tensor = self.compute_tensor.get("fifo_transpose_tensor")
        fifo_trans_reshape_tensor = self.compute_tensor.get("fifo_trans_reshape_tensor")

        self.sch[tensor_x_ub].emit_insn(tensor_x_ub.op.axis[0], dma_copy)
        self.sch[fifo_tensor].emit_insn(fifo_tensor.op.axis[0], dma_copy)
        self.sch[fwc_res].emit_insn(fwc_res.op.axis[0], dma_copy)
        self.sch[clean_cache_ub].emit_insn(clean_cache_ub.op.axis[0], dma_copy, attrs={"clean_cache_value":0})
        self.sch[fifo_res_ub_write].emit_insn(fifo_res_ub_write.op.axis[0], dma_copy)
        self.sch[fifo_res_ub_read].emit_insn(fifo_res_ub_read.op.axis[0], dma_copy)

        if fifo_trans_reshape_tensor is not None:
            self.sch[x_reshape_tensor].compute_inline(instant=True)
            self.sch[fifo_trans_reshape_tensor].compute_inline(instant=True)
            self.sch[x_reshape_tensor].emit_insn(x_reshape_tensor.op.axis[0], "phony_insn")
            self.sch[x_tranpose_tensor].emit_insn(x_tranpose_tensor.op.axis[0], "vnchwconv")
            self.sch[fifo_transpose_tensor].emit_insn(fifo_transpose_tensor.op.axis[0], "vnchwconv")
            self.sch[fifo_trans_reshape_tensor].emit_insn(fifo_trans_reshape_tensor.op.axis[0], "phony_insn")

    def _do_emit_insn(self, k_outer):
        """
        do emit insn for compute_tensor
        tensor_a buffer pipe: 1. tensor_a->tensor_a_nz
                              2. tensor_a->tensor_a_ub->tensor_a_align->tensor_a_nz
                              3. tensor_a->tensor_a_ub->tensor_a_nz (bm_fusion_flag = true)
        tensor_b buffer pipe: 1. tensor_b->tensor_b_zn
                              2. tensor_b->tensor_b_ub->tensor_b_zn
        tensor_c buffer pipe: 1. ->fixpipe_channel_merge_split
                              2. ->fixpie_out
                              3. ->fixpipe_channel_merge_split->fixpipe_channel_merge_split_res
                              4. ->fixpie_res->fixpie_out
        """
        dma_copy = "dma_copy"
        block_a_k0 = self.param_map.get("block_dict").get("block_a_k0")
        tensor_align = self.compute_tensor.get("tensor_a_align", None)
        if tensor_align is not None:
            tensor_a_ub = self.compute_tensor.get("tensor_a_ub")
            axis0, axis1 = self.sch[tensor_a_ub].split(tensor_a_ub.op.axis[-1], block_a_k0)
            self.sch[tensor_a_ub].reorder(*self.sch[tensor_a_ub].op.axis[:-3], axis0,
                                          *self.sch[tensor_a_ub].op.axis[-3:-1], axis1)
        self._do_emit_insn_tensor_input("tensor_a_ub", "tensor_a_nz", "tensor_a_align")
        self._do_emit_insn_tensor_input("tensor_b_ub", "tensor_b_zn", None)
        tensor_bias_align = self.compute_tensor.get("tensor_bias_align", None)
        if tensor_bias_align is not None:
            self.sch[tensor_bias_align].emit_insn(tensor_bias_align.op.axis[0], "dma_padding")
        for tensor in self.fixpipe_ub:
            self.sch[tensor].emit_insn(tensor.op.axis[-4], "dma_padding")
        for tensor in self.fixpipe_fb:
            self.sch[tensor].emit_insn(tensor.op.axis[-4], dma_copy)
        matmul_op = self.compute_tensor.get("matmul_op")
        _, _ = self.sch[matmul_op].split(self.sch[matmul_op].leaf_iter_vars[-1], 8)
        self.sch[matmul_op].emit_insn(matmul_op.op.axis[-4], "fixpipe_op", {"k_outer": k_outer})
        if self.bm_fusion_flag:
            fixpipe_cms_res = self.compute_tensor.get("fixpipe_channel_merge_split_res")
            fixpipe_res = self.compute_tensor.get("fixpipe_res")
            if fixpipe_cms_res is not None:
                self.sch[fixpipe_cms_res].emit_insn(self.sch[fixpipe_cms_res].leaf_iter_vars[-4], dma_copy)
            if fixpipe_res is not None:
                self.sch[fixpipe_res].emit_insn(self.sch[fixpipe_res].leaf_iter_vars[-4], dma_copy)
            self.sch[self.res].emit_insn(self.sch[self.res].leaf_iter_vars[-5], dma_copy)
        else:
            self.sch[self.res].emit_insn(self.sch[self.res].leaf_iter_vars[-4], dma_copy)
        if self.fifo_fusion_flag != 0:
            self._do_fifo_emit_insn()

    def _do_emit_insn_tensor_input(self, tensor_dma_name, tensor_nz_name, tensor_align_name):
        dma_copy = "dma_copy"
        tensor_align = self.compute_tensor.get(tensor_align_name, None)
        tensor_dma = self.compute_tensor.get(tensor_dma_name, None)
        tensor_nz = self.compute_tensor.get(tensor_nz_name)
        if self.bm_fusion_flag and tensor_nz_name == "tensor_a_nz":
            self.sch[tensor_dma].emit_insn(tensor_dma.op.axis[-5], dma_copy)
            self.sch[tensor_nz].emit_insn(tensor_nz.op.axis[-4], dma_copy)
            return
        if tensor_dma is not None:
            self.sch[tensor_dma].emit_insn(tensor_dma.op.axis[-4], dma_copy)
            if tensor_align is not None:
                self.sch[tensor_align].emit_insn(tensor_align.op.axis[-4], "vnchwconv")
                self.sch[tensor_nz].emit_insn(tensor_nz.op.axis[-4], dma_copy)
            else:
                self.sch[tensor_nz].emit_insn(tensor_nz.op.axis[-4], "vnchwconv")
        else:
            if tensor_align is not None:
                self.sch[tensor_align].emit_insn(tensor_align.op.axis[-4], "vnchwconv")
            self.sch[tensor_nz].emit_insn(tensor_nz.op.axis[-4], dma_copy)

    def _set_tensor_bound(self):
        block_m0 = self.param_map.get("block_dict").get("block_m0")
        block_n0 = self.param_map.get("block_dict").get("block_n0")
        m_aub_factor = self.tiling.get("aub_matrix")[1]
        n_bub_factor = self.tiling.get("bub_matrix")[1]
        aub_bound = m_aub_factor * block_m0 * self.tiling.get("aub_matrix")[0]
        bub_bound = n_bub_factor * block_n0 * self.tiling.get("bub_matrix")[0]
        cub_bound = reduce(lambda x, y: x * y, self.tiling.get("cub_matrix")[:-1])
        fixpipe_fb_bound = self.tiling.get("cub_matrix")[0] * self.tiling.get("cub_matrix")[3]
        matmul_op = self.compute_tensor.get("matmul_op")
        if self.fifo_fusion_flag != 0:
            aub_bound *= self.tiling.get("cub_matrix")[-1]
            bub_bound *= self.tiling.get("cub_matrix")[-1]
            cub_bound *= self.tiling.get("cub_matrix")[-1]

        if self.compute_tensor.get("fwc_res") is not None:
            cache_depth = self.compute_tensor.get("fwc_res").op.attrs.get("cache_depth")
        tensor_x_ub = self.compute_tensor.get("tensor_x_ub")
        if tensor_x_ub is not None:
            frame_size = reduce(lambda x, y: x * y, list(tensor_x_ub.op.input_tensors[0].shape))
        for tensor in self.tensor_a_list:
            if tensor.op.name in ["tensor_x_ub", "x_reshape_tensor", "x_tranpose_tensor"]:
                
                self.sch[tensor].set_buffer_size(aub_bound + frame_size)
            else:
                self.sch[tensor].set_buffer_size(aub_bound)
        for tensor in self.tensor_b_list:
            if tensor.op.name in ["tensor_x_ub", "x_reshape_tensor", "x_tranpose_tensor"]:
                self.sch[tensor].set_buffer_size(bub_bound + frame_size)
            else:
                self.sch[tensor].set_buffer_size(bub_bound)
        for tensor in self.fixpipe_ub:
            # dma_copy not support uint64, use uint32 repalce and buffer_size * 2
            self.sch[tensor].set_buffer_size(fixpipe_fb_bound * 2)
        for tensor in self.fixpipe_fb:
            self.sch[tensor].set_buffer_size(fixpipe_fb_bound * 2)
        self.sch[matmul_op].set_buffer_size(cub_bound)