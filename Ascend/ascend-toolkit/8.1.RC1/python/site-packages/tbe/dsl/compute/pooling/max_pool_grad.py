#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2023-2024 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
max pool grad
"""
from itertools import accumulate
from itertools import chain

from tbe import tvm
from tbe.dsl.compute import math as d_math
from tbe.dsl.compute import nn
from tbe.dsl.compute.constants import ComputeType
from tbe.dsl.utils import maths

MIN_VALUES = {
    "float16": -6.55e04,
    "float32": -3.4e38,
    "int32": -2147483648,
    "int16": -32768,
}


def _calc_pad(params):
    axes, sizes, strides = params["axes"], params["sizes"], params["strides"]
    shape_i, shape_o = params["shape_i"], params["shape_o"]
    padding_mode, ceil_mode = params["padding_mode"], params["ceil_mode"]
    ori_pads = params["ori_pads"]

    shape_p = list(shape_i)[:]
    for i, k, s in zip(axes, sizes, strides):
        shape_p[i] = (shape_o[i] - 1)*s + k

    if padding_mode == 'VALID':
        return [[0, 0]] * len(axes)

    if padding_mode == 'SAME':
        pads = []
        for i in axes:
            p = tvm.max(shape_p[i] - shape_i[i], 0)
            p_0 = p // 2
            p_1 = p - p_0
            pads.append([p_0, p_1])
        return pads

    # padding_mode is CALCULATED, ceil_mode is False
    if not ceil_mode:
        return ori_pads

    # padding_mode is CALCULATED, ceil_mode is True
    pads = []
    for i, p in zip(axes, ori_pads):
        p_s = p[0]
        p_e = max(shape_p[i] - shape_i[i] - p_s, 0)
        pads.append([p_s, p_e])

    return pads


def _calc_shape_p_with_pad(params):
    axes = params["axes"]
    pads = params["pads"]
    shape_i = params["shape_i"]

    shape_p = shape_i[:]
    for i, p in zip(axes, pads):
        shape_p[i] += sum(p)

    return shape_p


def _pad(tensor, params, pad_value=0):
    axes = params["axes"]
    shape_p = params["shape_p"]
    pads = params["pads"]

    def func(indices):
        conds = []
        x_i = list(indices)[:]
        for i, p in zip(axes, pads):
            conds.append(indices[i] > p[0] - 1)
            conds.append(indices[i] < shape_p[i] - p[1])
            x_i[i] = indices[i] - p[0]

        return tvm.select(tvm.all(*conds), tensor(*x_i), tvm.const(pad_value, dtype=dtype))

    dtype = tensor.dtype

    with tvm.tag_scope("pad"):
        x_p_attrs = {"_type": ComputeType.PAD, "axes": axes, "pads": pads}
        x_p = tvm.compute(shape_p, lambda *i: func(i), name="pad", attrs=x_p_attrs)

    return x_p


def _img2col(tensor, params):
    axes, sizes, strides = params["axes"], params["sizes"], params["strides"]
    shape_o = params["shape_o"]

    def func(indices):
        k = indices[0]
        x_i = list(indices[1:])
        k_a = list(accumulate(chain([1], reversed(sizes[1:])), lambda a, b: a*b))
        for i, s, k_a_i in zip(axes, strides, reversed(k_a)):
            x_i[i] = x_i[i]*s + tvm.floordiv(k, k_a_i)
            k = tvm.floormod(k, k_a_i)
        return tensor(*x_i)

    shape_img = tensor.shape
    shape_col = [maths.prod(sizes)] + shape_img[:]
    for i in axes:
        shape_col[i + 1] = shape_o[i]

    with tvm.tag_scope("img2col"):
        x_col_attrs = {"_type": ComputeType.IMG2COL, "axes": axes, "sizes": sizes, "strides": strides}
        x_col = tvm.compute(shape_col, lambda *i: func(i), name="img2col", attrs=x_col_attrs)
    return x_col


def _reshape(tensor, shape):
    with tvm.tag_scope("max_pool_gard|reshape"):
        x_r_attrs = {"_type": ComputeType.RESHAPE}
        x_r = tvm.compute(shape, lambda *i: tensor(*i[1:]), name="reshape", attrs=x_r_attrs)
    return x_r


def _col2img(tensor, params):
    axes, sizes, strides = params["axes"], params["sizes"], params["strides"]
    shape_p = params["shape_p"]

    def func(indices):
        k_a = list(accumulate(chain([1], reversed(sizes[1:])), lambda a, b: a*b))
        k = 0
        reduce_axes = []
        for i, x, k_a_i in zip(axes, sizes, reversed(k_a)):
            r_k_i = tvm.reduce_axis((0, x), name=f"r_k_{i}")
            reduce_axes.append(r_k_i)
            k += r_k_i*k_a_i

        dp_cond = []
        d_i = [k] + list(indices)[0:]
        for i, s, r in zip(axes, strides, reduce_axes[:]):
            r_o_i = tvm.reduce_axis((0, shape_col[i+1]), name=f"r_o_{i}")
            reduce_axes.append(r_o_i)
            dp_cond.append(indices[i] == r_o_i*s + r)
            d_i[i+1] = r_o_i

        return tvm.sum(tensor(*d_i), axis=reduce_axes, conditional_reduce=tvm.all(*dp_cond))

    shape_col, dtype = tensor.shape, tensor.dtype

    with tvm.tag_scope("col2img"):
        x_img_attrs = {"_type": ComputeType.COL2IMG, "axes": axes, "sizes": sizes, "strides": strides}
        x_img = tvm.compute(shape_p, lambda *i: func(i), name="col2img", attrs=x_img_attrs)
    return x_img


def _depad(tensor, params):
    axes = params["axes"]
    shape_i = params["shape_i"]
    pads = params["pads"]

    def _depad_body(indices):
        x_i = list(indices)[:]
        for i, p in zip(axes, pads):
            x_i[i] = indices[i] + p[0]
        return tensor(*x_i)

    with tvm.tag_scope("depad"):
        x_depad_attrs = {"_type": ComputeType.DEPAD, "axes": axes, "pads": pads}
        x_depad = tvm.compute(shape_i, lambda *i: _depad_body(i), name="depad", attrs=x_depad_attrs)

    return x_depad


def max_pool_grad(x, y, dy, window_axes, window_dimensions, window_strides, window_dilations=None,
                  padding_mode="SAME", padding_dimensions=None, ceil_mode=False):
    """
    calculate grad input of max pool

    Parameters
    ----------
    x : tvm.tensor
        input for max pool
    y : tvm.tensor
        output for max pool
    dy: tvm.tensor
        grad output for max pool
    window_axes : list or tuple
        Indices of window, only support
        Range : [-len(input.shape), len(input.shape) - 1]
    window_dimensions : list or tuple
        Dimensions of window, length is equal to window_axes
    window_strides : list or tuple
        Strides of window, length is equal to window_axes
    window_dilations : list or tuple
        Dilations of window, length is equal to window_axes
        None means padding dimensions are all one
    padding_mode : str
        Mode of padding, only support "SAME", "VALID" and "CALCULATED"
    padding_dimensions : list[list] or tuple[tuple]
        Dimensions of padding on all window sides and one window side corresponds to two dimensions
        This parameter is valid only when padding_mode is "CALCULATED"
        None means padding dimensions are all zero
    ceil_mode : bool
        When True, will use ceil instead of floor to compute the output shape
        This parameter is valid only when padding_mode is "CALCULATED"

    Returns
    -------
    dx : grad input of max pool
    """
    params = {
        "x": x,
        "axes": window_axes,
        "sizes": window_dimensions,
        "strides": window_strides,
        "padding_mode": padding_mode,
        "ori_pads": padding_dimensions,
        "ceil_mode": ceil_mode,
    }

    x.op.attrs["_max_pool_grad_input_name"] = "x"
    y.op.attrs["_max_pool_grad_input_name"] = "y"
    dy.op.attrs["_max_pool_grad_input_name"] = "dy"

    shape_i, shape_o = x.shape, y.shape
    x_dtype = x.dtype

    params.update(shape_i=shape_i, shape_o=shape_o)
    pads = _calc_pad(params)

    params.update(pads=pads)
    shape_p = _calc_shape_p_with_pad(params)

    params.update(shape_p=shape_p)

    # pad
    x_p = _pad(x, params, MIN_VALUES.get(x_dtype))

    # img2col
    x_col = _img2col(x_p, params)

    # mask ori
    r_y = _reshape(y, [1] + y.shape[:])
    b_y = nn.broadcast(r_y, [x_col.shape[0]] + y.shape[:])
    mask_ori = d_math.vcmp(x_col, b_y, operation="eq", mode="bit")

    # mask for input is nan
    mask_nan = d_math.vcmp(x_col, x_col, operation="eq", mode="bit")
    mask_nan_not = d_math.vnot(mask_nan)

    # fuse mask_ori and mask for nan
    mask0 = d_math.vor(mask_ori, mask_nan_not)

    # mask scan
    shape_col = mask0.shape
    scan_state = tvm.placeholder(shape_col, dtype="uint1", name="scan_state",
                                 attrs={"_type": ComputeType.SCAN_STATE})
    scan_init = nn.full(0, [1] + shape_col[1:], dtype="uint1")
    with tvm.tag_scope("scan_vor"):
        scan_update = tvm.compute(shape_col,
            lambda *i:scan_state[(i[0] - 1,) + i[1:]] | mask0[(i[0] - 1,) + i[1:]],
            name="scan_udpate", attrs={"_type": ComputeType.SCAN_UPDATE})
    with tvm.tag_scope("scan"):
        de_mask = tvm.scan(scan_init, scan_update, scan_state, mask0,
                           name="de_mask", attrs={"_type": ComputeType.SCAN})

    # mask
    de_mask_not = d_math.vnot(de_mask)
    mask = d_math.vand(de_mask_not, mask0)

    # dy sel
    r_dy = _reshape(dy, [1] + dy.shape[:])
    b_dy = nn.broadcast(r_dy, [mask.shape[0]] + dy.shape[:])
    dy_sel = d_math.vsel(mask, b_dy, tvm.const(0, dtype=x_dtype))

    # cast float16 to float32
    if x_dtype == "float16":
        dy_sel = d_math.cast_to(dy_sel, "float32")

    # col2img
    dp = _col2img(dy_sel, params)

    # depad
    dx = _depad(dp, params)

    return dx
