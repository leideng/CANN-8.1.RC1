#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2019-2020 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
Compute of Conv2d in v350.
"""
import math
from tbe import tvm
from tbe.common import utils
from tbe.common.utils import log
from tbe.common.utils.conv_util import lcm
from tbe.common.utils.op_util.op_util_conv2d import ceil_div
from tbe.common.platform import get_cube_mkn
from tbe.common.utils.op_util.op_util_conv2d import BIT_RATIO_MAP
from tbe.dsl.compute.conv_compute import shape_to_list
from tbe.common.utils.errormgr import error_manager_cube as err_man

# index 5hd value
INDEX_5HD_N = 0
INDEX_5HD_C1 = 1
INDEX_5HD_H = 2
INDEX_5HD_W = 3
INDEX_5HD_C0 = 4

# index NCHW value
INDEX_N = 0
INDEX_C = 1
INDEX_H = 2
INDEX_W = 3

# index FZ value
INDEX_FZ_N0 = 2
INDEX_FZ_C0 = 3

# index C1HWC0 value
INDEX_C1HWC0_C0 = 3

# index Get MKN interface index
INDEX_M0 = 0
INDEX_C0 = 1
INDEX_N0 = 2

# length constant
LEN_WEIGHT_DIM = 4
LEN_5HD_DIM = 5

OP_TAG = "convolution_"
TENSOR_MAP = {}


class ConvParam:
    """
    class of ConvParam
    """
    tensor_map = {}
    dim_map = {}
    option_dict = {}

    def __init__(self):
        pass

    @classmethod
    def set_default(cls):
        """
        Set the default value.
        """
        cls.tensor_map.clear()
        cls.dim_map.clear()
        cls.option_dict.clear()


def conv_v350(data, weight, para_dict, optim_dict=None, dsl_flag=True):

    def get_depthwise_flag():
        """
        Check whether it is depthwise conv.
        """
        groups = para_dict.get("groups")
        cout_ori, cin_ori, _, _ = para_dict.get("weight_ori_shape_nchw")
        return cin_ori == 1 and groups == cout_ori

    def check_input_param(data, weight, depthwise_flag=False):
        """
        check input param type, shape and dtype.
        """
        def check_data(data):
            """
            Check conv fmap param.
            """
            if not isinstance(data, tvm.Tensor):
                err_man.raise_err_specific("conv2d", "the first Input parameter must be a tvm.Tensor")
            if len(data.shape) != LEN_5HD_DIM:
                err_man.raise_err_specific("conv2d", "the first Input parameter must be a 5 dim tvm.Tensor")
            check_dtype_list = ("int16", "int8")
            utils.check_dtype_rule(data.dtype, check_dtype_list)

            cin0_data = get_cube_mkn(data.dtype)[INDEX_C0]
            if data.shape[INDEX_5HD_C0].value != cin0_data:
                err_man.raise_err_scene_equal_limitation("conv2d",
                                                         "the last dim of first Input parameter", str(cin0_data))

        def check_weight(weight):
            """
            Check conv weight param.
            """
            if not isinstance(weight, tvm.Tensor):
                err_man.raise_err_specific("conv2d", "the first Input parameter must be a tvm.Tensor")
            if len(weight.shape) != LEN_WEIGHT_DIM:
                err_man.raise_err_specific("conv2d", "the first Input parameter must be a 4 dim tvm.Tensor")
            check_dtype_list = ("int8")
            utils.check_dtype_rule(weight.dtype, check_dtype_list)

            cin0_weight = get_cube_mkn(weight.dtype)[INDEX_C0]
            if not depthwise_flag and weight.shape[INDEX_FZ_C0].value != cin0_weight:
                err_man.raise_err_scene_equal_limitation("conv2d",
                                                         "the last dim of second Input parameter", str(cin0_weight))

            n0 = get_cube_mkn(weight.dtype)[INDEX_N0]
            if not depthwise_flag and weight.shape[INDEX_FZ_N0].value != n0:
                err_man.raise_err_scene_equal_limitation("conv2d",
                                                         "the 3d dim of second Input parameter", str(n0))

            if depthwise_flag and weight.shape[INDEX_C1HWC0_C0].value != n0:
                err_man.raise_err_scene_equal_limitation("depthwiseconv2d",
                                                         "the 3d dim of second Input parameter", str(n0))

        def check_attrs():
            groups = para_dict.get("groups")
            filter_cout, *_ = para_dict.get("weight_ori_shape_nchw")
            fmap_cin = para_dict.get("fmap_cin_ori")
            if groups != 1 and (fmap_cin % groups or filter_cout % groups):
                err_man.raise_err_specific("conv2d",
                                           "the groups should be equal to 1 or divisible by cin and cout.")

        check_data(data)
        check_weight(weight)
        check_attrs()

    def get_group_opt_info():
        _, block_size_k_weight, block_size_n = get_cube_mkn(para_dict.get("weight_dtype"))
        cin_per_group = ConvParam.cin_ori // ConvParam.group
        cout_per_group = ConvParam.cout_ori // ConvParam.group
        enlarge = min(lcm(lcm(cin_per_group, block_size_k_weight) // cin_per_group,
                          lcm(cout_per_group, block_size_n) // cout_per_group), ConvParam.group)
        cin1_opt = math.ceil(cin_per_group * enlarge / block_size_k_weight)
        cout1_opt = math.ceil(cout_per_group * enlarge / block_size_n)
        group_opt = math.ceil(ConvParam.group / enlarge)
        return group_opt, cin1_opt, cout1_opt

    def save_input_tensor():
        """
        save conv input tensors into TENSOR_MAP
        """
        # save weight
        TENSOR_MAP["weight"] = weight
        # save fmap
        TENSOR_MAP["fmap"] = data
        # save bias
        if ConvParam.bias_flag:
            TENSOR_MAP["bias"] = para_dict.get("bias_tensor") # quant bias

    def save_conv_param(depthwise_flag=False):
        """
        save conv params in ConvParam.
        """
        def _save_tensor_shape():
            """
            calculate common used shape info and store in ConvParam.dim_map

            fmap shape info:
            fmap_tiling_shape: 5hd fmap shape for tiling

            weight shape info:
            weight_tiling_shape: 5hd weight shape for tiling

            output shape info:
            output_tiling_shape: 5hd conv_res shape for tiling

            """
            # calculate fmap shape
            batch, cin1_data, hin, win, cin0_data = para_dict["a_shape"]
            ConvParam.dim_map["fmap_tiling_shape"] = para_dict["a_shape"]

            # calculate weight shape
            cout_ori, cin_ori, h_k, w_k = para_dict["weight_ori_shape_nchw"]
            _, _, cout0, cin0_weight = shape_to_list(weight.shape)
            if depthwise_flag:
                _, _, _, cout0 = shape_to_list(weight.shape)
            cin1_weight = para_dict["cin1_weight"]
            ConvParam.dim_map["weight_tiling_shape"] = [cout_ori, cin1_weight, h_k, w_k, cin0_weight]

            # calculate conv/output shape
            hout = ConvParam.h_out
            wout = ConvParam.w_out
            ConvParam.dim_map["output_tiling_shape"] = [batch, ceil_div(cout_ori, cout0), hout, wout, cout0]

        def _save_params():
            """
            save params into ConvParam
            """
            # save conv param from para_dcit
            ConvParam.pad_top = para_dict.get("pad_h")[0]
            ConvParam.pad_bottom = para_dict.get("pad_h")[1]
            ConvParam.pad_left = para_dict.get("pad_w")[0]
            ConvParam.pad_right = para_dict.get("pad_w")[1]
            ConvParam.padding = [ConvParam.pad_top, ConvParam.pad_bottom,
                                 ConvParam.pad_left, ConvParam.pad_right]
            ConvParam.stride_h = para_dict.get("stride_h")
            ConvParam.stride_w = para_dict.get("stride_w")
            ConvParam.dilate_h = para_dict.get("dilate_h")
            ConvParam.dilate_w = para_dict.get("dilate_w")
            ConvParam.weight_h = para_dict.get("weight_h")
            ConvParam.weight_w = para_dict.get("weight_w")
            ConvParam.cin_ori = para_dict.get("weight_ori_shape_nchw")[INDEX_C]
            ConvParam.cout_ori = para_dict.get("weight_ori_shape_nchw")[INDEX_N]
            ConvParam.cin1_data = para_dict.get("cin1_data")
            ConvParam.mad_dtype = para_dict.get("mad_dtype", "int32")
            ConvParam.res_dtype = para_dict.get("res_dtype", "int32")
            ConvParam.offset_x = para_dict.get("offset_x")
            ConvParam.group = para_dict.get("groups")
            ConvParam.kernel_name = para_dict.get("kernel_name")
            if ConvParam.group > 1:
                ConvParam.cin_ori *= ConvParam.group

            # save param of conv shape
            ConvParam.batch = data.shape[0]
            ConvParam.para_dict = para_dict
            ConvParam.h_in = data.shape[INDEX_5HD_H]
            ConvParam.w_in = data.shape[INDEX_5HD_W]
            # cal weight with dilation
            weight_h_dilation = (ConvParam.weight_h - 1) * ConvParam.dilate_h + 1
            weight_w_dilation = (ConvParam.weight_w - 1) * ConvParam.dilate_w + 1
            ConvParam.weight_h_dilation = weight_h_dilation
            ConvParam.weight_w_dilation = weight_w_dilation
            # cal res out h and w
            ConvParam.h_out = int((ConvParam.h_in + (ConvParam.pad_top + ConvParam.pad_bottom) -
                               weight_h_dilation) // ConvParam.stride_h + 1)
            ConvParam.w_out = int((ConvParam.w_in + (ConvParam.pad_left + ConvParam.pad_right) -
                               weight_w_dilation) // ConvParam.stride_w + 1)
            ConvParam.group_opt, ConvParam.cin1_opt, ConvParam.cout1_opt = get_group_opt_info()

        _save_params()
        _save_tensor_shape()
        ConvParam.option_dict = optim_dict

    def set_conv_flag():
        """
        set conv feature flag according to params.
        """
        bias_tensor = para_dict.get("bias_tensor")
        ConvParam.bias_flag = isinstance(bias_tensor, tvm.Tensor)

    def conv_op_compute(fmap_with_pad, weight, depthwise_flag=False):
        """
        calculate res of conv_op
        """
        def check_params():
            if ConvParam.weight_h_dilation <= ConvParam.pad_top and \
               (ConvParam.pad_top + ConvParam.h_in - ConvParam.weight_h_dilation) // ConvParam.stride_h < 1:
                err_man.raise_err_specific("conv2d",
                                           "Invalid params because actual fmap h equals zero.")

            if ConvParam.weight_w_dilation <= ConvParam.pad_left and \
               (ConvParam.pad_left + ConvParam.w_in - ConvParam.weight_w_dilation) // ConvParam.stride_w < 1:
                err_man.raise_err_specific("conv2d",
                                           "Invalid params because actual fmap w equals zero.")

        def create_reduce_axis():
            cin1_reduce_axis = tvm.reduce_axis((0, ceil_div(ConvParam.cin_ori // ConvParam.group_opt,
                                                            block_size_k_data)), name="cin1_data")
            kh_reduce_axis = tvm.reduce_axis((0, para_dict.get("weight_h")), name="weight_h")
            kw_reduce_axis = tvm.reduce_axis((0, para_dict.get("weight_w")), name="weight_w")
            cin0_reduce_axis = tvm.reduce_axis((0, para_dict.get("a_shape")[-1]), name="cin0_data")

            return [cin1_reduce_axis, kh_reduce_axis, kw_reduce_axis, cin0_reduce_axis]

        def get_depthwise_fmap(cout1_idx, cout0_idx):
            if fmap_with_pad.dtype == weight.dtype:
                res = (cout1_idx, cout0_idx)
            else:
                res = ((cout1_idx * block_size_n + cout0_idx) // block_size_k_data,
                       (cout1_idx * block_size_n + cout0_idx) % block_size_k_data)
            return res

        def conv_res_weight_c1hwc0_compute():
            conv_res = tvm.compute(conv_res_shape,
                                lambda batch_idx, cout1_idx, ho_idx, wo_idx, cout0_idx: tvm.sum(
                                    tvm.conv_op(
                                        fmap_with_pad(batch_idx, get_depthwise_fmap(cout1_idx, cout0_idx)[0],
                                                        ho_idx * ConvParam.stride_h +
                                                        kh_reduce_axis * ConvParam.dilate_h - ConvParam.pad_top,
                                                        wo_idx * ConvParam.stride_w +
                                                        kw_reduce_axis * ConvParam.dilate_w - ConvParam.pad_left,
                                                        get_depthwise_fmap(cout1_idx, cout0_idx)[1]),
                                        weight(cout1_idx, kh_reduce_axis, kw_reduce_axis, cout0_idx),
                                        bias[cout1_idx * block_size_n + cout0_idx] if ConvParam.bias_flag else None,
                                        *conv_op_common_params,
                                        para_dict.get("res_dtype", "int32"),
                                        op_dict={
                                            "enable_depthwise": 1,
                                            "use_bias": int(ConvParam.bias_flag)
                                        }),
                                    axis=[kh_reduce_axis, kw_reduce_axis]),
                                name="conv_res",
                                tag=OP_TAG + "conv_res")
            return conv_res
        
        def conv_res_weight_group_fz_compute():
            conv_res = tvm.compute(conv_res_shape,
                                lambda batch_idx, group_cout1_idx, ho_idx, wo_idx, cout0_idx: tvm.sum(
                                    tvm.conv_op(
                                        fmap_with_pad(batch_idx, (group_cout1_idx // ConvParam.cout1_opt * \
                                                                  ConvParam.cin1_opt * block_size_k_weight // \
                                                                  block_size_k_data) + cin1_reduce_axis,
                                                      ho_idx * ConvParam.stride_h + kh_reduce_axis * \
                                                      ConvParam.dilate_h - ConvParam.pad_top,
                                                      wo_idx * ConvParam.stride_w + kw_reduce_axis * \
                                                      ConvParam.dilate_w - ConvParam.pad_left,
                                                      cin0_reduce_axis),
                                        weight((group_cout1_idx // ConvParam.cout1_opt) * ConvParam.cin1_opt * \
                                                ConvParam.weight_h * ConvParam.weight_w + ((cin1_reduce_axis * \
                                                block_size_k_data + cin0_reduce_axis) // block_size_k_weight) * \
                                                ConvParam.weight_h * ConvParam.weight_w + kh_reduce_axis * \
                                                ConvParam.weight_w + kw_reduce_axis,
                                                group_cout1_idx % ConvParam.cout1_opt,
                                                cout0_idx,
                                                (cin1_reduce_axis * block_size_k_data + cin0_reduce_axis) %
                                                block_size_k_weight),
                                        bias[(group_cout1_idx // ConvParam.cout1_opt * ConvParam.cout1_opt * \
                                              block_size_n) + (group_cout1_idx % ConvParam.cout1_opt) * \
                                              block_size_n + cout0_idx] if ConvParam.bias_flag else None,
                                        *conv_op_common_params,
                                        para_dict.get("res_dtype", "int32"),
                                        op_dict={
                                            "enable_depthwise": 0,
                                            "use_bias": int(ConvParam.bias_flag)
                                        }),
                                    axis=[cin1_reduce_axis, kh_reduce_axis, kw_reduce_axis, cin0_reduce_axis]),
                                name="conv_res",
                                tag=OP_TAG + "conv_res")
            return conv_res

        check_params()
        bias = para_dict.get("bias_tensor") if ConvParam.bias_flag else None
        fm_dtype = para_dict.get("fmap_dtype")
        w_dtype = para_dict.get("weight_dtype")
        block_size_k_data = get_cube_mkn(fm_dtype)[INDEX_C0]
        _, block_size_k_weight, block_size_n = get_cube_mkn(w_dtype)
        conv_op_common_params = [
            ConvParam.w_in, ConvParam.h_in, ConvParam.cin_ori,
            ConvParam.weight_w, ConvParam.weight_h, ConvParam.cout_ori,
            ConvParam.stride_w, ConvParam.stride_h, ConvParam.dilate_w,
            ConvParam.dilate_h, ConvParam.pad_top, ConvParam.pad_bottom,
            ConvParam.pad_left, ConvParam.pad_right, ConvParam.offset_x
        ]

        conv_res_shape = [
            ConvParam.batch, ConvParam.group_opt * ConvParam.cout1_opt,
            ConvParam.h_out, ConvParam.w_out, block_size_n
        ]
        # create reduce axis
        cin1_reduce_axis, kh_reduce_axis, kw_reduce_axis, cin0_reduce_axis = create_reduce_axis()

        if depthwise_flag:
            log.debug("Enter the depthwise_conv2d branch or multi_group conv2d branch equivalent to depthwise.")
            conv_res = conv_res_weight_c1hwc0_compute()
        else:
            conv_res = conv_res_weight_group_fz_compute()
        TENSOR_MAP["conv_res"] = conv_res

        return conv_res


    TENSOR_MAP.clear()
    ConvParam.set_default()
    depthwise_flag = get_depthwise_flag()
    # check input param
    check_input_param(data, weight, depthwise_flag)
    # set conv_flag
    set_conv_flag()
    # save conv_param and input tensor
    save_conv_param(depthwise_flag)
    save_input_tensor()
    # conv_op compute
    conv_res = conv_op_compute(data, weight, depthwise_flag)
    ConvParam.tensor_map = TENSOR_MAP

    return conv_res