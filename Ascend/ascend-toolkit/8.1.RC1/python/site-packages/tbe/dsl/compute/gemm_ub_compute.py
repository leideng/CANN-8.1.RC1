#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2022-2023 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
mmad_compute
"""
from __future__ import absolute_import

import functools

from tbe import tvm
from tbe.common.platform import platform_info
from tbe.common.utils import para_check
from tbe.common.utils import broadcast_shapes
from tbe.common.utils.errormgr import error_manager_cube
from tbe.dsl.compute.util import int_ceil_div
from tbe.dsl.compute.util import shape_to_list
from tbe.dsl.compute.util import DTYPE_BYTE
from tbe.tvm import Tensor

MM_LEN_NZ = 4
BMM_LEN_NZ = 5


def get_batch_broadcast(tensor_a, tensor_b):
    shape_tensor_a = shape_to_list(tensor_a.shape)
    shape_tensor_b = shape_to_list(tensor_b.shape)
    list_batch_a = shape_tensor_a[:-4]
    list_batch_b = shape_tensor_b[:-4]
    list_batch_broad = []
    if list_batch_a or list_batch_b:
        list_batch_a, list_batch_b, list_batch_broad = broadcast_shapes(list_batch_a, list_batch_b)
    return list_batch_a, list_batch_b, list_batch_broad


def get_batch_index(idx_reduce, list_batch_broad, list_batch_ori):
    # get index in batch_ori
    idx_ori = 0
    if list_batch_broad == list_batch_ori:
        return idx_reduce
    else:
        return [idx_ori]


@para_check.check_input_type(Tensor, Tensor, dict)
def matmul_ub_compute(tensor_a, tensor_b, para_dict):
    """
    algorithm: gemm
    calculate matrix multiplication C = A * B + bias

    Returns matrix c
    """
    matmul_compute = MatMulUBCompute(tensor_a, tensor_b, para_dict)
    result = matmul_compute.compute_matmul()
    return result


class MatMulUBCompute:
    """
    algorithm: mmad
    calculating matrix multiplication, C=A*B+bias

    Parameters:
    tensor_a : the first tensor a

    tensor_b : second tensor b.

    Returns None
    """

    def __init__(self, tensor_a, tensor_b, para_dict):
        self.tensor_a = tensor_a
        self.tensor_b = tensor_b
        self.format_a = para_dict.get("format_a", "FRACTAL_NZ")
        self.format_b = para_dict.get("format_b", "FRACTAL_NZ")
        self.format_out = para_dict.get("format_out")
        self.trans_a = para_dict.get("trans_a", False)
        self.trans_b = para_dict.get("trans_b", False)
        self.trans_a = not self.trans_a if self.format_a == "FRACTAL_NZ" else self.trans_a
        self.trans_b = not self.trans_b if self.format_b == "FRACTAL_NZ" else self.trans_b
        self.tensor_bias = para_dict.get("tensor_c", None)
        self.dst_dtype = para_dict.get("dst_dtype", "int32")
        self.kernel_name = para_dict.get("kernel_name", "gemm")
        self.block_m0 = int(platform_info.get_soc_spec("cube_m_size"))
        self.block_n0 = int(platform_info.get_soc_spec("cube_n_size"))
        self.block_a_k0 = int(platform_info.get_soc_spec("cube_k_size")) // DTYPE_BYTE.get(tensor_a.dtype)
        self.block_b_k0 = int(platform_info.get_soc_spec("cube_k_size")) // DTYPE_BYTE.get(tensor_b.dtype)
        self.mmad_dtype = "int32"
        self.op_type = para_dict.get("op_type")
        self.origin_m_shape = tensor_a.op.attrs["ori_shape"][-1] if self.trans_a else tensor_a.op.attrs["ori_shape"][-2]
        self.origin_n_shape = tensor_b.op.attrs["ori_shape"][-2] if self.trans_b else tensor_b.op.attrs["ori_shape"][-1]
        self.origin_k_shape = tensor_a.op.attrs["ori_shape"][-2] if self.trans_a else tensor_a.op.attrs["ori_shape"][-1]
        self.m_vnchw_align = 16
        self.bm_fusion_flag = False
        self.batch_prod = 1

    @staticmethod
    def _get_nz_trans_indices(indices, mn_c0, k_c0):
        """
        get tensor indices according c0 size if the tensor is transposed
        """
        src_indices = (
            *indices[:-4], indices[-3],
            (indices[-4] * k_c0 + indices[-1]) // mn_c0,
            (indices[-4] * k_c0 + indices[-1]) % mn_c0,
            indices[-2]
        )
        return src_indices

    def compute_matmul(self):
        """
        MatMul enter

        Input None
        return result in self.tensor_mmad
        ---------------------------------
        Return None
        """
        self.check_dim()
        self.bm_fusion_flag = self._get_bm_fusion_flag()
        tensor_a_nz = self._get_tensor_a_nz()
        tensor_b_zn = self._get_tensor_b_zn()
        tensor_bias_align = self._get_tensor_bias()
        tensor_matmul = self._compute_matmul(tensor_a_nz, tensor_b_zn, tensor_bias_align)
        return tensor_matmul

    def check_dim(self):
        shape_a_nz = self._get_shape_a_nz()
        shape_b_zn = self._get_shape_b_zn()
        if len(shape_a_nz) > BMM_LEN_NZ or len(shape_b_zn) > BMM_LEN_NZ:
            error_manager_cube.raise_err_specific("matmul input", "batch is only support single axis.")

    def _get_bm_fusion_flag(self):
        tensor_a_shape = shape_to_list(self.tensor_a.shape)
        tensor_b_shape = shape_to_list(self.tensor_b.shape)
        dim_support = len(tensor_a_shape) > MM_LEN_NZ and len(tensor_b_shape) == MM_LEN_NZ
        if not dim_support:
            return False
        self.batch_prod = functools.reduce(lambda x, y: x * y, tensor_a_shape[:-4])
        shape_support = self.batch_prod > 1 and self.origin_m_shape == 1
        if not shape_support:
            return False
        self.origin_m_shape *= self.batch_prod
        return True

    def _get_tensor_a(self, tensor_a_shape):
        tensor_name = "tensor_a_nz"
        if self.bm_fusion_flag:
            tensor_name = "tensor_a_ub"
        tensor_a_nz = tvm.compute(
            tensor_a_shape,
            lambda *indices: self.tensor_a(*indices),
            name=tensor_name,
            attrs={"trans_a": False,
                   "origin_m_shape": self.origin_m_shape,
                   "origin_k_shape": self.origin_k_shape})
        return tensor_a_nz

    def _get_tensor_a_nz(self):
        shape_a_nz = self._get_shape_a_nz()
        tensor_a_shape = shape_to_list(self.tensor_a.shape)
        if not self.trans_a:
            tensor_a_nz = self._get_tensor_a(tensor_a_shape)
            if self.bm_fusion_flag:
                tensor_a_nz = tvm.compute(
                    shape_a_nz,
                    lambda *indices: tensor_a_nz(indices[-3] // tensor_a_shape[-3], indices[-4],
                                                 indices[-3] % tensor_a_shape[-3], *indices[-2:]),
                    name="tensor_a_nz",
                    attrs={"trans_a": False,
                           "origin_m_shape": self.origin_m_shape,
                           "origin_k_shape": self.origin_k_shape})
        else:
            shape_k = tensor_a_shape[-3] * tensor_a_shape[-2]
            tensor_a_ub = tvm.compute(
                [*tensor_a_shape[:-4], int_ceil_div(self.origin_m_shape, self.m_vnchw_align),
                 int_ceil_div(self.origin_k_shape, self.block_a_k0), self.block_a_k0, self.m_vnchw_align],
                lambda *indices: tvm.select(
                    indices[-4] * self.m_vnchw_align + indices[-1] < tensor_a_shape[-4] * tensor_a_shape[-1],
                    self.tensor_a(*indices[:-4],
                                  (indices[-4] * self.m_vnchw_align + indices[-1]) // self.block_a_k0,
                                  (indices[-3] * self.block_a_k0 + indices[-2]) // self.block_m0,
                                  (indices[-3] * self.block_a_k0 + indices[-2]) % self.block_m0,
                                  (indices[-4] * self.m_vnchw_align + indices[-1]) % self.block_a_k0)),
                name="tensor_a_ub",
                attrs={"trans_a": True,
                       "origin_m_shape": self.origin_m_shape,
                       "origin_k_shape": self.origin_k_shape})
            tensor_a_align = tvm.compute(
                [*tensor_a_shape[:-4], int_ceil_div(self.origin_k_shape, self.block_a_k0),
                 int_ceil_div(self.origin_m_shape, self.m_vnchw_align), self.m_vnchw_align, self.block_a_k0],
                lambda *indices: tensor_a_ub(*indices[:-4], indices[-3], indices[-4], indices[-1], indices[-2]),
                name="tensor_a_align",
                attrs={"trans_a": True,
                       "origin_m_shape": self.origin_m_shape,
                       "origin_k_shape": self.origin_k_shape})
            tensor_a_nz = tvm.compute(
                shape_a_nz,
                lambda *indices: tensor_a_align(*indices[:-4], indices[-4],
                                 (indices[-3] * self.block_m0 + indices[-2]) // self.m_vnchw_align,
                                 (indices[-3] * self.block_m0 + indices[-2]) % self.m_vnchw_align,
                                 indices[-1]),
                name="tensor_a_nz",
                attrs={"trans_a": True,
                       "origin_m_shape": self.origin_m_shape,
                       "origin_k_shape": self.origin_k_shape})
        return tensor_a_nz

    def _get_tensor_b_zn(self):
        shape_b_zn = self._get_shape_b_zn()
        tensor_b_shape = shape_to_list(self.tensor_b.shape)
        if self.trans_b:
            # do align for n_axis, ddr: (k/k0, n/m0, m0, k0)  --> ub (k/k0, n/n0, n0, k0)
            tensor_b_zn = tvm.compute(
                shape_b_zn,
                lambda *indices: tvm.select(
                    indices[-3] * self.block_n0 + indices[-2] < tensor_b_shape[-3] * tensor_b_shape[-2],
                    self.tensor_b(*indices[:-3],
                                  (indices[-3] * self.block_n0 + indices[-2]) // self.block_m0,
                                  (indices[-3] * self.block_n0 + indices[-2]) % self.block_m0,
                                  indices[-1])),
                name="tensor_b_zn",
                attrs={"trans_b": True,
                       "origin_n_shape": self.origin_n_shape})
        else:
            # do align for k_axis, ddr: (n/k0, k/m0, m0, k0)  --> ub (n/k0, k/k0, k0, k0)
            shape_b_align = tensor_b_shape[:-3] + [
                int_ceil_div(tensor_b_shape[-3] * tensor_b_shape[-2], self.block_b_k0),
                self.block_b_k0, self.block_b_k0]
            tensor_b_ub = tvm.compute(
                shape_b_align,
                lambda *indices: tvm.select(
                    indices[-3] * self.block_b_k0 + indices[-2] < tensor_b_shape[-3] * tensor_b_shape[-2],
                    self.tensor_b(*indices[:-3],
                                  (indices[-3] * self.block_b_k0 + indices[-2]) // self.block_m0,
                                  (indices[-3] * self.block_b_k0 + indices[-2]) % self.block_m0,
                                  indices[-1])),
                name="tensor_b_ub",
                attrs={"trans_b":False,
                       "origin_n_shape": self.origin_n_shape})
            # (n/k0, k/k0, k0, k0) ---> (k/k0, n/n0, n0, k0)
            tensor_b_zn = tvm.compute(
                shape_b_zn,
                lambda *indices: tensor_b_ub(*self._get_nz_trans_indices(indices, self.block_n0, self.block_b_k0)),
                name="tensor_b_zn",
                attrs={"trans_b": False,
                       "origin_n_shape": self.origin_n_shape})
        return tensor_b_zn

    def _get_tensor_bias(self):
        if self.tensor_bias is None:
            return None
        # bias only support int32
        bias_dtype = self.tensor_bias.dtype
        shape_bias = shape_to_list(self.tensor_bias.shape)
        shape_bias_align = [*shape_bias[:-1], int_ceil_div(shape_bias[-1], self.block_n0) * self.block_n0]
        tensor_bias_align = tvm.compute(
            shape_bias_align,
            lambda *indices: tvm.select(indices[-1] < shape_bias[-1],
                                        self.tensor_bias(*indices).astype(bias_dtype)),
            name="tensor_bias_align"
        )
        return tensor_bias_align

    def _get_bias_indices(self, indices, tensor_bias_align, indices_b):
        if tensor_bias_align is None:
            return None
        # # if bias have batch_axis, batch_indices follow weight's batch_indices
        if len(tensor_bias_align.shape) > 1:
            return tensor_bias_align(*indices_b[:-4], indices[-4] * self.block_n0 + indices[-1])
        return tensor_bias_align(indices[-4] * self.block_n0 + indices[-1])

    def _compute_matmul(self, tensor_a_nz, tensor_b_zn, tensor_bias_align):
        def __mmad_func(*indices):
            *batch, n1, m1, m0, n0 = indices
            indices_a = [k // self.block_a_k0, m1, m0, k % self.block_a_k0]
            indices_b = [k // self.block_b_k0, n1, n0, k % self.block_b_k0]
            if batch:
                batch_prefix_a = get_batch_index(batch, list_batch_broad, list_batch_a)
                batch_prefix_b = get_batch_index(batch, list_batch_broad, list_batch_b)
                indices_a = (batch_prefix_a + indices_a)[-len(tensor_a_nz.shape):]
                indices_b = (batch_prefix_b + indices_b)[-len(tensor_b_zn.shape):]
            mad_expr = tvm.matmul_op(
                tensor_a_nz(*indices_a),
                tensor_b_zn(*indices_b),
                self._get_bias_indices(indices, tensor_bias_align, indices_b),
                dst_dtype="int32",
                op_dict={"use_bias": self.tensor_bias is not None,
                         "matrix_m": self.origin_m_shape,
                         "matrix_k": self.origin_k_shape,
                         "matrix_n": self.origin_n_shape}
            )
            sum_expr = tvm.sum(mad_expr, axis=[k, ])
            return sum_expr

        shape_k1, shape_m1, shape_m0, shape_k0 = shape_to_list(tensor_a_nz.shape)[-4:]
        shape_n1, shape_n0 = shape_to_list(tensor_b_zn.shape)[-3:-1]
        list_batch_a, list_batch_b, list_batch_broad = get_batch_broadcast(tensor_a_nz, tensor_b_zn)
        shape_matmul_op = [*list_batch_broad, shape_n1, shape_m1, shape_m0, shape_n0]
        k = tvm.reduce_axis((0, shape_k1 * shape_k0), name="k_axis")
        matmul_op = tvm.compute(shape_matmul_op, __mmad_func,
            name="matmul_op",
            tag="matmul_ub_to_ub",
            attrs={"block_m0": self.block_m0,
                   "block_n0": self.block_n0,
                   "block_a_k0": self.block_a_k0,
                   "block_b_k0": self.block_b_k0,
                   "op_type": self.op_type,
                   "ori_shape": (self.origin_m_shape, self.origin_n_shape),
                   "batch_shape": 1,
                   "bm_fusion_flag": self.bm_fusion_flag,
                   "format": "FRACTAL_NZ"})
        return matmul_op

    def _get_shape_a_nz(self):
        """
        get shape_a_nz for matmul
        """
        tensor_a_shape = shape_to_list(self.tensor_a.shape)
        if not self.trans_a:
            # -4 means m_axis, -3 means other axes
            if self.bm_fusion_flag:
                return [1, tensor_a_shape[-4], self.batch_prod * tensor_a_shape[-3], *tensor_a_shape[-2:]]
            return tensor_a_shape
        # [m_ori // k0, k_ori // m0, m0, k0] ---> [k_ori // k0, m_ori // m0, m0, k0]
        return tensor_a_shape[:-4] + [int_ceil_div(self.origin_k_shape, self.block_a_k0),
                                      int_ceil_div(self.origin_m_shape, self.block_m0),
                                      self.block_m0, self.block_a_k0]

    def _get_shape_b_zn(self):
        """
        get shape_b_zn for matmul
        """
        tensor_b_shape = shape_to_list(self.tensor_b.shape)
        # (k/k0, n/m0, m0, k0) ---> (k/k0, n/n0, n0, k0)
        if self.trans_b:
            return tensor_b_shape[:-3] + [int_ceil_div(self.origin_n_shape, self.block_n0),
                                          self.block_n0, tensor_b_shape[-1]]
        # (n/k0, k/m0, m0, k0)  --> (k/k0, n/n0, n0, k0)
        return tensor_b_shape[:-4] + [int_ceil_div(self.origin_k_shape, self.block_b_k0),
                                      int_ceil_div(self.origin_n_shape, self.block_n0),
                                      self.block_n0, self.block_b_k0]