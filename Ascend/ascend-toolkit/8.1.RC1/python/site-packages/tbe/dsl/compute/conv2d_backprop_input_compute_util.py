#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2019-2025 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
from abc import abstractmethod

from tbe import tvm
from tbe.common.platform import platform_info
from tbe.common.utils.const import WEIGHT_SPARSE_4_2
from tbe.common.utils.const import QUANT_DTYPES
from tbe.common.utils.errormgr import error_manager_cube
from tbe.dsl.compute.util import int_ceil_div
from tbe.dsl.compute.util import DTYPE_BYTE
from tbe.dsl.compute import cube_util
from tbe.tvm import abs as tvm_abs


SPARSE_4TO2_COMPRESS_INDEX_BIT_RATIO = 4


class CalL1SizeInputPara:
    '''
    input_dict:
        filter_shape_nchw: list
        dy_shape_nc1hwc0: list
        dx_shape_nchw: list
        bias: tensor or dict
        strides: [stride_h, stride_w]
        padding:
        dilations
        output_padding
        dy_dtype
        filter_dtype
    '''
    def __init__(self, input_dict):
        self._check_shape_and_attr(input_dict)
        self.filter_ori_shape_h = input_dict.get("filter_shape_nchw")[2]
        self.filter_ori_shape_w = input_dict.get("filter_shape_nchw")[3]
        self.dy_c1 = input_dict.get("dy_shape_nc1hwc0")[1]
        self.dy_h = input_dict.get("dy_shape_nc1hwc0")[2]
        self.dy_w = input_dict.get("dy_shape_nc1hwc0")[3]
        self.dx_ori_shape_c = input_dict.get("dx_shape_nchw")[1]
        self.dx_ori_shape_h = input_dict.get("dx_shape_nchw")[2]
        self.dx_ori_shape_w = input_dict.get("dx_shape_nchw")[3]
        self.bias = input_dict.get("bias_tensor")
        self.stride_h = input_dict.get("strides")[0]
        self.stride_w = input_dict.get("strides")[1]
        self.pad_up = input_dict.get("padding")[0]
        self.pad_left = input_dict.get("padding")[2]
        self.dilation_h = input_dict.get("dilations")[2]
        self.dilation_w = input_dict.get("dilations")[3]
        self.output_padding_h = 0
        self.output_padding_w = 0
        if input_dict.get("output_padding"):
            self.output_padding_h = input_dict.get("output_padding")[2]
            self.output_padding_w = input_dict.get("output_padding")[3]
        self.dy_dtype = input_dict.get("dy_dtype", "float16")
        self.filter_dtype = input_dict.get("filter_dtype", "float16")
        self.bias_dtype = input_dict.get("bias_dtype", "float16")
        self.filter_h_dilation = 0
        self.filter_w_dilation = 0
        self.dy_shape_h_modify = 0
        self.dy_shape_w_modify = 0
        self.sparse_4to2_flag = input_dict.get("alg") == WEIGHT_SPARSE_4_2
        self._cal_shape_modify()

    @staticmethod
    def _check_shape_and_attr(input_dict):
        if not input_dict.get("filter_shape_nchw") or not input_dict.get("dy_shape_nc1hwc0") or \
            not input_dict.get("dx_shape_nchw") or not input_dict.get("strides") or not input_dict.get("padding") or \
            not input_dict.get("dilations"):
            error_manager_cube.raise_err_specific("Conv2dBackpropInput", "cann't get shape or attr!")
        # dx_ori_shape_w or filter_ori_shape_h must be greater than 0
        if input_dict.get("dx_shape_nchw")[3] <= 0 or input_dict.get("filter_shape_nchw")[2] <= 0:
            error_manager_cube.raise_err_specific("Conv2dBackpropInput", "dx or filter shape dims is illegal!")

    def _cal_shape_modify(self):
        self.filter_h_dilation = (self.filter_ori_shape_h - 1) * self.dilation_h + 1
        self.filter_w_dilation = (self.filter_ori_shape_w - 1) * self.dilation_w + 1
        self.dy_shape_h_modify = self.dy_h * self.stride_h
        self.dy_shape_w_modify = self.dy_w * self.stride_w
        if isinstance(self.pad_up, int) and isinstance(self.pad_left, int):
            backprop_padu = (self.filter_ori_shape_h - 1) * self.dilation_h - self.pad_up
            backprop_padl = (self.filter_ori_shape_w - 1) * self.dilation_w - self.pad_left
            backprop_padd = self.dx_ori_shape_h - self.dy_h * self.stride_h - \
                backprop_padu + (self.filter_ori_shape_h - 1) * self.dilation_h
            backprop_padr = self.dx_ori_shape_w - self.dy_w * self.stride_w - \
                backprop_padl + (self.filter_ori_shape_w - 1) * self.dilation_w
            shape_up_modify = (backprop_padu - abs(backprop_padu)) // 2
            shape_left_modify = (backprop_padl - abs(backprop_padl)) // 2
            shape_down_modify = (backprop_padd - abs(backprop_padd)) // 2
            shape_right_modify = (backprop_padr - abs(backprop_padr)) // 2


class CalL1Size:
    def __init__(self, input_dict):
        self.input_para = CalL1SizeInputPara(input_dict)
        self.tiling_dict = {"m_al1": 1, "m": 1, "m0": 16, "n_bl1": 1, "n": 1, "n0": 16, "k_al1": 1,
                            "k_bl1": 1, "k_block_size": 16, "db_al1": 1, "db_bl1": 1, "db_bias_l1": 1}
        self.flag_dict = {
            "static_flag": True,
            "dynamic_flag": False,
            "binary_flag": False,
            "conv1d_flag": False,
            "conv2d_split_w_flag": False,
            "default_tiling_flag": False,
            "l0a_dma_flag": False,
        }

    def cal_l1_size(self, flag_dict, tiling_dict):
        '''
        Each L1size calculation requires passing the corresponding parameters.
        '''
        # Ensure the correctness of the tiling_dict
        if len(tiling_dict.keys() & self.tiling_dict.keys()) == len(self.tiling_dict.keys()):
            self.flag_dict = flag_dict
            self.tiling_dict = tiling_dict
        al1_size = self._cal_al1_size()
        bl1_size = self._cal_bl1_size()
        bias_l1_size = self._cal_bias_l1_size()
        if al1_size == 0 or bl1_size == 0:
            error_manager_cube.raise_err_specific("Conv2dBackpropInput", "flag_dict or tiling_dict is illegal!")
        return al1_size, bl1_size, bias_l1_size

    def _cal_hi(self):
        '''
        1: hi_wi > m_al1 * m * m0
            1.1: hi_wi % m_al1 * m * m0 == 0
            1.2: hi_wi % m_al1 * m * m0 != 0
        2: hi_wi = m_al1 * m * m0
            can include by 1.1
        3: hi_wi < m_al1 * m * m0
        '''
        hi_wi = self.tiling_dict.get("m_al1") * self.tiling_dict.get("m") * self.tiling_dict.get("m0")
        if hi_wi % self.input_para.dx_ori_shape_w == 0:
            hi = hi_wi // self.input_para.dx_ori_shape_w
        elif hi_wi < self.input_para.dx_ori_shape_w:
            hi = 2
        elif hi_wi > self.input_para.dx_ori_shape_w:
            hi = hi_wi // self.input_para.dx_ori_shape_w + 2
        return hi

    def _cal_ho(self, real_filter_h):
        """
        real_filter_h means actual h size of sliding window.
        """
        hi = self._cal_hi()
        # ho equal to (hi - 1) * stride_h + real_filter_h_dilation
        # default tiling, real_filter_h = 1
        # so real_filter_h_dilation = (1 - 1) * dilation_h + 1 = 1
        real_filter_h_dilation = (real_filter_h - 1) * self.input_para.dilation_h + 1
        ho = (hi - 1) * 1 + real_filter_h_dilation
        return ho

    def _get_co1_factor(self):
        """
        in sparse_4to2 scene, even fractals should be loaded on L1 and AL0 for k direction.
        if kh * kw is odd, cout1 must be even on AL1
        Returns:
            int
        """
        if not self.input_para.sparse_4to2_flag:
            return self.tiling_dict.get("k_al1")
        if self.input_para.filter_ori_shape_w * self.input_para.filter_ori_shape_h & 1 == 0:
            return 1
        if self.input_para.dy_c1 == 1:
            return 1
        return 2

    def _cal_al1_size(self):
        wo, ho = 0, 0
        if self.flag_dict.get("static_flag"):
            if self.flag_dict.get("conv1d_flag"):
                # "* 1" mean stride_w = 1
                # m_al1 means multiplier relationship on L1 and L0
                wo = (self.tiling_dict.get("m_al1") * self.tiling_dict.get("m") * self.tiling_dict.get("m0") - 1) * 1 \
                    + self.input_para.filter_w_dilation
                ho = 1
            elif self.flag_dict.get("conv2d_split_w_flag"):
                # m_al1 means number of hi, wi = m * m0
                wo = (self.tiling_dict.get("m") * self.tiling_dict.get("m0") - 1) * 1 \
                    + self.input_para.filter_w_dilation
                ho = (self.tiling_dict.get("m_al1") - 1) * 1 + self.input_para.filter_h_dilation
            elif self.flag_dict.get("default_tiling_flag"):
                # default tiling, min cal part is 16
                wo = self.input_para.filter_w_dilation + 15
                ho = 1
            else:
                wo = self.input_para.dy_shape_w_modify
                ho = self._cal_ho(self.input_para.filter_ori_shape_h)
                self.tiling_dict["k_al1"] = self._get_co1_factor()
        elif self.flag_dict.get("dynamic_flag"):
            wo = self.input_para.dy_shape_w_modify
            ho = self._cal_ho(self.input_para.filter_ori_shape_h)
        elif self.flag_dict.get("binary_flag"):
            if self.flag_dict.get("conv1d_flag"):
                wo = (self.tiling_dict.get("m_al1") * self.tiling_dict.get("m") *
                      self.tiling_dict.get("m0") - 1) * 1 + self.input_para.filter_w_dilation
                ho = 1
            elif self.flag_dict.get("conv2d_split_w_flag"):
                wo = self.tiling_dict.get("m") * self.tiling_dict.get("m0") + self.input_para.filter_w_dilation - 1
                ho = self.tiling_dict.get("m_al1") + self.input_para.filter_h_dilation - 1
            else:
                wo = self.input_para.dy_shape_w_modify
                ho = self._cal_ho(self.input_para.filter_ori_shape_h)
        ho = min(ho, self.input_para.dy_shape_h_modify)
        co = self.tiling_dict.get("k_al1") * self.tiling_dict.get("k_block_size")
        return ho * wo * co * self.tiling_dict.get("db_al1") * DTYPE_BYTE.get(self.input_para.dy_dtype)

    def _cal_bl1_size(self):
        cin1_hk_wk_cin0 = self.tiling_dict.get("n_bl1") * self.tiling_dict.get("n") * self.tiling_dict.get("n0") * \
            self.input_para.filter_ori_shape_h * self.input_para.filter_ori_shape_w
        co1g_reduce_co0 = self.tiling_dict.get("k_bl1") * self.tiling_dict.get("k_block_size")
        bl1_size = cin1_hk_wk_cin0 * co1g_reduce_co0 * \
            self.tiling_dict.get(
                "db_bl1") * DTYPE_BYTE.get(self.input_para.filter_dtype)

        if self.flag_dict.get("default_tiling_flag"):
            bl1_size = bl1_size // (self.input_para.filter_ori_shape_h * self.input_para.filter_ori_shape_w)
        if self.flag_dict.get("static_flag") and self.flag_dict.get("conv2d_split_w_flag"):
            bl1_size = bl1_size // self.input_para.filter_ori_shape_h

        if self.input_para.sparse_4to2_flag:
            bl1_size += bl1_size // SPARSE_4TO2_COMPRESS_INDEX_BIT_RATIO
        return bl1_size

    def _cal_bias_l1_size(self):
        bias_l1_size = 0
        # milan version, bias size need to be calculated in L1
        if self.input_para.bias is not None and platform_info.intrinsic_check_support("Intrinsic_data_move_l12bt"):
            bias_c = int_ceil_div(self.input_para.dx_ori_shape_c, self.tiling_dict.get(
                "n0")) * self.tiling_dict.get("n0")
            bias_l1_size = min(self.tiling_dict.get("n_bl1") * self.tiling_dict.get("n") * self.tiling_dict.get("n0"),
                               bias_c) * DTYPE_BYTE.get(self.input_para.bias_dtype) * self.tiling_dict.get("db_bias_l1")
        return bias_l1_size


class BMatrixHandler():

    __computes = {}

    def register_compute(dtype):
        """
        register compute description by dtype
        :param dtype: str
        :return
        """
        def add(key, value):
            if isinstance(key, (list, tuple)):
                for k in key:
                    BMatrixHandler.__computes[k] = value
            else:
                BMatrixHandler.__computes[key] = value
            return value
        return lambda x: add(dtype, x)

    def get_compute(dtype):
        """
        get compute description by dtype
        :param dtype: str
        :return compute class
        """
        return BMatrixHandler.__computes.get(dtype)

    def get_b_matrix(group_dict, param_dict):
        """
        generate b tensor on L0
        :param group_dict: group info
        :param param_dict: infos correlate with b matrix
        """
        kernel = param_dict.get("kernel")
        matrix_compute = BMatrixHandler.get_compute(kernel.dtype)
        if matrix_compute is None:
            error_manager_cube.raise_err_specific("Conv2DTransposeD",
                                                  f"no compute implemention for dtype {kernel.dtype}")
        return matrix_compute(group_dict, param_dict).generate_b()


class GenerateBMatrixCompute():

    def __init__(self, group_dict, param_dict) :
        self.kernel_h = param_dict.get("kernel_h")
        self.kernel_w = param_dict.get("kernel_w")
        self.group_dict = group_dict
        self.real_g = group_dict.get(cube_util.GroupDictKeys.g_extend)
        self.cout1_g = group_dict.get(cube_util.GroupDictKeys.co1g)
        self.cin1_g = group_dict.get(cube_util.GroupDictKeys.ci1g)
        self.kernel = param_dict.get("kernel")
        self.tensor_l0_name = "w_col"
        self.tensor_l0_tag = "inverse_trans"

    def generate_b(self):
        self._check_kernel_params()
        kernel_l1 = self._get_kernel_l1()
        kernel_l0 = self._get_kernel_l0(kernel_l1)
        self._post_processs(kernel_l0)
        return kernel_l0

    def _get_kernel_l1(self):
        return self.kernel

    @abstractmethod
    def _get_kernel_l0(self, kernel_l1):
        pass

    def _check_kernel_params(self):
        pass

    def _post_processs(self, kernel_l0):
        kernel_l0.op.attrs["kernel_h"] = self.kernel_h
        kernel_l0.op.attrs["kernel_w"] = self.kernel_w


@BMatrixHandler.register_compute(QUANT_DTYPES)
class GenerateBMatrixComputeQuant(GenerateBMatrixCompute):

    def __init__(self, group_dict, param_dict):
        super().__init__(group_dict, param_dict)
        self.compress_index = param_dict.get("compress_index")
        self.sparse_4to2_flag = param_dict.get("sparse_4to2_flag")

    def _check_kernel_params(self):
        if self.sparse_4to2_flag:
            if self.compress_index is None:
                error_manager_cube.raise_err_specific("Conv2DTransposeDCompress",
                                                      "compress_index cannot be None in sparse 4to2 scene.")
            if self.kernel.dtype != "int8":
                error_manager_cube.raise_err_specific("Conv2DTransposeDCompress",
                                                      "sparse 4to2 scene on;y support dtype int8.")

    def _get_shape_l0(self):
        # L1/DDR format: (co1ghw, cin1, cin0, co0(k0))
        kernel_co1ghw, kernel_ci1, n0, k0 = cube_util.shape_to_list(self.kernel.shape)
        # L0B format: (g, co1hw, cin1, cin0(n0), co0(k0))
        w_co1hw = kernel_co1ghw // self.real_g
        shape_w_l0b = (self.real_g, w_co1hw, kernel_ci1, n0, k0)
        return shape_w_l0b

    def _generate_sparse_4to2(self, kernel_l1):
        shape_l0 = self._get_shape_l0()
        kernel_l0 = tvm.compute(
            shape_l0,
            lambda group_idx, co1hw_idx, ci1_idx, ci0_idx, co0_idx: tvm.load_sparse(
                kernel_l1(group_idx * shape_l0[1] + co1hw_idx, ci1_idx, ci0_idx, co0_idx),
                self.compress_index(group_idx * shape_l0[1] + co1hw_idx, ci1_idx, ci0_idx,
                                    co0_idx // SPARSE_4TO2_COMPRESS_INDEX_BIT_RATIO)
            ),
            name=self.tensor_l0_name,
            tag=self.tensor_l0_tag
        )
        return kernel_l0

    def _generate_b_normal(self, kernel_l1):
        shape_l0 = self._get_shape_l0()
        kernel_l0 = tvm.compute(
            shape_l0,
            lambda group_idx, co1hw_idx, ci1_idx, ci0_idx, co0_idx: kernel_l1(
                group_idx * shape_l0[1] + co1hw_idx, ci1_idx, ci0_idx, co0_idx),
            name=self.tensor_l0_name,
            tag=self.tensor_l0_tag
        )
        return kernel_l0

    def _post_processs(self, kernel_l0):
        super()._post_processs(kernel_l0)
        kernel_l0.op.attrs["sparse_4to2_flag"] = self.sparse_4to2_flag

    def _get_kernel_l0(self, kernel_l1):
        if self.sparse_4to2_flag:
            kernel_l0 = self._generate_sparse_4to2(kernel_l1)
        else:
            kernel_l0 = self._generate_b_normal(kernel_l1)
        return kernel_l0