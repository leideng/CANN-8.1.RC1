#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2024-2024 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
Compute of Conv2d Winograd.
"""
from __future__ import division
from tbe import tvm
from tbe.common.platform import CUBE_MKN
from tbe.common.utils.op_util.op_util_conv2d import Conv2dTensorName
from tbe.common.utils.op_util.op_util_conv2d import BIT_RATIO_MAP
from tbe.common.utils.op_util.op_util_conv2d import C0_BYTE_LEN
from tbe.common.utils.op_util.op_util_conv2d import ceil_div
from tbe.common.utils.op_util.op_util_conv2d import WINO_IN_TILE_HW, WINO_OUT_TILE_HW

WINO_WEIGHT_C0_8 = 8

OP_TAG = "convolution_"


def conv_wino_compute(fmap, weight, para_dict, conv_param):
    """
    Compute of conv2d winograd.
    """
    def bias_bt_compute(bias_tensor, bias_co_ori, bias_shape):
        """
        compute bias_l1 and bias_bt
        """
        bias_tensor_map = {}
        if bias_tensor is None:
            return None, bias_tensor_map

        bias_dtype = bias_tensor.dtype
        bias_l1 = tvm.compute(bias_shape,
                              lambda group_idx, n_idx, co1_idx, h_idx, w_idx, co0_idx:
                                  tvm.select(
                                      (group_idx * co1_opt * block_n0 + co1_idx * block_n0 + co0_idx) < bias_co_ori,
                                      bias_tensor(group_idx * co1_opt * block_n0 + co1_idx * block_n0 + co0_idx)),
                              name="bias_l1",
                              tag=OP_TAG + "bias_l1")

        bias_dtype_size = BIT_RATIO_MAP.get(bias_dtype)
        bias_ori_align_n0 = group_opt * co1_opt * block_n0 * bias_dtype_size
        bias_ori_align_c0 = ceil_div(bias_co_ori * bias_dtype_size, C0_BYTE_LEN) * C0_BYTE_LEN
        # bias gm -> l1 use nd2nz, which always align data to C0 32B
        # b32 bias data need to align by 64B, so there is 32B l1 dirty data
        # use set_2d to set 0 in l1 to fix the bug
        if (bias_ori_align_n0 != bias_ori_align_c0):
            bias_l1_zero = tvm.compute(bias_shape,
                                       lambda *indice: tvm.const(0, bias_dtype),
                                       name="bias_l1_zero",
                                       tag=OP_TAG + "bias_l1_zero")
            bias_l1_vir_add = tvm.compute(bias_shape,
                                          lambda *indice:
                                              bias_l1_zero(*indice) + bias_l1(*indice),
                                          name="bias_l1_vir_add",
                                          tag=OP_TAG + "bias_l1_vir_add")
            conv_param.bias_init_align_dim_flag = True
            conv_param.tensor_map.update({"bias_l1_real": bias_l1,
                                          "bias_l1_zero": bias_l1_zero})
            bias_l1 = bias_l1_vir_add
        bias_bt = tvm.compute(bias_shape,
                              lambda *indice:
                                  bias_l1(*indice),
                                  name="bias_bt",
                              tag=OP_TAG + "bias_bt")
        bias_tensor_map[Conv2dTensorName.BIAS_BT] = bias_bt
        bias_tensor_map[Conv2dTensorName.BIAS_L1] = bias_l1
        return bias_bt, bias_tensor_map

    def wino_al0_compute(fmap, al0_shape):
        """
        compute wino_al0
        """
        def __im2col_idx(idx):
            n_idx, ci1_idx, kh_idx, kw_idx, m1_idx, m0_idx, k0_idx = idx
            _, _, fmap_h, fmap_w, _ = fmap.shape
            virtual_m = m1_idx * block_m0 + m0_idx
            ho_idx = virtual_m // wino_res_wo
            wo_idx = virtual_m % wino_res_wo
            back_h = ho_idx * stride_h + kh_idx
            back_w = wo_idx * stride_w + kw_idx
            return tvm.select(tvm.any(back_h < pad_top,
                                      back_h > fmap_h + pad_top - 1,
                                      back_w < pad_left,
                                      back_w > fmap_w + pad_left - 1),
                              tvm.const(offset_x, fmap.dtype),
                              fmap(n_idx,
                                   ci1_idx,
                                   back_h - pad_top,
                                   back_w - pad_left,
                                   k0_idx))
        return tvm.compute(al0_shape,
                           lambda *idx: __im2col_idx(idx),
                           name='al0_wino',
                           attrs={})

    def wino_bl0_compute(weight, bl0_shape):
        """
        compute wino_bl0
        """
        return tvm.compute(bl0_shape,
                           lambda ci1_idx, co1_idx, kh_idx, kw_idx, n0_idx, k0_idx:
                               weight(ci1_idx, co1_idx, n0_idx // WINO_WEIGHT_C0_8,
                                      kh_idx * WINO_IN_TILE_HW + kw_idx, n0_idx % WINO_WEIGHT_C0_8, k0_idx),
                           name='bl0_wino',
                           attrs={})

    def wino_cl0_compute(wino_al0, wino_bl0, bias_bt, wino_cl0_shape):
        """
        compute wino_cl0
        """
        k1_size, _, _, _, _, k0_size = wino_bl0.shape
        axis_k1 = tvm.reduce_axis((0, k1_size), name='k1')
        axis_k0 = tvm.reduce_axis((0, k0_size), name='k0')
        axis_wino = tvm.reduce_axis((0, WINO_IN_TILE_HW), name='wino')
        name = Conv2dTensorName.CL0_WINO
        if bias_bt is None:
            tag = OP_TAG + "c_col"
            return tvm.compute(wino_cl0_shape,
                               lambda n_idx, p1_idx, p2_idx, co1_idx, m_idx, co0_idx:
                               tvm.sum((wino_al0[n_idx, axis_k1, p1_idx * WINO_OUT_TILE_HW + p2_idx, axis_wino,
                                                 m_idx // block_m0, m_idx % block_m0, axis_k0] *
                                        wino_bl0[axis_k1, co1_idx, p1_idx * WINO_OUT_TILE_HW + p2_idx,
                                                 axis_wino, co0_idx, axis_k0]).astype("int32"),
                                        axis=[axis_wino, axis_k1, axis_k0]),
                               name=name,
                               tag=tag)
        else:
            tag = OP_TAG + "c_col_bias"
            return tvm.compute(wino_cl0_shape,
                               lambda n_idx, p1_idx, p2_idx, co1_idx, m_idx, co0_idx:
                               tvm.sum(
                                   tvm.select(
                                       tvm.all(axis_k1.var == 0, axis_k0.var == 0),
                                       (wino_al0[n_idx, axis_k1, p1_idx * WINO_OUT_TILE_HW + p2_idx, axis_wino,
                                                 m_idx // block_m0, m_idx % block_m0, axis_k0] *
                                        wino_bl0[axis_k1, co1_idx, p1_idx * WINO_OUT_TILE_HW + p2_idx,
                                                 axis_wino, co0_idx, axis_k0]).astype("int32") +
                                        bias_bt[0, 0, co1_idx, 0, 0, co0_idx],
                                        (wino_al0[n_idx, axis_k1, p1_idx * WINO_OUT_TILE_HW + p2_idx, axis_wino,
                                                  m_idx // block_m0, m_idx % block_m0, axis_k0] *
                                        wino_bl0[axis_k1, co1_idx, p1_idx * WINO_OUT_TILE_HW + p2_idx,
                                                 axis_wino, co0_idx, axis_k0]).astype("int32")),
                                        axis=[axis_wino, axis_k1, axis_k0]),
                               name=name,
                               tag=tag)

    def wino_fixpipe_compute(wino_cl0, wino_fixpipe_shape):
        """
        compute wino_fixpipe
        """
        name = Conv2dTensorName.RES_CONV2D_WINO
        tag = OP_TAG + "C"
        return tvm.compute(wino_fixpipe_shape,
                           lambda n_idx, co1_idx, p1_idx, hw_idx, p2_idx, co0_idx:
                               wino_cl0[n_idx,
                                        p1_idx,
                                        p2_idx,
                                        co1_idx,
                                        hw_idx,
                                        co0_idx].astype("int32"),
                           name=name,
                           tag=tag)

    # ===========================parse_parameters=========================
    # common parameters
    fmap_5hd_shape = para_dict["a_shape"]
    weight_ori_shape_nchw = para_dict["weight_ori_shape_nchw"]
    pad_top, pad_bottom = para_dict["pad_h"]
    pad_left, pad_right = para_dict["pad_w"]
    ci1_opt, co1_opt, group_opt = para_dict["c1_opt"], para_dict["cout1_opt"], para_dict["group_opt"]
    offset_x = para_dict["offset_x"]
    bias_tensor = para_dict["bias_tensor"]
    out_height = conv_param.h_out
    out_width = conv_param.w_out
    block_m0, block_k0, block_n0 = CUBE_MKN[fmap.dtype]["mac"]

    batch, in_c1, in_height, in_width, in_c0 = fmap_5hd_shape
    cout, _, k_h, k_w = weight_ori_shape_nchw
    stride_h, stride_w = 2, 2  # consider wino im2col as kernel 4*4, stride 2*2

    wino_res_ho = ceil_div(out_height, WINO_OUT_TILE_HW)
    wino_res_wo = ceil_div(out_width, WINO_OUT_TILE_HW)
    wino_res_m1 = ceil_div(wino_res_ho * wino_res_wo, block_m0)
    wino_res_m = wino_res_m1 * block_m0

    # =======================winograd compute===========================
    al0_shape = (batch, in_c1, WINO_IN_TILE_HW, WINO_IN_TILE_HW, wino_res_m1, block_m0, block_k0)
    wino_al0 = wino_al0_compute(fmap, al0_shape)

    bl0_shape = (ci1_opt, co1_opt, WINO_IN_TILE_HW, WINO_IN_TILE_HW, block_n0, block_k0)
    wino_bl0 = wino_bl0_compute(weight, bl0_shape)

    bias_shape = (group_opt, 1, co1_opt, 1, 1, block_n0)
    bias_bt, bias_tensor_map = bias_bt_compute(bias_tensor, cout, bias_shape)

    wino_cl0_shape = (batch, WINO_OUT_TILE_HW, WINO_OUT_TILE_HW, co1_opt, wino_res_m, block_n0)
    wino_cl0 = wino_cl0_compute(wino_al0, wino_bl0, bias_bt, wino_cl0_shape)

    wino_fixpipe_shape = (batch, co1_opt, WINO_OUT_TILE_HW, wino_res_ho * wino_res_wo, WINO_OUT_TILE_HW, block_n0)
    wino_fixpipe = wino_fixpipe_compute(wino_cl0, wino_fixpipe_shape)

    # =======================update tensormap==========================
    update_tensormap = {
        Conv2dTensorName.FMAP: fmap,
        Conv2dTensorName.FILTER: weight,
        Conv2dTensorName.FMAP_IMG2COL: wino_al0,
        Conv2dTensorName.BL0: wino_bl0,
        Conv2dTensorName.CL0: wino_cl0,
        Conv2dTensorName.FIXPIPE_RES: wino_fixpipe}
    update_tensormap.update(bias_tensor_map)
    conv_param.tensor_map.update(update_tensormap)

    # =======================update dimmap===============================
    filter_matrix_dim = (in_c1, ceil_div(cout, block_n0), block_n0 // WINO_WEIGHT_C0_8,
                         k_h * k_w, WINO_WEIGHT_C0_8, block_k0)
    update_dimmap = {"filter_matrix_dim": filter_matrix_dim}
    conv_param.dim_map.update(update_dimmap)

    # =======================update tiling_query_param=====================
    c_shape = [batch, co1_opt, out_height, out_width, block_n0]
    conv_param.tiling_query_param.update({"c_shape": c_shape})
    conv_param.show_conv_param_flag()

    return wino_fixpipe