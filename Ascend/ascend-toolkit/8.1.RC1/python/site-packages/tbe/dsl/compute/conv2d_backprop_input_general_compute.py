#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2019-2020 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
conv2d backprop input general compute.
"""
from tbe.common import platform as tbe_platform
from tbe.common.utils.const import SplitAxisMode
from tbe.common.utils.const import SPLIT_AXIS_MODE_STR
from tbe.common.utils.const import IS_CONV1D_SITUATION_STR
from tbe.common.utils.const import QUANT_DTYPES
from tbe.common.utils.const import WEIGHT_SPARSE_4_2
from tbe.common.utils.errormgr import error_manager_cube
from tbe.dsl.compute import cube_util
from tbe.dsl.compute import util as compute_util
from tbe.dsl.compute.conv2d_backprop_input_compute_util import BMatrixHandler
from tbe.dsl.base.operation import get_te_var
from tbe.dsl.base.operation import is_unify
from tbe import tvm
from tbe.tvm import abs as tvm_abs


class DeConvPattern(cube_util.CubeDslPattern):
    """
    class of convolution back propagation

    Parameters
    ----------
    kernel_sizes : shape of weight, [N, C, H, W]

    strides : list of strides, [strideh, stridew]

    pad: list of padding, [forward_padu, forward_padd, forward_padl, forward_padr]

    output_shape : shape of dE/dX, [N, C, H, W]

    dilations: list of dilations, [dilation_n, dilation_c, dilation_h, dilation_w]

    offset_x : offset of x

    kernel_name : cce kernel name

    group_dict : The params of group convolution.

    Returns
    -------
    deconv_pattern_instance : instance of deconv pattern
    """

    fusion_para_map = None
    dedy = None

    def __init__(
        self,
        kernel_sizes,
        strides,
        pad,
        output_shape,
        output_dtype,
        dilations,
        offset_x,
        fusion_para,
        kernel_name,
        group_dict,
        var_map,
        control_flag_dict
    ):
        super().__init__(group_dict.get(cube_util.GroupDictKeys.ci1g))
        _, _, self._kernel_h, self._kernel_w = kernel_sizes
        self._stride_h, self._stride_w = strides
        self._forward_padu, self._forward_padd, self._forward_padl, self._forward_padr = pad
        self._output_shape = output_shape
        self.output_dtype = output_dtype
        self._kernel_name = kernel_name
        _, _, self._dilation_h, self._dilation_w = dilations
        self.m_0, _, _ = tbe_platform.CUBE_MKN["float16"]["mac"]
        self._offset_x = offset_x
        self._fusion_para = fusion_para
        self._var_map = var_map
        self._group_dict = group_dict
        self._real_g = self._group_dict.get(cube_util.GroupDictKeys.g_extend)
        self._cout1_g = self._group_dict.get(cube_util.GroupDictKeys.co1g)
        self._support_l0c_to_out_flag = tbe_platform.intrinsic_check_support("Intrinsic_fix_pipe_l0c2out")
        self._support_ub_to_l1_flag = tbe_platform.intrinsic_check_support("Intrinsic_data_move_ub2l1")
        self._support_l1_to_bt_flag = tbe_platform.intrinsic_check_support("Intrinsic_data_move_l12bt")
        self.pooling_mode = control_flag_dict.get("pooling_mode")
        self.l0a_dma_flag = control_flag_dict.get("l0a_dma_flag")
        self.binary_mode = control_flag_dict.get("binary_mode")
        self.load3d_special_multiply = get_te_var("load3d_special").get_tvm_var() if self.binary_mode else 1
        self.split_axis_mode = control_flag_dict.get(SPLIT_AXIS_MODE_STR, 0)
        self._is_conv1d_situation = control_flag_dict.get(IS_CONV1D_SITUATION_STR, False)
        self.bias_dtype_map = {
            "float16": "float32",
            "float32": "float32",
            "int32": "int32"
        }
        self.alg = control_flag_dict.get("alg")
        self.sparse_4to2_flag = self.alg == WEIGHT_SPARSE_4_2


    def generate_a(self, dy_ddr):
        """
        generate dy_col tensor for mad

        Parameters
        ----------
        dy_ddr: 5D dE/dY tensor in ddr

        Returns
        ----------
        dy_col: dE/dY tensor of fractal shape in L0A
        """

        def _check_pad_zero(pad_list):
            """
            if pad less than 0, return True
            """
            for pad in pad_list:
                if pad < 0:
                    return True
            return False

        def _fill_zero(shape_dy_filling):
            """
            Get an all-zero tensor of shape 'shape_dy_filling'
            """
            dy_zero = tvm.compute(
                shape_dy_filling,
                lambda *indice: tvm.convert(self._offset_x).astype(dy_ddr.dtype),
                name="dy_filling_i",
                tag="init_zero"
            )
            return dy_zero

        def _write_select():
            if self._support_l0c_to_out_flag:
                # pad > kernel > 1 scene
                shape_dy_filling = (
                    dy_batch,
                    kernel_cout1,
                    dy_h * self._stride_h + shape_down_modify,
                    dy_w * self._stride_w + shape_right_modify,
                    kernel_cout0
                )
            else:
                shape_dy_filling = (
                    dy_batch,
                    kernel_cout1,
                    dy_h * self._stride_h,
                    dy_w * self._stride_w,
                    kernel_cout0
                )
            if self._stride_h == 1 and self._stride_w == 1:
                dy_filling = dy_ddr
            else:
                dy_zero = _fill_zero(shape_dy_filling)
                dy_filling = tvm.compute(
                    shape_dy_filling,
                    lambda batch_idx, kernel_cout1_idx, ho_idx, wo_idx, kernel_cout0_idx: tvm.select(
                        tvm.all(ho_idx % self._stride_h == 0, wo_idx % self._stride_w == 0),
                        dy_ddr[
                            batch_idx,
                            kernel_cout1_idx,
                            ho_idx // self._stride_h,
                            wo_idx // self._stride_w,
                            kernel_cout0_idx
                        ],
                        dy_zero[
                            batch_idx,
                            kernel_cout1_idx,
                            ho_idx,
                            wo_idx,
                            kernel_cout0_idx
                        ]
                    ),
                    name="dy_filling",
                    tag="stride_filling"
                )
            return dy_filling, shape_dy_filling

        def _write_select_dynamic():
            if self._support_l0c_to_out_flag:
                shape_dy_filling = (
                    dy_batch,
                    kernel_cout1,
                    dy_h * self._stride_h + shape_down_modify,
                    dy_w * self._stride_w + shape_right_modify,
                    kernel_cout0
                )
            else:
                shape_dy_filling = (
                    dy_batch,
                    kernel_cout1,
                    dy_h * self._stride_h,
                    dy_w * self._stride_w,
                    kernel_cout0
                )

            if self._stride_h == 1 and self._stride_w == 1:
                dy_vn = dy_ddr
            else:
                dy_zero = _fill_zero(shape_dy_filling)
                dy_filling = tvm.compute(
                    shape_dy_filling,
                    lambda idx_batch, idx_co1, idx_ho_expand, idx_wo_expand, idx_co0: tvm.select(
                        tvm.all(idx_ho_expand % self._stride_h == 0, idx_wo_expand % self._stride_w == 0),
                        dy_ddr[idx_batch,
                                idx_co1,
                                idx_ho_expand // self._stride_h,
                                idx_wo_expand // self._stride_w,
                                idx_co0]
                    ),
                    name="dy_filling",
                    tag="stride_filling"
                )
                dy_vn = tvm.compute(
                    shape_dy_filling,
                    lambda *indice: dy_zero(*indice) + dy_filling(*indice),
                    name="dy_vn",
                    tag="dy_vn"
                )

            return dy_vn, shape_dy_filling

        def _cal_hiwi(height_out, width_out):
            """
            calculate H*W of output(dedx).
            """
            kernel_h, kernel_w = self._kernel_h, self._kernel_w
            forward_padu, forward_padd, forward_padl, forward_padr = (self._forward_padu, self._forward_padd,
                                                                      self._forward_padl, self._forward_padr)
            dilation_h, dilation_w = (self._dilation_h, self._dilation_w)
            # stride_h stride_w is 1
            height_in = (height_out + forward_padu + forward_padd - (kernel_h - 1) * dilation_h - 1) + 1
            width_in = (width_out + forward_padl + forward_padr - (kernel_w - 1) * dilation_w - 1) + 1
            return height_in, width_in

        def _l1a_fractal_write_select():
            """
            Without ub scenes, generate fractal_a in l1
            ddr(5hd) -> L1(fractal) -> L0A(fractal)
            """
            padu, padd, padl, padr = dma_new_pad
            shape_dy_filling = (dy_batch, kernel_cout1, dy_h * self._stride_h + padu + padd,
                                dy_w * self._stride_w + padl + padr, kernel_cout0)
            a_batch, _, a_h, a_w, a_c0 = shape_dy_filling

            height_in, width_in = _cal_hiwi(a_h, a_w)
            hiwi = compute_util.align(height_in * width_in, self.m_0)
            a_im2col_row_major_shape = (a_batch, height_in * width_in, self._real_g *
                                        self._cout1_g * cout_1_factor, self._kernel_h, self._kernel_w, a_c0)
            a_im2col_fractal_shape = (self._real_g, a_batch, hiwi // self.m_0, self._cout1_g *
                                      cout_1_factor * self._kernel_h * self._kernel_w, self.m_0, a_c0)

            def _dy_filinging_indices(indices, fractal_indices):
                """
                input dy_filling indices
                return dy_ddr indices
                """
                batch_idx, kernel_cout1_idx, ho_idx, wo_idx, kernel_cout0_idx = indices
                g_index, n_index, m1_index, k1_index, m0_index, k0_index = fractal_indices
                if  dma_new_pad != (0, 0, 0, 0) or self._stride_h * self._stride_w > 1:
                    return tvm.select(
                            tvm.all((ho_idx - padu)  % self._stride_h == 0, (wo_idx - padl) % self._stride_w == 0,
                                    ho_idx >= padu, ho_idx < shape_dy_filling[2] - padd,
                                    wo_idx >= padl, wo_idx < shape_dy_filling[3] - padr,
                                    kernel_cout1_idx < kernel_cout1),
                            dy_ddr[batch_idx, kernel_cout1_idx, (ho_idx - padu) // self._stride_h,
                                   (wo_idx - padl) // self._stride_w, kernel_cout0_idx],
                            dy_zero[g_index, n_index, m1_index, k1_index, m0_index, k0_index]
                        )

                return dy_ddr[batch_idx, kernel_cout1_idx, ho_idx, wo_idx, kernel_cout0_idx]

            def _row_major_indices(indices, fractal_indices, slice_offset=0):
                """
                input row_major indices
                return dy_filling indices
                """
                _, _, _, a_width, _ = shape_dy_filling
                n_index, *hw_index, c1_index, kh_index, kw_index, c0_index = indices
                width_in = (a_width - ((self._kernel_w - 1) * self._dilation_w + 1)) + 1
                h_indice = hw_index[0] // width_in
                w_indice = hw_index[0] % width_in
                # stride_h stride_w is 1
                h_index = h_indice + kh_index * self._dilation_h
                w_index = w_indice + kw_index * self._dilation_w
                dy_filinging_indices = [n_index, c1_index, h_index + slice_offset, w_index, c0_index]
                return _dy_filinging_indices(dy_filinging_indices, fractal_indices)

            def _fractal_indices(fractal_indices):
                """
                input fractal indices
                return row_major indices
                """
                _, _, _, a_col_k1, a_col_m0, a_col_k0 = a_im2col_fractal_shape
                _, a_row_major_hw, _, _, _, _ = a_im2col_row_major_shape
                g_index, n_index, m1_index, k1_index, m0_index, k0_index = fractal_indices

                hw_index = m1_index * a_col_m0 + m0_index
                k_axis_index = (g_index * a_col_k1 + k1_index) * a_col_k0 + k0_index

                c1_index = ((k_axis_index // a_col_k0) // self._kernel_w) // self._kernel_h

                kh_index = ((k_axis_index // a_col_k0) // self._kernel_w) % self._kernel_h

                kw_index = (k_axis_index // a_col_k0) % self._kernel_w

                c0_index = k_axis_index % a_col_k0

                row_major_indices = [n_index, hw_index, c1_index, kh_index, kw_index, c0_index]

                return tvm.select(
                    tvm.all(hw_index >= 0, hw_index < a_row_major_hw),
                    _row_major_indices(row_major_indices, fractal_indices, self._offset_x),
                    dy_zero[g_index, n_index, m1_index, k1_index, m0_index, k0_index])

            if dma_new_pad != (0, 0, 0, 0) or self._stride_h * self._stride_w > 1:
                dy_zero = _fill_zero(a_im2col_fractal_shape)
            a_col = tvm.compute(a_im2col_fractal_shape,
                            lambda *indices: _fractal_indices(indices),
                            name='im2col_fractal',
                            tag='dy_col_no_ub_dma',
                            attrs={
                                "l0a_dma_flag": self.l0a_dma_flag,
                                "row_major_shape": a_im2col_row_major_shape,
                                "padding": (0, 0, 0, 0),
                                "dma_pad": dma_new_pad,
                                "dilation": (self._dilation_h, self._dilation_w),
                                "stride_expand": (self._stride_h, self._stride_w),
                                "load3d_special_multiply": self.load3d_special_multiply
                            })
            a_col.op.attrs["ho"] = dy_h
            a_col.op.attrs["wo"] = dy_w
            a_col.op.attrs["stride_h"] = self._stride_h
            a_col.op.attrs["stride_w"] = self._stride_w
            a_col.op.attrs["l0a_dma_flag"] = self.l0a_dma_flag
            return a_col

        def _l0a_dma_write_select():
            """
            In l0a dma scenes, both expands and pads done in ub.
            """
            padu, padd, padl, padr = dma_new_pad

            if padu != 0 or padd != 0 or padl != 0 or padr != 0 or self._stride_h * self._stride_w > 1:
                shape_dy_filling = (dy_batch, kernel_cout1, dy_h * self._stride_h + padu + padd,
                                    dy_w * self._stride_w + padl + padr, kernel_cout0)
                if self._stride_h * self._stride_w > 1:
                    dy_zero = _fill_zero(shape_dy_filling)
                    dy_filling = tvm.compute(
                        shape_dy_filling,
                        lambda batch_idx, kernel_cout1_idx, ho_idx, wo_idx, kernel_cout0_idx: tvm.select(
                            tvm.all((ho_idx - padu)  % self._stride_h == 0, (wo_idx - padl) % self._stride_w == 0,
                                     ho_idx >= padu, ho_idx < shape_dy_filling[2] - padd,
                                     wo_idx >= padl, wo_idx < shape_dy_filling[3] - padr),
                            dy_ddr[batch_idx, kernel_cout1_idx, (ho_idx - padu) // self._stride_h,
                                   (wo_idx - padl) // self._stride_w, kernel_cout0_idx],
                            dy_zero[batch_idx, kernel_cout1_idx, ho_idx, wo_idx, kernel_cout0_idx]
                        ),
                        name="dy_filling_dma",
                        tag="ub_filling_dma",
                        attrs={"dma_pad": dma_new_pad}
                    )
                else:
                    dy_filling = tvm.compute(
                        shape_dy_filling,
                        lambda batch_idx, kernel_cout1_idx, ho_idx, wo_idx, kernel_cout0_idx: tvm.select(
                            tvm.any(ho_idx < padu, ho_idx > shape_dy_filling[2] - padd - 1,
                                    wo_idx < padl, wo_idx > shape_dy_filling[3] - padr - 1),
                            tvm.const(self._offset_x, dy_ddr.dtype),
                            dy_ddr[batch_idx, kernel_cout1_idx, (ho_idx - padu),
                                   (wo_idx - padl), kernel_cout0_idx],
                        ),
                        name="dy_pad_dma",
                        tag="ub_pad_dma",
                        attrs={"dma_pad": dma_new_pad}
                    )

            else:
                dy_filling = dy_ddr
            return dy_filling

        fusion_para = self._fusion_para
        DeConvPattern.fusion_para_map = fusion_para
        DeConvPattern.dedy = dy_ddr

        dy_batch, kernel_cout1, dy_h, dy_w, kernel_cout0 = cube_util.shape_to_list(dy_ddr.shape)
        kernel_h, kernel_w = self._kernel_h, self._kernel_w
        _, _, dx_h, dx_w, _ = self._output_shape
        dilation_h, dilation_w = self._dilation_h, self._dilation_w
        dy_dilated_h = dy_h * self._stride_h
        dy_dilated_w = dy_w * self._stride_w

        backprop_padu = (kernel_h - 1) * dilation_h - self._forward_padu
        backprop_padl = (kernel_w - 1) * dilation_w - self._forward_padl
        backprop_padd = dx_h - dy_dilated_h - backprop_padu + (kernel_h - 1) * dilation_h
        backprop_padr = dx_w - dy_dilated_w - backprop_padl + (kernel_w - 1) * dilation_w
        pad_list = (backprop_padu, backprop_padd,
                    backprop_padl, backprop_padr)

        # stride > 1 ub->l1 may cut
        # In static and binary scenarios, shape_[xx]_modify and backprop_pad[x] are calculated in the same way,
        # the difference is that the calculation for binary scenarios is done in op tiling.
        if self.binary_mode:
            shape_up_modify = get_te_var("shape_up_modify").get_tvm_var()
            shape_left_modify = get_te_var("shape_left_modify").get_tvm_var()
            shape_down_modify = get_te_var("shape_down_modify").get_tvm_var()
            shape_right_modify = get_te_var("shape_right_modify").get_tvm_var()

            backprop_padu = get_te_var("pad_up_before").get_tvm_var()
            backprop_padl = get_te_var("pad_left_before").get_tvm_var()
            backprop_padd = get_te_var("pad_down_after").get_tvm_var()
            backprop_padr = get_te_var("pad_right_after").get_tvm_var()
        else:
            shape_up_modify = (backprop_padu - tvm_abs(backprop_padu)) // 2
            shape_left_modify = (backprop_padl - tvm_abs(backprop_padl)) // 2
            shape_down_modify = (backprop_padd - tvm_abs(backprop_padd)) // 2
            shape_right_modify = (backprop_padr - tvm_abs(backprop_padr)) // 2

            backprop_padu = (backprop_padu + tvm_abs(backprop_padu)) // 2
            backprop_padl = (backprop_padl + tvm_abs(backprop_padl)) // 2
            backprop_padd = (backprop_padd + tvm_abs(backprop_padd)) // 2
            backprop_padr = (backprop_padr + tvm_abs(backprop_padr)) // 2

        new_pad = (backprop_padu, backprop_padd,
                   backprop_padl, backprop_padr)

        cout_1_factor = 2 if dy_ddr.dtype == "float32" else 1
        if self._var_map:
            dy_filling, shape_dy_filling = _write_select_dynamic()
        elif self.l0a_dma_flag:
            dma_new_pad = (backprop_padu + shape_up_modify, backprop_padd + shape_down_modify,
                           backprop_padl + shape_left_modify, backprop_padr + shape_right_modify)
            if not self._support_ub_to_l1_flag:
                # Without ub, dam_copy scenes, ddr -> L1 -> L0
                return _l1a_fractal_write_select()
            dy_filling = _l0a_dma_write_select()
        else:
            dy_filling, shape_dy_filling = _write_select()
        dy_filling.op.attrs["ho"] = dy_h
        dy_filling.op.attrs["wo"] = dy_w
        dy_filling.op.attrs["stride_h"] = self._stride_h
        dy_filling.op.attrs["stride_w"] = self._stride_w
        dy_filling.op.attrs["l0a_dma_flag"] = self.l0a_dma_flag

        if self._var_map:
            dy_l1_shape_6d_cut = (
                self._real_g,
                dy_batch,
                self._cout1_g * cout_1_factor,
                dy_h * self._stride_h + shape_up_modify + shape_down_modify,
                dy_w * self._stride_w + shape_left_modify + shape_right_modify,
                kernel_cout0
            )
            dy_filling_l1 = tvm.compute(
                dy_l1_shape_6d_cut,
                lambda g_idx, batch_idx, cout1_g_idx, ho_idx, wo_idx, cout0_idx:
                    tvm.select(
                        tvm.all(cout1_g_idx + g_idx * self._cout1_g * cout_1_factor < kernel_cout1),
                        dy_filling[batch_idx,
                                   cout1_g_idx + g_idx * self._cout1_g * cout_1_factor,
                                   ho_idx - shape_up_modify,
                                   wo_idx - shape_left_modify,
                                   cout0_idx]
                    ),
                name="dy_l1_6d_cut",
                tag="dy_l1_6d_cut"
            )
            dy_filling = dy_filling_l1
        elif (self._stride_h > 1 or self._stride_w > 1) and not self.l0a_dma_flag:
            if _check_pad_zero(pad_list):
                shape_dy_filling_cut = (
                    dy_batch,
                    kernel_cout1,
                    dy_h * self._stride_h + shape_up_modify + shape_down_modify,
                    dy_w * self._stride_w + shape_left_modify + shape_right_modify,
                    kernel_cout0
                )

                # cut dy_filling
                dy_filling = tvm.compute(
                    shape_dy_filling_cut,
                    lambda batch_idx, kernel_cout1_idx, ho_idx, wo_idx, kernel_cout0_idx: dy_filling[
                        batch_idx,
                        kernel_cout1_idx,
                        ho_idx - shape_up_modify,
                        wo_idx - shape_left_modify,
                        kernel_cout0_idx
                    ],
                    name="dy_l1_cut",
                    tag="dy_l1"
                )
            else:
                dy_filling = tvm.compute(
                    shape_dy_filling,
                    lambda batch_idx, kernel_cout1_idx, ho_idx, wo_idx, kernel_cout0_idx: dy_filling[
                        batch_idx, kernel_cout1_idx, ho_idx, wo_idx, kernel_cout0_idx
                    ],
                    name="dy_l1",
                    tag="dy_l1"
                )
        elif _check_pad_zero(pad_list) and not self.l0a_dma_flag:
            shape_dy_filling_cut = (
                dy_batch,
                kernel_cout1,
                dy_h * self._stride_h + shape_up_modify + shape_down_modify,
                dy_w * self._stride_w + shape_left_modify + shape_right_modify,
                kernel_cout0
            )
            # cut dy_filling
            dy_filling = tvm.compute(
                shape_dy_filling_cut,
                lambda batch_idx, kernel_cout1_idx, ho_idx, wo_idx, kernel_cout0_idx: dy_filling[
                    batch_idx,
                    kernel_cout1_idx,
                    ho_idx - shape_up_modify,
                    wo_idx - shape_left_modify,
                    kernel_cout0_idx
                ],
                name="dy_l1_modify",
                tag="dy_l1_modify"
            )
        new_pad = new_pad if not self.l0a_dma_flag else [0, 0, 0, 0]
        pat_conv = cube_util.ConvDslPattern(
            (kernel_h, kernel_w),
            (1, 1),
            new_pad,
            (dilation_h, dilation_w),
            param_dict={"offset_x": self._offset_x,
                        "l0a_dma_flag": self.l0a_dma_flag,
                        "load3d_special_multiply": self.load3d_special_multiply}
        )
        dy_filling.op.attrs[SPLIT_AXIS_MODE_STR] = self.split_axis_mode
        dy_col = pat_conv.generate_a(
            dy_filling,
            self._real_g,
            self._cout1_g * cout_1_factor,
            self._var_map)

        self.load3d_special_multiply = pat_conv.load3d_special_multiply
        return dy_col

    def generate_b(self, kernels, compress_index=None):
        """
        generate w_col tensor for mad

        Parameters
        ----------
        kernels: weight tensor of fractal shape before transformation in ddr

        Returns
        ----------
        w_col: w tensor of fractal shape after transformation in L0B
        """
        shape_kernel = cube_util.shape_to_list(kernels.shape)
        group = self._real_g
        # w_[xx] indicates the variables owned by filter in L0B
        # kernel_[xx] indicates the variables owned by filter in DDR/L1
        w_co1 = self._cout1_g
        w_ci1 = self._cin1_g
        kernel_h, kernel_w = self._kernel_h, self._kernel_w
        if kernels.dtype in QUANT_DTYPES:
            params_dict = {
                "kernel": kernels,
                "compress_index": compress_index,
                "kernel_h": self._kernel_h,
                "kernel_w": self._kernel_w,
                "sparse_4to2_flag": self.sparse_4to2_flag
            }
            w_col = BMatrixHandler.get_b_matrix(self._group_dict, params_dict)
        else:
            # fp16 DDR/L1: (ci1ghw, co1, co0(n0), ci0(k0))
            # fp32 DDR: (ci1ghw, co1, co0(n0), ci0(k0))
            kernel_ci1ghw, kernel_co1, n0, k0 = shape_kernel
            kernel_hw = kernel_h * kernel_w
            if not self.binary_mode and kernel_ci1ghw % kernel_hw != 0:
                error_manager_cube.raise_err_specific("Conv2dBackpropInputD",
                                                      "kernel_ci1ghw could not be divided by kernel_h * kernel_w")
            kernel_ci1g = kernel_ci1ghw // kernel_hw
            w_co1hw = w_co1 * kernel_hw

            def _kernel_to_l1_compute(indices, kernels):
                kernel_ci1g_idx, kernel_hw_idx, kernel_co1_idx, n0_idx, k0_idx = indices
                kernel_ci1ghw_idx = kernel_ci1g_idx * kernel_hw + kernel_hw_idx
                return kernels[kernel_ci1ghw_idx, kernel_co1_idx, n0_idx, k0_idx]

            if self._support_l0c_to_out_flag and kernels.dtype == "float32":
                # fp32 L1: (ci1g, hw, co1, co0(n0), ci0(k0))
                shape_kernel_l1 = (kernel_ci1g, kernel_hw, kernel_co1, n0, k0)
                kernel_l1 = tvm.compute(shape_kernel_l1,
                                        lambda *indices: _kernel_to_l1_compute(indices, kernels),
                                        name="kernel_l1")
                # fp32 L0B: (g, co1*2*hw, ci1/2, ci0*2(n0), co0/2(k0))
                shape_w_l0b = (group, w_co1hw * 2, (w_ci1 + 1) // 2, n0, k0)
            else:
                kernel_l1 = kernels
                # fp16 L0B: (g, co1hw, ci1, ci0(n0), co0(k0))
                shape_w_l0b = (group, w_co1hw, w_ci1, n0, k0)

            def _kernel_to_l0_compute(indices, kernel_l1):
                _, k0, n0 = tbe_platform.CUBE_MKN[kernels.dtype]["mac"]
                w_ci0, w_co0 = n0, k0
                g_idx, w_co1hw_idx, w_ci1_idx, n0_idx, k0_idx = indices
                if kernels.dtype == "float32":
                    w_co_idx = (w_co1hw_idx // kernel_hw) * w_co0 + k0_idx
                    w_ci_idx = w_ci1_idx * w_ci0 + n0_idx
                    kernel_ci1g_idx = g_idx * w_ci1 + w_ci_idx // k0
                    kernel_hw_idx = (kernel_hw - 1) - w_co1hw_idx % kernel_hw
                    kernel_co1_idx = w_co_idx // n0
                    n0_idx = w_co_idx % n0
                    k0_idx = w_ci_idx % k0
                    return kernel_l1[kernel_ci1g_idx, kernel_hw_idx, kernel_co1_idx, n0_idx, k0_idx]
                else:
                    kernel_ci1ghw_idx = g_idx * w_ci1 * kernel_hw + w_ci1_idx * kernel_hw + (
                        kernel_hw - 1) - w_co1hw_idx % kernel_hw
                    kernel_co1_idx = w_co1hw_idx // kernel_hw
                    kernel_n0_idx, kernel_k0_idx = k0_idx, n0_idx
                    return kernel_l1[kernel_ci1ghw_idx, kernel_co1_idx, kernel_n0_idx, kernel_k0_idx]

            w_col = tvm.compute(shape_w_l0b,
                                lambda *indices: _kernel_to_l0_compute(indices, kernel_l1),
                                name="w_col",
                                tag="inverse_trans_dma")
        w_col.op.attrs['kernel_h'] = kernel_h
        w_col.op.attrs['kernel_w'] = kernel_w

        return w_col

    def generate_c(
        self, tensor_a, tensor_b, tensor_bias=None, bias_ori_shape=None
    ):
        """
        generate dx_ddr

        Parameters
        ----------
        tensor_a : dE/dY tensor of fractal shape in L0A

        tensor_b : w tensor of fractal shape after transformation in L0B

        tensor_bias : same as that in Class->CubeDslPattern

        Returns
        ----------
        dx_ddr: dx tensor in ddr
        """

        def _add_bias_in_ub(in_tensor0, in_tensor1):
            block_dim = tbe_platform.CUBE_MKN.get(in_tensor0.dtype).get("mac")[2]
            c_add_vector = tvm.compute(
                in_tensor0.shape,
                lambda *indice: in_tensor0(*indice) + in_tensor1(indice[1] * block_dim + indice[-1]),
                name="bias_add_vector")
            return c_add_vector

        def _get_bias_l1(tensor_bias):
            bias_shape = cube_util.shape_to_list(tensor_bias.shape)
            bias_l1_name = "bias_l1"
            if self.binary_mode or (not is_unify() and bias_shape[0] != bias_ori_shape):
                bt_tag = "bias_need_align"
                if (tbe_platform.platform_info.intrinsic_check_support("Intrinsic_set_l1") and
                    not tbe_platform.platform_info.intrinsic_check_support("Intrinsic_set_l1", "f32")):
                    # bias need do align in Ub
                    bias_ub = tvm.compute(bias_shape, lambda *indice:
                                          tvm.select(indice[0] < bias_ori_shape, tensor_bias(*indice),
                                          tvm.convert(0).astype(tensor_bias.dtype)), name="bias_ub")
                    bias_l1 = tvm.compute(bias_shape, lambda *indice:
                                          bias_ub(*indice), name=bias_l1_name)
                else:
                    # bias need do align in L1
                    bias_zero = tvm.compute(bias_shape, lambda *indice:
                                            tvm.convert(0).astype(tensor_bias.dtype), name="bias_zero")
                    bias_l1 = tvm.compute(bias_shape, lambda *indice:
                                          tvm.select(indice[0] < bias_ori_shape, tensor_bias(*indice),
                                          bias_zero(*indice)), name=bias_l1_name)
            else:
                bt_tag = "bias_no_need_align"
                bias_l1 = tvm.compute(bias_shape,
                                      lambda *indice: tensor_bias(*indice),
                                      name=bias_l1_name)
            return bias_l1, bt_tag, bias_shape

        dy_col = tensor_a
        w_col = tensor_b

        res_c_type = "float32"
        if not tbe_platform.intrinsic_check_support("Intrinsic_mmad", "f162f32"):
            res_c_type = "float16"
        if w_col.dtype in QUANT_DTYPES:
            res_c_type = "int32"

        if tensor_bias is not None and tensor_bias.dtype == "int32":
            bias = tensor_bias
        else:
            bias = None
        bias_table_flag = (tensor_bias is not None and self._support_l1_to_bt_flag and
                           tensor_bias.dtype in self.bias_dtype_map)
        if bias_table_flag:
            bias_l1, bt_tag, bias_shape = _get_bias_l1(tensor_bias)
            bias = tvm.compute(
                bias_shape,
                lambda *indice: bias_l1(*indice).astype(self.bias_dtype_map.get(bias_l1.dtype)),
                name='bias_bt',
                tag=bt_tag
            )
        mad_param = {
            "type_c": res_c_type,
            "offset_x": self._offset_x,
            "bias_table_flag": bias_table_flag,
            "cin1_g": self._cin1_g,
            "split_axis_mode": self.split_axis_mode,
            "sparse_4to2_flag": self.sparse_4to2_flag
        }

        dx_col = super().generate_c(
            dy_col, w_col, mad_param=mad_param, tensor_bias=bias
        )
        # real dx shape
        dx_batch, dx_cin1, dx_h, dx_w, dx_cin0 = self._output_shape
        out_shape = (dx_batch, dx_cin1, dx_h * dx_w, dx_cin0)
        # float32->output_dtype
        output_dtype = self.output_dtype
        if w_col.dtype in QUANT_DTYPES:
            output_dtype = "int32"

        if self._support_l0c_to_out_flag:
            if w_col.dtype == "bfloat16" and dy_col.dtype == "bfloat16":
                output_dtype = "bfloat16"
            if w_col.dtype == "float32":
                dx_ddr = self._get_gm_channel_merge_split(out_shape, dx_col, output_dtype)
            else:
                dx_ddr = self._get_gm_from_l0c(out_shape, dx_col, output_dtype)
        else:
            dx_ub = self._get_dx_ub(dx_col, output_dtype)
            if tensor_bias is not None and tensor_bias.dtype in ["float16", "float32"]:
                dx_ub = _add_bias_in_ub(dx_ub, tensor_bias)
            dx_ddr = self._get_gm_from_ub(dx_ub, out_shape, dx_col)
        dx_ddr.op.attrs[SPLIT_AXIS_MODE_STR] = self.split_axis_mode
        dx_ddr.op.attrs[IS_CONV1D_SITUATION_STR] = self._is_conv1d_situation
        return dx_ddr

    def _get_gm_channel_merge_split(self, out_shape, dx_col, output_dtype):
        dx_w, dx_c0 = self._output_shape[-2:]
        if self.split_axis_mode == SplitAxisMode.split_w.value:
            dx_ddr = tvm.compute(
                out_shape,
                lambda dx_batch_idx, dx_cin1_idx, dx_hw_idx, dx_cin0_idx:
                    dx_col[dx_cin1_idx // self._cin1_g,
                           dx_batch_idx,
                           dx_hw_idx // dx_w,
                           dx_cin1_idx % self._cin1_g // 2,
                           dx_hw_idx % dx_w,
                           dx_c0 * (dx_cin1_idx % self._cin1_g % 2) + dx_cin0_idx
                    ].astype(output_dtype),
                    name="c_ddr",
                    tag="conv2d_backprop_input",
                    attrs={
                        "output_shape": self._output_shape,
                        "output_dtype": self.output_dtype,
                        "group_dict": self._group_dict,
                        "l0c_shape": cube_util.shape_to_list(dx_col.shape),
                        "kernel_name": self._kernel_name
                    }
            )
        else:
            # fp32, one cin_g is an integer multiple of eight, ex 1*8, 2*8, 3*8 and so on
            # floordmod(dx_cin1_idx, _cin1_g) obtains the sequence number of the index in one cin_g
            # the length of each index is 8
            # 8*floormod(floordmod(dx_cin1_idx, _cin1_g), 2) obtains the first eight or the second eight in 16
            # because cin0 of l0c is 16
            dx_ddr = tvm.compute(
                out_shape,
                lambda dx_batch_idx, dx_cin1_idx, dx_hw_idx, dx_cin0_idx:
                    dx_col[dx_cin1_idx // self._cin1_g,
                           dx_batch_idx,
                           dx_cin1_idx % self._cin1_g // 2,
                           dx_hw_idx,
                           dx_c0 * (dx_cin1_idx % self._cin1_g % 2) + dx_cin0_idx
                    ].astype(output_dtype),
                    name="c_ddr",
                    tag="conv2d_backprop_input",
                    attrs={
                        "output_shape": self._output_shape,
                        "output_dtype": self.output_dtype,
                        "group_dict": self._group_dict,
                        "l0c_shape": cube_util.shape_to_list(dx_col.shape),
                        "kernel_name": self._kernel_name
                    }
            )
        return dx_ddr

    def _get_dx_ub(self, dx_col, output_dtype):
        dx_cin1 = self._output_shape[1]
        dx_w = self._output_shape[-2]
        if self.split_axis_mode == SplitAxisMode.split_w.value:
            _, dx_batch, dx_h, _, dx_w, dx_c0 = cube_util.shape_to_list(dx_col.shape)
            ub_shape = (dx_batch, dx_cin1, dx_h, dx_w, dx_c0)
            dx_ub = tvm.compute(
                ub_shape,
                lambda dx_batch_idx, dx_cin1_idx, dx_h_idx, dx_w_idx, dx_cin0_idx: dx_col[
                    dx_cin1_idx // self._cin1_g, dx_batch_idx, dx_h_idx,
                    dx_cin1_idx % self._cin1_g, dx_w_idx, dx_cin0_idx
                ].astype(output_dtype),
                name="c_ub"
            )
        else:
            _, dx_batch, _, dx_hw, dx_c0 = cube_util.shape_to_list(dx_col.shape)
            ub_shape = (dx_batch, dx_cin1, dx_hw, dx_c0)
            dx_ub = tvm.compute(
                ub_shape,
                lambda dx_batch_idx, dx_cin1_idx, dx_hw_idx, dx_cin0_idx: dx_col[
                    dx_cin1_idx // self._cin1_g, dx_batch_idx,
                    dx_cin1_idx % self._cin1_g, dx_hw_idx, dx_cin0_idx
                ].astype(output_dtype),
                name="c_ub"
            )
        return dx_ub

    def _get_gm_from_l0c(self, out_shape, dx_col, output_dtype):
        dx_w = self._output_shape[-2]
        attrs = {
            "output_shape": self._output_shape, "output_dtype": self.output_dtype, "group_dict": self._group_dict,
            "l0c_shape": cube_util.shape_to_list(dx_col.shape), "kernel_name": self._kernel_name
        }
        if self.split_axis_mode == SplitAxisMode.split_w.value:
            if self._real_g == 1:
                dx_ddr = tvm.compute(
                    out_shape,
                    lambda dx_batch_idx, dx_cin1_idx, dx_hw_idx, dx_cin0_idx: dx_col[
                        0, dx_batch_idx, dx_hw_idx // dx_w, dx_cin1_idx, dx_hw_idx % dx_w, dx_cin0_idx
                    ].astype(output_dtype),
                    name="c_ddr",
                    tag="conv2d_backprop_input",
                    attrs=attrs
                )
            else:
                dx_ddr = tvm.compute(
                    out_shape,
                    lambda dx_batch_idx, dx_cin1_idx, dx_hw_idx, dx_cin0_idx: dx_col[
                        dx_cin1_idx // self._cin1_g, dx_batch_idx, dx_hw_idx // dx_w,
                        dx_cin1_idx % self._cin1_g, dx_hw_idx % dx_w, dx_cin0_idx
                    ].astype(output_dtype),
                    name="c_ddr",
                    tag="conv2d_backprop_input",
                    attrs=attrs
                )
        else:
            if self._real_g == 1:
                dx_ddr = tvm.compute(
                    out_shape,
                    lambda dx_batch_idx, dx_cin1_idx, dx_hw_idx, dx_cin0_idx: dx_col[
                        0, dx_batch_idx, dx_cin1_idx, dx_hw_idx, dx_cin0_idx
                    ].astype(output_dtype),
                    name="c_ddr",
                    tag="conv2d_backprop_input",
                    attrs=attrs
                )
            else:
                dx_ddr = tvm.compute(
                    out_shape,
                    lambda dx_batch_idx, dx_cin1_idx, dx_hw_idx, dx_cin0_idx: dx_col[
                        dx_cin1_idx // self._cin1_g, dx_batch_idx, dx_cin1_idx % self._cin1_g, dx_hw_idx, dx_cin0_idx
                    ].astype(output_dtype),
                    name="c_ddr",
                    tag="conv2d_backprop_input",
                    attrs=attrs
                )
        return dx_ddr

    def _get_gm_from_ub(self, dx_ub, out_shape, dx_col):
        dx_w = self._output_shape[-2]
        if self.split_axis_mode == SplitAxisMode.split_w.value:
            dx_ddr = tvm.compute(
                out_shape,
                lambda dx_batch_idx, dx_cin1_idx, dx_hw_idx, dx_cin0_idx: dx_ub[
                    dx_batch_idx, dx_cin1_idx, dx_hw_idx // dx_w,
                    self.load3d_special_multiply * (dx_hw_idx % dx_w), dx_cin0_idx
                ],
                name="c_ddr",
                tag="conv2d_backprop_input",
                attrs={
                    "output_shape": self._output_shape,
                    "output_dtype": self.output_dtype,
                    "group_dict": self._group_dict,
                    "l0c_shape": cube_util.shape_to_list(dx_col.shape),
                    "kernel_name": self._kernel_name
                }
            )
        else:
            dx_ddr = tvm.compute(
                out_shape,
                lambda dx_batch_idx, dx_cin1_idx, dx_hw_idx, dx_cin0_idx: dx_ub[
                    dx_batch_idx, dx_cin1_idx, self.load3d_special_multiply * dx_hw_idx, dx_cin0_idx
                ],
                name="c_ddr",
                tag="conv2d_backprop_input",
                attrs={
                    "output_shape": self._output_shape,
                    "output_dtype": self.output_dtype,
                    "group_dict": self._group_dict,
                    "l0c_shape": cube_util.shape_to_list(dx_col.shape),
                    "kernel_name": self._kernel_name
                }
            )
        return dx_ddr
