#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2023-2024 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
classifier of shape in generic vector
"""
import copy
import dataclasses

from tbe.common.utils.errormgr import get_error_message
from tbe.dsl.base.operation import get_context

from . import shape_classifier
from . import util


def _raise_error(error_message, error_code="E90001"):
    """
    raise error
    """
    dict_args = {"errCode": error_code, "detailed_cause": error_message}
    raise RuntimeError(dict_args, get_error_message(dict_args))


def _check_true(condition, error_message, error_code="E90001"):
    if not condition:
        _raise_error(error_message, error_code)


def _convert_value_to_positive(ori_axes_list, max_dim_len):
    """
    convert negative value to positive
    -1 -> -1 + max_dim_len
    """
    _check_true(isinstance(ori_axes_list, list),
                "ori_axes_list must be a list in func of _convert_value_to_positive.")

    local_axes_list = ori_axes_list[:]

    return [x + max_dim_len if x < 0 else x for x in local_axes_list]


def _get_max_shape(shape_list):
    max_dim_length = max(len(t) for t in shape_list)
    max_shape = [1] * max_dim_length

    for cur_shape in shape_list:
        diff_length = max_dim_length - len(cur_shape)
        for idx in range(max_dim_length):
            cur_dim = 1 if idx < diff_length else cur_shape[idx - diff_length]
            if max_shape[idx] != cur_dim:
                max_shape[idx] = max(max_shape[idx], cur_dim)

    return max_shape


def _get_broadcast_axes(max_shape, cur_shape):
    max_length = len(max_shape)
    cur_length = len(cur_shape)
    # add 1 to the front
    if cur_length < max_length:
        cur_shape = [1] * (max_length - cur_length) + cur_shape

    broadcast_axes = []
    for idx in range(max_length):
        if cur_shape[idx] != max_shape[idx]:
            broadcast_axes.append(idx)

    return broadcast_axes


@dataclasses.dataclass
class InputInfo:
    """
    input info
    """
    shape: list = dataclasses.field(default_factory=list)
    shape_range: list = dataclasses.field(default_factory=list)
    broadcast_axes: list = dataclasses.field(default_factory=list)


class GenericVectorExtraInfo:
    """
    generic vector classify info
    """
    def __init__(self, extra_params):
        """
        generic vector classify info init
        """
        self._check_extra_params(extra_params)
        self._extra_params = extra_params
        self._reduce_axes = self._parse_reduce_axes()
        self._disable_fuse_axes = self._parse_disable_fuse_axes()

    @property
    def extra_params(self):
        return self._extra_params

    @property
    def reduce_axes(self):
        return self._reduce_axes

    @property
    def disable_fuse_axes(self):
        return self._disable_fuse_axes

    @staticmethod
    def _check_extra_params(extra_params):
        """
        check extra_params
        """
        _check_true(extra_params is None or isinstance(extra_params, dict),
                    "extra_params must be a dict or None when mode is generic vector.")

    @staticmethod
    def _check_reduce_axes(reduce_axes):
        """
        check extra_params
        """
        _check_true(isinstance(reduce_axes, (list, tuple)),
                    "reduce_axes must be a list or tuple when mode is generic vector.")

    @staticmethod
    def _check_disable_fuse_axes(disable_fuse_axes):
        """
        check disable_fuse_axes
        """
        _check_true(all(x >= 0 for x in disable_fuse_axes), "element in disable_fuse_axes must be positive.")

    def _parse_reduce_axes(self):
        """
        parse reduce_axes
        """
        if self.extra_params is None:
            return []

        reduce_axes = []
        if "reduce_axes" in self.extra_params:
            reduce_axes = self.extra_params.get("reduce_axes")
            self._check_reduce_axes(reduce_axes)

        return list(reduce_axes)

    def _parse_disable_fuse_axes(self):
        """
        parse disable_fuse_axes
        """
        if self.extra_params is None:
            return []

        disable_fuse_axes = []
        if "disable_fuse_axes" in self.extra_params:
            disable_fuse_axes = self.extra_params.get("disable_fuse_axes")
            self._check_disable_fuse_axes(disable_fuse_axes)

        return disable_fuse_axes


@shape_classifier.register_classifier(shape_classifier.GENERIC_VECTOR)
def classify(ins: list, extra_params: dict):
    """
    classify
    :param ins: inputs list
    :param extra_params: a dict with the following keys:
        "reduce_axes": list, reduce_axes.
    :return:
    """
    get_context().set_pattern("GenericVector")

    extra_info = GenericVectorExtraInfo(extra_params)
    generic_vector_classifier = GenericVectorClassifier(ins, extra_info)

    return generic_vector_classifier.classify()


class GenericVectorClassifier:
    """
    generic vector classifier
    """
    def __init__(self, inputs: list, extra_info: GenericVectorExtraInfo):
        """
        generic vector classifier init
        """
        self._ori_inputs = inputs
        self._extra_info = extra_info

        self._max_shape = _get_max_shape([x.get("shape") for x in inputs])
        self._max_shape_len = len(self._max_shape)
        self._reduce_axes = _convert_value_to_positive(extra_info.reduce_axes, self._max_shape_len)
        self._disable_fuse_axes = extra_info.disable_fuse_axes[:]

        self._input_info_list = self._gen_input_info_list()

    def classify(self):
        """
        generate generic vector classifier out
        """
        self._fuse()
        classify_output_list = [copy.deepcopy(self._ori_inputs)]
        for idx, single_output in enumerate(classify_output_list[0]):
            single_output["shape"] = self._input_info_list[idx].shape
            single_output["range"] = self._input_info_list[idx].shape_range

        if self._reduce_axes:
            classify_output_list[0].append(self._reduce_axes)

        return classify_output_list

    def _gen_input_info_list(self):
        input_info_list = []

        for single_input in self._ori_inputs:
            shape = list(single_input.get("shape"))
            if single_input.get("range") is None:
                shape_range = [(1, None)] * len(shape)
            else:
                shape_range = list(single_input.get("range"))

            ori_shape_len = len(shape)
            if ori_shape_len < self._max_shape_len:
                shape = [1] * (self._max_shape_len - ori_shape_len) + shape
                shape_range = [(1, 1)] * (self._max_shape_len - ori_shape_len) + shape_range
            broadcast_axes = _get_broadcast_axes(self._max_shape, shape)

            input_info_list.append(InputInfo(shape, shape_range, broadcast_axes))

        return input_info_list

    def _gen_axes_state_list(self):
        state_list = []
        for dim_idx in range(self._max_shape_len):
            if dim_idx in self._disable_fuse_axes:
                state_list.append(f"disable_{dim_idx}")
                continue
            is_reduce = dim_idx in self._reduce_axes
            is_broadcast = False
            broadcast_state = "broadcast"
            for input_idx, input_info in enumerate(self._input_info_list):
                if dim_idx in input_info.broadcast_axes:
                    broadcast_state = f"{broadcast_state}_{input_idx}"
                    is_broadcast = True
            if is_reduce and not is_broadcast:
                state_list.append("reduce")
            elif not is_reduce and is_broadcast:
                state_list.append(broadcast_state)
            elif is_reduce and is_broadcast:
                state_list.append(f"reduce_{broadcast_state}")
            else:
                state_list.append("common")

        return state_list

    def _fuse(self):
        state_list = self._gen_axes_state_list()

        for input_info in self._input_info_list:
            f_shape, f_ranges, f_reduce_axes, f_disable_fuse_axes = [], [], [], []
            state = "init"
            for idx, state_i in enumerate(state_list):
                if state == state_i:
                    f_shape[-1] = util.combine_dim([f_shape[-1], input_info.shape[idx]])
                    f_ranges[-1] = util.combine_range([f_ranges[-1], input_info.shape_range[idx]])
                else:
                    f_shape.append(input_info.shape[idx])
                    f_ranges.append(input_info.shape_range[idx])

                if "reduce" in state_i:
                    reduce_axis_idx = len(f_shape) - 1
                    append_reduce_axis = not f_reduce_axes or f_reduce_axes[-1] != reduce_axis_idx
                    if append_reduce_axis:
                        f_reduce_axes.append(reduce_axis_idx)

                if "disable" in state_i:
                    f_disable_fuse_axes.append(len(f_shape) - 1)

                state = state_i

            input_info.shape = f_shape
            input_info.shape_range = f_ranges
            self._reduce_axes = f_reduce_axes
            self._disable_fuse_axes = f_disable_fuse_axes
