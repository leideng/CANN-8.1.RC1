#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2022-2023 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
pooling grad with arg variable shape
"""
import enum
from functools import reduce
from tbe.common.utils.varshape.variable_shape import register_variable
from tbe.dsl.base import operation

_BLOCK_SIZE = 16
UNKNOWN_VALUE = -1
DIM_0 = 0
DIM_1 = 1
DIM_2 = 2
DIM_3 = 3
DIM_4 = 4
DIM_5 = 5
INPUT_X_INDEX = 0
INPUT_GRAD_INDEX = 1
INPUT_ARGMAX_INDEX = 2
INPUT_KSIZE_INDEX = 3
INPUT_STRIDES_INDEX = 4
INPUT_PADDING_INDEX = 5
INPUT_FORMAT_INDEX = 6


def get_format(format_info):
    format_dict = {"NC1HWC0": 0, "NCHW": 1, "NHWC": 2}
    return format_dict.get(format_info)


def variable_shape_4d(inputs):
    op_mode = operation.get_op_mode()
    if inputs[INPUT_FORMAT_INDEX].get("format") == "NCHW":
        if op_mode == "dynamic":
            var_n = operation.var_inner(
                "_x_dim_0_value", inputs[INPUT_X_INDEX].get("range")[DIM_0])
            var_c = operation.var_inner(
                "_x_dim_1_value", inputs[INPUT_X_INDEX].get("range")[DIM_1])
            var_hi = operation.var_inner(
                "_x_dim_2_value", inputs[INPUT_X_INDEX].get("range")[DIM_2])
            var_wi = operation.var_inner(
                "_x_dim_3_value", inputs[INPUT_X_INDEX].get("range")[DIM_3])
            var_ho = operation.var_inner(
                "_grad_dim_2_value", inputs[INPUT_GRAD_INDEX].get("range")[DIM_2])
            var_wo = operation.var_inner(
                "_grad_dim_3_value", inputs[INPUT_GRAD_INDEX].get("range")[DIM_3])
        else:
            var_n = inputs[INPUT_X_INDEX].get("shape")[DIM_0]
            var_c = inputs[INPUT_X_INDEX].get("shape")[DIM_1]
            var_hi = inputs[INPUT_X_INDEX].get("shape")[DIM_2]
            var_wi = inputs[INPUT_X_INDEX].get("shape")[DIM_3]
            var_ho = inputs[INPUT_GRAD_INDEX].get("shape")[DIM_2]
            var_wo = inputs[INPUT_GRAD_INDEX].get("shape")[DIM_3]
    else:
        pass
    var_ksize_list = []
    for i, ksize_value in enumerate(inputs[INPUT_KSIZE_INDEX].get("ksize")):
        if ksize_value == UNKNOWN_VALUE:
            var_ksize_list.append(operation.var_inner(f"_window_{i}_value", (1, None)))
        else:
            var_ksize_list.append(ksize_value)
    var_stride_list = []
    for i, stride_value in enumerate(inputs[INPUT_STRIDES_INDEX].get("strides")):
        if stride_value == UNKNOWN_VALUE:
            var_stride_list.append(operation.var_inner(f"_stride_{i}_value", (1, None)))
        else:
            var_stride_list.append(stride_value)
    var_pad_list = []
    for i, pad_value in enumerate(inputs[INPUT_PADDING_INDEX].get("pads")):
        if pad_value == UNKNOWN_VALUE:
            var_pad_list.append(operation.var_inner(f"_padding_{i}_value", (0, None)))
        else:
            var_pad_list.append(pad_value)
    current_operator = operation.get_context()
    if current_operator:
        current_compute = current_operator.get_current_compute()
        if current_compute:
            current_compute.add("_mode", op_mode)
            current_compute.add("_strategy", "common")
            current_compute.add(
                "_pad_info", var_pad_list)
            current_compute.add("_window_info", [reduce(
                (lambda x, y: x * y), var_ksize_list)])
            current_compute.add("_kernel_info", var_ksize_list)
            current_compute.add("_strides_info", var_stride_list)
            current_compute.add("_format_info", get_format(
                inputs[INPUT_FORMAT_INDEX].get("format")))
    if inputs[INPUT_FORMAT_INDEX].get("format") == "NCHW":
        shape_x = [var_n * var_c, var_hi, var_wi]
        shape_grad = [var_n * var_c, var_ho, var_wo]
        shape_argmax = [var_n * var_c, var_ho, var_wo]
    else:
        shape_x = [var_n, var_hi, var_wi, var_c]
        shape_grad = [var_n, var_ho, var_wo, var_c]
        shape_argmax = [var_n, var_ho, var_wo, var_c]
    ksize = var_ksize_list
    strides = var_stride_list
    paddings = var_pad_list
    return [shape_x, shape_grad, shape_argmax, ksize, strides, paddings]


@register_variable("pooling_grad_with_arg")
def variable_shape(inputs):
    if len(inputs[INPUT_X_INDEX].get("shape")) == 4:
        return variable_shape_4d(inputs)
    op_mode = operation.get_op_mode()
    if op_mode == "dynamic":
        var_n = operation.var_inner(
            "_x_dim_0_value", inputs[INPUT_X_INDEX].get("range")[DIM_0])
        var_di = operation.var_inner("_x_dim_1_value", inputs[INPUT_X_INDEX].get(
            "range")[DIM_1]) if inputs[INPUT_X_INDEX].get("shape")[DIM_1] == -1 \
            else inputs[INPUT_X_INDEX].get("shape")[DIM_1]
        var_c1 = operation.var_inner(
            "_x_dim_2_value", inputs[INPUT_X_INDEX].get("range")[DIM_2])
        var_hi = operation.var_inner(
            "_x_dim_3_value", inputs[INPUT_X_INDEX].get("range")[DIM_3])
        var_wi = operation.var_inner(
            "_x_dim_4_value", inputs[INPUT_X_INDEX].get("range")[DIM_4])
        var_c0 = inputs[INPUT_X_INDEX].get("shape")[DIM_5]

        var_do = operation.var_inner("_grad_dim_1_value", inputs[INPUT_GRAD_INDEX].get(
            "range")[DIM_1]) if inputs[INPUT_GRAD_INDEX].get("shape")[DIM_1] == -1 \
            else inputs[INPUT_GRAD_INDEX].get("shape")[DIM_1]
        var_ho = operation.var_inner(
            "_grad_dim_3_value", inputs[INPUT_GRAD_INDEX].get("range")[DIM_3])
        var_wo = operation.var_inner(
            "_grad_dim_4_value", inputs[INPUT_GRAD_INDEX].get("range")[DIM_4])
    else:
        var_n = inputs[INPUT_X_INDEX].get("shape")[DIM_0]
        var_di = inputs[INPUT_X_INDEX].get("shape")[DIM_1]
        var_c1 = inputs[INPUT_X_INDEX].get("shape")[DIM_2]
        var_hi = inputs[INPUT_X_INDEX].get("shape")[DIM_3]
        var_wi = inputs[INPUT_X_INDEX].get("shape")[DIM_4]
        var_c0 = inputs[INPUT_X_INDEX].get("shape")[DIM_5]

        var_do = inputs[INPUT_GRAD_INDEX].get("shape")[DIM_1]
        var_ho = inputs[INPUT_GRAD_INDEX].get("shape")[DIM_3]
        var_wo = inputs[INPUT_GRAD_INDEX].get("shape")[DIM_4]

    var_ksize_list = []
    for i, ksize_value in enumerate(inputs[INPUT_KSIZE_INDEX].get("ksize")):
        var_ksize_list.append(operation.var_inner(
            f"_window_{i}_value", (1, None)) if ksize_value == UNKNOWN_VALUE else ksize_value)

    var_stride_list = []
    for i, stride_value in enumerate(inputs[INPUT_STRIDES_INDEX].get("strides")):
        var_stride_list.append(operation.var_inner(
            f"_stride_{i}_value", (1, None)) if stride_value == UNKNOWN_VALUE else stride_value)

    var_pad_list = []
    for i, pad_value in enumerate(inputs[INPUT_PADDING_INDEX].get("pads")):
        var_pad_list.append(operation.var_inner(
            f"_padding_{i}_value", (0, None)) if pad_value == UNKNOWN_VALUE else pad_value)

    current_operator = operation.get_context()
    if current_operator:
        current_compute = current_operator.get_current_compute()
        if current_compute:
            current_compute.add("_mode", op_mode)
            current_compute.add("_strategy", "common")
            current_compute.add(
                "_pad_info", var_pad_list)
            current_compute.add("_window_info", [reduce(
                (lambda x, y: x * y), var_ksize_list)])
            current_compute.add("_kernel_info", var_ksize_list)
            current_compute.add("_strides_info", var_stride_list)
            current_compute.add("_format_info", get_format(inputs[INPUT_FORMAT_INDEX].get("format")))

    shape_x = [var_n, var_di, var_c1, var_hi, var_wi, var_c0]
    shape_grad = [var_n, var_do, var_c1, var_ho, var_wo, var_c0]
    shape_argmax = [var_n, var_do, var_c1, reduce((lambda x, y: x * y), var_ksize_list),
                    (var_ho * var_wo + _BLOCK_SIZE - 1) // _BLOCK_SIZE * _BLOCK_SIZE, var_c0]
    ksize = var_ksize_list
    strides = var_stride_list
    paddings = var_pad_list
    return [shape_x, shape_grad, shape_argmax, ksize, strides, paddings]
