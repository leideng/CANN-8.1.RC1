#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright(C) 2022. Huawei Technologies Co., Ltd. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
transdata-graph
"""
from typing import Dict, List, Optional
from typing import Set, Iterable
from tbe.tvm import Tensor
from tbe.tvm import PlaceholderOp
from tbe.dsl.classifier.transdata.constants import intrinsic_check_support


class Graph:
    """
    Graph: collect info by DFS
    """

    def __init__(self, output_tensors: Iterable[Tensor]):
        # OutputTensors
        self.output_tensor_set = set()
        self.real_output_tensor_set = set()
        # InputTensors
        self.input_tensor_set = set()
        self.non_gm_input_tensor_set = set()
        # MiddleTensors
        self.mid_output_tensor_set = set()
        self.mid_tensor_set = set()
        self.endpoint_output_tensor_set = set()
        # TransDataTensors
        self.transpose_tensor_set = set()
        self.pad_tensor_set = set()
        self.de_pad_tensor_set = set()
        self.f_reshape_tensor_set = set()
        self.s_reshape_tensor_set = set()

        self.tensor_list: Optional[List[Tensor]] = list()
        self.exist_nodes: Optional[Dict] = None
        self.tensor_consumers_map: Optional[Dict[Tensor, Set[Tensor]]] = None
        self.tensor_producers_map: Optional[Dict[Tensor, Set[Tensor]]] = None

        self._collect(output_tensors)
        self._max_ub_count()

    @staticmethod
    def dfs_compute_graph(root, hooks):
        """
        compute graph using dfs algorithm
        """

        def recursive_func(_root, _visited_list, _tensor_consumers_map, _tensor_producers_map, _hooks):
            _visited_list.add(_root)
            _tensor_producers_map.setdefault(_root, set())
            _tensor_consumers_map.setdefault(_root, set())
            for hook in hooks:
                hook(_root)
            for in_tensor in _root.op.input_tensors:
                _tensor_consumers_map.setdefault(in_tensor, set())
                _tensor_consumers_map[in_tensor].add(_root)
                _tensor_producers_map[_root].add(in_tensor)
                recursive_func(in_tensor, _visited_list, _tensor_consumers_map, _tensor_producers_map, _hooks)

        visited_list = set()
        tensor_consumers_map = {}
        tensor_producers_map = {}
        if isinstance(root, (list, tuple, set)):
            for tensor in root:
                recursive_func(tensor, visited_list, tensor_consumers_map, tensor_producers_map, hooks)
        elif isinstance(root, Tensor):
            recursive_func(root, visited_list, tensor_consumers_map, tensor_producers_map, hooks)
        else:
            raise RuntimeError("dfs_compute_graph() supports list, tuple, Tensor only. Received %s"
                               % str(type(root)))
        return list(visited_list), tensor_consumers_map, tensor_producers_map

    def get_all_producers_computes(self, tensor):
        """
        Get all parents for tensor.
        """
        parents = set()
        for parent in self.tensor_producers_map.get(tensor, None):
            parents.add(parent)
            parents.update(self.get_all_producers_computes(parent))
        return parents

    def _gen_endpoint_output_tensor_set(self):
        """
        get pure endpoint output tensors without middle output tensors
        """
        for output_tensor in self.output_tensor_set:
            if not self.tensor_consumers_map.get(output_tensor, None):
                self.endpoint_output_tensor_set.add(output_tensor)

    def _gen_mid_tensor_sets(self):
        """
        get  middle tensors(with middle output tensors) and middle output tensors
        """
        for tensor in self.tensor_list:
            if tensor in self.output_tensor_set and self.tensor_consumers_map.get(tensor, None):
                # Tensor in output and has consumers is middle_out_tensor
                self.mid_output_tensor_set.add(tensor)
                self.mid_tensor_set.add(tensor)
            elif tensor not in self.output_tensor_set | self.input_tensor_set | self.non_gm_input_tensor_set:
                self.mid_tensor_set.add(tensor)

    def _collect(self, output_tensors: Iterable[Tensor]):
        def _add_input_tensor_set(_tensor):
            if isinstance(_tensor.op, PlaceholderOp):
                self.input_tensor_set.add(_tensor)
            elif not _tensor.op.input_tensors:
                self.non_gm_input_tensor_set.add(_tensor)

        def _add_transpose_tensor(_tensor):
            if _tensor.op.tag.find("transdata|transpose") != -1:
                self.transpose_tensor_set.add(_tensor)

        def _add_pad_tenspr(_tensor):
            if _tensor.op.tag.find("transdata|pad") != -1:
                self.pad_tensor_set.add(_tensor)

        def _add_depad_tensor(_tensor):
            if _tensor.op.tag.find("transdata|depad") != -1:
                self.de_pad_tensor_set.add(_tensor)

        def _add_f_reshape_tensor(_tensor):
            if _tensor.op.tag.find("transdata|f_reshape") != -1:
                self.f_reshape_tensor_set.add(_tensor)

        def _add_s_reshape_tensor(_tensor):
            if _tensor.op.tag.find("transdata|s_reshape") != -1:
                self.s_reshape_tensor_set.add(_tensor)

        self.output_tensor_set = set(output_tensors)
        self.tensor_list, self.tensor_consumers_map, self.tensor_producers_map = \
            self.dfs_compute_graph(self.output_tensor_set,
                                   (
                                    _add_input_tensor_set,
                                    _add_transpose_tensor,
                                    _add_pad_tenspr,
                                    _add_depad_tensor,
                                    _add_f_reshape_tensor,
                                    _add_s_reshape_tensor
                                   ))
        # Initialize non-hookable info
        self._gen_mid_tensor_sets()
        # endpoint_output_tensor_set
        self._gen_endpoint_output_tensor_set()

    def _max_ub_count(self):

        def calc_instr_space(_tensor, space):
            def transpose():
                perm = [int(x) for x in _tensor.op.attrs["permute"]]
                if perm[-1] != len(perm) - 1 and dtype in ["float32", "int32", "uint32"]:
                    space.extend([dtype] if intrinsic_check_support() else [dtype] * 3)
                else:
                    space.append(dtype)

            dtype = _tensor.dtype
            if _tensor in self.transpose_tensor_set:
                transpose()
            else:
                space.append(dtype)

        def refresh(_tensor):
            for i in _tensor.op.input_tensors:
                if i not in dependent:
                    continue
                dependent.get(i, None).remove(_tensor)
                if not dependent.get(i, None):
                    dependent.pop(i)

            if _tensor not in dependent:
                dependent[_tensor] = self.tensor_consumers_map.get(_tensor, None).copy()

        def update_nodes(_tensor, space):
            if _tensor in dependent:
                space.append([i.dtype for i in dependent.keys()])
                return

            for j in _tensor.op.input_tensors:
                update_nodes(j, space)

            curr_space = [i.dtype for i in dependent.keys()]
            calc_instr_space(_tensor, curr_space)
            space.append(curr_space)

            refresh(_tensor)

        # Seek nodes
        nodes, dependent = [], {}
        _out = list(self.output_tensor_set)[0]
        for tensor in _out.op.input_tensors:
            update_nodes(tensor, nodes)

        # Deal last nodes
        curr_nodes = [i.dtype for i in dependent.keys()]
        calc_instr_space(_out, curr_nodes)
        nodes.append(curr_nodes)
        self.exist_nodes = nodes
