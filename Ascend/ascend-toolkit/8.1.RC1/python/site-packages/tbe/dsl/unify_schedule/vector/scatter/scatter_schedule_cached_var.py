#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2022 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
scatter schedule cached var
"""
from ...schedule import Schedule
from .scatter_tilingcase import TilingStrategy
from .scatter_schedule_base import ScatterBaseSchedule

# Represents the axis that does not need to be split
DUMMY_DIM = -10


# 'pylint: disable=R0902, R0903
class ScatterCacheSchedule(ScatterBaseSchedule):
    """
    scatter schedule
    """

    def _do_tiling(self):
        if self._tiling_strategy == TilingStrategy.DYNAMIC:
            b_idx = self._tiling_case["block_tiling_norm_axis"]
            u_idx_norm = self._tiling_case["ub_tiling_norm_axis"]
            u_idx_sparse = self._tiling_case["ub_tiling_sparse_axis"]

            block_factor = self._block_tiling_vars.get(b_idx)
            ub_norm_factor = self._ub_norm_tiling_vars.get(u_idx_norm)
            ub_sparse_factor = self._ub_sparse_tiling_vars.get(u_idx_sparse)
        else:
            b_idx = self._const_block_axis
            u_idx_norm = self._const_ub_norm_axis if self._const_ub_norm_axis != DUMMY_DIM else None
            u_idx_sparse = self._const_ub_sparse_axis

            block_factor = self._const_block_factor
            ub_norm_factor = self._const_ub_norm_factor
            ub_sparse_factor = self._const_ub_sparse_factor

        b_o, b_i = self._schedule[self._out_tensor].split(self._out_tensor.op.axis[b_idx],
                                                          factor=block_factor)

        if u_idx_norm is not None:
            self._is_split_last_axis = u_idx_norm == (len(self._out_tensor.shape) - 1)
            if u_idx_norm == b_idx:
                u_norm_o, u_norm_i = self._schedule[self._out_tensor].split(b_i,
                                                                            factor=ub_norm_factor)
            else:
                u_norm_o, u_norm_i = self._schedule[self._out_tensor].split(self._out_tensor.op.axis[u_idx_norm],
                                                                            factor=ub_norm_factor)

        if u_idx_sparse is not None:
            u_sparse_o, u_sparse_i = self._schedule[self._scatter_ub].split(
                self._scatter_ub.op.sparse_axis[u_idx_sparse], factor=ub_sparse_factor)
            self._reorder_axis.extend([u_sparse_o, u_sparse_i])

        for i in range(len(self._scatter_ub.op.axis)):
            self._reorder_axis.append(self._scatter_ub.op.axis[i])

        self._block_bind_axis = b_o
        self._compute_at_norm_axis = u_norm_o if u_idx_norm is not None else b_i
        self._compute_at_sparse_axis = u_sparse_o if u_idx_sparse is not None else self._scatter_ub.op.sparse_axis[0]
        self._emit_axis = u_idx_sparse if u_idx_sparse is not None else -1
        self._emit_scatter_axis = u_norm_i if u_idx_norm is not None else b_i

    def _do_storage_align(self):
        if self._is_need_storage_align and not self._is_need_align_pad:
            self._schedule[self._var_ub].storage_align(self._var_ub.op.axis[-2],
                                                       self._align_factor, 0)
            self._schedule[self._update_ub].storage_align(self._update_ub.op.axis[-2],
                                                          self._align_factor, 0)
            self._schedule[self._scatter_ub].storage_align(self._scatter_ub.op.axis[-2],
                                                           self._align_factor, 0)
        if self._is_need_align_pad:
            self._schedule[self._update_align_pad_ub].storage_align(self._update_align_pad_ub.op.axis[-2],
                                                                    self._align_factor, 0)
            self._schedule[self._var_align_pad_ub].storage_align(self._var_align_pad_ub.op.axis[-2],
                                                                 self._align_factor, 0)
            self._schedule[self._scatter_ub].storage_align(self._scatter_ub.op.axis[-2],
                                                           self._align_factor, 0)

    def _calc_compute_at(self):
        compute_axis = self._scatter_ub.op.axis[-1] if self._is_split_last_axis else self._compute_at_sparse_axis
        self._compute_at_map[self._indices_ub] = [self._scatter_ub, self._compute_at_sparse_axis]
        self._compute_at_map[self._update_ub] = [self._scatter_ub, compute_axis]
        if self._is_need_align_pad:
            self._compute_at_map[self._update_align_pad_ub] = [self._scatter_ub, compute_axis]

        self._compute_at_map[self._var_ub] = [self._out_tensor, self._compute_at_norm_axis]
        if self._is_need_align_pad:
            self._compute_at_map[self._var_align_pad_ub] = [self._out_tensor, self._compute_at_norm_axis]

        self._compute_at_map[self._scatter_ub] = [self._out_tensor, self._compute_at_norm_axis]
        if self._is_need_remove_pad:
            self._compute_at_map[self._remove_pad_ub] = [self._out_tensor, self._compute_at_norm_axis]

    def _calc_emit_insn(self):
        self._emit_insn_map[self._indices_ub] = [self._indices_ub.op.axis[0], "dma_copy"]
        self._emit_insn_map[self._update_ub] = [self._update_ub.op.axis[self._emit_axis], "dma_copy",
                                                {"gm_to_ub_gap_out": 1}]
        self._emit_insn_map[self._var_ub] = [self._var_ub.op.axis[self._emit_axis], "dma_copy"]
        if self._is_need_align_pad:
            self._emit_insn_map[self._update_align_pad_ub] = [self._update_align_pad_ub.op.axis[self._emit_axis],
                                                              "align_pad"]
            self._emit_insn_map[self._var_align_pad_ub] = [self._var_align_pad_ub.op.axis[self._emit_axis],
                                                           "align_pad"]
        self._emit_insn_map[self._scatter_ub] = [self._scatter_ub.op.axis[-1], "vector_auto"]
        if self._is_need_remove_pad:
            self._emit_insn_map[self._remove_pad_ub] = [self._remove_pad_ub.op.axis[self._emit_axis],
                                                        "remove_pad"]
        self._emit_insn_map[self._out_tensor] = [self._emit_scatter_axis, "dma_copy", {"no_overlap": 2}]
        self._schedule[self._out_tensor].pragma(self._emit_scatter_axis, "loop_with_no_overlap_tensor",
                                                pragma_tensor=self._out_tensor)
