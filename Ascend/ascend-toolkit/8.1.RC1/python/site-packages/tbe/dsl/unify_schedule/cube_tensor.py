#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2022-2023 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
cube tensor util
"""
from tbe.common.platform import platform_info as tbe_platform_info
from tbe.dsl.static_schedule.util import get_all_tensor


class TensorCube:
    """
    use to get tensor for cube
    """

    def __init__(self, res_list):
        self.res_list = res_list
        self.tensor_map = {}
        self.para_map = {}
        self.last_tensor = self._process_multioutput()
        self.all_tensor = get_all_tensor(self.last_tensor)
        self.compute_tensors, self.placeholder_tensors, self.output_tensors = self.all_tensor
        self.compute_tensors["res"] = self.compute_tensors.pop(self.last_tensor.op.name)

    def _process_multioutput(self):
        """
        handle the multi output
        """
        return self.res_list[-1]

    def _get_single_cube_tensor(self):
        """
        get the tensor in cube calculation
        """
        self.tensor_map["a_l0a"] = self.compute_tensors.get("tensor_a_zz")
        if tbe_platform_info.get_soc_spec("L0A_LAYOUT_IS_zN"):
            self.tensor_map["a_l0a"] = self.compute_tensors.get("tensor_a_nz")
        self.tensor_map["b_l0b"] = self.compute_tensors.get("tensor_b_zn")
        self.tensor_map["c_l0c"] = self.compute_tensors.get("tensor_mmad")
        # fb bias is add in c matrix, l0c with 3 inputs
        if len(self.tensor_map.get("c_l0c").op.input_tensors) == 3:
            # the index 2 is bias
            tensor_bias = self.tensor_map.get("c_l0c").op.input_tensors[2]
            if "tensor_bias_f162f32" == tensor_bias.op.name:
                # if bias is need cast, the result tensor must be in bias bt
                self.tensor_map["bias_bt"] = tensor_bias
                self.tensor_map["bias"] = tensor_bias.op.input_tensors[0]
            else:
                self.tensor_map["bias"] = tensor_bias

        # add bias in l0c
        self.tensor_map["bias_ub"] = self.compute_tensors.get("tensor_bias_ub")
        self.tensor_map["bias_ub_fp16"] = self.compute_tensors.get("tensor_bias_ub_float16")
        self.tensor_map["bias_ub_fp32"] = self.compute_tensors.get("tensor_bias_ub_float32")
        self.tensor_map["bias_l0c"] = self.compute_tensors.get("tensor_bias_nz")
        self.tensor_map["c_add_bias"] = self.compute_tensors.get("tensor_mmad_with_bias")
        # init bias to zero
        self.tensor_map["init_value_of_bias_ub"] = self.compute_tensors.get("tensor_init_value_of_bias_ub")
        self.tensor_map["virtual_add_bias"] = self.compute_tensors.get("tensor_virtual_add_bias")

    def _get_fusion_tensor(self):
        """
        get the tensor after cube
        """
        # fixpipe_trans_eletwise is trans from 5hd to NZ for fixpipe eltwise add/sub
        self.tensor_map["fixpipe_trans_eltwise"] = self.compute_tensors.get("fixpipe_trans_eltwise")
        res = self.compute_tensors.get("res")
        if res.op.tag not in ("gemm", "matmul_gemv", "matmul_gevm", "matmul"):
            self.tensor_map["tensor_c_gm"] = self.compute_tensors.get("tensor_c_gm")
            if res.op.tag == "fixpipe_reform":
                self._get_fixpipe_tensor(res)
            else:
                self._get_ub_tensor()
        else:
            self.tensor_map["tensor_c_gm"] = res
        self.para_map["c_dtype"] = self.tensor_map.get("tensor_c_gm").dtype

    def _get_fixpipe_tensor(self, res):
        """
        get fixpipe tensor of cube
        """
        self.tensor_map["tensor_c_gm"] = res
        if res.dtype == "int8":
            self.para_map["fixpipe_quant"] = True
        fixpipe_input_tensor = res.op.input_tensors[0]
        while fixpipe_input_tensor.op.name != "tensor_mmad":
            if fixpipe_input_tensor.op.tag == "fixpipe":
                self.tensor_map["fixpipe_input_name"] = fixpipe_input_tensor.op.attrs["vector_params"]
                self.tensor_map["fixpipe_input_tensor"] = fixpipe_input_tensor.op.attrs["vector_tensors"]
                self.tensor_map["fixpipe"] = fixpipe_input_tensor
            fixpipe_input_tensor = fixpipe_input_tensor.op.input_tensors[0]

    def _get_ub_tensor(self):
        """
        get ub fusion tensor of cube
        """
        eltwise_input_tensor = []
        eltwise_tensor = []
        for input_tensor in self.placeholder_tensors.values():
            for next_tensor in self.output_tensors.get(input_tensor, []):
                if "elewise" in next_tensor.op.tag or "broadcast" in next_tensor.op.tag:
                    eltwise_input_tensor.append(input_tensor)
                    break
        self.tensor_map["eltwise_input_tensor"] = eltwise_input_tensor
        for tensor_mem in self.compute_tensors.values():
            if "elewise" in tensor_mem.op.tag:
                eltwise_tensor.append(tensor_mem)
            if tensor_mem.op.tag == "fixpipe_reform":
                self._get_fixpipe_tensor(tensor_mem)
        self.tensor_map["eltwise_tensor"] = eltwise_tensor
        # quant fusion flag
        for tensor in self.compute_tensors.values():
            if tensor.op.name == "dequant":
                self.tensor_map["dequant_tensor"] = tensor
                self.para_map["dequant_fusion"] = True
            if tensor.op.tag == "quant":
                self.tensor_map["quant_tensor"] = tensor
                self.para_map["quant_fusion"] = True
            if tensor.op.tag in ("requant_scale", "requant_vector"):
                self.tensor_map["requant_tensor"] = tensor
                self.para_map["requant_fusion"] = True
            if "dequant_sqrt" in tensor.op.name:
                self.tensor_map["dequant_sqrt"] = tensor
            if "dequant_relu" in tensor.op.name:
                self.tensor_map["dequant_relu"] = tensor
            if "dequant_NZ" in tensor.op.name:
                self.tensor_map["dequant_nz"] = tensor
            if "dequant_ND" in tensor.op.name:
                self.tensor_map["dequant_nd"] = tensor
            if "input_ub" in tensor.op.name:
                self.tensor_map["input_ub"] = tensor
            if tensor.op.name in ("data_transfer", "reform_by_vadds", "reform_by_vmuls"):
                self.tensor_map["tensor_reform"] = tensor
        self.para_map["quantify_fusion"] = self.para_map.get("quant_fusion", False) or \
            self.para_map.get("requant_fusion", False) or self.para_map.get("dequant_fusion", False)
        self.para_map["has_ub_fusion"] = True
