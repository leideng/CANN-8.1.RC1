#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2019-2020 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
gemm tiling case
"""
import collections
import copy
import json
import math
import itertools
from functools import reduce
from itertools import product

from tbe import tvm
from tbe.common.platform import platform_info as tbe_platform_info
from tbe.common.tiling import get_tiling
from tbe.common.context import op_context
from tbe.common import platform as tbe_platform
from tbe.common.utils.const import ComputeFlow
from tbe.common.utils.errormgr import error_manager_cube
from tbe.dsl.base.operation import in_dynamic
from tbe.dsl.compute.util import int_ceil_div
from tbe.dsl.base.operation import add_compile_info
from tbe.dsl.base.operation import get_te_var
from tbe.dsl.base.operation import register_tiling_case
from tbe.dsl.base.operation import get_context
from tbe.dsl.static_schedule import gemm_schedule_util
from tbe.dsl.compute.gemm_compute_util import GEMMComputeParam
from tbe.dsl.unify_schedule.cube_tilingcase import CubeTilingOp
from tbe.dsl.unify_schedule.cube_tilingcase import MAX_RANGE
from tbe.dsl.unify_schedule.cube_tilingcase import TilingSelection
from tbe.dsl.unify_schedule.cube_tilingcase import TilingUtils as utils
from tbe.dsl.unify_schedule.constants import Pattern
from tbe.dsl.unify_schedule.gemm_tensor_util import TensorMatMul
from tbe.dsl.unify_schedule.gemm_tiling_util import MatMulTiling
from tbe.dsl.unify_schedule.gemm_tiling_util import get_tiling_key

K_LEN = 2
M_LEN = 2
N_LEN = 2
UNIT_LEN = 16
DEFAULT_K_VALUE = 32
INT_32_MAX = 2147483647
BIT_RATIO_DICT = {"int32": 4, "float32": 4, "float16": 2,
                  "uint8": 1, "int8": 1, "uint4": 0.5, "int4": 0.5}
BIT_DIR = {"float32": 16, "int32": 16, "float16": 16, "int8": 32, "int4": 64}
UNKNOWN_DIM = -1
# Gerneral schedule pattern: 10000~20000; Aligned schedule pattern: 20000~30000.
# There is a related flag in file: gemm.cc which also uses this offset.
INITIAL_TILING_ID = 10000
ALIGNED_TILING_ID_OFFSET = 10000
SHAPE_BMKN_LEN = 4
BANK_THRESHOLD = 64
BANK_GAP = 16
OFFSET_ONE = 1
OFFSET_TWO = 2
OFFSET_FOUR = 4


def set_var_value(info, target_area):
    """
    set range value for tiling

    Parameters
    ----------
    info: ops information

    target_area: range value of m k n b

    Returns
    -------
    total info of ops
    """
    key_list = ["ha_var_range", "ca1_var_range", "cb1_var_range", "batch_var_range"]
    for index, value in enumerate(target_area):
        info[key_list[index]] = value
    info["none_range_area"] = None in sum(target_area, [])
    return info


def _get_kernel_compile_info(tiling_key, compile_info_ori, change_keys, tiling_case):
    """
    get compile info for kernel list

    Parameters
    ----------
    tiling_key: tiling_key
    compile_info_ori: compile info
    change_keys: keys in compile_info_ori to be updated
    tiling_case: tiling case

    Returns
    -------
    dict, compile info
    """
    compile_info = copy.deepcopy(compile_info_ori)
    for key in change_keys:
        content = compile_info_ori[key].get(tiling_key, [])
        compile_info[key] = {tiling_key: content} if len(content) > 0 else {}
    block_dim = reduce(lambda x, y: x * y, tiling_case["tiling_strategy"]["block_dim"])
    compile_info["block_dim"] = {tiling_key: block_dim}
    return compile_info


def _calc_tiling_case(mode, target_area, cnt, compute_param):
    """
    calculate tiling case

    Parameters
    ----------
    mode: dynamic mode
    target_area: range to be compiled
    cnt: initial value of tiling key

    Returns
    -------
    list of dict, each dict for a tiling case
    """

    info = tvm.deepcopy(compute_param.tiling_info_dict)
    info = set_var_value(info, target_area)

    tiling_op = MatmulTiling(info, mode, compute_param)

    tiling_cases = TilingSelection(tiling_op, cnt).calc_tiling(target_area)
    return tiling_cases


def _get_tiling_case(context, tiling_cases, tiling_data, tiling_key):
    """
    get static tiling case
    """
    if context.get_addition("st_mode") and context.get_addition("testcase"):
        new_tiling_cases = []
        for idx, _ in enumerate(tiling_cases):
            if tiling_cases[idx]["key"] == tiling_key:
                new_tiling_cases.append(tiling_cases[idx])
                break
        tiling_cases = new_tiling_cases
    elif context.get_addition("is_binary_constant"):
        new_tiling_cases = []
        for idx, _ in enumerate(tiling_cases):
            if tiling_cases[idx]["key"] == tiling_key:
                tiling_cases[idx]["tiling_strategy"]["binary_tiling_data"] = tiling_data
                new_tiling_cases.append(tiling_cases[idx])
                context.add_addition("al1_db", tiling_data.get("al1_db", 0))
                context.add_addition("bl1_db", tiling_data.get("bl1_db", 0))
        tiling_cases = new_tiling_cases
    return tiling_cases


@register_tiling_case(pattern=Pattern.MAT_MUL)
def calc_matmul(outs, option=None):
    """
    tiling_case func for dynamic shape matmul

    Parameters
    ----------
    outs: tvm tensor or list of tvm tensor, results for tvm compute

    Returns
    -------
    list of dict, each dict for a tiling case
    """
    tensor_matmul = TensorMatMul(outs)
    tensor_list = tensor_matmul.get_tensor_and_para_map()
    # when tensor_and_para_map is none, goto old schedule mmad_schedule
    if not tensor_list:
        return[{"tensor_list": None}]
    # calculate the info dict of matmul
    matmul_tiling = MatMulTiling(tensor_list, outs)
    tiling_info_dict = matmul_tiling.get_tiling_info_dict()
    context = op_context.get_context()
    compute_param = GEMMComputeParam()
    if in_dynamic():
        # update the GEMMComputeParam of matmul
        compute_param.update_dynamic_para(tiling_info_dict, tensor_list[3], tensor_list[4])
    else:
        compute_param.need_aub = tensor_list[4].get("need_aub")
        tiling_static = matmul_tiling.get_static_tiling(context)
        tiling_case = [{"tiling_strategy": tiling_static}]
        tiling_case = gemm_schedule_util.process_tiling(tiling_case, tensor_list)
        return tiling_case

    mode = compute_param.dynamic_mode
    # The variables is named x_ori in ND format, otherwise named x
    m_name = compute_param.m_var_name
    k_name = compute_param.k_var_name
    n_name = compute_param.n_var_name

    var_names = {"dynamic_mkn": (m_name, k_name, n_name), "dynamic_mknb": (m_name, k_name, n_name, "batch")}

    target_area = copy.deepcopy([list(get_te_var(v).get_bound()) for v in var_names.get(mode)])
    # process target_area result in ND mode. make it M1/ K1 / N1
    if compute_param.format_a == "ND":
        target_area[0][0] = math.ceil(target_area[0][0] / UNIT_LEN)
        target_area[0][1] = None if target_area[0][1] is None else math.ceil(target_area[0][1] / UNIT_LEN)
        target_area[1][0] = math.ceil(target_area[1][0] / UNIT_LEN)
        target_area[1][1] = None if target_area[1][1] is None else math.ceil(target_area[1][1] / UNIT_LEN)
    if compute_param.format_b == "ND":
        target_area[2][0] = math.ceil(target_area[2][0] / UNIT_LEN)
        target_area[2][1] = None if target_area[2][1] is None else math.ceil(target_area[2][1] / UNIT_LEN)

    add_compile_info("format_a", str(compute_param.format_a))
    add_compile_info("format_b", str(compute_param.format_b))

    context.add_addition("nd2nz_type", tensor_list[4].get("nd2nz_type"))
    tiling_cases = _calc_tiling_case(mode, target_area, INITIAL_TILING_ID, compute_param)

    tiling_data, tiling_key = get_tiling_key(context)
    # Generate Aligned schedule for ND input
    if compute_param.format_a == "ND" and compute_param.format_b == "ND":
        tiling_cases = _generate_aligned_tilingcase(tiling_cases)
    tiling_cases = gemm_schedule_util.process_tiling(tiling_cases, tensor_list)

    tiling_cases = _get_tiling_case(context, tiling_cases, tiling_data, tiling_key)
    return tiling_cases


def _generate_aligned_tilingcase(tiling_cases):
    # For aligned schedule pattern in MatMul/BatchMatMul
    case_length = len(tiling_cases)
    aligned_tiling_cases = []
    if case_length >= ALIGNED_TILING_ID_OFFSET:
        error_manager_cube.raise_err_one_para(
            "E62306",
            "MatMul/BatchMatMul",
            "The compiled kernel number exceeds 10000."
        )
    for tiling in tiling_cases:
        # cache_tiling doesn't modify tilingkey
        if tiling["tiling_strategy"].get("attach_at_flag"):
            return tiling_cases
        aligned_tiling = copy.deepcopy(tiling)
        # The general tilingkey is '1xxxx' and adding this offset makes it '2xxxx'
        aligned_tiling["key"] = aligned_tiling["key"] + ALIGNED_TILING_ID_OFFSET
        aligned_tiling.get("tiling_strategy")["schedule_pattern"] = "Aligned"
        aligned_tiling_cases.append(aligned_tiling)
    tiling_cases += aligned_tiling_cases
    return tiling_cases


class MatmulTiling(CubeTilingOp):
    """
    the cube tiling op of matmul
    """
    def __init__(self, tiling_info, dynamic_mode, compute_param):
        super().__init__(tiling_info, dynamic_mode)
        self.a_info = self.tiling_info["A_shape"]
        self.b_info = self.tiling_info["B_shape"]
        self.c_info = self.tiling_info["C_shape"]
        self.a_type = self.tiling_info["A_dtype"]
        self.b_type = self.tiling_info["B_dtype"]
        self.c_type = self.tiling_info["C_dtype"]
        self.compute_param = compute_param
        self.format_a = self.compute_param.format_a
        self.format_b = self.compute_param.format_b
        self.unaligned_flag = self.tiling_info["unaligned_flag"]
        self.bias_flag = self.tiling_info["bias_flag"]
        self.none_range_area = self.tiling_info["none_range_area"]
        self.support_l0c2out = tbe_platform_info.intrinsic_check_support("Intrinsic_fix_pipe_l0c2out")
        self.use_cache_tiling = self.none_range_area
        self.nd2nz_type = op_context.get_context().get_addition("nd2nz_type")
        self.sparse_4to2_flag = self.compute_param.sparse_4to2_flag
        self.pre_conv_mode = self.compute_param.pre_conv_mode
        self.pad_flag = self.tiling_info["pad_flag"]
        self.deq_vec_flag = self.compute_param.deq_vec_flag
        self.nz_fusion_flag = self.tiling_info["nz_fusion_flag"]

        get_context().add("_use_cache_tiling", self.use_cache_tiling)
        self._get_calc_info()
        self.key = ("A_shape", "B_shape")
        self.op_type = "matmul"
        # block_n, block_m, mal1, nbl1, kal1, kbl1, n_l0c_value, m_l0c_value, k_l0a, is_al1_double, is_bl1_double
        self.tiling_value = [1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1]

    @staticmethod
    def preprocess_tiling(tiling_in):
        """
        preprocess tiling for get tiling range

        Parameters
        ----------
        tiling_in : dict, result of tiling fetch

        Returns
        -------
        tiling_case, range covered for tiling
        """

        tiling = copy.deepcopy(tiling_in)
        return tiling

    @staticmethod
    def get_compile_time(target_area):
        """
        caculate total all compile time depends on target_area
        """
        compile_time = 1
        for value in target_area:
            compile_time *= (value[1] - value[0] + 1)
        return compile_time

    def get_cache_tiling(self):
        '''
        according to size in l1, generate 9 kind of templates, each subdivided into 132 different
        templates as follows templates according to size in l1 sub template
        --------------------------------------------|-----
        al1 @l0c and bl1 @l0c                       | 48
        al1 @l0c and bl1 @ddr                       | 16
        al1 @l0c and bl1 full load                  | 8
        al1 @ddr and bl1 @l0c                       | 16
        al1 @ddr and bl1 @ddr                       | 16
        al1 @ddr and bl1 full load                  | 8
        al1 full load and bl1 @l0c                  | 8
        al1 full load and bl1 @ddr                  | 8
        al1 full load and bl1 full load             | 4

        Returns
        ----------
        cache_tiling_all: list, include 132 different tiling templates
        '''
        # add compile_info
        info_dict = self.tiling_info
        bias_flag = info_dict.get("bias_flag")
        nd_flag = self.compute_param.format_a == "ND" and self.compute_param.format_b == "ND"
        split_k_flag = self.compute_param.split_k_flag
        sparse_4to2_flag = self.sparse_4to2_flag
        support_out2l1_nd2nz = tbe_platform_info.intrinsic_check_support("Intrinsic_data_move_out2l1_nd2nz")
        fused_double_operand_num = 1 if not support_out2l1_nd2nz and self.compute_param.format_out == "ND" else 0
        weight_nz = self.compute_param.format_a == "ND" and self.compute_param.format_b == "FRACTAL_NZ" and \
                    self.compute_param.format_out == "ND" and (not self.support_l0c2out)
        add_compile_info("fused_double_operand_num", fused_double_operand_num)
        add_compile_info("binary_mode_flag", True)
        add_compile_info("binary_attrs", {"bias_flag": bias_flag,
                                          "nd_flag": nd_flag,
                                          "split_k_flag": split_k_flag,
                                          "zero_flag": False,
                                          "weight_nz": weight_nz})
        add_compile_info("sparse_4to2_flag", sparse_4to2_flag)
        # get cache_tiling
        cache_tiling_all = {}
        attach_choices = self._get_attach_choices()
        for choice in attach_choices:
            cache_tiling = {
                'block_dim': [-1, -1, -1, 1],
                'AL0_matrix': [-1, -1, utils.CUBE_SIZE, utils.CUBE_SIZE, 1, 1],
                'BL0_matrix': [-1, -1, utils.CUBE_SIZE, utils.CUBE_SIZE, 1, 1],
                'CL0_matrix': [-1, -1, utils.CUBE_SIZE, utils.CUBE_SIZE, 1, 1],
                'CUB_matrix': [-1, -1, utils.CUBE_SIZE, utils.CUBE_SIZE, 1, 1],
                'BUB_shape': [-1, -1, 1, 1],
                'AL1_shape': [-1, -1, 1, 1], 'BL1_shape': [-1, -1, 1, 1],
                'AUB_shape': [-1, -1, 1, 1],
                'n_bef_batch_flag': 0, 'n_bef_group_flag': 0, 'batch_bef_group_flag': 0,
                'A_overhead_opt_flag': 0, 'B_overhead_opt_flag': 0,
                'AUB_channel_wise_flag': None, 'BUB_channel_wise_flag': None, 'CUB_channel_wise_flag': None,
                'manual_pingpong_buffer': {'AUB_pbuffer': utils.DB_ON, 'BUB_pbuffer': utils.DB_ON,
                'AL1_pbuffer': -1, 'BL1_pbuffer': -1,
                'AL0_pbuffer': utils.DB_ON, 'BL0_pbuffer': utils.DB_ON, 'CL0_pbuffer': utils.DB_ON,
                'CUB_pbuffer': utils.DB_ON, 'UBG_pbuffer': utils.DB_OFF},
                'attach_at_flag': {'cub_attach_flag': utils.ATTACH_LESS, 'cl0_attach_flag': utils.ATTACH_LARGE,
                'al0_attach_flag': utils.ATTACH_LESS, 'bl0_attach_flag': utils.ATTACH_LESS, 'al1_attach_flag': -1,
                'bl1_attach_flag': -1, 'aub_attach_flag': utils.ATTACH_LESS, 'bub_attach_flag': utils.ATTACH_LESS,
                'abkl1_attach_flag': -1, 'aub_multi_flag': -1, 'bub_multi_flag': -1, 'l0c_multi_batch': -1},
                "non_factor_bmn_flag": -1, 'non_factor_k_flag': -1, "performance_flag": -1, "unaligned_flag": -1,
                "zero_flag": -1, "reorder_flag": 0,
            }
            data_type_list = [self.a_type, self.b_type, self.c_type]
            if self._check_template_valid(choice, split_k_flag, bias_flag, data_type_list):
                continue
            # if bl1 attach at l0c, nbl1, should be 1
            if choice[5] == utils.ATTACH_LESS:
                cache_tiling.get("BL1_shape")[1] = 1
            # al1 attach at l0c
            if choice[4] == utils.ATTACH_LESS:
                # if al1 attach at l0c, mal1 should be 1
                cache_tiling.get('AL1_shape')[1] = 1
            cache_tiling.get('manual_pingpong_buffer')['CL0_pbuffer'] = choice[2]
            cache_tiling.get('attach_at_flag')['abkl1_attach_flag'] = choice[3]
            cache_tiling.get('attach_at_flag')['al1_attach_flag'] = choice[4]
            cache_tiling.get('attach_at_flag')['bl1_attach_flag'] = choice[5]
            cache_tiling.get('attach_at_flag')['min_kl1_cmp_kl0'] = choice[6]
            cache_tiling.get('attach_at_flag')['l0c_multi_batch'] = choice[7]
            if self.compute_param.need_aub:
                cache_tiling.get('attach_at_flag')['aub_multi_flag'] = choice[8]
                cache_tiling.get('attach_at_flag')['bub_multi_flag'] = choice[9]
                cache_tiling["schedule_pattern"] = "Aligned"

            cache_tiling['non_factor_k_flag'] = choice[-7]
            cache_tiling['non_factor_bmn_flag'] = choice[-6]
            cache_tiling['performance_flag'] = choice[-5]
            cache_tiling['unaligned_flag'] = self.unaligned_flag
            cache_tiling['zero_flag'] = choice[-3]
            cache_tiling['reorder_flag'] = choice[-1]
            if self.pre_conv_mode is not None:
                cache_tiling["pre_conv_flag"] = self.pre_conv_mode
            if self.deq_vec_flag is not None:
                cache_tiling["deq_vec_flag"] = self.deq_vec_flag
            if split_k_flag:
                cache_tiling["block_dim"] = [UNKNOWN_DIM, UNKNOWN_DIM, UNKNOWN_DIM, UNKNOWN_DIM]
            cache_tiling_all[self._get_tiling_id(choice, split_k_flag)] = [[], cache_tiling, []]
        return cache_tiling_all

    def assembly_case(self, m_k_n_shape, tiling, coverage, cnt):
        """
        get the covered info of a tiling

        Parameters
        ----------
        tiling : dict, result of tiling fetch

        coverage : list, size of dymanic element

        cnt: index of tiling

        Returns
        -------
        tiling_case, range covered for tiling
        """

        var_range = collections.OrderedDict()

        m_name = self.compute_param.m_var_name
        k_name = self.compute_param.k_var_name
        n_name = self.compute_param.n_var_name

        block_in = self.compute_param.block_in
        block_out = self.compute_param.block_out
        block_reduce = self.compute_param.block_reduce
        if coverage:
            if self.compute_param.format_a == "ND":
                m_range = (coverage[0] * block_in, min(coverage[1] * block_in, INT_32_MAX))
                k_range = (coverage[2] * block_reduce, min(coverage[3] * block_reduce, INT_32_MAX))
            else:
                m_range = (coverage[0], coverage[1])
                k_range = (coverage[2], coverage[3])
            if self.compute_param.format_b == "ND":
                n_range = (coverage[4] * block_out, min(coverage[5] * block_out, INT_32_MAX))
            else:
                n_range = (coverage[4], coverage[5])
            var_range[m_name] = m_range
            var_range[k_name] = k_range
            var_range[n_name] = n_range
            if self.dynamic_mode == "dynamic_mknb":
                var_range["batch"] = (coverage[6], coverage[7])

        return {"key": cnt, "tiling_strategy": tiling, "var_range": var_range, "m_k_n_shape": m_k_n_shape,
                "compute_param": self.compute_param}

    def _check_template_valid(self, choice, split_k_flag, bias_flag, data_type_list):
        """
        Check if the template is valid

        Returns
        -------
        bool: True, the template is valid
        """
        (al1_pb, bl1_pb, _, abkl1_attach, al1_attach_flag, bl1_attach_flag, min_kl1_cmp_kl0,
         l0c_multi_batch, *_, non_factor_k_flag, _, performance_flag, _, zero_flag, _, reorder_flag) = choice
        # Check Data_type and FP32-->FP32 Mode does not have performance mode
        a_type, b_type, c_type = data_type_list
        invalid_choice = (a_type == "float32" and a_type != c_type) or (
            a_type != b_type and (a_type == "float32" or b_type == "float32"))
        # al1 full load, check invalid abkl1_attach
        invalid_choice = invalid_choice or (al1_attach_flag == utils.ATTACH_FULL_LOAD and (
            (bl1_attach_flag in (utils.ATTACH_FULL_LOAD, utils.ATTACH_EQUAL) and abkl1_attach != 0) or
            (bl1_attach_flag == utils.ATTACH_LESS and abkl1_attach != utils.ATTACH_EQUAL)))

        # al1 attach at c_ddr, check invalid abkl1_attach
        invalid_choice = invalid_choice or (al1_attach_flag == utils.ATTACH_EQUAL and (
            (bl1_attach_flag in (utils.ATTACH_FULL_LOAD, utils.ATTACH_EQUAL) and abkl1_attach != 0) or
            (bl1_attach_flag == utils.ATTACH_LESS and abkl1_attach != utils.ATTACH_EQUAL)))

        # al1 attach at l0c, check invalid abkl1_attach
        invalid_choice = invalid_choice or (al1_attach_flag == utils.ATTACH_LESS and
                                            bl1_attach_flag in (utils.ATTACH_FULL_LOAD, utils.ATTACH_EQUAL) and
                                            abkl1_attach != utils.ATTACH_LESS)

        # if not split k, non_factor_k_flag can't be used
        invalid_choice = invalid_choice or (not split_k_flag and non_factor_k_flag == 1)

        # if non factor k, al1 and bl1 must attach at l0c
        invalid_choice = invalid_choice or (split_k_flag and non_factor_k_flag == 1 and
                                            (al1_attach_flag != utils.ATTACH_LESS
                                             or bl1_attach_flag != utils.ATTACH_LESS))

        # only batch_matmul L0C, L1A, L1B full load and double buffer on templates support multi_batch
        invalid_choice = invalid_choice or (l0c_multi_batch > 0 and
            (not (self.compute_param.batch_a or self.compute_param.batch_b) or
            abkl1_attach != utils.ATTACH_FULL_LOAD or al1_attach_flag != utils.ATTACH_FULL_LOAD or
            bl1_attach_flag != utils.ATTACH_FULL_LOAD or min_kl1_cmp_kl0 != 0))

        # if split k, performance_flag must be 1
        invalid_choice = invalid_choice or ((split_k_flag and performance_flag == 0) or
            (not split_k_flag and not bias_flag and c_type == "float16" and
             a_type != "int8" and performance_flag == 0) or
            (bias_flag and performance_flag == 1) or (a_type == "int8" and performance_flag == 1))


        # in fp32 padfusion, performance_flag must be 0
        invalid_choice = invalid_choice or (
            (self.pad_flag or self.nz_fusion_flag or self.nd2nz_type > ComputeFlow.mix_l2.value) and zero_flag)
        invalid_choice = invalid_choice or (reorder_flag and (a_type == 'int8' or b_type == 'int8'
                                                              or c_type == 'int8' or split_k_flag
                                                              or (performance_flag == 1 and a_type == 'float32')))

        return invalid_choice

    def _get_calc_info(self):
        """
        preprocess info, convert tvm var to -1
        """

        self._convert_type(self.a_info, self.b_info)

    def _get_tiling_id(self, choice, split_k_flag):
        '''
        ---------------------------------------
        | db_flag | al1_db | bl1_db | cl0_db
        ---------------------------------------
        |    1    |   off  |   off  |  off
        |    2    |   off  |   off  |  on
        |    3    |   off  |   on   |  off
        |    4    |   off  |   on   |  on
        |    5    |   on   |   off  |  off
        |    6    |   on   |   off  |  on
        |    7    |   on   |   on   |  off
        |    8    |   on   |   on   |  on

        Returns
        ----------
        kernel_mode: int, kernel flag in binary
        '''
        aub_multi_flag = None
        bub_multi_flag = None
        reorder_flag = None
        if self.compute_param.need_aub:
            (al1_pb, bl1_pb, l0c_pb, abkl1_attach, al1_attach_flag, bl1_attach_flag,
             min_kl1_cmp_kl0, l0c_multi_batch, aub_multi_flag, bub_multi_flag,
             non_factor_k_flag, non_factor_mn_flag, performance_flag, nd2nz_type,
             zero_flag, pre_conv_flag, reorder_flag) = choice
        else:
            (al1_pb, bl1_pb, l0c_pb, abkl1_attach, al1_attach_flag, bl1_attach_flag,
             min_kl1_cmp_kl0, l0c_multi_batch, non_factor_k_flag, non_factor_mn_flag,
             performance_flag, nd2nz_type, zero_flag, pre_conv_flag, reorder_flag) = choice
        tiling_id = reorder_flag
        tiling_id = (tiling_id << OFFSET_TWO) + self.nz_fusion_flag
        tiling_id = (tiling_id << OFFSET_TWO) + self.pad_flag
        tiling_id = (tiling_id << OFFSET_ONE) + pre_conv_flag
        tiling_id = (tiling_id << OFFSET_ONE) + zero_flag
        tiling_id = (tiling_id << OFFSET_TWO) + nd2nz_type
        tiling_id = (tiling_id << OFFSET_ONE) + performance_flag
        tiling_id = (tiling_id << OFFSET_ONE) + split_k_flag
        tiling_id = (tiling_id << OFFSET_FOUR) + l0c_multi_batch
        # use non_factor_bmn default
        tiling_id = (tiling_id << OFFSET_ONE) + non_factor_mn_flag
        tiling_id = (tiling_id << OFFSET_ONE) + non_factor_k_flag
        if bub_multi_flag is not None:
            tiling_id = (tiling_id << OFFSET_ONE) + bub_multi_flag
        if aub_multi_flag is not None:
            tiling_id = (tiling_id << OFFSET_ONE) + aub_multi_flag
        tiling_id = (tiling_id << OFFSET_ONE) + min_kl1_cmp_kl0
        tiling_id = (tiling_id << OFFSET_TWO) + bl1_attach_flag
        tiling_id = (tiling_id << OFFSET_TWO) + al1_attach_flag
        tiling_id = (tiling_id << OFFSET_TWO) + abkl1_attach
        tiling_id = (tiling_id << OFFSET_ONE) + l0c_pb - 1

        return tiling_id

    def _get_attach_choices(self):
        """
        generates all selections of l0 flags

        Returns
        -------
        list: all selections of flags
        """
        if self.unaligned_flag:
            non_factor_mn_flag_choice = [0]
        else:
            non_factor_mn_flag_choice = [1]
        pre_conv_flag_choice = [0]
        if self.pre_conv_mode is not None and self.pre_conv_mode in ("VS322F16", "VF322B8"):
            pre_conv_flag_choice = [1]
        support_out2l1_nd2nz = tbe_platform_info.intrinsic_check_support("Intrinsic_data_move_out2l1_nd2nz")
        reorder_choice = [0]
        if support_out2l1_nd2nz and self.pad_flag == 0 and self.nz_fusion_flag == 0:
            reorder_choice = [0, 1]

        # Performance Mode 使用 0 模式描述FP32進FP32出 和FP16模式下的FP16進FP32出
        (al1_pb, bl1_pb, l0c_pb, abkl1_attach, al1_attach_flag, bl1_attach_flag,
         min_kl1_cmp_kl0, aub_multi_flag, bub_multi_flag, non_factor_k_flag,
         non_factor_mn_flag, l0c_multi_batch, performance_flag, pre_conv_flag,
         reorder_flag) = (
            [utils.DB_OFF], [utils.DB_OFF], [utils.DB_OFF, utils.DB_ON],
            [utils.ATTACH_FULL_LOAD, utils.ATTACH_EQUAL, utils.ATTACH_LESS],
            [utils.ATTACH_FULL_LOAD, utils.ATTACH_EQUAL, utils.ATTACH_LESS],
            [utils.ATTACH_FULL_LOAD, utils.ATTACH_EQUAL, utils.ATTACH_LESS],
            [0, 1],
            [utils.ABUB_NOT_FULL_LOAD_MM, utils.ABUB_FULL_LOAD_MM],
            [utils.ABUB_NOT_FULL_LOAD_MM, utils.ABUB_FULL_LOAD_MM], [0, 1], non_factor_mn_flag_choice,
            [0, 1, 2, 3, 4, 5, 6, 7, 8], [0, 1], pre_conv_flag_choice, reorder_choice)

        prefix_choice_list = [al1_pb, bl1_pb, l0c_pb, abkl1_attach, al1_attach_flag,
                              bl1_attach_flag, min_kl1_cmp_kl0, l0c_multi_batch]
        mid_choice_list = []
        zero_flag_mid_choice = []
        zero_flag = [0]
        suffix_choice_list = [non_factor_k_flag, non_factor_mn_flag,
                              performance_flag, [self.nd2nz_type], zero_flag,
                              pre_conv_flag, reorder_flag]
        if self.compute_param.need_aub:
            mid_choice_list = [aub_multi_flag, bub_multi_flag]
            zero_flag_mid_choice = [[utils.ABUB_NOT_FULL_LOAD_MM], [utils.ABUB_NOT_FULL_LOAD_MM]]
        choice_list = prefix_choice_list + mid_choice_list + suffix_choice_list
        attach_choices = list(product(*choice_list))

        if self.unaligned_flag or self.nd2nz_type == 0:
            # add zero_flag choice
            zero_flag = [1]
            non_factor_k_flag = [0]
            zero_flag_prefix_choice = [[utils.DB_ON], [utils.DB_ON], [utils.DB_ON], [utils.ATTACH_FULL_LOAD],
                                       [utils.ATTACH_EQUAL], [utils.ATTACH_EQUAL], [0], [0]]
            # non_factor_k_flag, non_factor_mn_flag, performance_flag, nd2nz_type, zero_flag
            zero_flag_suffix_choice = [non_factor_k_flag, non_factor_mn_flag_choice,
                                       performance_flag, [self.nd2nz_type], zero_flag, pre_conv_flag, [0]]
            zero_choice_list = zero_flag_prefix_choice + zero_flag_mid_choice + zero_flag_suffix_choice
            attach_choices = attach_choices + list(product(*zero_choice_list))
        return attach_choices
