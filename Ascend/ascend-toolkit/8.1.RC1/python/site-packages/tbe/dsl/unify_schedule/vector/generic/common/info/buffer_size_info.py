#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2023-2024 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.constants
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
buffer size info
"""
import dataclasses

from . import soc_info
from .. import constants
from .. import helper


@dataclasses.dataclass
class BufferSizeItems:
    """
    dataclass for items to calculate buffer size, including temp_size, extra_node_size and weighted_coexist_node_num
    """
    temp_size: int = 0
    extra_node_size: int = 0
    weighted_coexist_node_num: int = 0

    def max(self, buffer_size_items_obj):
        """
        calculate max between current items and input items
        """
        self.temp_size = max(self.temp_size, buffer_size_items_obj.temp_size)
        self.extra_node_size = max(self.extra_node_size, buffer_size_items_obj.extra_node_size)
        self.weighted_coexist_node_num = \
            max(self.weighted_coexist_node_num, buffer_size_items_obj.weighted_coexist_node_num)

    def add(self, buffer_size_items_obj):
        """
        calculate add between current items and input items
        """
        self.temp_size += buffer_size_items_obj.temp_size
        self.extra_node_size += buffer_size_items_obj.extra_node_size
        self.weighted_coexist_node_num += buffer_size_items_obj.weighted_coexist_node_num

    def calc_buffer_size(self, soc_size):
        """
        calculate buffer size according to current items
        """
        return int((soc_size - self.temp_size - self.extra_node_size) // self.weighted_coexist_node_num)


class BufferSizeInfo:
    """
    class for buffer size calculation
    """
    def __init__(self, res_sch_node_obj, mem_unique_sch_node_objs=None, compute_root_sch_node_objs_group=None):
        # ub size
        self._soc_ub_size = soc_info.SocInfo.get_ub_size()
        self._res_sch_node_obj = res_sch_node_obj
        self._mem_unique_sch_node_objs = [] if mem_unique_sch_node_objs is None else mem_unique_sch_node_objs
        self._compute_root_sch_node_objs_group = \
            self._normalize_compute_root_sch_node_objs_group(compute_root_sch_node_objs_group)
        # common node
        self._max_buffer_size_items_for_common = BufferSizeItems()
        # mem unique node
        self._max_buffer_size_items_for_mem_unique = BufferSizeItems()
        # compute root node
        self._max_buffer_size_items_for_compute_root = BufferSizeItems()
        # total
        self._max_buffer_size_items = BufferSizeItems()

        self._max_buffer_size = 0
        self._max_db_buffer_size = 0

        self._dependent_sch_node_obj_map = {}

    @property
    def max_buffer_size_items(self):
        return self._max_buffer_size_items

    @property
    def max_buffer_size(self):
        return self._max_buffer_size

    @property
    def max_db_buffer_size(self):
        return self._max_db_buffer_size

    @property
    def max_coexist_node_num(self):
        return self._max_buffer_size_items.weighted_coexist_node_num

    @staticmethod
    def _normalize_compute_root_sch_node_objs_group(compute_root_sch_node_objs_group):
        if compute_root_sch_node_objs_group is None:
            return []

        return [item if helper.judge_iterable(item) else [item] for item in compute_root_sch_node_objs_group]

    @staticmethod
    def _get_extra_node_size(cur_sch_node_obj):
        if cur_sch_node_obj.insn_obj.extra_node_size != 0:
            return cur_sch_node_obj.insn_obj.extra_node_size

        return constants.BLOCK_SIZE if cur_sch_node_obj.buffer_size_ratio != 1 else 0

    @staticmethod
    def _calc_weighted_node_num(cur_sch_node_obj):
        return cur_sch_node_obj.buffer_size_ratio

    @staticmethod
    def _pop_sch_node_obj(cur_sch_node_obj, dependent_sch_node_obj_map):
        for producer_sch_node_obj in cur_sch_node_obj.producers:
            if producer_sch_node_obj not in dependent_sch_node_obj_map:
                continue
            dependent_sch_node_obj_map.get(producer_sch_node_obj).remove(cur_sch_node_obj)
            if not dependent_sch_node_obj_map.get(producer_sch_node_obj):
                dependent_sch_node_obj_map.pop(producer_sch_node_obj)

    def calc_max_buffer_size(self):
        """
        calculate max buffer size and max db buffer size
        """
        self._calc_max_buffer_size_items()

        self._max_buffer_size = self._max_buffer_size_items.calc_buffer_size(self._soc_ub_size)
        # 32B aligned
        self._max_buffer_size = helper.value_aligned(self._max_buffer_size, constants.BLOCK_SIZE, is_ceil=False)

        self._max_db_buffer_size = self._max_buffer_size_items.calc_buffer_size(self._soc_ub_size // 2)
        # 32B aligned
        self._max_db_buffer_size = helper.value_aligned(self._max_db_buffer_size, constants.BLOCK_SIZE, is_ceil=False)

    def _calc_max_buffer_size_items(self):
        self._calc_max_buffer_size_items_for_common()
        self._calc_max_buffer_size_items_for_mem_unique()
        self._calc_max_buffer_size_items_for_compute_root()

        self._max_buffer_size_items.temp_size = max(self._max_buffer_size_items_for_common.temp_size,
                                                    self._max_buffer_size_items_for_mem_unique.temp_size) + \
            self._max_buffer_size_items_for_compute_root.temp_size

        self._max_buffer_size_items.extra_node_size = self._max_buffer_size_items_for_common.extra_node_size + \
            self._max_buffer_size_items_for_mem_unique.extra_node_size + \
            self._max_buffer_size_items_for_compute_root.extra_node_size

        self._max_buffer_size_items.weighted_coexist_node_num = \
            self._max_buffer_size_items_for_common.weighted_coexist_node_num + \
            self._max_buffer_size_items_for_mem_unique.weighted_coexist_node_num + \
            self._max_buffer_size_items_for_compute_root.weighted_coexist_node_num

    def _calc_max_buffer_size_items_for_common(self):
        self._dependent_sch_node_obj_map = {}
        self._recursion(self._res_sch_node_obj, self._max_buffer_size_items_for_common,
                        lambda x: not self._is_compute_root(x) and not self._is_mem_unique(x))

    def _calc_max_buffer_size_items_for_mem_unique(self):
        for mem_unique_node in self._mem_unique_sch_node_objs:
            self._max_buffer_size_items_for_mem_unique.weighted_coexist_node_num += \
                self._calc_weighted_node_num(mem_unique_node)
            self._max_buffer_size_items_for_mem_unique.extra_node_size += self._get_extra_node_size(mem_unique_node)
            self._max_buffer_size_items_for_mem_unique.temp_size = \
                max(mem_unique_node.insn_obj.extra_temp_size, self._max_buffer_size_items_for_mem_unique.temp_size)

    def _calc_max_buffer_size_items_for_compute_root(self):
        for cur_compute_root_node_list in self._compute_root_sch_node_objs_group:
            self._dependent_sch_node_obj_map = {}
            local_buffer_size_items = BufferSizeItems()
            self._recursion(self._res_sch_node_obj, local_buffer_size_items, lambda x: x in cur_compute_root_node_list)
            self._max_buffer_size_items_for_compute_root.add(local_buffer_size_items)

    def _recursion(self, cur_sch_node_obj, max_buffer_size_items: BufferSizeItems, select_func):
        # cur_sch_node_obj has been visited
        if cur_sch_node_obj in self._dependent_sch_node_obj_map:
            return

        for producer_sch_node_obj in cur_sch_node_obj.producers:
            self._recursion(producer_sch_node_obj, max_buffer_size_items, select_func)

        cur_buffer_size_items = self._calc_cur_buffer_size_items(cur_sch_node_obj, select_func)
        if not cur_sch_node_obj.tensor_obj.is_fake_node():
            max_buffer_size_items.max(cur_buffer_size_items)

        self._update_dependent_sch_node_obj_map(cur_sch_node_obj)

    def _calc_cur_buffer_size_items(self, cur_sch_node_obj, select_func):
        cur_buffer_size_items = BufferSizeItems()
        if not callable(select_func) or not select_func(cur_sch_node_obj):
            return cur_buffer_size_items

        # 1. dependent node
        weighted_dependent_node_num = 0
        dependent_extra_node_size = 0
        for single_sch_node_obj in self._dependent_sch_node_obj_map:
            if not select_func(single_sch_node_obj):
                continue
            weighted_dependent_node_num += self._calc_weighted_node_num(single_sch_node_obj)
            dependent_extra_node_size += self._get_extra_node_size(single_sch_node_obj)

        # 2. node itself
        weighted_node_itself_num = 0
        node_itself_extra_size = 0
        if cur_sch_node_obj not in self._dependent_sch_node_obj_map and \
                not self._judge_dst_can_reuse_src(cur_sch_node_obj):
            weighted_node_itself_num = self._calc_weighted_node_num(cur_sch_node_obj)
            node_itself_extra_size += self._get_extra_node_size(cur_sch_node_obj)

        # 3. insn extra node num
        weighted_extra_node_num = cur_sch_node_obj.insn_obj.extra_node_num * cur_sch_node_obj.extra_node_size_ratio

        cur_buffer_size_items.weighted_coexist_node_num = weighted_dependent_node_num + weighted_node_itself_num + \
            weighted_extra_node_num
        cur_buffer_size_items.temp_size = cur_sch_node_obj.insn_obj.extra_temp_size
        cur_buffer_size_items.extra_node_size = dependent_extra_node_size + node_itself_extra_size

        return cur_buffer_size_items

    def _is_mem_unique(self, cur_sch_node_obj):
        return cur_sch_node_obj in self._mem_unique_sch_node_objs

    def _is_compute_root(self, cur_sch_node_obj):
        for compute_root_sch_node_obj_list in self._compute_root_sch_node_objs_group:
            if cur_sch_node_obj in compute_root_sch_node_obj_list:
                return True

        return False

    def _judge_dst_can_reuse_src(self, cur_sch_node_obj):
        if cur_sch_node_obj.insn_obj.is_can_not_reuse_src_insn():
            return False

        if not cur_sch_node_obj.producers:
            return False
        producer_sch_node_obj = cur_sch_node_obj.producers[0]
        if self._calc_weighted_node_num(cur_sch_node_obj) != self._calc_weighted_node_num(producer_sch_node_obj):
            return False
        if self._get_extra_node_size(cur_sch_node_obj) != self._get_extra_node_size(producer_sch_node_obj):
            return False

        # if src are all in after_pop_dependent_sch_node_obj_map, dst can not reuse src
        after_pop_dependent_sch_node_obj_map = helper.copy_dict(self._dependent_sch_node_obj_map)
        self._pop_sch_node_obj(cur_sch_node_obj, after_pop_dependent_sch_node_obj_map)
        is_dst_and_src_independent = not helper.ListHelper.get_difference(cur_sch_node_obj.producers,
                                                                          after_pop_dependent_sch_node_obj_map.keys())
        if is_dst_and_src_independent:
            return False

        if cur_sch_node_obj in self._mem_unique_sch_node_objs or \
                producer_sch_node_obj in self._mem_unique_sch_node_objs:
            return False

        return True

    def _update_dependent_sch_node_obj_map(self, cur_sch_node_obj):
        self._pop_sch_node_obj(cur_sch_node_obj, self._dependent_sch_node_obj_map)
        self._append_sch_node_obj(cur_sch_node_obj)

    def _append_sch_node_obj(self, cur_sch_node_obj):
        if cur_sch_node_obj not in self._dependent_sch_node_obj_map:
            self._dependent_sch_node_obj_map[cur_sch_node_obj] = cur_sch_node_obj.consumers[:]
