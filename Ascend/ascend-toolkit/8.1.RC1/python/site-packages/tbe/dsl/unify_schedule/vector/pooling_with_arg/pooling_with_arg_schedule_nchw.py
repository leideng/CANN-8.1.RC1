#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2022-2023 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
pooling_with_arg_vars schedule nchw
"""
from typing import Any
from functools import reduce

from tbe import tvm
from tbe.common.utils import op_tiling
from tbe.common.platform.platform_info import scope_ubuf as BUFFER_UB
from tbe.dsl.base import operation

from ... import util
from ...constants import CompileInfo
from ...constants import PoolingWithArgPattern
from ...constants import Pattern
from ...constants import DTYPE_BYTE_MAPPING
from ...schedule import Schedule
from .pooling_with_arg_tilingcase import CEIL_MODE_MAP
from .pooling_with_arg_tilingcase import TilingStrategy
from .pooling_with_arg_tilingcase import PoolingWithArgCompileInfo
from .pooling_with_arg_tilingcase import unify_attr_info

BUFFER_GM = "local.UB"

NCHW_DYNAMIC = 2
NCHW_STATIC = 3
COMMON_COEX = 4
WORKSPACE_COEX = 5
NC_ALIGN = 16
OVERLAP_MODE_SAFE = 4
HO_AXIS = 2

DEFAULT = "default"
SCOPE_UB = "local.UB"
NO_SPLIT = "NO_SPLIT"
SPLIT = "SPLIT"
HW_BLOCK = "HW_BLOCK"
N_BLOCK = "N_BLOCK"

SPLIT_DICT = {
    0: NO_SPLIT,
    1: SPLIT,
}

BLOCK_MODE_DICT = {
    0: HW_BLOCK,
    1: N_BLOCK,
}

INPUT_EXPAND_AXIS_MAP = {
    0: 0,
    1: 2,
    2: 3
}

TRANSPOSE_ALIGN = 16
STORAGE_ALIGN = 16
STORAGE_FRACTAL = 256

DTYPE_BYTES_MAP = {
    "float16": 2,
    "float32": 4,
    "int32": 4,
    "uint1": 1
}

EMIT_INSI_MAP = {
    "pooling_with_arg_pad": "dma_copy",
    "pooling_with_arg_expand": "vector_or",
    "pooling_with_arg_max": "vector_reduce_max",
    "pooling_with_arg_vcmp": "vector_eq",
    "pooling_with_arg_indices": "vector_linear_sequence",
    "pooling_with_arg_select": "vector_select_bool",
    "pooling_with_arg_min": "vector_reduce_min"
}

EMIT_AXIS_MAP = {
    "pooling_with_arg_pad": 1,
    "pooling_with_arg_expand": 2,
    "pooling_with_arg_max": 0,
    "pooling_with_arg_vcmp": 1,
    "pooling_with_arg_indices": 0,
    "pooling_with_arg_select": 1,
    "pooling_with_arg_min": 0
}

VNCHWCONV_B32_FLAG = {
    TilingStrategy.STATIC: 2,
    TilingStrategy.DYNAMIC: 1,
}

UB_TEMP_BUFFER = 256


class PoolingWithArgNchwDispatch(Schedule):
    """
    pooling with arg vars schedule
    """

    def __init__(self, outs, tiling_case):
        self._output_tensors = outs
        self._tiling_case = tiling_case
        self._split_mode = self._tiling_case.get("split_mode")

    @classmethod
    def get_instance(cls, outs, tiling_case):  # type: (list[Any], Any) -> "Schedule"
        return cls(outs, tiling_case)

    @classmethod
    def get_supported_soc(cls):  # type: () -> list[str]
        return [DEFAULT]

    @classmethod
    def get_supported_pattern(cls):  # type: () -> list[str]
        return [Pattern.POOLINGWITHARG]

    @classmethod
    def get_supported_sub_pattern(cls):  # type: () -> list[str]
        return [PoolingWithArgPattern.SCHEDULE_NCHW]

    def do_schedule(self):  # type: () -> TVM_Schedule
        schedule_map = {
            NO_SPLIT: NchwCommonSchedule,
            SPLIT: NchwWorkSpaceSchedule,
        }
        current_schedule = schedule_map.get(self._split_mode)
        return current_schedule(self._output_tensors, self._tiling_case).do_schedule()


class PoolingWithArgScheduleNchwBase():
    """
    pooling with arg vars schedule
    """

    def __init__(self, outs, tiling_case):
        self._output_tensors = outs
        self._schedule_outs = outs
        self._sch = None
        self._tiling_case = tiling_case
        self._tiling_key = self._tiling_case.get("key")
        self._tiling_strategy = self._tiling_case.get("tiling_strategy")
        self._split_mode = self._tiling_case.get("split_mode")
        self._block_mode = self._tiling_case.get("block_mode")
        self._ub_axis = INPUT_EXPAND_AXIS_MAP.get(self._tiling_case.get("ub_axis"))
        self._ceil_mode = self._tiling_case.get("ceil_mode")
        self._valid_tiling = True

        self._in_out_map = {}
        self._input_tensors = set()
        self._inner_input_tensors = set()
        self._no_input_tensors = set()
        self._middle_tensors = set()
        self._middle_out_tensors = set()

        self._cache_read_tensors = set()
        self._cache_write_tensors = set()
        self._transpose_tensors = set()
        self._input_transpose_tensors = set()
        self._output_transpose_tensors = set()
        self._compute_inline_tensors = set()

        self._reverse_compute_at_tensors = set()

        self._reverse_split_tensor = None
        self._reduce_split_tensor = None
        self._split_tensor = None

        self._block_axis = None
        self._block_factor = None
        self._block_ub_factor = None
        self._block_ub_outer = None
        self._block_ub_inner = None
        self._ub_factor = None
        self._khw_factor = None

        self._coex_node = -1

    def _construct_graph(self):
        visited_tensors = set()
        for _out in self._output_tensors:
            self.__dfs_sub_graph(_out, visited_tensors)

        for _out in self._output_tensors:
            if _out not in self._middle_out_tensors:
                self._split_tensor = _out

    def _calc_tiling(self):
        funcs = {TilingStrategy.DYNAMIC: self._calc_tiling_dynamic,
                 TilingStrategy.STATIC: self._calc_tiling_static}
        funcs.get(self._tiling_strategy)()

    def _calc_tiling_dynamic(self):
        pass

    def _calc_tiling_static(self):
        org_input_shape = operation.get_context().get("_org_shape")
        input_shape = util.shape_to_list(org_input_shape)
        input_dtype = self._split_tensor.dtype
        inputs = [{"shape": input_shape, "dtype": input_dtype}]
        outputs = [{"shape": input_shape, "dtype": input_dtype}, {"shape": input_shape, "dtype": input_dtype}]

        op_cores = util.get_core_num()
        op_ub_size = util.get_ub_size() - UB_TEMP_BUFFER
        op_l1_size = 0
        op_input_bytes = operation.get_context().get(PoolingWithArgCompileInfo.INPUT_BYTES)
        op_input_format = operation.get_context().get(PoolingWithArgCompileInfo.INPUT_FORMAT)
        op_ceil_mode = operation.get_context().get(PoolingWithArgCompileInfo.CALCULATE_MODE)
        op_pooling_mode = NCHW_DYNAMIC if operation.get_op_mode() == "dynamic" else NCHW_STATIC
        base_info = [op_cores, op_l1_size, op_ub_size, op_input_bytes, op_input_format, CEIL_MODE_MAP.get(op_ceil_mode),
                     op_pooling_mode]

        op_window_axes = operation.get_context().get("_org_pooling_axes")
        op_attr_axes = operation.get_context().get(PoolingWithArgCompileInfo.ATTR_AXES)
        op_window_dimensions = operation.get_context().get(PoolingWithArgCompileInfo.POOLING_DIMENSIONS)
        op_window_strides = operation.get_context().get(PoolingWithArgCompileInfo.POOLING_STRIDES)
        op_window_dilations = operation.get_context().get(PoolingWithArgCompileInfo.POOLING_DILATIONS)
        op_window_pads = operation.get_context().get(PoolingWithArgCompileInfo.POOLING_PADS)

        op_context_axes = unify_attr_info(op_window_axes)
        op_context_attr_axes = unify_attr_info(op_attr_axes)
        op_context_dimensions = unify_attr_info(op_window_dimensions)
        op_context_strides = unify_attr_info(op_window_strides)
        op_context_dilations = unify_attr_info(op_window_dilations)
        op_context_pads = unify_attr_info(op_window_pads)
        op_context_info = [op_context_axes, op_context_attr_axes, op_context_dimensions, op_context_strides,
                           op_context_dilations, op_context_pads]

        const_compile_info = {"_base_info": base_info,
                              "_coexisting_quantity": {"NO_SPLIT": COMMON_COEX, "SPLIT": WORKSPACE_COEX},
                              "_pattern": "PoolingWithArg",
                              "_pooling_info": op_context_info}

        op_type = "AutoTiling"
        run_info = op_tiling.do_op_tiling(op_type, const_compile_info, inputs, outputs)
        tiling_format = {
            "key_pattern": "int",
            "key_split": "int",
            "ub_axis": "int",
            "block_factor": "int",
            "block_ub_factor": "int",
            "ub_fractal_factor": "int",
            "ub_khw_factor": "int"
        }

        tiling_data = op_tiling.decode(run_info.get("tiling_data"), tiling_format)

        if SPLIT_DICT.get(tiling_data.get("key_split")) == self._split_mode \
                and BLOCK_MODE_DICT.get(tiling_data.get("key_pattern")) == self._block_mode \
                and INPUT_EXPAND_AXIS_MAP.get(tiling_data.get("ub_axis")) == self._ub_axis:
            self._valid_tiling = True
            self._block_factor = tiling_data.get("block_factor")
            self._block_ub_factor = tiling_data.get("block_ub_factor")
            self._ub_factor = tiling_data.get("ub_fractal_factor")
            self._khw_factor = tiling_data.get("ub_khw_factor")
            self._block_axis = min(self._ub_axis, 2) if self._block_mode == "HW_BLOCK" else 0
        else:
            self._valid_tiling = False

    def _add_compile_info(self):
        coex_node = operation.get_compile_info().get(CompileInfo.COEXISTING_QUANTITY, {})
        coex_node[self._split_mode] = self._coex_node
        operation.add_compile_info_inner(CompileInfo.COEXISTING_QUANTITY, coex_node)

    def __dfs_sub_graph(self, out, visited_tensors: set):
        for tensor_i in out.op.input_tensors:
            util.merge_value(self._in_out_map, tensor_i, out)

            if util.is_placeholder(tensor_i):
                self._classify_input_tensors(tensor_i)
            else:
                self._classify_middle_tensors(tensor_i)

            if tensor_i in visited_tensors:
                continue

            visited_tensors.add(tensor_i)

            self.__dfs_sub_graph(tensor_i, visited_tensors)

    def _classify_input_tensors(self, input_tensor):
        self._input_tensors.add(input_tensor)

    def _classify_middle_tensors(self, middle_tensor):
        if middle_tensor in self._output_tensors:
            self._middle_out_tensors.add(middle_tensor)
        elif len(middle_tensor.op.input_tensors) == 0:
            self._no_input_tensors.add(middle_tensor)
        else:
            self._middle_tensors.add(middle_tensor)

    def _set_scope(self):
        ub_tensors = self._input_transpose_tensors | self._output_transpose_tensors | self._transpose_tensors \
                     | self._no_input_tensors | self._cache_read_tensors
        for _one_tensor in ub_tensors:
            self._sch[_one_tensor].set_scope(BUFFER_UB)

    def _do_compute_align(self):
        for _tensor in self._input_transpose_tensors:
            self._sch[_tensor].compute_align(self._sch[_tensor].op.axis[-1], TRANSPOSE_ALIGN,
                                             tvm.const(0, dtype=_tensor.dtype))
            self._sch[_tensor].compute_align(self._sch[_tensor].op.axis[-2], TRANSPOSE_ALIGN)

        for _tensor in self._transpose_tensors:
            self._sch[_tensor].compute_align(self._sch[_tensor].op.axis[-1], TRANSPOSE_ALIGN)

        for _tensor in self._output_transpose_tensors:
            self._sch[_tensor].compute_align(self._sch[_tensor].op.axis[-1], TRANSPOSE_ALIGN)

    def _do_storage_align(self):
        for _tensor in (self._no_input_tensors | self._cache_read_tensors):
            self._sch[_tensor].storage_align(self._sch[_tensor].op.axis[-2], STORAGE_ALIGN, 0)

        for _tensor in self._transpose_tensors:
            dtypes = [_tensor.dtype, ]
            for _input_tensor in _tensor.op.input_tensors:
                dtypes.append(_input_tensor.dtype)
            if "uint1" in dtypes:
                self._sch[_tensor].storage_align(self._sch[_tensor].op.axis[1], STORAGE_FRACTAL, 0)

            if len(_tensor.op.reduce_axis) > 0 or _tensor.op.tag == "pooling_with_arg_expand":
                self._sch[_tensor].storage_align(self._sch[_tensor].op.axis[-3], STORAGE_FRACTAL, 0)

    def _set_constraint(self):
        if self._tiling_strategy == TilingStrategy.DYNAMIC and self._block_mode == "N_BLOCK":
            self._sch.set_constraint(self._block_factor >= 1)
            self._sch.set_constraint(tvm.expr.FloorDiv(
                (((tvm.expr.FloorDiv((self._block_ub_factor + NC_ALIGN - 1), NC_ALIGN) * NC_ALIGN)
                  + self._block_ub_factor) - 1), self._block_ub_factor) <= self._block_factor)

        if self._split_mode == NO_SPLIT:
            n_block_cond = self._block_ub_outer.var % self._block_factor == 0
            hw_block_cond = self._block_ub_outer.var == 0
            condition = n_block_cond if self._block_mode == N_BLOCK else hw_block_cond
            # only do once
            for _tensor in self._no_input_tensors:
                self._sch[_tensor].set_store_predicate(condition)

            for _tensor in self._input_transpose_tensors:
                if _tensor.dtype == "int32":
                    self._sch[_tensor].set_store_predicate(condition)

            for _tensor in self._transpose_tensors:
                if _tensor.dtype == "int32":
                    if _tensor.op.tag == "pooling_with_arg_pad":
                        self._sch[_tensor].set_store_predicate(condition)
                    elif _tensor.op.tag == "pooling_with_arg_expand":
                        self._sch[_tensor].set_store_predicate(condition)
                        self._sch[_tensor].mem_unique()

        shape_h = operation.get_context().get_current_compute().get("_fm_h")
        shape_w = operation.get_context().get_current_compute().get("_fm_w")
        kh = operation.get_context().get_current_compute().get("_kh")
        kw = operation.get_context().get_current_compute().get("_kw")
        stride_h = operation.get_context().get_current_compute().get("_stride_h")
        stride_w = operation.get_context().get_current_compute().get("_stride_w")
        pt = operation.get_context().get_current_compute().get("_padding_top")
        pb = operation.get_context().get_current_compute().get("_padding_bottom")
        pl = operation.get_context().get_current_compute().get("_padding_left")
        pr = operation.get_context().get_current_compute().get("_padding_right")
        dilate_h = operation.get_context().get_current_compute().get("_dilation_h")
        dilate_w = operation.get_context().get_current_compute().get("_dilation_w")

        if self._ceil_mode == 'FLOOR':
            cond_h = tvm.div((((((pt + shape_h) + pb) + stride_h) - (dilate_h * (kh - 1))) - 1), stride_h) > 0
            cond_w = tvm.div((((((pl + shape_w) + pr) + stride_w) - (dilate_w * (kw - 1))) - 1), stride_w) > 0
        else:
            cond_h = tvm.div((((((pt + shape_h) + pb) + 2 * stride_h) - (dilate_h * (kh - 1))) - 2), stride_h) > 0
            cond_w = tvm.div((((((pl + shape_w) + pr) + 2 * stride_w) - (dilate_w * (kw - 1))) - 2), stride_w) > 0

        self._sch.set_constraint(cond_h)
        self._sch.set_constraint(cond_w)

        if self._tiling_strategy == TilingStrategy.DYNAMIC:
            cond_ho = tvm.expr.GT((((pt + shape_h) + pb) + stride_h) - kh, 0)
            cond_wo = tvm.expr.GT((((pl + shape_w) + pr) + stride_w) - kw, 0)
            self._sch.set_constraint(cond_ho)
            self._sch.set_constraint(cond_wo)

    def _add_group_axis(self):
        group_id = tvm.call_extern("int32", "axis_group", 0, "append")
        for _tensor in self._transpose_tensors:
            if _tensor.op.tag in ("pooling_with_arg_vcmp", "pooling_with_arg_select"):
                self._sch[_tensor].pragma(self._sch[_tensor].op.axis[2], "axis_group", group_id)
                self._sch[_tensor].pragma(self._sch[_tensor].op.axis[3], "axis_group", group_id)

        if self._ub_axis == HO_AXIS:
            for _tensor in self._output_transpose_tensors:
                self._sch[_tensor].pragma(self._sch[_tensor].op.axis[2], "axis_group", group_id)
                self._sch[_tensor].pragma(self._sch[_tensor].op.axis[3], "axis_group", group_id)

        for _tensor in self._input_transpose_tensors:
            self._sch[_tensor].pragma(self._sch[_tensor].op.axis[0], "axis_group", group_id)
            self._sch[_tensor].pragma(self._sch[_tensor].op.axis[1], "axis_group", group_id)


class NchwCommonSchedule(PoolingWithArgScheduleNchwBase):
    """
    pooling with arg vars schedule
    """

    def __init__(self, outs, tiling_case):
        PoolingWithArgScheduleNchwBase.__init__(self, outs, tiling_case)
        self._block_outer = None
        self._block_inner = None
        self._ub_outer = None
        self._ub_inner = None
        self._reverse_split_outer = None
        self._reverse_split_inner = None
        self._reverse_split_at_outer = None
        self._reverse_split_at_inner = None

        self._ub_reversed_buffer = UB_TEMP_BUFFER
        self._coex_node = COMMON_COEX

    def do_schedule(self):
        self._construct_graph()
        self._calc_tiling()
        if not self._valid_tiling:
            return None
        self._sch = tvm.create_schedule([_out.op for _out in self._schedule_outs])
        self._sch.tiling_key = self._tiling_key.tiling_key
        self._do_cache_read()
        self._do_cache_write()
        self._do_cache_transpose()
        self._set_scope()
        self._do_compute_align()
        self._do_storage_align()
        self._do_tiling()
        self._do_storage_bound()
        self._do_reorder()
        self._do_compute_at()
        self._do_emit_insn()
        self._add_compile_info()
        self._set_constraint()
        self._add_group_axis()
        return self._sch

    def _do_cache_read(self):
        for _input_tensor in self._input_tensors:
            _cache_read_tensor = self._sch.cache_read(_input_tensor, BUFFER_UB,
                                                      list(self._in_out_map.get(_input_tensor)))
            self._in_out_map[_cache_read_tensor] = self._in_out_map.get(_input_tensor)
            self._in_out_map[_input_tensor] = {_cache_read_tensor, }
            self._cache_read_tensors.add(_cache_read_tensor)

    def _do_cache_write(self):
        for _output_tensor in self._output_tensors:
            if _output_tensor not in self._middle_out_tensors:
                _cache_write_tensor = self._sch.cache_write(_output_tensor, BUFFER_UB)
                self._cache_write_tensors.add(_cache_write_tensor)

    def _do_cache_transpose(self):
        # cache read tensor
        for _cache_read_tensor in self._cache_read_tensors:
            _cache_transpose_tensor = self._sch.cache_transpose(_cache_read_tensor, [1, 2, 0], BUFFER_UB,
                                                                list(self._in_out_map.get(_cache_read_tensor)))
            self._input_transpose_tensors.add(_cache_transpose_tensor)

        # middle tensor
        for _no_input_tensor in self._no_input_tensors:
            _cache_transpose_tensor = self._sch.cache_transpose(_no_input_tensor, [1, 2, 0], BUFFER_UB,
                                                                list(self._in_out_map.get(_no_input_tensor)))
            self._input_transpose_tensors.add(_cache_transpose_tensor)

        # middle out tensor
        for _middle_out_tensor in self._middle_out_tensors:
            self._sch[_middle_out_tensor].reorder(*self._sch[_middle_out_tensor].op.axis[1:],
                                                  self._sch[_middle_out_tensor].op.axis[0])
            self._reverse_split_tensor = self._sch.cache_write(_middle_out_tensor, BUFFER_UB)
            self._transpose_tensors.add(self._reverse_split_tensor)
            _cache_clone_tensor = self._sch.cache_clone(_middle_out_tensor, BUFFER_UB,
                                                        list(self._in_out_map.get(_middle_out_tensor)))
            self._sch[_cache_clone_tensor].compute_inline()
            _cache_write_tensor = self._sch.cache_write(_middle_out_tensor, BUFFER_UB)
            self._output_transpose_tensors.add(_cache_write_tensor)

            self._reverse_compute_at_tensors.add(_cache_write_tensor)
            self._reverse_compute_at_tensors.add(_middle_out_tensor)

        # middle tensor
        for _middle_tensor in self._middle_tensors:
            self._sch[_middle_tensor].reorder(*self._sch[_middle_tensor].op.axis[1:],
                                              self._sch[_middle_tensor].op.axis[0])
            _cache_transpose_tensor = self._sch.cache_write(_middle_tensor, BUFFER_UB)
            self._transpose_tensors.add(_cache_transpose_tensor)
            self._sch[_middle_tensor].compute_inline()

        # cache write tensor
        for _cache_write_tensor in self._cache_write_tensors:
            self._sch[_cache_write_tensor].reorder(*self._sch[_cache_write_tensor].op.axis[1:],
                                                   self._sch[_cache_write_tensor].op.axis[0])
            _cache_transpose_tensor = self._sch.cache_write(_cache_write_tensor, BUFFER_UB)
            self._transpose_tensors.add(_cache_transpose_tensor)
            self._reduce_split_tensor = _cache_transpose_tensor
            self._output_transpose_tensors.add(_cache_write_tensor)

    def _calc_tiling_dynamic(self):
        self._block_factor = operation.var_inner("_block_factor_0", (1, None))
        self._block_ub_factor = 16
        if self._block_mode == "HW_BLOCK":
            self._block_axis = min(self._ub_axis, 2)
        else:
            self._block_axis = 0
        self._ub_factor = operation.var_inner("_ub_fractal_factor_0", (1, None))

    def _do_tiling(self):
        # indices reduce
        self._ub_outer, self._ub_inner = self._sch[self._split_tensor].split(
            self._sch[self._split_tensor].op.axis[self._ub_axis], self._ub_factor)

        if self._block_mode == "N_BLOCK":
            self._block_ub_outer, self._block_ub_inner = self._sch[self._split_tensor].split(
                self._sch[self._split_tensor].op.axis[self._block_axis], self._block_ub_factor)

            self._block_outer, self._block_inner = self._sch[self._split_tensor].split(
                self._block_ub_outer, self._block_factor)
        else:
            self._block_ub_outer, self._block_ub_inner = self._sch[self._split_tensor].split(
                self._sch[self._split_tensor].op.axis[0], self._block_ub_factor)

            if self._ub_axis == self._block_axis:
                self._block_outer, self._block_inner = \
                    self._sch[self._split_tensor].split(self._ub_outer, self._block_factor)
            else:
                block_fuse = self._sch[self._split_tensor].fuse(
                    self._sch[self._split_tensor].op.axis[self._block_axis], self._ub_outer)
                self._block_outer, self._block_inner = \
                    self._sch[self._split_tensor].split(block_fuse, self._block_factor)

        # reverse compute at tensor
        self._reverse_split_outer, self._reverse_split_inner = self._sch[self._reverse_split_tensor].split(
            self._sch[self._reverse_split_tensor].op.axis[self._ub_axis - 1], self._ub_factor)
        self._reverse_split_at_outer, self._reverse_split_at_inner = self._sch[self._reverse_split_tensor].split(
            self._reverse_split_inner, nparts=1)

        self._sch[self._split_tensor].bind(self._block_outer, tvm.thread_axis("blockIdx.x"))

    def _do_reorder(self):
        if self._block_mode == "N_BLOCK":
            if self._ub_axis == HO_AXIS:
                # nc, 1, h, w
                self._sch[self._split_tensor].reorder(self._block_outer,
                                                      self._sch[self._split_tensor].op.axis[1],
                                                      self._ub_outer,
                                                      self._block_inner,
                                                      self._ub_inner,
                                                      self._sch[self._split_tensor].op.axis[3],
                                                      self._block_ub_inner)
                self._sch[self._reverse_split_tensor].reorder(self._sch[self._reverse_split_tensor].op.axis[0],
                                                              self._reverse_split_outer,
                                                              self._reverse_split_at_outer,
                                                              self._sch[self._reverse_split_tensor].op.reduce_axis[0],
                                                              self._reverse_split_at_inner,
                                                              self._sch[self._reverse_split_tensor].op.axis[2],
                                                              self._sch[self._reverse_split_tensor].op.axis[3])
            else:
                self._sch[self._split_tensor].reorder(self._block_outer,
                                                      self._sch[self._split_tensor].op.axis[1],
                                                      self._sch[self._split_tensor].op.axis[2],
                                                      self._ub_outer,
                                                      self._block_inner,
                                                      self._ub_inner,
                                                      self._block_ub_inner)
                self._sch[self._reverse_split_tensor].reorder(self._sch[self._reverse_split_tensor].op.axis[0],
                                                              self._sch[self._reverse_split_tensor].op.axis[1],
                                                              self._reverse_split_outer,
                                                              self._reverse_split_at_outer,
                                                              self._sch[self._reverse_split_tensor].op.reduce_axis[0],
                                                              self._reverse_split_at_inner,
                                                              self._sch[self._reverse_split_tensor].op.axis[3])
        else:
            if self._block_axis == self._ub_axis:
                # nc, 1, h, w
                self._sch[self._split_tensor].reorder(self._sch[self._split_tensor].op.axis[1],
                                                      self._block_outer,
                                                      self._block_inner,
                                                      self._block_ub_outer,
                                                      self._ub_inner,
                                                      self._sch[self._split_tensor].op.axis[3],
                                                      self._block_ub_inner)
                self._sch[self._reverse_split_tensor].reorder(self._sch[self._reverse_split_tensor].op.axis[0],
                                                              self._reverse_split_outer,
                                                              self._reverse_split_at_outer,
                                                              self._sch[self._reverse_split_tensor].op.reduce_axis[0],
                                                              self._reverse_split_at_inner,
                                                              self._sch[self._reverse_split_tensor].op.axis[2],
                                                              self._sch[self._reverse_split_tensor].op.axis[3])
            else:
                self._sch[self._split_tensor].reorder(self._sch[self._split_tensor].op.axis[1],
                                                      self._block_outer,
                                                      self._block_inner,
                                                      self._block_ub_outer,
                                                      self._ub_inner,
                                                      self._block_ub_inner)
                self._sch[self._reverse_split_tensor].reorder(self._sch[self._reverse_split_tensor].op.axis[0],
                                                              self._sch[self._reverse_split_tensor].op.axis[1],
                                                              self._reverse_split_outer,
                                                              self._reverse_split_at_outer,
                                                              self._sch[self._reverse_split_tensor].op.reduce_axis[0],
                                                              self._reverse_split_at_inner,
                                                              self._sch[self._reverse_split_tensor].op.axis[3])
        self._sch[self._reduce_split_tensor].reorder(self._sch[self._reduce_split_tensor].op.axis[0],
                                                     self._sch[self._reduce_split_tensor].op.reduce_axis[0],
                                                     *self._sch[self._reduce_split_tensor].op.axis[1:])

    def _do_storage_bound(self):
        ub_size = util.get_ub_size() - self._ub_reversed_buffer
        buffer_size = ub_size // self._coex_node
        buffer_tensors = self._input_transpose_tensors | self._no_input_tensors | self._cache_read_tensors \
                         | self._transpose_tensors | self._output_transpose_tensors
        for _one_tensor in buffer_tensors:
            self._sch[_one_tensor].set_buffer_size(buffer_size // DTYPE_BYTES_MAP.get(_one_tensor.dtype))

    def _do_compute_at(self):
        compute_at_tensors = self._input_transpose_tensors | self._no_input_tensors \
                             | self._cache_read_tensors | self._transpose_tensors | self._cache_write_tensors
        compute_at_axis = self._block_inner if self._block_mode == "N_BLOCK" else self._block_ub_outer
        for _one_tensor in compute_at_tensors:
            self._sch[_one_tensor].compute_at(self._sch[self._split_tensor], compute_at_axis)

        for _one_tensor in self._reverse_compute_at_tensors:
            self._sch[_one_tensor].reverse_compute_at(self._sch[self._reverse_split_tensor],
                                                      self._reverse_split_at_outer)

    def _do_emit_insn(self):
        three_dim_in_order = (1, 2, 0)
        three_dim_in_ord = tvm.call_intrin("handle", "tir.tvm_tuple", *tuple(three_dim_in_order))
        four_dim_out_order = (3, 0, 1, 2)
        four_dim_out_ord = tvm.call_intrin("handle", "tir.tvm_tuple", *tuple(four_dim_out_order))

        for _one_tensor in self._cache_read_tensors:
            self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[0], "dma_copy")

        for _one_tensor in self._no_input_tensors:
            self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[0], "vector_linear_sequence")

        transpose_three_attrs = {"src_in_dst_order": three_dim_in_ord, "is_trans_align": 1}
        for _one_tensor in self._input_transpose_tensors:
            if _one_tensor.dtype in ("int32", "float32"):
                transpose_three_attrs["enable_vnchwconv_b32"] = \
                    VNCHWCONV_B32_FLAG.get(self._tiling_case.get("tiling_strategy"))
            self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[0], "vector_transpose",
                                             attrs=transpose_three_attrs)

        for _one_tensor in self._transpose_tensors:
            tensor_tag = _one_tensor.op.tag
            dtypes = [_one_tensor.dtype, ]
            for _input_tensor in _one_tensor.op.input_tensors:
                dtypes.append(_input_tensor.dtype)
            if "uint1" in dtypes:
                self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[EMIT_AXIS_MAP.get(tensor_tag)],
                                                 EMIT_INSI_MAP.get(tensor_tag))
            elif len(_one_tensor.op.reduce_axis) == 0:
                self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[EMIT_AXIS_MAP.get(tensor_tag)],
                                                 EMIT_INSI_MAP.get(tensor_tag))
            else:
                self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.reduce_axis[0],
                                                 EMIT_INSI_MAP.get(tensor_tag))

        transpose_four_attrs = {"src_in_dst_order": four_dim_out_ord, "is_trans_align": 1}
        for _one_tensor in self._output_transpose_tensors:
            if _one_tensor.dtype in ("int32", "float32"):
                transpose_four_attrs["enable_vnchwconv_b32"] = \
                    VNCHWCONV_B32_FLAG.get(self._tiling_case.get("tiling_strategy"))
            self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[0], "vector_transpose",
                                             attrs=transpose_four_attrs)

        # out
        for _one_tensor in self._output_tensors:
            if _one_tensor == self._split_tensor:
                self._sch[_one_tensor].emit_insn(self._ub_inner, "dma_copy")
            else:
                self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[0], "dma_copy")


class NchwWorkSpaceSchedule(PoolingWithArgScheduleNchwBase):
    """
    pooling with arg vars schedule
    """

    def __init__(self, outs, tiling_case):
        PoolingWithArgScheduleNchwBase.__init__(self, outs, tiling_case)
        self._block_outer = None
        self._block_inner = None
        self._ub_outer = None
        self._ub_inner = None
        self._reverse_split_outer = None
        self._reverse_split_inner = None
        self._reverse_split_at_outer = None
        self._reverse_split_at_inner = None

        self._ub_reversed_buffer = UB_TEMP_BUFFER
        self._coex_node = WORKSPACE_COEX

        self._workspace_tensors = set()
        self._workspace_read_tensors = set()
        self._workspace_read_transpose_tensors = set()
        self._workspace_read_consumers = {}
        self._workspace_write_tensors = set()
        self._workspace_transpose_tensor = None

        self._workspace_reduce_outer = None
        self._workspace_reduce_inner = None
        self._reverse_split_reduce_outer = None
        self._reverse_split_reduce_inner = None
        self._reduce_split_reduce_outer = None
        self._reduce_split_reduce_inner = None
        self._block_workspace_ub_outer = None
        self._block_workspace_ub_inner = None
        self._ub_workspace_outer = None
        self._ub_workspace_inner = None
        self._block_workspace_outer = None
        self._block_workspace_inner = None

        self._workspace_compute_at_tensors = set()
        self._reduce_input_compute_at_tensors = set()
        self._reduce_indices_compute_at_tensors = set()
        self._output_gm_compute_at_tensors = set()

    def do_schedule(self):
        self._construct_graph()
        self._construct_workspace()
        self._calc_tiling()
        if not self._valid_tiling:
            return None
        self._sch = tvm.create_schedule([_out.op for _out in self._schedule_outs])
        self._sch.tiling_key = self._tiling_key.tiling_key
        self._do_cache_read()
        self._do_cache_read_workspace()
        self._do_cache_write()
        self._do_cache_write_workspace()
        self._do_cache_transpose_workspace()
        self._do_cache_transpose()
        self._set_scope()
        self._set_scope_workspace()
        self._do_compute_align()
        self._do_compute_align_workspace()
        self._do_storage_align()
        self._do_storage_align_workspace()
        self._do_tiling()
        self._do_storage_bound()
        self._do_reorder()
        self._do_compute_at()
        self._do_emit_insn()
        self._add_workspace_json()
        self._add_compile_info()
        self._set_constraint()
        self._add_group_axis()
        return self._sch

    def _construct_workspace(self):
        for _one_tensor in self._middle_tensors:
            if _one_tensor.op.attrs.get("workspace") is not None:
                self._workspace_tensors.add(_one_tensor)

        for _one_tensor in self._workspace_tensors:
            self._middle_tensors.remove(_one_tensor)

    def _do_cache_read_workspace(self):
        for _input_tensor in self._workspace_tensors:
            tmp_cache_read_tensors = set()
            for _consumer_tensor in self._in_out_map.get(_input_tensor):
                _cache_read_tensor = self._sch.cache_read(_input_tensor, BUFFER_UB, [_consumer_tensor])
                self._in_out_map[_cache_read_tensor] = _consumer_tensor
                tmp_cache_read_tensors.add(_cache_read_tensor)
                self._workspace_read_tensors.add(_cache_read_tensor)
                self._workspace_read_consumers[_cache_read_tensor] = _consumer_tensor
            self._in_out_map[_input_tensor] = tmp_cache_read_tensors

    def _do_cache_read(self):
        for _input_tensor in self._input_tensors:
            _cache_read_tensor = self._sch.cache_read(_input_tensor, BUFFER_UB,
                                                      list(self._in_out_map.get(_input_tensor)))
            self._in_out_map[_cache_read_tensor] = self._in_out_map.get(_input_tensor)
            self._in_out_map[_input_tensor] = {_cache_read_tensor, }
            self._cache_read_tensors.add(_cache_read_tensor)

    def _do_cache_write_workspace(self):
        for _output_tensor in self._workspace_tensors:
            _cache_write_tensor = self._sch.cache_write(_output_tensor, BUFFER_UB)
            self._workspace_write_tensors.add(_cache_write_tensor)

    def _do_cache_write(self):
        for _output_tensor in self._output_tensors:
            if _output_tensor not in self._middle_out_tensors:
                _cache_write_tensor = self._sch.cache_write(_output_tensor, BUFFER_UB)
                self._cache_write_tensors.add(_cache_write_tensor)

    def _do_cache_transpose_workspace(self):
        # middle tensor
        for _middle_tensor in self._workspace_write_tensors:
            self._sch[_middle_tensor].reorder(*self._sch[_middle_tensor].op.axis[1:],
                                              self._sch[_middle_tensor].op.axis[0])
            _cache_transpose_tensor = self._sch.cache_write(_middle_tensor, BUFFER_UB)
            self._transpose_tensors.add(_cache_transpose_tensor)
            self._sch[_middle_tensor].compute_inline()
            self._workspace_compute_at_tensors.add(_cache_transpose_tensor)

        for _middle_tensor in self._workspace_read_tensors:
            self._sch[_middle_tensor].reorder(*self._sch[_middle_tensor].op.axis[1:],
                                              self._sch[_middle_tensor].op.axis[0])
            _cache_transpose_tensor = self._sch.cache_write(_middle_tensor, BUFFER_UB)
            self._workspace_read_transpose_tensors.add(_cache_transpose_tensor)
            self._sch[_middle_tensor].compute_inline()
            if len(self._workspace_read_consumers.get(_middle_tensor).op.reduce_axis) > 0:
                self._reduce_input_compute_at_tensors.add(_cache_transpose_tensor)
            else:
                self._reduce_indices_compute_at_tensors.add(_cache_transpose_tensor)

        # workspace
        for _workspace_tensor in self._workspace_tensors:
            self._sch[_workspace_tensor].reorder(*self._sch[_workspace_tensor].op.axis[1:],
                                                 self._sch[_workspace_tensor].op.axis[0])
            _cache_transpose_tensor = self._sch.cache_write(_workspace_tensor, BUFFER_GM)
            self._workspace_transpose_tensor = _cache_transpose_tensor
            self._sch[_workspace_tensor].compute_inline()
            self._output_gm_compute_at_tensors.add(_cache_transpose_tensor)

    def _do_cache_transpose(self):
        # cache read tensor
        for _cache_read_tensor in self._cache_read_tensors:
            _cache_transpose_tensor = self._sch.cache_transpose(_cache_read_tensor, [1, 2, 0], BUFFER_UB,
                                                                list(self._in_out_map.get(_cache_read_tensor)))
            self._input_transpose_tensors.add(_cache_transpose_tensor)
            self._workspace_compute_at_tensors.add(_cache_read_tensor)
            self._workspace_compute_at_tensors.add(_cache_transpose_tensor)

        # middle tensor
        for _no_input_tensor in self._no_input_tensors:
            _cache_transpose_tensor = self._sch.cache_transpose(_no_input_tensor, [1, 2, 0], BUFFER_UB,
                                                                list(self._in_out_map.get(_no_input_tensor)))
            self._input_transpose_tensors.add(_cache_transpose_tensor)
            self._reduce_indices_compute_at_tensors.add(_no_input_tensor)
            self._reduce_indices_compute_at_tensors.add(_cache_transpose_tensor)

        # middle out tensor
        for _middle_out_tensor in self._middle_out_tensors:
            self._sch[_middle_out_tensor].reorder(*self._sch[_middle_out_tensor].op.axis[1:],
                                                  self._sch[_middle_out_tensor].op.axis[0])
            self._reverse_split_tensor = self._sch.cache_write(_middle_out_tensor, BUFFER_UB)
            self._output_gm_compute_at_tensors.add(self._reverse_split_tensor)
            self._transpose_tensors.add(self._reverse_split_tensor)
            _cache_clone_tensor = self._sch.cache_clone(_middle_out_tensor, BUFFER_UB,
                                                        list(self._in_out_map.get(_middle_out_tensor)))
            self._sch[_cache_clone_tensor].compute_inline()
            _cache_write_tensor = self._sch.cache_write(_middle_out_tensor, BUFFER_UB)
            self._output_transpose_tensors.add(_cache_write_tensor)

            self._reverse_compute_at_tensors.add(_cache_write_tensor)
            self._reverse_compute_at_tensors.add(_middle_out_tensor)

        # middle tensor
        for _middle_tensor in self._middle_tensors:
            self._sch[_middle_tensor].reorder(*self._sch[_middle_tensor].op.axis[1:],
                                              self._sch[_middle_tensor].op.axis[0])
            _cache_transpose_tensor = self._sch.cache_write(_middle_tensor, BUFFER_UB)
            self._transpose_tensors.add(_cache_transpose_tensor)
            self._sch[_middle_tensor].compute_inline()

            if _middle_tensor.dtype in ("float16", "float32"):
                self._workspace_compute_at_tensors.add(_cache_transpose_tensor)
            else:
                self._reduce_indices_compute_at_tensors.add(_cache_transpose_tensor)

        # cache write tensor
        for _cache_write_tensor in self._cache_write_tensors:
            self._sch[_cache_write_tensor].reorder(*self._sch[_cache_write_tensor].op.axis[1:],
                                                   self._sch[_cache_write_tensor].op.axis[0])
            _cache_transpose_tensor = self._sch.cache_write(_cache_write_tensor, BUFFER_UB)
            self._transpose_tensors.add(_cache_transpose_tensor)
            self._reduce_split_tensor = _cache_transpose_tensor
            self._output_transpose_tensors.add(_cache_write_tensor)
            # output gm compute at
            self._output_gm_compute_at_tensors.add(_cache_write_tensor)
            self._output_gm_compute_at_tensors.add(_cache_transpose_tensor)

    def _calc_tiling_dynamic(self):
        self._block_factor = operation.var_inner("_block_factor_0", (1, None))
        self._block_ub_factor = 16
        if self._block_mode == "HW_BLOCK":
            self._block_axis = min(self._ub_axis, 2)
        else:
            self._block_axis = 0
        self._ub_factor = operation.var_inner("_ub_fractal_factor_0", (1, None))
        self._khw_factor = operation.var_inner("_ub_khw_factor_0", (1, None))

    def _do_compute_align_workspace(self):
        self._sch[self._workspace_transpose_tensor].compute_align(
            self._sch[self._workspace_transpose_tensor].op.axis[-1], 16)

    def _do_storage_align_workspace(self):
        for _tensor in self._workspace_read_transpose_tensors:
            self._sch[_tensor].storage_align(self._sch[_tensor].op.axis[-2], 16, 0)

    def _set_scope_workspace(self):
        for _middle_tensor in (self._workspace_read_transpose_tensors | self._workspace_write_tensors):
            self._sch[_middle_tensor].set_scope(BUFFER_UB)

    def _do_tiling(self):
        # indices reduce
        self._ub_outer, self._ub_inner = self._sch[self._split_tensor].split(
            self._sch[self._split_tensor].op.axis[self._ub_axis], self._ub_factor)

        if self._block_mode == "HW_BLOCK":
            self._block_ub_outer, self._block_ub_inner = self._sch[self._split_tensor].split(
                self._sch[self._split_tensor].op.axis[0], self._block_ub_factor)

            if self._ub_axis == self._block_axis:
                self._block_outer, self._block_inner = \
                    self._sch[self._split_tensor].split(self._ub_outer, self._block_factor)
            else:
                block_fuse = self._sch[self._split_tensor].fuse(
                    self._sch[self._split_tensor].op.axis[self._block_axis], self._ub_outer)
                self._block_outer, self._block_inner = \
                    self._sch[self._split_tensor].split(block_fuse, self._block_factor)

            # workspace
            self._block_workspace_ub_outer, self._block_workspace_ub_inner = self._sch[
                self._workspace_transpose_tensor].split(
                self._sch[self._workspace_transpose_tensor].op.axis[-1], self._block_ub_factor)

            self._ub_workspace_outer, self._ub_workspace_inner = \
                self._sch[self._workspace_transpose_tensor].split(
                    self._sch[self._workspace_transpose_tensor].op.axis[self._ub_axis - 1], self._ub_factor)

            if self._ub_axis == self._block_axis:
                self._block_workspace_outer, self._block_workspace_inner = \
                    self._sch[self._workspace_transpose_tensor].split(self._ub_workspace_outer, self._block_factor)
            else:
                block_workspace_fuse = self._sch[self._workspace_transpose_tensor].fuse(
                    self._sch[self._workspace_transpose_tensor].op.axis[self._block_axis - 1], self._ub_workspace_outer)
                self._block_workspace_outer, self._block_workspace_inner = \
                    self._sch[self._workspace_transpose_tensor].split(block_workspace_fuse, self._block_factor)

            self._workspace_reduce_outer, self._workspace_reduce_inner = \
                self._sch[self._workspace_transpose_tensor].split(
                    self._sch[self._workspace_transpose_tensor].op.axis[0], self._khw_factor)

            # reverse compute at tensor
            self._reverse_split_outer, self._reverse_split_inner = self._sch[self._reverse_split_tensor].split(
                self._sch[self._reverse_split_tensor].op.axis[self._ub_axis - 1], self._ub_factor)
            self._reverse_split_at_outer, self._reverse_split_at_inner = self._sch[self._reverse_split_tensor].split(
                self._reverse_split_inner, nparts=1)
            self._reverse_split_reduce_outer, self._reverse_split_reduce_inner = \
                self._sch[self._reverse_split_tensor].split(
                    self._sch[self._reverse_split_tensor].op.reduce_axis[0], self._khw_factor)

            # reduce
            self._reduce_split_reduce_outer, self._reduce_split_reduce_inner = \
                self._sch[self._reduce_split_tensor].split(
                    self._sch[self._reduce_split_tensor].op.reduce_axis[0], self._khw_factor)
        else:
            # outputs
            self._block_ub_outer, self._block_ub_inner = self._sch[self._split_tensor].split(
                self._sch[self._split_tensor].op.axis[self._block_axis], self._block_ub_factor)
            self._block_outer, self._block_inner = self._sch[self._split_tensor].split(
                self._block_ub_outer, self._block_factor)

            # workspace
            self._ub_workspace_outer, self._ub_workspace_inner = self._sch[self._workspace_transpose_tensor].split(
                self._sch[self._workspace_transpose_tensor].op.axis[self._ub_axis - 1], self._ub_factor)
            self._workspace_reduce_outer, self._workspace_reduce_inner = \
                self._sch[self._workspace_transpose_tensor].split(
                    self._sch[self._workspace_transpose_tensor].op.axis[0], self._khw_factor)
            self._block_workspace_ub_outer, self._block_workspace_ub_inner = \
                self._sch[self._workspace_transpose_tensor].split(
                    self._sch[self._workspace_transpose_tensor].op.axis[-1], self._block_ub_factor)
            self._block_workspace_outer, self._block_workspace_inner = \
                self._sch[self._workspace_transpose_tensor].split(self._block_workspace_ub_outer, self._block_factor)

            # reverse compute at tensor
            self._reverse_split_outer, self._reverse_split_inner = self._sch[self._reverse_split_tensor].split(
                self._sch[self._reverse_split_tensor].op.axis[self._ub_axis - 1], self._ub_factor)
            self._reverse_split_at_outer, self._reverse_split_at_inner = self._sch[self._reverse_split_tensor].split(
                self._reverse_split_inner, nparts=1)
            self._reverse_split_reduce_outer, self._reverse_split_reduce_inner = \
                self._sch[self._reverse_split_tensor].split(
                    self._sch[self._reverse_split_tensor].op.reduce_axis[0], self._khw_factor)

            # reduce
            self._reduce_split_reduce_outer, self._reduce_split_reduce_inner = \
                self._sch[self._reduce_split_tensor].split(
                    self._sch[self._reduce_split_tensor].op.reduce_axis[0], self._khw_factor)

        self._sch[self._split_tensor].bind(self._block_outer, tvm.thread_axis("blockIdx.x"))

    def _do_reorder(self):
        if self._block_mode == "HW_BLOCK":
            if self._block_axis == self._ub_axis:
                self._sch[self._split_tensor].reorder(self._block_outer,
                                                      self._block_ub_outer,
                                                      self._block_inner,
                                                      self._sch[self._split_tensor].op.axis[1],
                                                      self._ub_inner,
                                                      self._sch[self._split_tensor].op.axis[3],
                                                      self._block_ub_inner)

                self._sch[self._workspace_transpose_tensor].reorder(self._block_workspace_outer,
                                                                    self._block_workspace_ub_outer,
                                                                    self._block_workspace_inner,
                                                                    self._workspace_reduce_outer,
                                                                    self._workspace_reduce_inner,
                                                                    self._ub_workspace_inner,
                                                                    self._sch[self._workspace_transpose_tensor]
                                                                    .op.axis[2],
                                                                    self._block_workspace_ub_inner)

                self._sch[self._reverse_split_tensor].reorder(self._sch[self._reverse_split_tensor].op.axis[0],
                                                              self._reverse_split_outer,
                                                              self._reverse_split_at_outer,
                                                              self._reverse_split_reduce_outer,
                                                              self._reverse_split_reduce_inner,
                                                              self._reverse_split_at_inner,
                                                              self._sch[self._reverse_split_tensor].op.axis[2],
                                                              self._sch[self._reverse_split_tensor].op.axis[3])
                self._sch[self._reduce_split_tensor].reorder(self._sch[self._reduce_split_tensor].op.axis[0],
                                                             self._reduce_split_reduce_outer,
                                                             self._reduce_split_reduce_inner,
                                                             *self._sch[self._reduce_split_tensor].op.axis[1:])
            else:
                self._sch[self._split_tensor].reorder(self._block_outer,
                                                      self._block_ub_outer,
                                                      self._block_inner,
                                                      self._sch[self._split_tensor].op.axis[1],
                                                      self._ub_inner,
                                                      self._block_ub_inner)

                self._sch[self._workspace_transpose_tensor].reorder(self._block_workspace_outer,
                                                                    self._block_workspace_ub_outer,
                                                                    self._block_workspace_inner,
                                                                    self._workspace_reduce_outer,
                                                                    self._workspace_reduce_inner,
                                                                    self._ub_workspace_inner,
                                                                    self._block_workspace_ub_inner)

                self._sch[self._reverse_split_tensor].reorder(self._sch[self._reverse_split_tensor].op.axis[0],
                                                              self._sch[self._reverse_split_tensor].op.axis[1],
                                                              self._reverse_split_outer,
                                                              self._reverse_split_at_outer,
                                                              self._reverse_split_reduce_outer,
                                                              self._reverse_split_reduce_inner,
                                                              self._reverse_split_at_inner,
                                                              self._sch[self._reverse_split_tensor].op.axis[3])
                self._sch[self._reduce_split_tensor].reorder(self._sch[self._reduce_split_tensor].op.axis[0],
                                                             self._sch[self._reduce_split_tensor].op.axis[1],
                                                             self._reduce_split_reduce_outer,
                                                             self._reduce_split_reduce_inner,
                                                             *self._sch[self._reduce_split_tensor].op.axis[2:])

        else:
            if self._ub_axis == HO_AXIS:
                # nc, 1, h, w
                self._sch[self._split_tensor].reorder(self._block_outer,
                                                      self._block_inner,
                                                      self._ub_outer,
                                                      self._sch[self._split_tensor].op.axis[1],
                                                      self._ub_inner,
                                                      self._sch[self._split_tensor].op.axis[3],
                                                      self._block_ub_inner)
                # khw, h, w, nc
                self._sch[self._workspace_transpose_tensor].reorder(self._block_workspace_outer,
                                                                    self._block_workspace_inner,
                                                                    self._ub_workspace_outer,
                                                                    self._workspace_reduce_outer,
                                                                    self._workspace_reduce_inner,
                                                                    self._ub_workspace_inner,
                                                                    self._sch[self._workspace_transpose_tensor]
                                                                    .op.axis[2],
                                                                    self._block_workspace_ub_inner)
                self._sch[self._reverse_split_tensor].reorder(self._sch[self._reverse_split_tensor].op.axis[0],
                                                              self._reverse_split_outer,
                                                              self._reverse_split_at_outer,
                                                              self._reverse_split_reduce_outer,
                                                              self._reverse_split_reduce_inner,
                                                              self._reverse_split_at_inner,
                                                              self._sch[self._reverse_split_tensor].op.axis[2],
                                                              self._sch[self._reverse_split_tensor].op.axis[3])
                self._sch[self._reduce_split_tensor].reorder(self._sch[self._reduce_split_tensor].op.axis[0],
                                                             self._reduce_split_reduce_outer,
                                                             self._reduce_split_reduce_inner,
                                                             *self._sch[self._reduce_split_tensor].op.axis[1:])
            else:
                # nc, 1, h, w
                self._sch[self._split_tensor].reorder(self._block_outer,
                                                      self._block_inner,
                                                      self._sch[self._split_tensor].op.axis[1],
                                                      self._sch[self._split_tensor].op.axis[2],
                                                      self._ub_outer,
                                                      self._ub_inner,
                                                      self._block_ub_inner)
                # khw, h, w, nc
                self._sch[self._workspace_transpose_tensor].reorder(self._block_workspace_outer,
                                                                    self._block_workspace_inner,
                                                                    self._ub_workspace_outer,
                                                                    self._workspace_reduce_outer,
                                                                    self._sch[self._workspace_transpose_tensor]
                                                                    .op.axis[1],
                                                                    self._workspace_reduce_inner,
                                                                    self._ub_workspace_inner,
                                                                    self._block_workspace_ub_inner)
                self._sch[self._reverse_split_tensor].reorder(self._sch[self._reverse_split_tensor].op.axis[0],
                                                              self._reverse_split_outer,
                                                              self._reverse_split_at_outer,
                                                              self._sch[self._reverse_split_tensor].op.axis[1],
                                                              self._reverse_split_reduce_outer,
                                                              self._reverse_split_reduce_inner,
                                                              self._reverse_split_at_inner,
                                                              self._sch[self._reverse_split_tensor].op.axis[3])
                self._sch[self._reduce_split_tensor].reorder(self._sch[self._reduce_split_tensor].op.axis[0],
                                                             self._sch[self._reduce_split_tensor].op.axis[1],
                                                             self._reduce_split_reduce_outer,
                                                             self._reduce_split_reduce_inner,
                                                             *self._sch[self._reduce_split_tensor].op.axis[2:])

    def _do_storage_bound(self):
        ub_size = util.get_ub_size() - self._ub_reversed_buffer
        buffer_size = ub_size // self._coex_node
        buffer_tensors = self._input_transpose_tensors | self._no_input_tensors | self._cache_read_tensors \
                         | self._transpose_tensors | self._output_transpose_tensors \
                         | self._workspace_read_transpose_tensors | self._workspace_write_tensors
        for _one_tensor in buffer_tensors:
            self._sch[_one_tensor].set_buffer_size(buffer_size // DTYPE_BYTES_MAP.get(_one_tensor.dtype))

    def _do_compute_at(self):
        # expand_t
        for _one_tensor in self._workspace_compute_at_tensors:
            self._sch[_one_tensor].compute_at(self._sch[self._workspace_transpose_tensor], self._workspace_reduce_outer)

        # input reduce
        for _one_tensor in self._reverse_compute_at_tensors:
            self._sch[_one_tensor].reverse_compute_at(self._sch[self._reverse_split_tensor],
                                                      self._reverse_split_at_outer)
        for _one_tensor in self._reduce_input_compute_at_tensors:
            self._sch[_one_tensor].compute_at(self._sch[self._reverse_split_tensor],
                                              self._reverse_split_reduce_outer)
        # indices reduce
        for _one_tensor in self._reduce_indices_compute_at_tensors:
            self._sch[_one_tensor].compute_at(self._sch[self._reduce_split_tensor], self._reduce_split_reduce_outer)

        for _one_tensor in self._output_gm_compute_at_tensors:
            if self._block_mode == "HW_BLOCK":
                self._sch[_one_tensor].compute_at(self._sch[self._split_tensor], self._block_inner)
            else:
                self._sch[_one_tensor].compute_at(self._sch[self._split_tensor], self._ub_outer)

    def _do_emit_insn(self):
        three_dim_in_order = (1, 2, 0)
        three_dim_in_ord = tvm.call_intrin("handle", "tir.tvm_tuple", *tuple(three_dim_in_order))
        four_dim_out_order = (3, 0, 1, 2)
        four_dim_out_ord = tvm.call_intrin("handle", "tir.tvm_tuple", *tuple(four_dim_out_order))

        for _one_tensor in self._cache_read_tensors:
            self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[0], "dma_copy")

        for _one_tensor in self._workspace_read_transpose_tensors:
            self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[0], "dma_copy")

        for _one_tensor in self._no_input_tensors:
            self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[0], "vector_linear_sequence")

        transpose_three_attrs = {"src_in_dst_order": three_dim_in_ord, "is_trans_align": 1}
        for _one_tensor in self._input_transpose_tensors:
            if _one_tensor.dtype in ("int32", "float32"):
                transpose_three_attrs["enable_vnchwconv_b32"] = \
                    VNCHWCONV_B32_FLAG.get(self._tiling_case.get("tiling_strategy"))
            self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[0], "vector_transpose",
                                             attrs=transpose_three_attrs)

        for _one_tensor in self._transpose_tensors:
            tensor_tag = _one_tensor.op.tag
            dtypes = [_one_tensor.dtype, ]
            for _input_tensor in _one_tensor.op.input_tensors:
                dtypes.append(_input_tensor.dtype)
            if "uint1" in dtypes:
                self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[EMIT_AXIS_MAP.get(tensor_tag)],
                                                 EMIT_INSI_MAP.get(tensor_tag))
            elif len(_one_tensor.op.reduce_axis) == 0:
                self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[EMIT_AXIS_MAP.get(tensor_tag)],
                                                 EMIT_INSI_MAP.get(tensor_tag))

        reverse_tag = self._reverse_split_tensor.op.tag
        self._sch[self._reverse_split_tensor].emit_insn(self._reverse_split_reduce_inner,
                                                        EMIT_INSI_MAP.get(reverse_tag))
        reduce_tag = self._reduce_split_tensor.op.tag
        self._sch[self._reduce_split_tensor].emit_insn(self._reduce_split_reduce_inner, EMIT_INSI_MAP.get(reduce_tag))

        transpose_four_attrs = {"src_in_dst_order": four_dim_out_ord, "is_trans_align": 1}
        for _one_tensor in self._output_transpose_tensors:
            if _one_tensor.dtype in ("int32", "float32"):
                transpose_four_attrs["enable_vnchwconv_b32"] = \
                    VNCHWCONV_B32_FLAG.get(self._tiling_case.get("tiling_strategy"))
            self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[0], "vector_transpose",
                                             attrs=transpose_four_attrs)

        # out
        self._sch[self._workspace_transpose_tensor].emit_insn(self._ub_workspace_inner, "dma_copy")

        for _one_tensor in self._output_tensors:
            if _one_tensor == self._split_tensor:
                self._sch[_one_tensor].emit_insn(self._ub_inner, "dma_copy")
            else:
                self._sch[_one_tensor].emit_insn(self._sch[_one_tensor].op.axis[0], "dma_copy")

    def _add_workspace_json(self):
        self._output_tensors.append(self._workspace_transpose_tensor)
        if self._tiling_strategy == TilingStrategy.STATIC:
            fractal_shape = util.shape_to_list(self._workspace_transpose_tensor.shape)
            workspace_size = reduce(lambda x, y: x * y, fractal_shape[:-1]) \
                             * ((fractal_shape[-1] + TRANSPOSE_ALIGN - 1) // TRANSPOSE_ALIGN * TRANSPOSE_ALIGN) * \
                             DTYPE_BYTE_MAPPING.get(self._workspace_transpose_tensor.dtype)
            workspace_dict_in_json = {
                "num": 1,
                "size": [workspace_size, ],
                "type": [0]
            }
            operation.get_op_context().add_build_json_result("workspace", workspace_dict_in_json)
