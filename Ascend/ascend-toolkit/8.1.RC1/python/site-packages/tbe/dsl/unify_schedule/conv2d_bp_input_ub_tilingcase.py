#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2022-2023 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================

from itertools import product
from tbe.common.utils import decode
from tbe.common.utils import do_op_tiling
from tbe.common.utils import log
from tbe.common.utils.errormgr import error_manager_cube
from tbe.dsl.compute.util import shape_to_list
from tbe.dsl.compute.util import int_ceil_div
from tbe.dsl.base.operation import add_compile_info
from tbe.dsl.base.operation import register_tiling_case
from tbe.dsl.base.operation import get_compile_info
from tbe.dsl.static_schedule.util import get_all_tensor
from tbe.dsl.unify_schedule.constants import Pattern
from tbe.dsl.unify_schedule.cube_tilingcase import TilingUtils as utils


OFFSET_ONE = 1
UB_BLOCK_SIZE = 16
INT = "int"
ORI_SHAPE = "ori_shape"


@register_tiling_case(pattern=Pattern.CONV2D_BACKPROP_INPUT_UB)
def calc_ub_conv2d_bp(outs, option=None):
    """
    tiling_case func for dynamic shape cov2d backprop

    Parameters
    ----------
    outs: tvm tensor or list of tvm tensor, results for tvm compute

    Returns
    -------
    list of dict, each dict for a tiling case
    """
    tensor_conv2d_bp_ub = TensorConv2dBpUb(outs)
    tensor_list, param_map = tensor_conv2d_bp_ub.get_tensor_and_param_map()
    tiling_conv2d_bp_ub = TilingConv2dBpUb(param_map)
    tiling_cases = []
    inputs, outputs = tensor_conv2d_bp_ub.get_input_output_para_list()
    attrs = tensor_conv2d_bp_ub.get_attrs()
    tiling_cases = tiling_conv2d_bp_ub.get_tilingcase_static(inputs, outputs, attrs)
    for tiling_case in tiling_cases:
        tiling_case["tensor_list"] = tensor_list
        tiling_case["param_map"] = param_map
    return tiling_cases


class TensorConv2dBpUb():
    """
    use to get tensor for conv2dtranspose
    """
    def __init__(self, res_list):
        self.res_list = res_list
        self.param_map = {}
        self.compute_tensor = {}
        self.placeholder_tensor = []
        self.tensor_dst_node = {}

    @staticmethod
    def get_attrs():
        attrs = ({"name": "groups", "dtype": "int", "value": 1},)
        return attrs

    def get_tensor_and_param_map(self):
        self.compute_tensor, self.placeholder_tensor, self.tensor_dst_node = get_all_tensor(self.res_list[-1])
        if self.compute_tensor.get("fwc_res", None) is not None:
            fifo_res = self.compute_tensor.get("fwc_res")
            self.param_map["fifo_fusion_flag"] = True
        conv_res_op = self.compute_tensor.get("conv_res").op
        fixpipe_op = self.compute_tensor.get("fixpipe", None)
        block_dict = {"fm_c0": int(conv_res_op.attrs["fm_c0"]),
                      "w_k0": int(conv_res_op.attrs["w_k0"]),
                      "w_n0": int(conv_res_op.attrs["w_n0"]),
                      "res_c0": int(conv_res_op.attrs["res_c0"])}
        self.param_map["block_dict"] = block_dict
        ori_res_shape = {"batch_ub":  int(conv_res_op.attrs[ORI_SHAPE][0]),
                         "c_cub": int(conv_res_op.attrs[ORI_SHAPE][1]),
                         "h_cub": int(conv_res_op.attrs[ORI_SHAPE][2]),
                         "w_cub": int(conv_res_op.attrs[ORI_SHAPE][3])}
        self.param_map["ori_res_shape"] = ori_res_shape
        self.param_map["ori_format"] = conv_res_op.attrs["ori_format"]
        if fixpipe_op is not None:
            self.param_map["fixpipe_vector_params"] = fixpipe_op.op.attrs["vector_params"]
            self.param_map["fixpipe_vector_tensors"] = fixpipe_op.op.attrs["vector_tensors"]
            self.param_map["fixpipe_nz2nd_flag"] = fixpipe_op.op.attrs["nz2nd_flag"]
            self.param_map["fixpipe_anti_quant_flag"] = fixpipe_op.op.attrs["nz2nd_flag"]
            self.param_map["fixpipe_op_dict"] = fixpipe_op.op.attrs["op_dict"]
        conv_param = {"forward_dilation_h": int(conv_res_op.attrs["forward_dilation_h"]),
                      "forward_dilation_w": int(conv_res_op.attrs["forward_dilation_w"]),
                      "need_prepad": bool(conv_res_op.attrs["need_prepad"])}
        self.param_map["conv_param"] = conv_param
        self.param_map["op_type"] = "Conv2DTranspose"
        self.param_map["bias_flag"] = self.compute_tensor.get("tensor_bias", None) is not None
        return [self.compute_tensor, self.placeholder_tensor], self.param_map

    def get_input_output_para_list(self):
        inputs = []
        for tensor in self.placeholder_tensor.values():
            tensor_shape = shape_to_list(tensor.shape)
            tensor_ori_shape = shape_to_list(tensor.op.attrs[ORI_SHAPE]) if tensor.op.attrs.get(ORI_SHAPE) else []
            tensor_format = tensor.op.attrs["format"] if tensor.op.attrs.get("format") else ""
            tensor_para = {"shape": tensor_shape,
                           "ori_shape": tensor_ori_shape,
                           "format": tensor_format,
                           "dtype": tensor.dtype}
            inputs.append(tensor_para)
        outputs = []
        if self.param_map.get("fifo_fusion_flag"):
            tensor = self.compute_tensor.get("fwc_res")
            tensor_shape = shape_to_list(tensor.shape)
            tensor_ori_shape = shape_to_list(tensor.op.attrs[ORI_SHAPE]) if tensor.op.attrs.get(ORI_SHAPE) else []
            tensor_format = tensor.op.attrs["format"] if tensor.op.attrs.get("format") else ""
            tensor_para = {"shape": tensor_shape,
                           "ori_shape": tensor_ori_shape,
                           "format": tensor_format,
                           "dtype": tensor.dtype}
            outputs.append(tensor_para)
        for tensor in self.res_list:
            tensor_shape = shape_to_list(tensor.shape)
            tensor_ori_shape = shape_to_list(tensor.op.attrs[ORI_SHAPE]) if tensor.op.attrs.get(ORI_SHAPE) else []
            tensor_format = tensor.op.attrs["format"] if tensor.op.attrs.get("format") else ""
            tensor_para = {"shape": tensor_shape,
                           "ori_shape": tensor_ori_shape,
                           "format": tensor_format,
                           "dtype": tensor.dtype}
            outputs.append(tensor_para)
        return inputs, outputs


class TilingConv2dBpUb():

    def __init__(self, param_map):
        self.param_map = param_map

    @staticmethod
    def _get_tiling_id(choice):
        """
        calculate tiling_id according template choice
        """
        (a_pb, b_pb, c_pb, reorder_mn_flag, split_cout_flag, split_k_flag) = choice
        tiling_id = 0
        tiling_id = (tiling_id << OFFSET_ONE) + (a_pb - 1)
        tiling_id = (tiling_id << OFFSET_ONE) + (b_pb - 1)
        tiling_id = (tiling_id << OFFSET_ONE) + (c_pb - 1)
        tiling_id = (tiling_id << OFFSET_ONE) + reorder_mn_flag
        tiling_id = (tiling_id << OFFSET_ONE) + split_cout_flag
        tiling_id = (tiling_id << OFFSET_ONE) + split_k_flag
        return tiling_id

    @staticmethod
    def _get_attach_choices():
        """
        generates all selections of l0 flags

        Returns
        -------
        list: all selections of flags
        """    
        (a_pb, b_pb, c_pb, reorder_mn_flag, split_cout_flag, split_k_flag) = ([utils.DB_ON, utils.DB_OFF],
            [utils.DB_ON, utils.DB_OFF], [utils.DB_ON, utils.DB_OFF], [1, 0], [1, 0], [1, 0])
        choice_list = [a_pb, b_pb, c_pb, reorder_mn_flag, split_cout_flag, split_k_flag]
        template_choices = list(product(*choice_list))
        return template_choices

    @staticmethod
    def _set_tiling_value(cache_tiling, tiling_data):
        """
        set cache_tiling value for static scene
        """
        cache_tiling["Aub_shape"] = [tiling_data.get("batch_ub"), tiling_data.get("c_aub")]
        cache_tiling["Bub_shape"] = [tiling_data.get("h_bub"), tiling_data.get("w_bub")]
        cache_tiling["Cub_shape"] = [tiling_data.get("batch_ub"), tiling_data.get("c_cub"),
                                     tiling_data.get("h_cub"), tiling_data.get("w_cub")]
        log.debug("Tiling from op_tiling is {}".format(cache_tiling))

    def get_cache_tiling(self, inputs):
        """
        get all tiling template of conv2dtranspose
        ---------------------------------
        cache_tiling variable:
        return list of tilingcase
        """
        add_compile_info("dynamic_mode", "dynamic_mkn")
        add_compile_info("binary_mode_flag", True)
        add_compile_info("binary_attrs", {"bias_flag": self.param_map.get("bias_flag"),
                                          "nd_flag": False,
                                          "split_k_flag": False,
                                          "zero_flag": False,
                                          "weight_nz": False})
        add_compile_info("block_dim", {"CORE_NUM":1})
        add_compile_info("block_dict", self.param_map.get("block_dict"))
        add_compile_info("ori_res_shape", self.param_map.get("ori_res_shape"))
        add_compile_info("conv_param", self.param_map.get("conv_param"))
        add_compile_info("fifo_fusion_flag", True if self.param_map.get("fifo_fusion_flag") else False)
        add_compile_info("ori_format", self.param_map.get("ori_format"))
        if self.param_map.get("fixpipe_op_dict", None) is not None:
            fixpipe_op_dict = {
                "pre_conv": str(self.param_map.get("fixpipe_op_dict").get("pre_conv")),
                "pre_activation": str(self.param_map.get("fixpipe_op_dict").get("pre_activation")),
                "post_anti_quant": str(self.param_map.get("fixpipe_op_dict").get("post_anti_quant")),
                "post_eltwise": str(self.param_map.get("fixpipe_op_dict").get("post_eltwise")),
                "post_activation": str(self.param_map.get("fixpipe_op_dict").get("post_activation")),
                "post_quant": str(self.param_map.get("fixpipe_op_dict").get("post_quant")),
                "post_transform": str(self.param_map.get("fixpipe_op_dict").get("post_transform"))
            }
            add_compile_info("fixpipe_op_dict", fixpipe_op_dict)
        # get cache_tiling
        tilingcases = []
        weight_shape = inputs[1].get("shape")
        template_choices = self._get_attach_choices()
        for choice in template_choices:
            cache_tiling = {'manual_pingpong_buffer': {'AUB_pbuffer': choice[0], 'BUB_pbuffer': choice[1],
                            'CUB_pbuffer': choice[2]},
                            "reorder_mn_flag": choice[3],
                            "split_cout_flag": choice[4],
                            "split_k_flag": choice[5]}
            one_tilingcase = {"key": self._get_tiling_id(choice),
                              "tiling_strategy": cache_tiling}
            tilingcases.append(one_tilingcase)
        return tilingcases

    def get_tilingcase_static(self, inputs, outputs, attrs):
        tiling_cases = self.get_cache_tiling(inputs)
        run_info = self._get_op_tiling(inputs, outputs, attrs)
        tiling_key = run_info.get("tiling_key")
        new_tiling_cases = []
        for idx, _ in enumerate(tiling_cases):
            if tiling_cases[idx]["key"] == tiling_key:
                self._set_tiling_value(tiling_cases[idx]["tiling_strategy"], run_info.get("tiling_data"))
                new_tiling_cases.append(tiling_cases[idx])
        tiling_cases = new_tiling_cases
        if new_tiling_cases == []:
            error_manager_cube(f"invalid tiling_id {tiling_key}")
        return tiling_cases

    def _get_op_tiling(self, inputs, outputs, attrs):
        run_info = do_op_tiling(self.param_map.get("op_type"), get_compile_info(), inputs, outputs, None, None, attrs)
        tiling_var = {"c_aub": INT, "h_bub": INT, "w_bub": INT,
                      "batch_ub": INT, "c_cub": INT, "h_cub": INT, "w_cub": INT}
        tiling_data = decode(run_info.get("tiling_data"), tiling_var)
        run_info["tiling_data"] = tiling_data
        return run_info
