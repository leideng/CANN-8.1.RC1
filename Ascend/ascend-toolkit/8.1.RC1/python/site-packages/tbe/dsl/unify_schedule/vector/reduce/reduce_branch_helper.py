#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright (c) Huawei Technologies Co., Ltd. 2022-2023. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
helper for branch tensor before reduce
"""


class BranchTensorInfo:
    def __init__(self, graph_info, schedule, cache_read_map, cache_write_map):
        self.graph_info = graph_info
        self.schedule = schedule
        self.cache_read_tensor_and_buffer_map = cache_read_map
        self.cache_write_tensor_and_buffer_map = cache_write_map
        self.hook_tensors = graph_info.branch_tensor_hook_map.keys()
        self.real_hook_stages = self._get_real_hook_stage()
        self.hook_tensor_split_map = self._do_hook_tensor_split()

    def get_hook_tensor_axis(self, tensor, ori_emit_insn_axis):
        emit_insn_axis = ori_emit_insn_axis
        if tensor in self.hook_tensor_split_map:
            emit_insn_axis = self.hook_tensor_split_map.get(tensor)[1]
        return emit_insn_axis

    def get_all_branch_stages(self, backward_stage_graph_map):
        producers = set()
        for branch_output in self.graph_info.branch_output_tensors:
            producers.update(self._get_all_branch_producer_stages(branch_output, backward_stage_graph_map))
        producers = producers | self.graph_info.branch_output_tensors
        return producers

    def do_reverse_compute_at(self):
        for hook_tensor, branch_tensors in self.graph_info.branch_tensor_hook_map.items():
            # hook tensor can be placeholder or mid output tensor before reduce
            real_hook_stage = self._get_real_hook(hook_tensor)

            for branch_tensor in branch_tensors:
                branch_tensors_ub_read_write_set = set()

                def get_branch_buffer_set(tensor, buffer_map):
                    if tensor in buffer_map:
                        buffer_tensor = buffer_map.get(tensor)
                        branch_tensors_ub_read_write_set.add(buffer_tensor)
                        get_branch_buffer_set(buffer_tensor, buffer_map)

                get_branch_buffer_set(branch_tensor, self.cache_read_tensor_and_buffer_map)
                get_branch_buffer_set(branch_tensor, self.cache_write_tensor_and_buffer_map)

                hook_compute_at_axis = self.hook_tensor_split_map.get(real_hook_stage)[0]
                self.schedule[branch_tensor].reverse_compute_at(self.schedule[real_hook_stage],
                                                                hook_compute_at_axis)

                for branch_buffer_tensor in branch_tensors_ub_read_write_set:
                    self.schedule[branch_buffer_tensor].reverse_compute_at(self.schedule[real_hook_stage],
                                                                           hook_compute_at_axis)

    def _get_real_hook(self, hook_tensor):
        if hook_tensor in self.cache_read_tensor_and_buffer_map:
            hook_tensor_buffer = self.cache_read_tensor_and_buffer_map.get(hook_tensor)
            return self._get_real_hook(hook_tensor_buffer)
        return hook_tensor

    def _get_real_hook_stage(self):
        real_hook_stages = set()
        for hook_tensor in self.hook_tensors:
            real_hook_stages.add(self._get_real_hook(hook_tensor))
        return real_hook_stages

    def _do_hook_tensor_split(self):
        hook_tensor_split_map = {}
        for real_hook_stage in self.real_hook_stages:
            outer, inner = self.schedule[real_hook_stage].split(self.schedule[real_hook_stage].op.axis[0], nparts=1)
            hook_tensor_split_map[real_hook_stage] = [outer, inner]
        return hook_tensor_split_map

    def _get_all_branch_producer_stages(self, tensor, backward_stage_graph_map):
        producers = set()
        for producer in backward_stage_graph_map.get(tensor):
            if producer in self.real_hook_stages:
                continue
            producers.add(producer)
            producers.update(self._get_all_branch_producer_stages(producer, backward_stage_graph_map))
        return producers
