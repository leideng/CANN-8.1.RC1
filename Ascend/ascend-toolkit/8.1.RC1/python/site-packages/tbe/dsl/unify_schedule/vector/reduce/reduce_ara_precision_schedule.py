#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2024-2025 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
reduce ra high precision schedule
"""

from tbe import tvm
from tbe.dsl.base.operation import var_inner_adaptive
from tbe.dsl.base.operation import get_context
from tbe.common.utils.errormgr import get_error_message

from .reduce_tilingcase import SingleReduceInfo
from .reduce_tilingcase import ReduceTilingCase
from .vector_info import ComputeGraphInfo
from .reduce_base_precision_schedule import ReduceBasePrecisionSchedule
from ... import util
from ...constants import FAKE_NODE_TAG
from ...constants import DTYPE_BYTE_MAPPING
from ...constants import ReduceSchType


BLOCK_IDX = "blockIdx.x"
INT32_MAX = 2 ** 31 - 1
CONST = "const"
LOCAL_UB = "local.UB"
PARENT = "parent"
SCOPE = "scope"
INSTRUCTION = "instruction"
ATTRS = "attrs"


class ReduceARANormalPrecisionSchedule(ReduceBasePrecisionSchedule):
    """
    Schedule for Normal High Precision Reduce
    """
    def __init__(self, graph_info: ComputeGraphInfo, reduce_info: SingleReduceInfo,
                 tiling_case: ReduceTilingCase, outs):
        super().__init__(graph_info, reduce_info, tiling_case, outs)

        self.reduce_rf_tensor = None
        self.reduce_rf_wks_tensor = None
        self.reduce_rf_ub_tensor = None
        self.reduce_rf_reread_ub_tensor = None

        self.iter_rf_outer = None
        self.iter_rf_inner = None
        self.iter_ub_outer_2 = None
        self.iter_ub_inner_2 = None
        self.iter_rf_tensor_outer = None
        self.iter_rf_tensor_inner = None

        self.ub_split_reduce_idx = None
        self.factor_axis_idx = None

        self.multi_core_bind_axis = None
        self.block_split_same_axis = False
        self.need_workspace = self.tiling_case.reduce_sch_type == ReduceSchType.ARA_HIGH_PRECISION_WORKSPACE or \
                            self.tiling_case.reduce_sch_type == ReduceSchType.ARA_HIGH_PRECISION_BIG_DIM_WORKSPACE

    def do_schedule(self):
        self._create_schedule()

        self._do_cache_read()
        self._do_cache_write()
        self._do_mid_output_tensor_process()
        self._set_scope()
        self._init_branch_info()
        self._collect_tensors()
        self._do_input_db()

        self._do_tiling()
        self._do_buffer_tile()
        self._do_reorder()

        self._calc_storage_align()
        self._do_storage_align()
        self._calc_bind_buffer()
        self._do_bind_buffer()

        self._do_storage_bound()
        self._do_set_constraint()
        self._do_multi_core()

        self._calc_compute_at()
        self._do_compute_at()
        self._do_reverse_compute_at()

        self._calc_emit_insn()
        self._do_emit_insn()

        self._calc_compute_align()
        self._do_compute_align()

        # 该场景下只有一个workspace，且没有sync tensor，需要额外增加一个fake workspace
        if self.need_workspace:
            util.add_sch_additional_entry(self.sch, "need_extra_fake_workspace", True)

        return self.sch

    def _do_tiling(self):
        self._get_tiling_factor()
        self._do_blk_tiling()
        self._do_ub_tiling()

        # input -> input_ub -> reduce_rf_tensor -> reduce_tensor -> res
        # 举例:   (8192, 128)    (A128,R64,128)     (R128,128)      (128)
        # ub tiling做rfactor
        self.factor_axis_idx = self.tiling_case.ub_split_axis_index
        self.reduce_rf_tensor = self.sch.rfactor(self.reduce_tensor, self.ub_split_result["outer_itervar"],
                                                 factor_axis=self.factor_axis_idx)
        self.update_stage(self.reduce_rf_tensor, self.reduce_tensor, True)
        self.sch[self.reduce_rf_tensor].set_scope(LOCAL_UB)

        # reduce_rf_tensor split, 第二刀切分
        rf_axis_var = self.sch[self.reduce_rf_tensor].op.axis[self.factor_axis_idx]
        self.iter_rf_tensor_outer, self.iter_rf_tensor_inner = \
            self.sch[self.reduce_rf_tensor].split(rf_axis_var, factor=self.ub_split_result["factor2"])

        if self.need_workspace:
            self._do_workspace_tiling()
        else:
            # reduce_tensor的reduce轴大小已经变了, 第二刀切分
            iter_axis_2 = self.sch[self.reduce_tensor].op.reduce_axis[self.ub_split_reduce_idx]
            self.iter_ub_outer_2, self.iter_ub_inner_2 = self.sch[self.reduce_tensor].split(iter_axis_2,
                                                            factor=self.ub_split_result["factor2"])

    def _do_workspace_tiling(self):
        # 先强制做两次rfactor + 1次workspace
        # (1) input -> input_ub -> reduce_rf_tensor -> reduce_rf_ub_tensor -> reduce_rf_wks_tensor ->
        # 举例:                  (1,A384*R96,6144)     (1,A4*R96,6144)          (1,A4,6144)
        # (2) -> reduce_rf_reread_ub_tensor -> reduce_tensor -> res
        # 举例:       (1,A4,6144)                (1,R4,6144)
        # 第二刀切分
        iter_axis = self.sch[self.reduce_tensor].op.reduce_axis[self.ub_split_reduce_idx]
        iter_ub_outer2, iter_ub_inner2 = self.sch[self.reduce_tensor].split(iter_axis,
                                                                        factor=self.ub_split_result["factor2"])
        self.reduce_rf_wks_tensor = self.sch.rfactor(self.reduce_tensor, iter_ub_outer2,
                                                    factor_axis=self.factor_axis_idx)
        self.update_stage(self.reduce_rf_wks_tensor, self.reduce_tensor, True)
        self.sch[self.reduce_rf_wks_tensor].set_scope(LOCAL_UB)

        self.reduce_rf_ub_tensor = self.sch.cache_write(self.reduce_rf_wks_tensor, LOCAL_UB)
        self.reduce_rf_reread_ub_tensor = \
            self.sch.cache_read(self.reduce_rf_wks_tensor, LOCAL_UB, [self.reduce_tensor])
        self.sch[self.reduce_rf_wks_tensor].set_scope("")
        self.outs.append(self.reduce_rf_wks_tensor)

        self.cache_write_tensors_and_buffer_map[self.reduce_rf_wks_tensor] = self.reduce_rf_ub_tensor
        self.update_stage(self.reduce_rf_ub_tensor, self.reduce_rf_wks_tensor, True)
        self.cache_read_tensors_and_buffer_map[self.reduce_rf_wks_tensor] = self.reduce_rf_reread_ub_tensor
        self.update_stage(self.reduce_rf_reread_ub_tensor, self.reduce_rf_wks_tensor, False)

        # reduce_tensor的reduce轴大小已经变了, 第三刀切分
        iter_axis_2 = self.sch[self.reduce_tensor].op.reduce_axis[self.ub_split_reduce_idx]
        self.iter_ub_outer_2, self.iter_ub_inner_2 = self.sch[self.reduce_tensor].split(iter_axis_2,
                                                        factor=self.ub_split_result["factor3"])

    def _get_tiling_factor(self):
        # block
        blk_factor = self.tiling_case.block_factor
        block_inner = blk_factor if blk_factor is not None else var_inner_adaptive("_block_factor", (1, None))
        self.block_split_result["factor"] = block_inner

        # ub_factor
        ub_factor = self.tiling_case.ub_factor
        ub_inner = ub_factor if ub_factor is not None else var_inner_adaptive("_ub_factor", (1, INT32_MAX))
        self.ub_split_result["factor"] = ub_inner

        # ub_factor_2
        ub_factor2 = self.tiling_case.ub_factor_2
        ub_inner_2 = ub_factor2 if ub_factor2 is not None else var_inner_adaptive("_ub_factor_2", (1, INT32_MAX))
        self.ub_split_result["factor2"] = ub_inner_2

        if self.need_workspace:
            # ub_factor_3
            ub_factor_r_3 = self.tiling_case.ub_factor_r_3
            ub_inner_r_secondary = ub_factor_r_3 if ub_factor_r_3 is not None else \
                var_inner_adaptive("_ub_factor_r_3", (1, INT32_MAX))
            self.ub_split_result["factor3"] = ub_inner_r_secondary

            #  workspace tensor buffer tile
            tile_max = self.tiling_case.buffer_tile_max
            buffer_tile_max_var = tile_max if tile_max is not None else \
                var_inner_adaptive("_buffer_tile_max", (1, None))
            self.ub_split_result["buffer_tile_max"] = buffer_tile_max_var

    def _do_blk_tiling(self):
        # blk split
        axis_idx = self.none_reduce_index_map.get(self.tiling_case.block_split_axis_index,
                                                  self.tiling_case.block_split_axis_index)
        iter_blk_outer, iter_blk_inner = self.sch[self.res_tensor].split(self.res_tensor.op.axis[axis_idx],
                                                                         factor=self.block_split_result["factor"])
        self.block_split_result["outer_itervar"] = iter_blk_outer
        self.block_split_result["inner_itervar"] = iter_blk_inner

    def _do_ub_tiling(self):
        # ub一定切R轴
        ub_split_idx = self.tiling_case.ub_split_axis_index
        if ub_split_idx not in self.reduce_info.reduce_axis_indexes:
            dict_args = {"errCode": "E90003",
                         "detailed_cause": f"ub_split_axis_index {ub_split_idx} should be reduce axis"}
            raise RuntimeError(dict_args, get_error_message(dict_args))

        # ub split
        self.ub_split_reduce_idx = self.reduce_info.reduce_axis_indexes.index(ub_split_idx)
        iter_ub_outer, iter_ub_inner = \
            self.sch[self.reduce_tensor].split(self.sch[self.reduce_tensor].op.reduce_axis[self.ub_split_reduce_idx],
                                               factor=self.ub_split_result["factor"])
        self.ub_split_result["outer_itervar"] = iter_ub_outer
        self.ub_split_result["inner_itervar"] = iter_ub_inner

    def _do_buffer_tile(self):
        # 1. reduce_rf_tensor 前的tensor，compute_at后, infer bound会放大，需要增加 buffer_tile
        if self.need_workspace:
            # 最外层的reduce for循环最终会compute_at在 reduce_rf_wks_tensor 的 op.axis[self.factor_axis_idx]
            reduce_compute_at_axis = self.sch[self.reduce_rf_wks_tensor].op.axis[self.factor_axis_idx]
        else:
            # 最外层的reduce for循环最终会compute_at在 reduce_tensor 的 iter_ub_outer_2
            reduce_compute_at_axis = self.iter_ub_outer_2

        before_rf_tensor = list(self.backward_stage_graph_map[self.reduce_rf_tensor])[0]
        buffer_tile_list = []
        for idx, value in enumerate(before_rf_tensor.shape):
            if idx == self.tiling_case.ub_split_axis_index:
                # buffer_tile推导： (6000, 8000), ub_factor为72, ub_factor2为72,
                #     6000
                #  84(i) 72(a) -----> compute_at在i轴上，a为ub内的轴，需要描述 before_rf_tensor的a的大小
                # 2(j) 72(k)
                # a = min(6000 - i * ub_factor, ub_factor), i为轴变量，ub_factor为切分因子
                # i = min(j * ub_factor2 + k, maxi), 其中 maxi=84=ceil(6000, ub_factor), j为切分的外轴，k为切分的内轴
                maxi = tvm.div(value + self.ub_split_result["factor"] - 1, self.ub_split_result["factor"])
                # j 需要使用compute at后的变量
                i = tvm.min(reduce_compute_at_axis * self.ub_split_result["factor2"] + self.iter_rf_tensor_inner,
                            maxi)
                a = tvm.min(value - i * self.ub_split_result["factor"], self.ub_split_result["factor"])
                buffer_tile_list.append((None, a))
            else:
                buffer_tile_list.append((None, None))
        self.sch[before_rf_tensor].buffer_tile(*buffer_tile_list)

        # 2. reduce_rf_wks_tensor的 infer bound也不对
        if self.need_workspace:
            buffer_tile_list = []
            for j in range(len(self.reduce_rf_wks_tensor.shape)):
                if j == self.tiling_case.ub_split_axis_index:
                    buffer_tile_list.append((None, self.ub_split_result["buffer_tile_max"]))
                else:
                    buffer_tile_list.append((None, None))
            self.sch[self.reduce_rf_wks_tensor].buffer_tile(*buffer_tile_list)

    def _do_reorder(self):
        reordered_axis_list = []
        alen = self.factor_axis_idx
        blen = len(list(self.sch[self.reduce_rf_tensor].op.axis)) - 1
        reordered_axis_list.extend([x for x in list(self.sch[self.reduce_rf_tensor].op.axis)[:alen]])
        reordered_axis_list.append(self.iter_rf_tensor_outer)
        reordered_axis_list.append(self.iter_rf_tensor_inner)
        reordered_axis_list.extend([x for x in list(self.sch[self.reduce_rf_tensor].op.axis)[alen + 1 : blen]])
        reordered_axis_list.append(self.sch[self.reduce_rf_tensor].op.reduce_axis[0])
        reordered_axis_list.append(self.sch[self.reduce_rf_tensor].op.axis[-1])
        self.sch[self.reduce_rf_tensor].reorder(*reordered_axis_list)

        reduce_reorder = []
        alen = len(list(self.sch[self.reduce_tensor].op.axis)) - 1
        reduce_reorder.extend([x for x in list(self.sch[self.reduce_tensor].op.axis)[:alen]])
        reduce_reorder.append(self.iter_ub_outer_2)
        reduce_reorder.append(self.iter_ub_inner_2)
        reduce_reorder.append(self.sch[self.reduce_tensor].op.axis[-1])
        self.sch[self.reduce_tensor].reorder(*reduce_reorder)

        if self.need_workspace:
            reordered_axis_list = []
            alen = len(list(self.sch[self.reduce_rf_ub_tensor].op.axis)) - 1
            reordered_axis_list.extend([x for x in list(self.sch[self.reduce_rf_ub_tensor].op.axis)[:alen]])
            reordered_axis_list.append(self.sch[self.reduce_rf_ub_tensor].op.reduce_axis[0])
            reordered_axis_list.append(self.sch[self.reduce_rf_ub_tensor].op.axis[-1])
            self.sch[self.reduce_rf_ub_tensor].reorder(*reordered_axis_list)

    def _calc_storage_align(self):
        align_index = -2 # RA -> ARA
        # before reduce stage
        # 也需要对 branch tensor 做 storage_align，所以可以直接使用 self.tensors_before_reduce
        for tensor in self.tensors_before_reduce:
            if tensor not in self.graph_info.input_tensor_set:
                align_factor = int(self.block_size_byte // DTYPE_BYTE_MAPPING.get(tensor.dtype))
                self.storage_align_map[tensor] = [tensor.op.axis[align_index], align_factor, 0]

        # after reduce stage
        for tensor in self.tensors_after_reduce:
            if tensor not in self.graph_info.endpoint_output_tensor_set | self.graph_info.real_output_tensor_set | \
                    self.graph_info.input_tensor_set:
                align_factor = int(self.block_size_byte // DTYPE_BYTE_MAPPING.get(tensor.dtype))
                self.storage_align_map[tensor] = [tensor.op.axis[align_index], align_factor, 0]

        reduce_align_factor = int(self.block_size_byte // DTYPE_BYTE_MAPPING.get(self.reduce_tensor.dtype))
        reduce_tensors = [self.reduce_rf_tensor, self.reduce_tensor]
        if self.need_workspace:
            reduce_tensors.extend([self.reduce_rf_ub_tensor, self.reduce_rf_reread_ub_tensor])
        for tensor in reduce_tensors:
            self.storage_align_map[tensor] = [self.sch[tensor].op.axis[align_index], reduce_align_factor, 0]

    def _calc_bind_buffer(self):
        if self.need_workspace:
            align_factor = int(self.block_size_byte // DTYPE_BYTE_MAPPING.get(self.reduce_tensor.dtype))
            bind_axis = len(self.reduce_rf_wks_tensor.shape) - 2
            bind_factor = tvm.div((self.reduce_rf_wks_tensor.shape[bind_axis + 1] + align_factor - 1),
                                  align_factor) * align_factor
            self.bind_buffer_map[self.reduce_rf_wks_tensor] = \
                [self.sch[self.reduce_rf_wks_tensor].op.axis[bind_axis], bind_factor, 0]

    def _do_storage_bound(self):
        all_tensors_before_reduce = self.get_all_producers_stages(self.reduce_tensor)
        all_tensors_before_reduce = all_tensors_before_reduce.union(
            self.branch_tensor_info.get_all_branch_stages(self.backward_stage_graph_map))
        for stage_tensor in self.forward_stage_graph_map:
            if stage_tensor in self.graph_info.real_output_tensor_set:
                # don't set bound for real_output_tensors(gm)
                continue
            if stage_tensor in self.graph_info.input_tensor_set:
                # don't set bound for input_tensor_set(gm)
                continue
            if stage_tensor is self.reduce_rf_wks_tensor:
                # don't set bound for reduce_rf_wks_tensor(gm)
                continue

            # reduce_tensor is after reduce
            if stage_tensor in all_tensors_before_reduce:
                ub_count = self.tiling_case.tensor_ub_size_before_reduce
            else:
                ub_count = self.tiling_case.tensor_ub_size_after_reduce
            self.sch[stage_tensor].set_buffer_size(ub_count)

    def _do_set_constraint(self):
        if get_context().get_current_compute().get("_mode") == CONST:
            return
        # 1. set for ub constraint
        self._do_set_ub_constraint()
        # 2. set for block constraint
        self.sch.set_constraint(self.block_split_result.get("factor") <= self.tiling_case.tensor_ub_size_after_reduce)

    def _do_set_ub_constraint(self):
        ub_size = self.tiling_case.tensor_ub_size_before_reduce
        # first stage constraint
        first_stage_shape_in_ub = 1
        for index, value in enumerate(self.reduce_info.shape_before_reduce):
            if index < self.tiling_case.ub_split_axis_index:
                continue
            if index == self.tiling_case.ub_split_axis_index:
                self.sch.set_constraint(self.ub_split_result.get("factor") <= ub_size)
                first_stage_shape_in_ub *= self.ub_split_result.get("factor")
            elif index == self.tiling_case.block_split_axis_index:
                first_stage_shape_in_ub *= self.block_split_result.get("factor")
            else:
                self.sch.set_constraint(value <= ub_size)
                first_stage_shape_in_ub *= value
        self.sch.set_constraint(first_stage_shape_in_ub <= ub_size)

    def _do_multi_core(self):
        block = tvm.thread_axis("blockIdx.x")
        fuse_axis_list = []
        if self.tiling_case.is_secondary_block_split:
            block_factor_2 = self.tiling_case.block_factor_2
            block_inner_2 = block_factor_2 if block_factor_2 is not None else \
                            var_inner_adaptive("_block_factor_2", (1, None))
            self.block_split_result_2["factor"] = block_inner_2
            if self.tiling_case.block_split_axis_index_2 == self.tiling_case.block_split_axis_index or \
                self.tiling_case.block_split_axis_index == 0:
                # split -> fuse -> multicore
                self.block_split_same_axis = True
                split_axis = self.block_split_result.get("outer_itervar")
                blk_outer_2, blk_inner_2 = self.sch[self.res_tensor].split(split_axis, factor=block_inner_2)

                blk_idx = self.none_reduce_index_map.get(self.tiling_case.block_split_axis_index,
                                                         self.tiling_case.block_split_axis_index)
                fuse_axis_list = [self.sch[self.res_tensor].op.axis[idx] for idx in range(0, blk_idx)]
                fuse_axis_list.append(blk_outer_2)
            else:
                axis_idx = self.none_reduce_index_map.get(self.tiling_case.block_split_axis_index_2,
                                                          self.tiling_case.block_split_axis_index_2)
                split_axis = self.sch[self.res_tensor].op.axis[axis_idx]
                blk_outer_2, blk_inner_2 = self.sch[self.res_tensor].split(split_axis, factor=block_inner_2)
                fuse_axis_list = [blk_outer_2]
            self.block_split_result_2["outer_itervar"] = blk_outer_2
            self.block_split_result_2["inner_itervar"] = blk_inner_2
        else:
            blk_idx = self.none_reduce_index_map.get(self.tiling_case.block_split_axis_index,
                                                     self.tiling_case.block_split_axis_index)
            fuse_axis_list = [self.sch[self.res_tensor].op.axis[idx] for idx in range(0, blk_idx)]
            fuse_axis_list.append(self.block_split_result.get("outer_itervar"))

        if len(fuse_axis_list) > 1:
            self.multi_core_bind_axis = self.sch[self.res_tensor].fuse(*fuse_axis_list)
        else:
            self.multi_core_bind_axis = fuse_axis_list[0]
        self.sch[self.res_tensor].bind(self.multi_core_bind_axis, block)

    def _calc_compute_at(self):
        if self.tiling_case.is_secondary_block_split:
            res_at_axis = self.block_split_result_2.get("inner_itervar") if self.block_split_same_axis else \
                self.block_split_result.get("outer_itervar")
        else:
            res_at_axis = self.multi_core_bind_axis

        # 不能直接使用 self.tensors_before_reduce，需要去掉 get_all_branch_stages
        # branch tensor不参与compute at
        tensors_before_rf = self.get_all_producers_stages(self.reduce_rf_tensor)
        for tensor in tensors_before_rf:
            # reduce_rf_tensor的 axis[self.factor_axis_idx] 被切分成了outer和inner
            self.compute_at_map[tensor] = {
                PARENT: self.sch[self.reduce_rf_tensor],
                SCOPE: self.iter_rf_tensor_inner
            }

        if self.need_workspace:
            self.compute_at_map[self.reduce_rf_tensor] = {
                PARENT: self.sch[self.reduce_rf_ub_tensor],
                SCOPE: self.sch[self.reduce_rf_ub_tensor].op.axis[self.factor_axis_idx]
            }
            self.compute_at_map[self.reduce_rf_ub_tensor] = {
                PARENT: self.sch[self.reduce_rf_wks_tensor],
                SCOPE: self.sch[self.reduce_rf_wks_tensor].op.axis[self.factor_axis_idx]
            }
            self.compute_at_map[self.reduce_rf_reread_ub_tensor] = {
                PARENT: self.sch[self.reduce_tensor],
                SCOPE: self.iter_ub_outer_2
            }
            self.compute_at_map[self.reduce_tensor] = {
                PARENT: self.sch[self.res_tensor],
                SCOPE: res_at_axis
            }
            for tensor in self.tensors_after_reduce:
                self.compute_at_map[tensor] = {
                    PARENT: self.sch[self.res_tensor],
                    SCOPE: res_at_axis
                }

            self.compute_at_map[self.reduce_rf_wks_tensor] = {
                PARENT: self.sch[self.res_tensor],
                SCOPE: res_at_axis
            }
        else:
            self.compute_at_map[self.reduce_rf_tensor] = {
                PARENT: self.sch[self.reduce_tensor],
                SCOPE: self.iter_ub_outer_2
            }
            self.compute_at_map[self.reduce_tensor] = {
                PARENT: self.sch[self.res_tensor],
                SCOPE: res_at_axis
            }
            for tensor in self.tensors_after_reduce:
                self.compute_at_map[tensor] = {PARENT: self.sch[self.res_tensor], SCOPE: res_at_axis}

    def _calc_emit_insn(self):
        self._calc_reduce_emit_insn()
        self._calc_other_emit_insn()

    def _calc_reduce_emit_insn(self):
        insn = self._get_insn(self.reduce_info.reduce_tensor)

        if self.tiling_case.reduce_sch_type == ReduceSchType.ARA_HIGH_PRECISION or \
            self.tiling_case.reduce_sch_type == ReduceSchType.ARA_HIGH_PRECISION_WORKSPACE:
            reduce_attrs = self.ara_reduce_attr
        else:
            reduce_attrs = self.ara_reduce_big_attr
        self.emit_insn_map[self.reduce_rf_tensor] = {
            SCOPE: self.sch[self.reduce_rf_tensor].op.reduce_axis[0],
            INSTRUCTION: insn,
            ATTRS: reduce_attrs
        }
        self.emit_insn_map[self.reduce_tensor] = {
            SCOPE: self.iter_ub_inner_2,
            INSTRUCTION: insn,
            ATTRS: reduce_attrs
        }

        if self.need_workspace:
            self.emit_insn_map[self.reduce_rf_ub_tensor] = {
                SCOPE: self.sch[self.reduce_rf_ub_tensor].op.reduce_axis[0],
                INSTRUCTION: insn,
                ATTRS: reduce_attrs
            }
            self.emit_insn_map[self.reduce_rf_wks_tensor] = {
                SCOPE: self.sch[self.reduce_rf_wks_tensor].op.axis[self.factor_axis_idx + 1],
                INSTRUCTION: "dma_copy"
            }
            self.emit_insn_map[self.reduce_rf_reread_ub_tensor] = {
                SCOPE: self.sch[self.reduce_rf_reread_ub_tensor].op.axis[0],
                INSTRUCTION: "dma_copy"
            }

    def _calc_other_emit_insn(self):
        # 也需要对branch tensor打上指令映射，所以可以直接使用 self.tensors_before_reduce
        # not include self.reduce_tensor
        remaining_tensors = self.tensors_before_reduce | self.tensors_after_reduce | \
            self.graph_info.endpoint_output_tensor_set

        for tensor in remaining_tensors:
            if tensor in self.graph_info.input_tensor_set:
                continue
            insn_info = self._get_insn(tensor)
            iter_var = self.sch[tensor].op.axis[0]
            if tensor in self.mid_output_tensor_cache_read_list:
                insn_info = "phony_insn"
            elif tensor in self.graph_info.real_output_tensor_set:
                insn_info = "dma_copy"
            if insn_info == "":
                insn_info = "dma_copy"

            if tensor in self.graph_info.endpoint_output_tensor_set:
                iter_var = self.block_split_result.get("inner_itervar")

            self.emit_insn_map[tensor] = {
                SCOPE: self.branch_tensor_info.get_hook_tensor_axis(tensor, iter_var),
                INSTRUCTION: insn_info
            }

    def _calc_compute_align(self):
        for single_tensor, param in self.storage_align_map.items():
            insn = self.emit_insn_map.get(single_tensor).get(INSTRUCTION)
            if insn in ["dma_copy", ""]:
                continue
            axis = self.sch[single_tensor].op.axis[-1]
            factor = param[1]
            self.compute_align_map[single_tensor] = [axis, factor, None]


class ReduceARAGroupPrecisionSchedule(ReduceBasePrecisionSchedule):
    """
    Schedule for Group High Precision ARA Reduce
    """
    def __init__(self, graph_info: ComputeGraphInfo, reduce_info: SingleReduceInfo,
                 tiling_case: ReduceTilingCase, outs):
        super().__init__(graph_info, reduce_info, tiling_case, outs)

        self.reduce_blk_rf_tensor = None
        self.reduce_blk_rf_ub_tensor = None
        self.reduce_blk_rf_reread_ub_tensor = None
        self.reduce_rf_tensor = None

        self.iter_rf_tensor_outer = None
        self.iter_rf_tensor_inner = None
        self.iter_blk_rf_ub_outer = None
        self.iter_blk_rf_ub_inner = None
        self.reduce_outer = None
        self.reduce_inner = None

        self.factor_axis_idx = 0
        self.ub_tiling_reduce_axis_index = None
        self.multi_core_bind_axis = None
        self.thread = None

    def do_schedule(self):
        self._create_schedule()

        # do prepare schedule
        self._do_cache_read()
        self._do_cache_write()
        self._do_mid_output_tensor_process()
        self._set_scope()
        self._init_branch_info()
        self._collect_tensors()
        self._do_input_db()

        # do tiling and reorder
        self._do_tiling()
        self._do_buffer_tile()
        self._do_reorder()

        # align
        self._calc_storage_align()
        self._do_storage_align()
        self._calc_bind_buffer()
        self._do_bind_buffer()

        # group reduce special
        self._do_storage_bound()
        self._do_set_constraint()
        self._do_multi_core()
        self._do_set_store_predicate()
        self._do_block_sync()

        self._calc_compute_at()
        self._do_compute_at()
        self._do_reverse_compute_at()
        self._do_compute_root()

        self._calc_emit_insn()
        self._do_emit_insn()

        self._calc_compute_align()
        self._do_compute_align()

        self._add_build_args()
        self._add_block_sync_flag(self.tiling_case.tiling_key)

        return self.sch

    def _do_tiling(self):
        self._get_tiling_factor()

        # 对 reduce_tensor 做blk切分，并做rfactor 借A轴开多核
        # input -> cast -> reduce_rf_tensor -> reduce_blk_rf_ub_tensor -> reduce_blk_rf_tensor ->
        # -> reduce_blk_rf_reread_ub_tensor -> reduce_tensor -> cast
        self._do_blk_tiling()
        # 对 reduce_blk_rf_ub_tensor 做ub切分
        self._do_ub_tiling()

        self.factor_axis_idx = self.tiling_case.ub_split_axis_index
        # (A,Ar.o,R.i.o,R.i,A) -> (A,Ar.o,A.i.o,R.i,A)
        self.reduce_rf_tensor = self.sch.rfactor(self.reduce_blk_rf_ub_tensor,
                                                 self.ub_split_result["outer_itervar"],
                                                 factor_axis=self.factor_axis_idx + 1)
        self.update_stage(self.reduce_rf_tensor, self.reduce_blk_rf_ub_tensor, True)
        self.sch[self.reduce_rf_tensor].set_scope(LOCAL_UB)

        # reduce_rf_tensor split 第二刀
        rf_axis_var = self.sch[self.reduce_rf_tensor].op.axis[self.factor_axis_idx + 1]
        self.iter_rf_tensor_outer, self.iter_rf_tensor_inner = \
            self.sch[self.reduce_rf_tensor].split(rf_axis_var, factor=self.ub_split_result["factor2"])

        # reduce_blk_rf_ub_tensor 的reduce轴大小已经改变，第二刀
        ub_axis_var = self.sch[self.reduce_blk_rf_ub_tensor].op.reduce_axis[self.ub_tiling_reduce_axis_index]
        self.iter_blk_rf_ub_outer, self.iter_blk_rf_ub_inner = \
            self.sch[self.reduce_blk_rf_ub_tensor].split(ub_axis_var, factor=self.ub_split_result["factor2"])

        # group reduce第二阶段的reduce_tensor也需要再次切分, 第三刀
        ub_axis_var = self.sch[self.reduce_tensor].op.reduce_axis[self.ub_tiling_reduce_axis_index]
        self.reduce_outer, self.reduce_inner = \
            self.sch[self.reduce_tensor].split(ub_axis_var, factor=self.ub_split_result["factor3"])

        self._do_tiling_buffer_tile()
        self._do_secondary_ub_split()

    def _get_tiling_factor(self):
        # block
        block_factor = self.tiling_case.block_factor
        block_inner = block_factor if block_factor is not None else var_inner_adaptive("_block_factor", (1, None))
        self.block_split_result["factor"] = block_inner

        # ub_factor
        ub_factor = self.tiling_case.ub_factor
        ub_inner = ub_factor if ub_factor is not None else var_inner_adaptive("_ub_factor", (1, INT32_MAX))
        self.ub_split_result["factor"] = ub_inner

        # ub_factor_2
        ub_factor_2 = self.tiling_case.ub_factor_2
        ub_inner_2 = ub_factor_2 if ub_factor_2 is not None else var_inner_adaptive("_ub_factor_2", (1, INT32_MAX))
        self.ub_split_result["factor2"] = ub_inner_2

        # ub_factor_3
        ub_factor_r_3 = self.tiling_case.ub_factor_r_3
        ub_inner_r_secondary = ub_factor_r_3 if ub_factor_r_3 is not None else \
            var_inner_adaptive("_ub_factor_r_3", (1, INT32_MAX))
        self.ub_split_result["factor3"] = ub_inner_r_secondary

    def _do_blk_tiling(self):
        block_split_axis_index = self.tiling_case.block_split_axis_index
        block_split_reduce_axis_index = self.reduce_info.reduce_axis_indexes.index(block_split_axis_index)
        block_axis_var = self.reduce_tensor.op.reduce_axis[block_split_reduce_axis_index]
        iter_blk_outer, iter_blk_inner = self.sch[self.reduce_tensor].split(block_axis_var,
                                                                        factor=self.block_split_result["factor"])
        self.block_split_result["outer_itervar"] = iter_blk_outer
        self.block_split_result["inner_itervar"] = iter_blk_inner
        self.reduce_blk_rf_tensor = self.sch.rfactor(self.reduce_tensor, iter_blk_outer, block_split_axis_index)

        self.reduce_blk_rf_ub_tensor = self.sch.cache_write(self.reduce_blk_rf_tensor, LOCAL_UB)
        self.reduce_blk_rf_reread_ub_tensor = self.sch.cache_read(self.reduce_blk_rf_tensor, LOCAL_UB,
                                                                  [self.reduce_tensor])
        self.sch[self.reduce_blk_rf_tensor].set_scope("")
        self.outs.append(self.reduce_blk_rf_tensor)
        self.update_stage(self.reduce_blk_rf_tensor, self.reduce_tensor, True)

        self.cache_write_tensors_and_buffer_map[self.reduce_blk_rf_tensor] = self.reduce_blk_rf_ub_tensor
        self.update_stage(self.reduce_blk_rf_ub_tensor, self.reduce_blk_rf_tensor, True)
        self.cache_read_tensors_and_buffer_map[self.reduce_blk_rf_tensor] = self.reduce_blk_rf_reread_ub_tensor
        self.update_stage(self.reduce_blk_rf_reread_ub_tensor, self.reduce_blk_rf_tensor, False)

    def _do_ub_tiling(self):
        ub_split_axis_index = self.tiling_case.ub_split_axis_index
        # ub一定切R轴
        if ub_split_axis_index not in self.reduce_info.reduce_axis_indexes:
            dict_args = {"errCode": "E90003",
                         "detailed_cause": f"ub_split_axis_index {ub_split_axis_index} should be reduce axis"}
            raise RuntimeError(dict_args, get_error_message(dict_args))

        block_split_axis_index = self.tiling_case.block_split_axis_index
        block_split_reduce_axis_index = self.reduce_info.reduce_axis_indexes.index(block_split_axis_index)
        self.ub_tiling_reduce_axis_index = \
            self.reduce_info.reduce_axis_indexes.index(ub_split_axis_index) - block_split_reduce_axis_index
        ub_axis_var = self.sch[self.reduce_blk_rf_ub_tensor].op.reduce_axis[self.ub_tiling_reduce_axis_index]

        iter_rf_ub_outer, iter_rf_ub_inner = self.sch[self.reduce_blk_rf_ub_tensor].split(ub_axis_var,
                                                factor=self.ub_split_result["factor"])
        self.ub_split_result["outer_itervar"] = iter_rf_ub_outer
        self.ub_split_result["inner_itervar"] = iter_rf_ub_inner

    def _do_tiling_buffer_tile(self):
        before_rf_tensor = list(self.backward_stage_graph_map[self.reduce_rf_tensor])[0]
        buffer_tile_list = []
        for idx, value in enumerate(before_rf_tensor.shape):
            if idx == self.tiling_case.ub_split_axis_index:
                # buffer_tile推导：
                # R轴为 819200, block_factor为a=17067， ub_factor为b=c=71
                # 48(i)  17067(a)           ---- 第一刀, block切分
                # 48(i)   231(j)  71(b)     ---- 第二刀, ub切分
                # 48(i) 4(k) 71(c)          ---- 第三刀, ub2切分
                # 目的是求b轴的大小(因为是input_ub compute_at到了j轴，需要求b的大小)
                # a轴 = min(819200 - i * 17067, 17067)
                # b轴 = min(a - j * 71, 71)   ---- 但在ir里没有j轴，因为j又被切了一次，需要求j的大小
                # j=min（第三刀的outer * factor + 第三刀的inner, maxj）---- maxj=ceil(17067,71)=231,outer和inner是变量
                # 注意：每切一刀非整切就会有一个min（outer * factor + inner, 切之前的大小）的结构
                # 则：
                # b轴 = min(a - j * 71, 71)
                maxj = tvm.div(self.block_split_result["factor"] + self.ub_split_result["factor"] - 1,
                               self.ub_split_result["factor"])
                # reduce_rf_tensor compute_at 到 iter_blk_rf_ub_outer, ir里面只会记录 iter_blk_rf_ub_outer
                j = tvm.min(self.iter_blk_rf_ub_outer * self.ub_split_result["factor2"] + self.iter_rf_tensor_inner,
                            maxj)
                a = tvm.min(value - self.block_split_result["outer_itervar"] * self.block_split_result["factor"],
                            self.block_split_result["factor"])
                b = tvm.min(a - j * self.ub_split_result["factor"], self.ub_split_result["factor"])
                buffer_tile_list.append((None, b))
            else:
                buffer_tile_list.append((None, None))
        self.sch[before_rf_tensor].buffer_tile(*buffer_tile_list)

    def _do_secondary_ub_split(self):
        if self.tiling_case.is_secondary_ub_split:
            ub_factor_a_4 = self.tiling_case.ub_factor_a_4
            ub_inner_a = ub_factor_a_4 if ub_factor_a_4 is not None else \
                        var_inner_adaptive("_ub_factor_a_4", (1, INT32_MAX))
            # ub2一定切last A轴, reduce_blk_rf_ub_tensor 多了一个rfactor后的A轴，需要加 1
            axis_idx = self.none_reduce_index_map.get(self.tiling_case.ub_split_axis_index_2,
                                                      self.tiling_case.ub_split_axis_index_2)
            axis_var_2 = self.sch[self.reduce_blk_rf_ub_tensor].op.axis[axis_idx + 1]
            split_outer, split_inner = self.sch[self.reduce_blk_rf_ub_tensor].split(axis_var_2, factor=ub_inner_a)
            self.ub_split_result_2["factor"] = ub_inner_a
            self.ub_split_result_2["outer_itervar"] = split_outer
            self.ub_split_result_2["inner_itervar"] = split_inner

            # ub2一定切last A轴 先固定写死 axis[-1]
            ub_axis_var = self.sch[self.reduce_tensor].op.axis[-1]
            split_outer_2, split_inner_2 = \
                self.sch[self.reduce_tensor].split(ub_axis_var, factor=ub_inner_a)
            self.ub_split_result_2["outer_itervar_2"] = split_outer_2
            self.ub_split_result_2["inner_itervar_2"] = split_inner_2

    def _do_buffer_tile(self):
        # 针对workspace tensor 的buffer tile
        tile_max = self.tiling_case.buffer_tile_max
        buffer_tile_max_var = tile_max if tile_max is not None else var_inner_adaptive("_buffer_tile_max", (1, None))

        # 二阶段的reduce，ub也同样切分r轴
        buffer_tile_list = []
        for i in range(len(self.reduce_blk_rf_tensor.shape)):
            if self.tiling_case.ub_split_axis_index == i:
                buffer_tile_list.append((0, buffer_tile_max_var))
            else:
                buffer_tile_list.append((None, None))
        self.sch[self.reduce_blk_rf_tensor].buffer_tile(*buffer_tile_list)

    def _do_reorder(self):
        rf_reorder = []
        for i in range(0, self.factor_axis_idx + 1):
            rf_reorder.append(self.sch[self.reduce_rf_tensor].op.axis[i])
        rf_reorder.append(self.iter_rf_tensor_outer)
        rf_reorder.append(self.iter_rf_tensor_inner)
        for i in range(self.factor_axis_idx + 1 + 1, len(self.sch[self.reduce_rf_tensor].op.axis) - 1):
            rf_reorder.append(self.sch[self.reduce_rf_tensor].op.axis[i])
        rf_reorder.append(self.sch[self.reduce_rf_tensor].op.reduce_axis[0])
        rf_reorder.append(self.sch[self.reduce_rf_tensor].op.axis[-1])
        self.sch[self.reduce_rf_tensor].reorder(*rf_reorder)

        if self.tiling_case.is_secondary_ub_split:
            rf_ub_reorder = []
            # ub内RA, ub外AR
            for i in range(0, len(self.sch[self.reduce_blk_rf_ub_tensor].op.axis) - 1):
                rf_ub_reorder.append(self.sch[self.reduce_blk_rf_ub_tensor].op.axis[i])
            rf_ub_reorder.append(self.ub_split_result_2["outer_itervar"])
            rf_ub_reorder.append(self.iter_blk_rf_ub_outer)
            rf_ub_reorder.append(self.iter_blk_rf_ub_inner)
            rf_ub_reorder.append(self.ub_split_result_2["inner_itervar"])
            self.sch[self.reduce_blk_rf_ub_tensor].reorder(*rf_ub_reorder)
        else:
            rf_ub_reorder = []
            for i in range(0, len(self.sch[self.reduce_blk_rf_ub_tensor].op.axis) - 1):
                rf_ub_reorder.append(self.sch[self.reduce_blk_rf_ub_tensor].op.axis[i])
            rf_ub_reorder.append(self.iter_blk_rf_ub_outer)
            rf_ub_reorder.append(self.iter_blk_rf_ub_inner)
            rf_ub_reorder.append(self.sch[self.reduce_blk_rf_ub_tensor].op.axis[-1])
            self.sch[self.reduce_blk_rf_ub_tensor].reorder(*rf_ub_reorder)

        if self.tiling_case.is_secondary_ub_split:
            reduce_reorder = []
            for i in range(0, len(self.sch[self.reduce_tensor].op.axis) - 1):
                reduce_reorder.append(self.sch[self.reduce_tensor].op.axis[i])
            reduce_reorder.append(self.ub_split_result_2["outer_itervar_2"])
            reduce_reorder.append(self.reduce_outer)
            reduce_reorder.append(self.reduce_inner)
            reduce_reorder.append(self.ub_split_result_2["inner_itervar_2"])
            self.sch[self.reduce_tensor].reorder(*reduce_reorder)
        else:
            reduce_reorder = []
            for i in range(0, len(self.sch[self.reduce_tensor].op.axis) - 1):
                reduce_reorder.append(self.sch[self.reduce_tensor].op.axis[i])
            reduce_reorder.append(self.reduce_outer)
            reduce_reorder.append(self.reduce_inner)
            reduce_reorder.append(self.sch[self.reduce_tensor].op.axis[-1])
            self.sch[self.reduce_tensor].reorder(*reduce_reorder)

    def _calc_storage_align(self):
        align_index = -2 # RA -> ARA
        # before reduce stage
        # 也需要对 branch tensor 做 storage_align，所以可以直接使用 self.tensors_before_reduce
        for tensor in self.tensors_before_reduce:
            if tensor not in self.graph_info.input_tensor_set:
                align_factor = int(self.block_size_byte // DTYPE_BYTE_MAPPING.get(tensor.dtype))
                self.storage_align_map[tensor] = [tensor.op.axis[align_index], align_factor, 0]

        # rfactor tensors
        reduce_align_factor = int(self.block_size_byte // DTYPE_BYTE_MAPPING.get(self.reduce_tensor.dtype))
        for tensor in [self.reduce_rf_tensor, self.reduce_blk_rf_ub_tensor,
                       self.reduce_blk_rf_reread_ub_tensor, self.reduce_tensor]:
            self.storage_align_map[tensor] = [self.sch[tensor].op.axis[align_index], reduce_align_factor, 0]

        # after reduce stage
        for tensor in self.tensors_after_reduce:
            if tensor not in self.graph_info.endpoint_output_tensor_set | self.graph_info.real_output_tensor_set | \
                    self.graph_info.input_tensor_set:
                align_factor = int(self.block_size_byte // DTYPE_BYTE_MAPPING.get(tensor.dtype))
                self.storage_align_map[tensor] = [tensor.op.axis[align_index], align_factor, 0]

    def _calc_bind_buffer(self):
        align_factor = int(self.block_size_byte // DTYPE_BYTE_MAPPING.get(self.reduce_tensor.dtype))
        bind_axis = len(self.reduce_blk_rf_tensor.shape) - 2
        bind_factor = \
            tvm.div((self.reduce_blk_rf_tensor.shape[bind_axis + 1] + align_factor - 1), align_factor) * align_factor
        self.bind_buffer_map[self.reduce_blk_rf_tensor] = \
            [self.sch[self.reduce_blk_rf_tensor].op.axis[bind_axis], bind_factor, 0]

    def _do_storage_bound(self):
        all_tensors_before_reduce = self.get_all_producers_stages(self.reduce_tensor)
        all_tensors_before_reduce = all_tensors_before_reduce.union(
            self.branch_tensor_info.get_all_branch_stages(self.backward_stage_graph_map))
        for stage_tensor in self.forward_stage_graph_map:
            if stage_tensor in self.graph_info.real_output_tensor_set:
                # don't set bound for real_output_tensors(gm)
                continue
            if stage_tensor in self.graph_info.input_tensor_set:
                # don't set bound for input_tensor_set(gm)
                continue
            if stage_tensor is self.reduce_blk_rf_tensor:
                # don't set bound for reduce_blk_rf_tensor(gm)
                continue

            # reduce_tensor is after reduce
            ub_count = self.tiling_case.tensor_ub_size_before_reduce if stage_tensor in all_tensors_before_reduce \
                else self.tiling_case.tensor_ub_size_after_reduce
            self.sch[stage_tensor].set_buffer_size(ub_count)

    def _do_set_constraint(self):
        if get_context().get_current_compute().get("_mode") == CONST:
            return
        self._do_set_ub_constraint()

    def _do_set_ub_constraint(self):
        ub_size = self.tiling_case.tensor_ub_size_before_reduce
        # first stage constraint
        first_stage_shape_in_ub = 1
        for index, value in enumerate(self.reduce_info.shape_before_reduce):
            if index < self.tiling_case.ub_split_axis_index:
                continue
            if index == self.tiling_case.ub_split_axis_index:
                self.sch.set_constraint(self.ub_split_result.get("factor") <= ub_size)
                first_stage_shape_in_ub *= self.ub_split_result.get("factor")
                continue
            if self.tiling_case.is_secondary_ub_split and index == self.tiling_case.ub_split_axis_index_2:
                self.sch.set_constraint(self.ub_split_result_2.get("factor") <= ub_size)
                first_stage_shape_in_ub *= self.ub_split_result_2.get("factor")
                continue
            self.sch.set_constraint(value <= ub_size)
            first_stage_shape_in_ub *= value

        self.sch.set_constraint(first_stage_shape_in_ub <= ub_size)

    def _do_multi_core(self):
        fuse_axis_list = self.sch[self.reduce_blk_rf_tensor].op.axis[:self.tiling_case.block_split_axis_index + 1]
        self.multi_core_bind_axis = self.sch[self.reduce_blk_rf_tensor].fuse(*fuse_axis_list)
        self.thread = tvm.thread_axis(BLOCK_IDX)
        self.sch[self.reduce_blk_rf_tensor].bind(self.multi_core_bind_axis, self.thread)

    def _do_set_store_predicate(self):
        set_store_predicate_tensor_set = self.tensors_after_reduce | \
            {self.reduce_blk_rf_reread_ub_tensor, self.reduce_tensor, self.res_tensor}
        for after_reduce_tensor in set_store_predicate_tensor_set:
            self.sch[after_reduce_tensor].set_store_predicate(self.thread.var.equal(0),
                                                              partition=False, rebase_root=True)

    def _do_block_sync(self):
        sync_tensor = self.sch.create_block_sync()
        # sync axis is the axis after self.multi_core_bind_axis
        sync_axis = self.sch[self.reduce_blk_rf_tensor].leaf_iter_vars[1]
        self.sch[self.reduce_blk_rf_tensor].wait_block_sync(sync_axis, tensor=sync_tensor, bottom=True)
        self.sch[self.reduce_blk_rf_tensor].set_block_sync(sync_axis, tensor=sync_tensor, bottom=True)

    def _calc_compute_at(self):
        # input -> cast -> reduce_rf_tensor -> reduce_blk_rf_ub_tensor -> reduce_blk_rf_tensor ->
        # -> reduce_blk_rf_reread_ub_tensor -> reduce_tensor -> cast

        # 不能直接使用 self.tensors_before_reduce，需要去掉 get_all_branch_stages
        # branch tensor 不参与 compute at
        tensors_before_rf = self.get_all_producers_stages(self.reduce_rf_tensor)
        for tensor in tensors_before_rf:
            self.compute_at_map[tensor] = {
                PARENT: self.sch[self.reduce_rf_tensor],
                SCOPE: self.iter_rf_tensor_inner
            }

        # ub第二次切分时，compute_at的轴是否正确
        self.compute_at_map[self.reduce_rf_tensor] = {
            PARENT: self.sch[self.reduce_blk_rf_ub_tensor],
            SCOPE: self.iter_blk_rf_ub_outer
        }
        self.compute_at_map[self.reduce_blk_rf_ub_tensor] = {
            PARENT: self.sch[self.reduce_blk_rf_tensor],
            SCOPE: self.multi_core_bind_axis
        }

        # 第二阶段切分, 不管是否ub二次切分，都需要at在 self.reduce_outer 轴上
        self.compute_at_map[self.reduce_blk_rf_reread_ub_tensor] = {
            PARENT: self.sch[self.reduce_tensor],
            SCOPE: self.reduce_outer
        }

    def _do_compute_root(self):
        # reread tensor会compute_at到reduce_tensor，不里不包含reread tensor
        compute_root_tensor_set = self.tensors_after_reduce | {self.reduce_tensor, self.res_tensor}
        for tensor in compute_root_tensor_set:
            self.sch[tensor].compute_root()

    def _calc_emit_insn(self):
        self._calc_reduce_emit_insn()
        self._calc_other_emit_insn()

    def _calc_reduce_emit_insn(self):
        # input -> cast -> reduce_rf_tensor -> reduce_blk_rf_ub_tensor -> reduce_blk_rf_tensor ->
        # -> reduce_blk_rf_reread_ub_tensor -> reduce_tensor -> cast
        insn = self._get_insn(self.reduce_info.reduce_tensor)

        if self.tiling_case.reduce_sch_type == ReduceSchType.ARA_HIGH_PRECISION_WORKSPACE:
            reduce_attrs = self.ara_reduce_attr
        else:
            reduce_attrs = self.ara_reduce_big_attr
        self.emit_insn_map[self.reduce_rf_tensor] = {
            SCOPE: self.sch[self.reduce_rf_tensor].op.reduce_axis[0],
            INSTRUCTION: insn,
            ATTRS: reduce_attrs
        }

        self.emit_insn_map[self.reduce_blk_rf_ub_tensor] = {
            SCOPE: self.iter_blk_rf_ub_inner,
            INSTRUCTION: insn,
            ATTRS: reduce_attrs
        }

        # ub二次切分时，轴是否正确
        self.emit_insn_map[self.reduce_blk_rf_tensor] = {
            SCOPE: self.sch[self.reduce_blk_rf_tensor].op.axis[self.factor_axis_idx + 1],
            INSTRUCTION: "dma_copy"
        }
        self.emit_insn_map[self.reduce_blk_rf_reread_ub_tensor] = {
            SCOPE: self.sch[self.reduce_blk_rf_reread_ub_tensor].op.axis[0],
            INSTRUCTION: "dma_copy"
        }

        # 不管是否ub二次切分，都需要打在 self.reduce_inner 轴上
        self.emit_insn_map[self.reduce_tensor] = {
            SCOPE: self.reduce_inner,
            INSTRUCTION: insn,
            ATTRS: reduce_attrs
        }

    def _calc_other_emit_insn(self):
        # 也需要对branch tensor打上指令映射，所以可以直接使用 self.tensors_before_reduce
        remaining_tensors = self.tensors_before_reduce | \
            self.tensors_after_reduce | self.graph_info.endpoint_output_tensor_set

        for tensor in remaining_tensors:
            if tensor in self.graph_info.input_tensor_set:
                continue
            insn = self._get_insn(tensor)
            iter_var = self.sch[tensor].op.axis[0]
            if tensor in self.graph_info.real_output_tensor_set:
                insn = "dma_copy"
            elif tensor in self.mid_output_tensor_cache_read_list:
                insn = "phony_insn"
            if insn == "":
                insn = "dma_copy"

            self.emit_insn_map[tensor] = {SCOPE: self.branch_tensor_info.get_hook_tensor_axis(tensor, iter_var),
                                          INSTRUCTION: insn}

        if self.res_tensor.op.tag == FAKE_NODE_TAG:
            self.emit_insn_map[self.res_tensor] = {SCOPE: self.res_tensor.op.axis[0],
                                                   INSTRUCTION: "phony_insn"}

    def _calc_compute_align(self):
        for single_tensor, param in self.storage_align_map.items():
            insn = self.emit_insn_map.get(single_tensor).get(INSTRUCTION)
            if insn in ["dma_copy", ""]:
                continue
            axis = self.sch[single_tensor].op.axis[-1]
            factor = param[1]
            self.compute_align_map[single_tensor] = [axis, factor, None]
