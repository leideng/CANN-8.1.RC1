#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2022-2022 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
sort tiling case
"""
from enum import Enum
from enum import auto
from typing import Any

from tbe import tvm
from tbe.common.platform import SHORT_SOC_VERSION
from tbe.common.platform.platform_info import get_soc_spec
from tbe.common.platform.platform_info import ASCEND_031
from tbe.common.platform import ASCEND_310B
from tbe.common.platform import AS31XM1
from tbe.common.platform import ASCEND_910B
from tbe.common.platform import ASCEND_910_93
from tbe.common.platform import ASCEND_610LITE
from tbe.common.platform import BS9SX2A
from tbe.common.platform import MC61AM21A
from tbe.common.utils import op_tiling
from tbe.dsl.base import operation
from tbe.dsl.base.operation import get_compile_info
from tbe.dsl.base.operation import register_build_pointcut
from tbe.dsl.unify_schedule.vector.tiling_key import TilingKey
from tbe.dsl.unify_schedule.vector.tiling_key import ScheduleType

from ... import util
from ...computation import Computation
from ...constants import CompileInfo
from ...constants import DTYPE_BYTE_MAPPING
from ...constants import SortPattern
from ...constants import Pattern

DEFAULT = "default"
# sort mode
NORMAL = "normal"
DB = "db"
K_SMALL = "k_small"
ONE_DIM = "one_dim"
WORKSPACE = "workspace"
STATIC = "static"
# sort pattern
SORT = "sort"
SORT_MERGE = "sort_merge"
SORT_SYNC_MERGE = "sort_sync_merge"
SORT_MERGE_SYNC_MERGE = "sort_merge_sync_merge"


MODE_VALUE_MAP = {
    NORMAL: 0x0,
    DB: 0x1,
    K_SMALL: 0x2,
    ONE_DIM: 0x3,
    WORKSPACE: 0x4,
    STATIC: 0x999
}

PATTERN_VALUE_MAP = {
    SORT: [0x0, 0x0, 0x0],
    SORT_MERGE: [0x1, 0x0, 0x1],
    SORT_SYNC_MERGE: [0x2, 0x0, 0x1],
    SORT_MERGE_SYNC_MERGE: [0x3, 0x0, 0x1]
}

AXIS_MAP = {
    0x0: 0,
    0x1: 1
}

TILING_MODE_MAP = {
    0: NORMAL,
    1: DB,
    2: K_SMALL,
    3: ONE_DIM,
    4: WORKSPACE,
    5: STATIC
}

TILING_PATTERN_MAP = {
    0: SORT,
    1: SORT_MERGE,
    2: SORT_SYNC_MERGE,
    3: SORT_MERGE_SYNC_MERGE
}


def ceil_div(dividend, divisor):
    """
    ceil div
    """
    result = (dividend + divisor - 1) // divisor
    return result


class SortCompileInfo:
    """
    Built-in Compile info keys
    """
    IS_STATIC = "_is_static"
    OP_MODE = "_op_mode"
    X_DTYPE_BYTES = "_x_dtype_bytes"
    K_NUM = "_k_num"
    PROPOSAL_NUM = "_proposal_num"
    COEXISTING_NUM = "_coexisting_num"
    TILING_PATTERN = "_tiling_pattern"
    WORKSPACE_LEN = "_workspace_len"
    IS_UNKNOWN_SHAPE = "_is_unknown_shape"


class TilingStrategy(Enum):
    """
    TilingStrategy
    """
    DYNAMIC = auto()
    STATIC = auto()


class SortComputation(Computation):
    """
    SortComputation
    """
    def __init__(self, outs, option):
        self.outs = outs if isinstance(outs, (list, tuple)) else [outs]
        self.option = option
        self.inputs = []

        self.is_static = operation.get_op_mode() == "static"
        self.op_mode = operation.get_context().get(SortCompileInfo.OP_MODE)

        self._construct_compute_graph()

        # reserved ub size
        reserve_space = 1024
        self.ub_size = util.get_ub_size() - reserve_space
        self.bytes = DTYPE_BYTE_MAPPING.get(self.inputs[0].dtype)
        self.block_size_bytes = 32
        self.proposal_num = 8
        self.coexisting_quantity = 3
        self.soc_version = get_soc_spec(SHORT_SOC_VERSION)
        self.specific_version = self.soc_version in [ASCEND_031, ASCEND_310B, ASCEND_910B, ASCEND_910_93, 
            AS31XM1, ASCEND_610LITE, BS9SX2A, MC61AM21A]
        if self.specific_version:
            self.proposal_num = 4
            self.coexisting_quantity = 4
            if self.inputs[0].dtype == "float32" or self.inputs[0].dtype == "bfloat16":
                self.proposal_num = 2
        operation.get_context().add(SortCompileInfo.COEXISTING_NUM, self.coexisting_quantity)
        operation.get_context().add(SortCompileInfo.PROPOSAL_NUM, self.proposal_num)
        self.ub_available = self.ub_size // self.coexisting_quantity // self.block_size_bytes * \
                            self.block_size_bytes // self.bytes // self.proposal_num
        self.k_num = operation.get_context().get(SortCompileInfo.K_NUM) if self.op_mode == 1 else 0

    @classmethod
    def get_instance(cls, outs, option):  # type: (list[Any], dict[str, Any]) -> "Computation"
        return cls(outs, option)

    @classmethod
    def get_supported_pattern(cls):  # type: () -> list[str]
        return [Pattern.SORT]

    @classmethod
    def get_supported_soc(cls):  # type: () -> list[str]
        return [DEFAULT]

    @staticmethod
    def _calc_key(mode, pattern):
        tiling_key = TilingKey(ScheduleType.SORT)
        tiling_key.mode = MODE_VALUE_MAP.get(mode)
        tiling_key.pattern = PATTERN_VALUE_MAP.get(pattern)[0]
        tiling_key.block_axis = PATTERN_VALUE_MAP.get(pattern)[1]
        tiling_key.ub_axis = PATTERN_VALUE_MAP.get(pattern)[2]
        return tiling_key.tiling_key

    def get_sub_pattern(self):  # type: () -> str
        return SortPattern.NORMAL_SCHEDULE

    def do_tiling_case(self):  # type: () -> list[Any]
        return self._calc_static_sort() if self.is_static else self._calc_dynamic_sort()

    def _calc_mode(self):
        return [NORMAL, DB, K_SMALL, ONE_DIM, WORKSPACE] if self.op_mode > 0 else [NORMAL, DB]

    def _calc_pattern(self, mode):
        if mode == DB:
            if self.op_mode == 1 and self.k_num > self.ub_available:
                return []
            return [SORT]

        if mode == K_SMALL:
            return [SORT_MERGE]

        if mode == ONE_DIM:
            return [SORT_SYNC_MERGE, SORT_MERGE_SYNC_MERGE]

        if mode == WORKSPACE or (self.op_mode == 1 and self.k_num > self.ub_available):
            return [SORT_MERGE, SORT_SYNC_MERGE, SORT_MERGE_SYNC_MERGE]

        return [SORT, SORT_MERGE, SORT_SYNC_MERGE, SORT_MERGE_SYNC_MERGE]

    def _construct_compute_graph(self):
        visited_tensors = set()
        self.__dfs_sub_graph(self.outs[0], visited_tensors)

    def __dfs_sub_graph(self, out, visited_tensors: set):
        for tensor_i in out.op.input_tensors:
            if util.is_placeholder(tensor_i):
                self.inputs.append(tensor_i)

            if tensor_i in visited_tensors:
                continue

            visited_tensors.add(tensor_i)

            self.__dfs_sub_graph(tensor_i, visited_tensors)

    def _calc_static_sort(self):
        tiling_key = TilingKey(ScheduleType.SORT)
        if self.is_static:
            tiling_key.mode = MODE_VALUE_MAP.get(STATIC)

        cases = self._get_static_tiling_data()
        return cases

    def _calc_dynamic_sort(self):
        cases = []
        mode = self._calc_mode()
        for _mode in mode:
            patterns = self._calc_pattern(_mode)
            for _pattern in patterns:
                cases.append({
                    "key": self._calc_key(_mode, _pattern),
                    "block_axis": AXIS_MAP.get(PATTERN_VALUE_MAP.get(_pattern)[1]),
                    "ub_axis": AXIS_MAP.get(PATTERN_VALUE_MAP.get(_pattern)[2]),
                    "tiling_strategy": TilingStrategy.DYNAMIC,
                    "mode": _mode,
                    "pattern": _pattern
                })
        return cases

    def _get_static_tiling_data(self):
        tmp_output_shape = util.shape_to_list(self.outs[0].shape)[:]
        outputs = [{"shape": tmp_output_shape, "dtype": self.outs[0].dtype}]

        tmp_x_shape = util.shape_to_list(self.inputs[0].shape)[:]
        inputs = [{"shape": tmp_x_shape, "dtype": self.inputs[0].dtype}]

        dtype_byte = DTYPE_BYTE_MAPPING.get(self.outs[0].dtype if self.outs[0].dtype != "bfloat16" else "float32")
        const_compile_info = {
            CompileInfo.CORE_NUM: util.get_core_num(),
            CompileInfo.UB_SIZE: self.ub_size,
            CompileInfo.SOC_VERSION: get_soc_spec(SHORT_SOC_VERSION),
            SortCompileInfo.X_DTYPE_BYTES: dtype_byte,
            SortCompileInfo.COEXISTING_NUM: self.coexisting_quantity,
            SortCompileInfo.PROPOSAL_NUM: self.proposal_num,
            SortCompileInfo.OP_MODE: self.op_mode,
            SortCompileInfo.K_NUM: self.k_num,
            SortCompileInfo.IS_STATIC: True
        }

        const_compile_info.update(get_compile_info())
        op_type = "AutoTiling"
        run_info = op_tiling.do_op_tiling(op_type, const_compile_info, inputs, outputs)
        tiling_format = {
            "tiling_key": "int64",
            "block_axis": "int64",
            "block_factor": "int64",
            "ub_axis": "int64",
            "ub_factor_0": "int64",
            "ub_factor_1": "int64",
            "tiling_mode": "int64",
            "tiling_pattern": "int64",
            "block_start_addr": "int64",
            "block_stride_0": "int64",
            "block_stride_1": "int64"
        }

        tiling_data = op_tiling.decode(run_info["tiling_data"], tiling_format)
        workspace_size = self._add_workspace_info_in_json(tiling_data)
        cases = [{
            "key": tiling_data.get("tiling_key"),
            "block_axis": tiling_data.get("block_axis"),
            "block_factor": tiling_data.get("block_factor"),
            "ub_axis": tiling_data.get("ub_axis"),
            "ub_factor_0": tiling_data.get("ub_factor_0"),
            "ub_factor_1": tiling_data.get("ub_factor_1"),
            "mode": TILING_MODE_MAP.get(tiling_data.get("tiling_mode")),
            "pattern": TILING_PATTERN_MAP.get(tiling_data.get("tiling_pattern")),
            "tiling_strategy": TilingStrategy.STATIC,
            "block_start_addr": tiling_data.get("block_start_addr"),
            "block_stride_0": tiling_data.get("block_stride_0"),
            "block_stride_1": tiling_data.get("block_stride_1"),
            "workspace_size": workspace_size
        }]
        return cases

    def _add_workspace_info_in_json(self, tiling_data):
        self.bytes = self.bytes * 2 if self.inputs[0].dtype == "bfloat16" else self.bytes
        pattern = TILING_PATTERN_MAP.get(tiling_data.get("tiling_pattern"))
        mode = TILING_MODE_MAP.get(tiling_data.get("tiling_mode"))
        ub_factor_0 = tiling_data.get("ub_factor_0")
        ub_factor_1 = tiling_data.get("ub_factor_1")
        workspace_size = 0
        if pattern != SORT:
            input_shape = util.shape_to_list(self.inputs[0].shape)[:]
            align_num = self.block_size_bytes // self.bytes
            proposal_bytes = self.proposal_num * self.bytes
            workspace_size = input_shape[0] * ceil_div(input_shape[1], align_num) * align_num

            if mode in [WORKSPACE, K_SMALL, ONE_DIM]:
                k_num_align = ceil_div(self.k_num, align_num) * align_num
                if self.inputs[0].dtype == "bfloat16":
                    bf16_factor = 2
                    k_num_align = ceil_div(self.k_num, align_num * bf16_factor) * align_num * bf16_factor
                workspace_size = input_shape[0] * ceil_div(input_shape[1], ub_factor_0) * k_num_align
                if pattern == SORT_MERGE_SYNC_MERGE:
                    workspace_size = input_shape[0] * ceil_div(input_shape[1], ub_factor_0) * \
                                     ceil_div(ub_factor_0, ub_factor_1) * k_num_align

            workspace_num = 1
            workspace_bytes = workspace_size * proposal_bytes * 2
            workspace = [workspace_bytes]
            workspace_type = [0]
            if pattern == SORT_MERGE_SYNC_MERGE:
                workspace_num = 2
                workspace.append(workspace_bytes)
                workspace_type.append(0)

            # sync tensor has been processed in pass
            workspace_dict_in_json = {
                "num": workspace_num,
                "size": workspace,
                "type": workspace_type
            }
            operation.get_op_context().add_build_json_result("workspace", workspace_dict_in_json)
        self.bytes = self.bytes // 2 if self.inputs[0].dtype == "bfloat16" else self.bytes
        return workspace_size


def _pre_build(schedules_list):
    def _flatten_sch(_schedules: list):
        for sub_schs in schedules_list:
            if isinstance(sub_schs, list):
                _schedules.extend(sub_schs)
            else:
                _schedules.append(sub_schs)

    def _add_fake_workspace():
        parameter_length_set = set()
        for same_compute_schs in schedules_list:
            for single_sch in same_compute_schs:
                parameter_length_set.add(len(util.get_sch_additional_entry(single_sch, "real_outs")))

        max_workspace_num = 3
        operation.add_compile_info_inner(SortCompileInfo.WORKSPACE_LEN, max_workspace_num)

        parameter_max_length, parameter_min_length = max(parameter_length_set), min(parameter_length_set)
        if parameter_max_length == parameter_min_length:
            return

        for same_compute_schs in schedules_list:
            for single_sch in same_compute_schs:
                single_sch_context = util.get_sch_additional_entry(single_sch, "context")
                tiling_pattern = single_sch_context.get(SortCompileInfo.TILING_PATTERN)
                ori_real_outs = util.get_sch_additional_entry(single_sch, "real_outs")
                if len(ori_real_outs) == parameter_max_length:
                    continue

                for index in range(parameter_max_length - len(ori_real_outs)):
                    fake_workspace = tvm.placeholder([], dtype="float16", name="fake_workspace_" + str(index))
                    ori_real_outs.append(fake_workspace)
                if tiling_pattern in [SORT, SORT_MERGE]:
                    fake_sync = tvm.placeholder([], dtype="float16", name="fake_sync_0")
                    ori_real_outs.append(fake_sync)

                util.add_sch_additional_entry(single_sch, "real_outs", ori_real_outs)

        workspace_type = [0] * max_workspace_num
        workspace_dict_in_json = {
            "num": max_workspace_num,
            "size": [32] * max_workspace_num,
            "type": workspace_type
        }
        operation.get_op_context().add_build_json_result("workspace", workspace_dict_in_json)

    # add build config
    if get_soc_spec(SHORT_SOC_VERSION) in [ASCEND_910B, ASCEND_910_93] and operation.get_op_mode() == "dynamic":
        operation.add_build_arg("enforce_mix_mode", True)

    schedules = []
    _flatten_sch(schedules)

    cpt_cores, cpt_ub_size, cpt_x_dtype_bytes = [], [], []
    cpt_computes = operation.get_context().get_computes()
    for cpt in cpt_computes:
        for sch_context in cpt.get_schedules():
            cpt_cores.append(sch_context.get(CompileInfo.CORE_NUM))
            cpt_ub_size.append(sch_context.get(CompileInfo.UB_SIZE))
            cpt_x_dtype_bytes.append(sch_context.get(SortCompileInfo.X_DTYPE_BYTES))

        operation.add_compile_info_inner(CompileInfo.CORE_NUM, max(cpt_cores))
        operation.add_compile_info_inner(CompileInfo.UB_SIZE, min(cpt_ub_size))
        operation.add_compile_info_inner(CompileInfo.SOC_VERSION, get_soc_spec(SHORT_SOC_VERSION))
        operation.add_compile_info_inner(SortCompileInfo.X_DTYPE_BYTES, min(cpt_x_dtype_bytes))

        cpt_op_mode = operation.get_context().get(SortCompileInfo.OP_MODE)
        operation.add_compile_info_inner(SortCompileInfo.OP_MODE, cpt_op_mode)

        cpt_coexisting_num = operation.get_context().get(SortCompileInfo.COEXISTING_NUM)
        operation.add_compile_info_inner(SortCompileInfo.COEXISTING_NUM, cpt_coexisting_num)

        cpt_proposal_num = operation.get_context().get(SortCompileInfo.PROPOSAL_NUM)
        operation.add_compile_info_inner(SortCompileInfo.PROPOSAL_NUM, cpt_proposal_num)

        if cpt_op_mode > 0:
            cpt_k_num = operation.get_context().get(SortCompileInfo.K_NUM)
            operation.add_compile_info_inner(SortCompileInfo.K_NUM, cpt_k_num)
            is_unknown_shape = operation.get_context().get(SortCompileInfo.IS_UNKNOWN_SHAPE)
            if is_unknown_shape:
                operation.add_compile_info_inner(SortCompileInfo.IS_UNKNOWN_SHAPE, is_unknown_shape)

    _add_fake_workspace()


@register_build_pointcut(pattern=Pattern.SORT)
def build_pointcut(func, *args, **kwargs):
    """
    build_pointcut
    :param func:
    :param args:
    :param kwargs:
    :return:
    """
    _pre_build(args[0])
    func(*args, **kwargs)
