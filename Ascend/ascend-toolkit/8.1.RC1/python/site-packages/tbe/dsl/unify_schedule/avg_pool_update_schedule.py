#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2021 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
avgpool_update schedule
"""
from tbe import tvm
from tbe.dsl.base.operation import register_schedule
from tbe.dsl.base.operation import get_context
from tbe.dsl.base.operation import get_te_var
from tbe.common.utils import log
from tbe.common.utils.op_util.op_util_avg_pool_update import TilingDataKey, TilingDataIdx
from tbe.common.utils.op_util.op_util_avg_pool_update import TILINGDATA_KEY_RANGE_MAP, TILINGDATA_KEY_MAP
from tbe.common.platform import platform_info as cce_params
from .constants import Pattern
from . import util


BLOCK_IDX = "blockIdx.x"
LOCAL_UB = "local.UB"
CONST = "const"
N_AXIS = 0
C1_AXIS = 1
M_AXIS = 2
C0_AXIS = 3
C_AXIS_NHWC = 3
C_AXIS_NCHW = 1
H_AXIS_NHWC = 1
H_AXIS_NCHW = 2
W_AXIS_NHWC = 2
W_AXIS_NCHW = 3
C0_FP32 = 8
STORAGE_ALIGN_AXIS = -2


@register_schedule(pattern=Pattern.AvgPoolUpdate)
def schedule(outs, tiling_case):
    """
    AvgPoolUpdate schedule
    """
    return AvgpoolUpdateSchedule(outs, tiling_case).do_schedule()


class AvgpoolUpdateSchedule:
    """
    AvgPoolUpdate schedule
    """
    def __init__(self, outs, tiling_case):
        self._res_tensor = outs[0]
        self._tiling_case = tiling_case
        self._ub_size = util.get_ub_size()

        self._sch = None
        self._scope = LOCAL_UB
        self._is_const = get_context().get_current_compute().get("_mode") == CONST
        self._graph_info = get_context().get_current_compute().get("_graph_info")
        self._is_fp32_mode = self._tiling_case.data_dtype == "float32"

        self._cache_read_tensors = set()
        self._cache_write_tensors = set()
        self._read_tensor = None
        self._write_tensor = None
        self._mid_tensor = None
        self._fuse_axis = None
        self._emit_dma_axis_res = None

        self._h_axis_nd = H_AXIS_NHWC if self._tiling_case.data_format == "NHWC" else H_AXIS_NCHW
        self._w_axis_nd = W_AXIS_NHWC if self._tiling_case.data_format == "NHWC" else W_AXIS_NCHW
        self._c_axis_nd = C_AXIS_NHWC if self._tiling_case.data_format == "NHWC" else C_AXIS_NCHW

    def do_schedule(self):
        self._sch = tvm.create_schedule(self._res_tensor.op)
        self._sch.tiling_key = self._tiling_case.tiling_key

        # During dynamic situation debug, you can add method test_set_value here to set variable's value.
        self._do_sequential_malloc()
        self._handle_var_range()
        self._init_tiling_case()

        self._do_cache_read()
        self._do_cache_write()
        self._set_scope()

        self._do_reorder()
        self._do_tiling()
        self._do_double_buffer()
        self._do_emit_insn()

        return self._sch

    def _do_sequential_malloc(self):
        if self._is_const and not self._is_fp32_mode:
            return

        self._sch.sequential_malloc(cce_params.scope_ubuf)

    def _handle_var_range(self):
        if self._is_const:
            return

        for var_name, var_range in TILINGDATA_KEY_RANGE_MAP.items():
            self._sch.set_var_range(get_te_var(var_name).get_tvm_var(), *var_range)

    def _init_tiling_case(self):
        if self._is_const:
            return

        self._tiling_case.block_nparts_m = get_te_var(TilingDataKey.BLOCK_NPARTS_M).get_tvm_var()
        self._tiling_case.block_nparts_n = get_te_var(TilingDataKey.BLOCK_NPARTS_N).get_tvm_var()
        self._tiling_case.block_nparts_c1 = get_te_var(TilingDataKey.BLOCK_NPARTS_C1).get_tvm_var()
        self._tiling_case.ub_factor_m = get_te_var(TilingDataKey.UB_FACTOR_M).get_tvm_var()
        self._tiling_case.ub_factor_n = get_te_var(TilingDataKey.UB_FACTOR_N).get_tvm_var()
        self._tiling_case.ub_factor_c1 = get_te_var(TilingDataKey.UB_FACTOR_C1).get_tvm_var()

    def _do_cache_read(self):
        for tensor in self._graph_info.input_tensor_set:
            self._read_tensor = self._sch.cache_read(
                tensor, self._scope, self._graph_info.tensor_consumers_map.get(tensor))
            self._cache_read_tensors.add(self._read_tensor)

    def _do_cache_write(self):
        for tensor in self._graph_info.output_tensor_set:
            self._write_tensor = self._sch.cache_write(tensor, self._scope)
            self._cache_write_tensors.add(self._write_tensor)

    def _set_scope(self):
        # move mid tensor to UB
        for mid_tensor in self._graph_info.non_gm_input_tensor_set:
            self._mid_tensor = mid_tensor
            self._sch[mid_tensor].set_scope(self._scope)

    def _do_reorder(self):
        # reoder to M, N, C1, C0 in fp16 or H, W, N, C in fp32
        for tensor in self._cache_read_tensors | self._cache_write_tensors | self._graph_info.output_tensor_set:
            if self._is_fp32_mode and self._is_const:
                self._sch[tensor].reorder(
                    tensor.op.axis[self._h_axis_nd], tensor.op.axis[self._w_axis_nd],
                    tensor.op.axis[N_AXIS], tensor.op.axis[self._c_axis_nd])
            else:
                self._sch[tensor].reorder(
                    tensor.op.axis[M_AXIS], tensor.op.axis[N_AXIS], tensor.op.axis[C1_AXIS], tensor.op.axis[C0_AXIS])

    def _do_tiling(self):
        if self._is_fp32_mode and self._is_const:
            self._do_tiling_fp32()
        else:
            self._do_tiling_fp16()

    def _do_tiling_fp32(self):
        # tensors at UB needs to be 32-Byte aligned.
        self._sch[self._read_tensor].storage_align(self._read_tensor.op.axis[STORAGE_ALIGN_AXIS], C0_FP32, 0)
        self._sch[self._write_tensor].storage_align(self._write_tensor.op.axis[STORAGE_ALIGN_AXIS], C0_FP32, 0)
        self._sch[self._mid_tensor].storage_align(self._mid_tensor.op.axis[STORAGE_ALIGN_AXIS], C0_FP32, 0)

        # split axes
        block_h_o, block_h_i = self._sch[self._res_tensor].split(
            self._res_tensor.op.axis[self._h_axis_nd], nparts=self._tiling_case.block_nparts_h)
        ub_h_o, ub_h_i = self._sch[self._res_tensor].split(block_h_i, factor=self._tiling_case.ub_factor_h)

        block_w_o, block_w_i = self._sch[self._res_tensor].split(
            self._res_tensor.op.axis[self._w_axis_nd], nparts=self._tiling_case.block_nparts_w)
        ub_w_o, ub_w_i = self._sch[self._res_tensor].split(block_w_i, factor=self._tiling_case.ub_factor_w)

        block_n_o, block_n_i = self._sch[self._res_tensor].split(
            self._res_tensor.op.axis[N_AXIS], nparts=self._tiling_case.block_nparts_n)
        ub_n_o, ub_n_i = self._sch[self._res_tensor].split(block_n_i, factor=self._tiling_case.ub_factor_n)

        block_c_o, block_c_i = self._sch[self._res_tensor].split(
            self._res_tensor.op.axis[self._c_axis_nd], nparts=self._tiling_case.block_nparts_c)
        ub_c_o, ub_c_i = self._sch[self._res_tensor].split(block_c_i, factor=self._tiling_case.ub_factor_c)

        if self._tiling_case.reorder_n_c_flag:
            self._sch[self._res_tensor].reorder(
                block_h_o, block_w_o, block_n_o, block_c_o,
                ub_h_o, ub_w_o, ub_c_o, ub_n_o,
                ub_h_i, ub_w_i, ub_n_i, ub_c_i
            )
            self._sch[self._read_tensor].compute_at(self._sch[self._res_tensor], ub_n_o)
            self._sch[self._write_tensor].compute_at(self._sch[self._res_tensor], ub_n_o)
        else:
            self._sch[self._res_tensor].reorder(
                block_h_o, block_w_o, block_n_o, block_c_o,
                ub_h_o, ub_w_o, ub_n_o, ub_c_o,
                ub_h_i, ub_w_i, ub_n_i, ub_c_i
            )
            self._sch[self._read_tensor].compute_at(self._sch[self._res_tensor], ub_c_o)
            self._sch[self._write_tensor].compute_at(self._sch[self._res_tensor], ub_c_o)

        if self._tiling_case.data_format == "NHWC":
            # mean_matrix's shape is h*w*c
            self._sch[self._mid_tensor].compute_at(self._sch[self._res_tensor], ub_c_o)
        else:
            # mean_matrix's shape is h*w
            self._sch[self._mid_tensor].compute_at(self._sch[self._res_tensor], ub_w_o)
        self._sch.bind_axes([block_h_o, block_w_o, block_n_o, block_c_o], tvm.thread_axis("blockIdx.x"))
        self._emit_dma_axis_res = ub_h_i

    def _do_tiling_fp16(self):
        # split axes
        block_m_o, block_m_i = self._sch[self._res_tensor].split(
            self._res_tensor.op.axis[M_AXIS], nparts=self._tiling_case.block_nparts_m)
        ub_m_o, ub_m_i = self._sch[self._res_tensor].split(block_m_i, factor=self._tiling_case.ub_factor_m)

        block_n_o, block_n_i = self._sch[self._res_tensor].split(
            self._res_tensor.op.axis[N_AXIS], nparts=self._tiling_case.block_nparts_n)
        ub_n_o, ub_n_i = self._sch[self._res_tensor].split(block_n_i, factor=self._tiling_case.ub_factor_n)

        block_c1_o, block_c1_i = self._sch[self._res_tensor].split(
            self._res_tensor.op.axis[C1_AXIS], nparts=self._tiling_case.block_nparts_c1)
        ub_c1_o, ub_c1_i = self._sch[self._res_tensor].split(block_c1_i, factor=self._tiling_case.ub_factor_c1)

        if self._tiling_case.reorder_n_c1_flag:
            self._sch[self._res_tensor].reorder(
                block_m_o, block_n_o, block_c1_o,
                ub_m_o, ub_c1_o, ub_n_o,
                ub_m_i, ub_n_i, ub_c1_i, self._res_tensor.op.axis[C0_AXIS]
            )
            self._sch[self._read_tensor].compute_at(self._sch[self._res_tensor], ub_n_o)
            self._sch[self._write_tensor].compute_at(self._sch[self._res_tensor], ub_n_o)
        else:
            self._sch[self._res_tensor].reorder(
                block_m_o, block_n_o, block_c1_o,
                ub_m_o, ub_n_o, ub_c1_o,
                ub_m_i, ub_n_i, ub_c1_i, self._res_tensor.op.axis[C0_AXIS]
            )
            self._sch[self._read_tensor].compute_at(self._sch[self._res_tensor], ub_c1_o)
            self._sch[self._write_tensor].compute_at(self._sch[self._res_tensor], ub_c1_o)

        self._sch[self._mid_tensor].compute_at(self._sch[self._res_tensor], ub_m_o)
        self._sch.bind_axes([block_m_o, block_n_o, block_c1_o], tvm.thread_axis("blockIdx.x"))
        self._emit_dma_axis_res = ub_m_i

    def _do_double_buffer(self):
        if self._tiling_case.enable_db:
            for tensor in self._cache_read_tensors | self._cache_write_tensors:
                self._sch[tensor].double_buffer()

    def _do_emit_insn(self):
        if self._is_fp32_mode and self._is_const:
            self._sch[self._read_tensor].emit_insn(self._read_tensor.op.axis[self._h_axis_nd], 'dma_copy')
            self._sch[self._write_tensor].emit_insn(self._write_tensor.op.axis[self._h_axis_nd], 'vector_auto')
            if self._tiling_case.data_format == "NHWC" and self._tiling_case.ub_factor_c != 1:
                # NHWC format, mean-matrix is of shape H*W*C,
                # if C is 1, C-axis will be removed by TBE-PASS and no duplication (vec-dup) needs to be done.
                self._sch[self._mid_tensor].emit_insn(self._mid_tensor.op.axis[2], 'vector_dup') # c of (h*w*c)
            else: # NCHW
                self._sch[self._mid_tensor].emit_insn(self._mid_tensor.op.axis[0], 'data_mov')
        else:
            self._sch[self._read_tensor].emit_insn(self._read_tensor.op.axis[M_AXIS], 'dma_copy')
            self._sch[self._write_tensor].emit_insn(self._write_tensor.op.axis[M_AXIS], 'vector_auto')
            self._sch[self._mid_tensor].emit_insn(self._mid_tensor.op.axis[1], 'vector_dup')
        self._sch[self._res_tensor].emit_insn(self._emit_dma_axis_res, 'dma_copy')


def test_set_value(sch: tvm.Schedule, tiling_data: list):
    """
    Input tiling_data must keep the same range with which in op_util_avg_pool_update TilingDataIdx.
    """
    for i in range(TilingDataIdx.TILINGDATA_IDX_END):
        var_name = TILINGDATA_KEY_MAP.get(i)
        sch.set_var_value(get_te_var(var_name).get_tvm_var(), tiling_data[i])
        log.warn("set_value: {} -> {}".format(var_name, tiling_data[i]))
