#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2023-2024 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
tensor info
"""
import dataclasses
from typing import Type

from tbe.tvm import Tensor

from . import node_base_info
from .. import constants
from .. import helper
from ..... import constants as unify_constants
from ..... import util as unify_helper


@dataclasses.dataclass
class TensorFlags:
    placeholder_flag: bool = False
    endpoint_flag: bool = False
    real_output_flag: bool = False
    middle_flag: bool = False
    fake_node_flag: bool = False


class TensorBase():
    def __init__(self, tvm_tensor):
        self._tvm_tensor: Tensor = tvm_tensor
        self._dtype = tvm_tensor.dtype
        self._src_shapes, self._shape = self._get_shapes()
        self._src_dtypes, self._dtype = self._get_dtypes()
        self._actual_shape = self._shape[:]
        self._producers = []
        self._consumers = []
        self._flags = TensorFlags()

    def __eq__(self, tensor_base_obj):
        return self._tvm_tensor == tensor_base_obj.tvm_tensor

    def __hash__(self):
        return self._tvm_tensor.__hash__()

    def __ne__(self, tensor_base_obj):
        return self._tvm_tensor != tensor_base_obj.tvm_tensor

    def __repr__(self):
        return self._tvm_tensor.__repr__()

    @property
    def tvm_tensor(self):
        return self._tvm_tensor

    @property
    def src_shapes(self):
        return self._src_shapes

    @property
    def shape(self):
        return self._shape

    @property
    def actual_shape(self):
        return self._actual_shape

    @actual_shape.setter
    def actual_shape(self, value):
        self._actual_shape = value

    @property
    def src_dtypes(self):
        return self._src_dtypes

    @property
    def dtype(self):
        return self._dtype

    @property
    def flags(self):
        return self._flags

    @flags.setter
    def flags(self, value):
        self._flags = value

    def copy(self, ori_tensor_obj):
        self._flags = ori_tensor_obj.flags
        self._actual_shape = ori_tensor_obj.actual_shape

    def is_placeholder(self):
        return self._flags.placeholder_flag

    def is_endpoint(self):
        return self._flags.endpoint_flag

    def is_real_output(self):
        return self._flags.real_output_flag

    def is_middle(self):
        return self._flags.middle_flag

    def is_fake_node(self):
        return self._flags.fake_node_flag

    def is_real_middle_output(self):
        return self._flags.real_output_flag and self._flags.middle_flag

    def is_real_non_middle_output(self):
        return self._flags.real_output_flag and not self._flags.middle_flag

    def is_local_scope(self):
        return not self._flags.real_output_flag and self._flags.middle_flag

    def _get_shapes(self):
        input_tensors = helper.get_tvm_input_tensors(self._tvm_tensor)
        src_shapes = None
        if input_tensors is not None:
            src_shapes = [unify_helper.shape_to_list(input_tensor.shape) for input_tensor in input_tensors]

        return src_shapes, unify_helper.shape_to_list(self._tvm_tensor.shape)

    def _get_dtypes(self):
        input_tensors = helper.get_tvm_input_tensors(self._tvm_tensor)
        src_dtypes = None
        if input_tensors is not None:
            src_dtypes = [input_tensor.dtype for input_tensor in input_tensors]

        return src_dtypes, self._tvm_tensor.dtype


class BroadcastTensor(node_base_info.BroadcastNodeBase, TensorBase):
    def __init__(self, tvm_tensor):
        node_base_info.BroadcastNodeBase.__init__(self)
        TensorBase.__init__(self, tvm_tensor)
        self._length = len(tvm_tensor.op.axis)
        self._broadcast_axes_indices = self._get_broadcast_axes_indices()
        self._node_pattern = self._get_node_pattern()

    def _get_broadcast_axes_indices(self):
        if self._src_shapes is None or len(self._src_shapes) < 1:
            return list(range(self._length))

        helper.check_true(len(self._src_shapes) == 1,
                          "if broadcast tensor has inputs, input length must be 1, please check.")

        src_shape = self._src_shapes[0][:]
        src_shape_len = len(src_shape)
        # add 1 to the front
        if src_shape_len < self._length:
            src_shape = [1] * (self._length - src_shape_len) + src_shape

        broadcast_axes_indices = []
        for idx in range(self._length):
            if not unify_helper.expr_equal(src_shape[idx], self._shape[idx]):
                broadcast_axes_indices.append(idx)

        return broadcast_axes_indices


class ReduceTensor(node_base_info.ReduceNodeBase, TensorBase):
    def __init__(self, tvm_tensor):
        node_base_info.ReduceNodeBase.__init__(self)
        TensorBase.__init__(self, tvm_tensor)
        self._before_reduce_shape_length = len(tvm_tensor.op.input_tensors[0].shape)
        self._after_reduce_shape_length = len(tvm_tensor.shape)
        self._reduce_axes_indices = self._get_reduce_axes_indices()
        self._keep_dims = self._before_reduce_shape_length == self._after_reduce_shape_length
        self._node_pattern = self._get_node_pattern()

    @property
    def keep_dims(self):
        return self._keep_dims

    def _get_reduce_axes_indices(self):
        return unify_helper.get_reduce_axis_indexes(self._tvm_tensor)


class DataMoveTensor(node_base_info.DataMoveNodeBase, TensorBase):
    def __init__(self, tvm_tensor):
        node_base_info.DataMoveNodeBase.__init__(self)
        TensorBase.__init__(self, tvm_tensor)


class CommonTensor(node_base_info.CommonNodeBase, TensorBase):
    def __init__(self, tvm_tensor):
        node_base_info.CommonNodeBase.__init__(self)
        TensorBase.__init__(self, tvm_tensor)


def get_tensor_type(tvm_tensor: Tensor) -> constants.NodeType:
    """
    judge type of tensor according to tensor tag
    """
    special_broadcast_insns = ("broadcast", "one_shape_broadcast", "one_rank_broadcast")
    insn = unify_helper.get_dsl_insn(tvm_tensor)
    cur_compute_type = None
    for compute_type, insns in unify_constants.COMPUTE_TYPE_INSN_MAPPING.items():
        if insn in insns:
            cur_compute_type = compute_type
        if insn in special_broadcast_insns:
            cur_compute_type = unify_constants.ComputeType.BROADCAST

    if cur_compute_type == unify_constants.ComputeType.BROADCAST:
        return constants.NodeType.BROADCAST
    elif cur_compute_type == unify_constants.ComputeType.REDUCE:
        return constants.NodeType.REDUCE
    else:
        return constants.NodeType.COMMON


def gen_tensor_obj(tvm_tensor, tensor_type=None) -> Type[TensorBase]:
    """
    generate tensor obj according to tensor type
    """
    if tensor_type is None:
        tensor_type = get_tensor_type(tvm_tensor)

    type_and_tensor_map = {
        constants.NodeType.BROADCAST: BroadcastTensor,
        constants.NodeType.REDUCE: ReduceTensor,
        constants.NodeType.DATA_MOVE: DataMoveTensor,
        constants.NodeType.COMMON: CommonTensor
    }

    return type_and_tensor_map.get(tensor_type)(tvm_tensor)
