#!/usr/bin/env python
# -*- coding: UTF-8 -*-
# Copyright(C) 2022. Huawei Technologies Co., Ltd. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
transdata backward schedule
"""
import copy
from tbe.dsl.base.operation import var_inner
from tbe.dsl.base.operation import get_context
from tbe.dsl.unify_schedule.constants import TransdataCategory
from tbe.common.utils.errormgr import get_error_message
from tbe.common.utils.shape_util import shape_to_list
from tbe.common.platform import get_soc_spec
from tbe.dsl.classifier.transdata.constants import DATA_TYPE_SIZE, INT64
from tbe.dsl.classifier.transdata.constants import STORAGE_ALIGN, COMMON_ALIGN
from tbe.dsl.classifier.transdata.constants import NO_OVERLAP, STRIDE_2, B8, B16

from ..common.transdata_base_sch import TransdataBaseSch
from ..common.transdata_base_sch import set_align


class TransBackwardSchedule(TransdataBaseSch):
    """Perform rank conversion in the most direct way.
    It decomposes complex rank conversion operations through
    the simply rank conversion of adjacent axes. In the schedule,
    complex-transpose = last-transpose + n_last_transpose
    """

    def __init__(self, outs, tiling_case):
        # avoid_conflict_handle_tensors: avoid bc need insert tensors
        # keep_mte_db_handle_tensors: keep mte-db need insert tensors
        TransdataBaseSch.__init__(self, outs, tiling_case)
        self.mapping_indexes = []
        self.avoid_conflict_handle_tensors = []
        self.not_compute_inline_tensors = []
        self.c0_index = None
        self.c1_index = None
        self.ori_tiling_case = None
        self.split_i = self.tiling_case.ub_split_first_idx
        self.split_o = self.tiling_case.ub_split_second_idx
        self.align_tensor = None
        self.shadow_tensor = None
        self.block = int(get_soc_spec("ubblock_size"))
        self.ub_size = int(get_soc_spec("ub_size"))

    @classmethod
    def get_supported_sub_pattern(cls):
        return TransdataCategory.GENERAL_BACKWARD

    def do_schedule(self):
        """
        Process of schedule
        """
        self._analysis_case()
        self._create_schedule()
        self._do_cache_read()
        self._do_set_scope()
        self._init_tensors()

        self._calc_tiling()
        self._do_tiling()

        self._analysis_transpose()

        self._do_buffer_align()
        self._do_storage_align()
        self._do_compute_align()
        self._remove_pad_spec_process()

        self._do_storage_bound()
        self._do_mem_reused()

        self._calc_compute_inline()
        self._do_compute_inline()
        self._do_inline_buffer_align()

        self._calc_multi_core()
        self._do_multi_core()

        self._calc_compute_at()
        self._do_compute_at()

        self._calc_emit_insn()
        self._do_emit_insn()
        self._do_pragma()

        self.schedule.tiling_key = self.tiling_case.tiling_key
        return self.schedule

    def _check_branch(self):
        """
        This branch is for some special cases of nano.
            1.src_format = NC1HWC0 and dst_format = NCHW
            2.N = 1, C = 1
        """
        src_format, dst_format = get_context().get("_transdata_format")
        input_tensor = list(self.graph_info.input_tensor_set)[0]
        output_tensor = list(self.graph_info.output_tensor_set)[0]
        input_shape = shape_to_list(input_tensor.shape)
        output_shape = shape_to_list(output_tensor.shape)
        if self.block != 16:
            return False
        if src_format != "NC1HWC0" or dst_format != "NCHW":
            return False
        if not output_shape[:-1] or any(i < 1 for i in output_shape):
            return False
        if any(i != 1 for i in output_shape[:-1]):
            return False
        return True

    def _calc_compute_inline(self):
        if self._check_branch():
            self.not_compute_inline_tensors.append(self.mte2_tensor)
            self.not_compute_inline_tensors.append(self.transpose_tensors[0])
            self.not_compute_inline_tensors.append(self.tiling_tensor)
            self.not_compute_inline_tensors.extend(self.graph_info.input_tensor_set)
            for tensor in self.get_all_producers_stages(self.tiling_tensor):
                if tensor not in self.not_compute_inline_tensors:
                    self.compute_inline_list.append(tensor)

    def _do_inline_buffer_align(self):
        if self.compute_inline_list:
            bound = [[1, 1] for x in range(len(self.transpose_tensors[0].shape))]
            bound[-2] = [1, self.transpose_tensors[0].shape[-2]]
            self.schedule[self.transpose_tensors[0]].buffer_align(*bound)

    def _do_compute_at(self):
        if self.compute_inline_list:
            self.schedule[self.transpose_tensors[0]].compute_at(self.schedule[self.tiling_tensor], self.ub_outer)
            self.schedule[self.mte2_tensor].compute_at(self.schedule[self.tiling_tensor], self.ub_outer)
        else:
            super()._do_compute_at()

    def _analysis_case(self, ):
        if self.tiling_case.shape_type not in [COMMON_ALIGN, STORAGE_ALIGN]:
            dict_args = {"errCode": "E90003", "detailed_cause": "branch is error."}
            raise RuntimeError(dict_args, get_error_message(dict_args))

        if self.tiling_case.shape_type == COMMON_ALIGN and len(list(self.graph_info.output_tensor_set)[0].shape) == 1:
            self.tiling_case.shape_type = STORAGE_ALIGN

    def _init_tensors(self):
        """
        StorageAlign Process:
        input -> mte2_tensor -> transpose_tensor -> reshape_tensor -> depad_tensor -> output(depad)
        CommonAlign Process:
        input -> mte2_tensor -> transpose_tensor -> reshape_tensor -> depad_tensor -> remove_pad -> output(depad)
        """
        self.depad_tensors = list(self.graph_info.de_pad_tensor_set)
        self.depad_tensors.sort(key=lambda x: int(x.op.attrs["axes"]))
        self.depad_axis_list = [int(x.op.attrs["axes"]) for x in self.depad_tensors]
        self.pad_var_list = self.graph_info.src_pad_var

        self.transpose_tensors = self.graph_info.transpose_tensor_list
        self.reshape_tensors = list(self.graph_info.f_reshape_tensor_set)

        self.tiling_tensor = list(self.graph_info.output_tensor_set)[0]
        self.mte2_tensor = self.child(list(self.graph_info.input_tensor_set)[0])

        # eg: [N,C,H], COMMON_ALIGN work in H, ub2ub work in C
        # eg: [N,C,H], STORAGE_ALIGN work in H, ub2ub work in C
        if self.tiling_case.shape_type == COMMON_ALIGN:
            if self.depad_axis_list[-1] != len(self.tiling_tensor.shape) - 1:
                self._do_cache_write()
                self.depad_tensors[-1] = self.parent(self.tiling_tensor)
                self.remove_pad_tensor = self.single_cache_read(self.depad_tensors[-1])
            else:
                self._do_cache_write()
                self.remove_pad_tensor = self.parent(self.tiling_tensor)
        else:
            if self.depad_axis_list[-1] != len(self.tiling_tensor.shape) - 1:
                self._do_cache_write()
                self.depad_tensors[-1] = self.parent(self.tiling_tensor)

        # remove tiling_tensor from depad_tensors
        if self.depad_tensors[-1] == self.tiling_tensor:
            self.depad_tensors = self.depad_tensors[:-1]
            self.depad_axis_list = self.depad_axis_list[:-1]

        # Special Branch: last-dim si BLOCK*X and shape_type is storage-align,
        # use ub2ub make tensor's data serial
        if self.tiling_case.last_dim_type == 1 and self.tiling_case.shape_type != COMMON_ALIGN:
            self.align_tensor = self.single_cache_write(self.tiling_tensor)
            self.depad_tensors.append(self.align_tensor)
            self.depad_axis_list.append(len(self.align_tensor.shape) - 1)

    def _calc_tiling(self):
        # define factor
        self.dtype = self.tiling_tensor.dtype
        self.align_factor = self.get_block_size(self.dtype)
        self.split_once = self.tiling_case.ub_split_second_idx == self.tiling_case.ub_split_first_idx
        if not self.tiling_case.ub_first_factor:
            self.tiling_case.ub_first_factor = var_inner("_ub_first_factor", (1, None), dtype=INT64)
        if not self.split_once and not self.tiling_case.ub_second_factor:
            self.tiling_case.ub_second_factor = var_inner("_ub_second_factor", (1, None), dtype=INT64)
        if not self.tiling_case.block_factor:
            self.tiling_case.block_factor = var_inner("_block_factor", (1, None), dtype=INT64)
        self.ori_tiling_case = copy.copy(self.tiling_case)

        # regulation
        self.parses_axis_type(self.graph_info.permute)
        self.mapping_indexes, self.c1_index, self.c0_index = self.parses_f_reshape(self.reshape_tensors[-1])
        self.parses_tiling_info(self.mapping_indexes, self.c1_index, self.c0_index, self.graph_info.c0)

    def _do_buffer_align(self):
        """
        Input is [X0,X1,X2,C0], buffer_align reshape to assure mte2.burst_len is x*C0.
        buffer_align: delay entry into force.
        """

        def buffer_align(tensor, axes, values):
            bound = [[1, 1] for x in range(len(tensor.shape))]
            for i, j in zip(axes, values):
                bound[i] = [1, j]
            self.schedule[tensor].buffer_align(*bound)

        # Align C to make mte2.burst_len is x*C0.
        # Align lastDim to make transpose legal(FZ->HWCN).
        # NHC -> NHC: effect, NC1HC0 -> NHC1C0 -> NHC : not effect.
        # NCH -> NCH: effect, NC1HC0 -> NC1C0H -> NCH : not effect.
        aligns = [len(shape_to_list(self.reshape_tensors[-1].shape)) - 1]
        if self.c1_index or self.c1_index == 0:
            c_idx = self.mapping_indexes[self.c1_index]
            aligns.append(c_idx)

        factors = [self.graph_info.src_pad_var[i] for i in aligns]
        buffer_align(self.reshape_tensors[-1], aligns, factors)

    def _ub_internal_length(self, index, length):
        if index == self.ori_tiling_case.ub_split_first_idx:
            return self.ori_tiling_case.ub_first_factor
        if index == self.ori_tiling_case.ub_split_second_idx:
            return self.ori_tiling_case.ub_second_factor
        return length

    def _avoid_conflict_nc1hwc0(self, tensor, optimize, a_idx, b_idx):
        """
        Transpose [a,b] to [b,a]
        :param optimize: The func that avoid conflict in transpose instructions.
        :param a_idx: a's index in [b,a]
        :param b_idx: b's index in [b,a]
        :constraint: Support 5HD and NZ.
        """
        # a: Left var in transpose-mode [a,b] -> [b,a]
        # b: Right var in transpose-mode [a,b] -> [b,a]
        # c0: align value
        shape = shape_to_list(tensor.shape)
        a = self._ub_internal_length(a_idx, shape[a_idx])
        b = self._ub_internal_length(b_idx, shape[b_idx])
        c0 = shape[self.graph_info.c1c0[1]]

        # handle tensors which to solve conflict
        handle_after_tensor = self.single_cache_read(tensor)
        handle_before_tensor = self.single_cache_read(self.mte2_tensor)
        self.avoid_conflict_handle_tensors.extend([handle_before_tensor, handle_after_tensor])
        src, dst = optimize(a, b, c0, tensor)
        perm = [int(x) for x in list(tensor.op.attrs["permute"])]

        # align src-tensor to avoid conflict
        self.schedule[handle_before_tensor].storage_align(handle_before_tensor.op.axis[perm[a_idx]], src, 0)
        # align dst-tensor to avoid conflict
        self.schedule[tensor].storage_align(tensor.op.axis[b_idx], dst, 0)
        # while last-transpose need update vnchwconv-align
        if perm[-1] != len(perm) - 1:
            self.do_vnchwconv_align(tensor, dst)
        # backward need deal with gap that create in _avoid_conflict_nc1hwc0
        self.schedule[handle_after_tensor].storage_align(handle_after_tensor.op.axis[-2], c0, 0)

    def _vor_nc1hwc0_mode(self, tensor):
        """
        Eg: (C1,H,C0)->(H,C1,C0) has two ways:
            1. Liner Read and Interval Write
            2. Interval Read and Liner Write
        """
        idx_c1, idx_h = self.graph_info.c1c0[0], self.graph_info.c1c0[0] - 1
        self._avoid_conflict_nc1hwc0(tensor, self.optimization_vor, idx_c1, idx_h)

    def _vnc_nc1hwc0_mode(self, tensor):
        """
        Eg: (C1,H,C0)->(C1,C0,H) has two ways:
            1. Liner Read and Interval Write
            2. Interval Read and Liner Write
        """
        idx_h, idx_c0 = self.graph_info.c1c0[1] + 1, self.graph_info.c1c0[1]
        self._avoid_conflict_nc1hwc0(tensor, self.optimization_vnc, idx_h, idx_c0)

    def _avoid_bank_conflict(self):
        """
        Func: avoid bank-conflict in n-last-transpose that used VOR.
              avoid bank-conflict in last-transpose that used VNCHWCONV.
        """
        if len(self.transpose_tensors) != 1:
            return
        if self.tiling_case.transpose_work == 0:
            return
        if self.tiling_case.avoid_bank_conflict == 0:
            return

        for tensor, perm in zip(self.transpose_tensors, self.permutes):
            _, insn, _ = self.choose_transpose_insn(tensor.dtype, perm)
            if insn == "vector_or":
                self._vor_nc1hwc0_mode(tensor)
            elif insn == "vector_transpose" and DATA_TYPE_SIZE.get(tensor.dtype, 1) in [B8, B16]:
                self._vnc_nc1hwc0_mode(tensor)

    def _do_storage_align(self):
        for tensor, perm in zip(self.transpose_tensors, self.permutes):
            if perm and perm[-1] != len(perm) - 1:
                self.do_vnchwconv_align(tensor, self.align_factor)

        for tensor in self.get_all_producers_stages(self.tiling_tensor):
            if tensor in self.graph_info.input_tensor_set:
                continue
            if tensor in self.transpose_tensors or len(tensor.shape) < STRIDE_2:
                continue
            if tensor in [self.mte2_tensor, self.remove_pad_tensor, self.align_tensor]:
                continue
            # tensors after transpose
            # while complex-transpose, it must be n_last + last
            # tensor after n-last wouldn't be effect by last + b32
            # tensor after last would be effect by last + b32
            align_factor = self.align_factor
            if self.graph_info.is_last_transpose:
                if self.get_block_size(tensor.dtype) not in [self.b8_block, self.b16_block]:
                    align_factor = self.b32_align_size
            self.schedule[tensor].storage_align(tensor.op.axis[-2], align_factor, 0)

        self._avoid_bank_conflict()

    def _do_compute_align(self):
        """
        Work Tensors: Depad tensors
        Func: 0. Align last-dim
              1. Make emit-insn more effective
              2. Make axis-group work
        align_factor should be effected by transpose-mode and split-mode
        """
        # transpose-mode change align_factor
        align_factor = self.align_factor
        if self.graph_info.is_last_transpose:
            if self.get_block_size(self.transpose_tensors[0].dtype) not in [self.b8_block, self.b16_block]:
                align_factor = self.b32_align_size

        # split-mode change align_factor
        if self.tiling_tensor.op.axis[-1] in self.reorder_list:
            align_factor = set_align(shape_to_list(self.reshape_tensors[-1].shape)[-1], align_factor)

        # compute-align
        for i, (axes, tensor) in enumerate(zip(self.depad_axis_list, self.depad_tensors)):
            if self.depad_axis_list[i + 1:]:
                for j in self.depad_axis_list[i + 1:]:
                    self.schedule[tensor].compute_align(tensor.op.axis[j], self.pad_var_list[j])
            if axes != len(tensor.shape) - 1:
                self.schedule[tensor].compute_align(tensor.op.axis[-1], align_factor)

    def _do_mem_reused(self):
        if self._check_branch():
            return
        source_tensor = self.transpose_tensors[-1]
        if self.avoid_conflict_handle_tensors:
            source_tensor = self.avoid_conflict_handle_tensors[-1]
        for tensor in self.reshape_tensors:
            self.schedule[source_tensor].reused_by(tensor)

    def _remove_pad_spec_process(self):
        """
        1. B32 Transpose + RemovePad maybe exceed UBSize, need depad before remove_pad.
        2. RemovePad from (dimA,dimB,dimC) -> (dimA,dim_b*dim_c).
        """
        if self.tiling_case.shape_type != COMMON_ALIGN:
            return

        _tensor = self.remove_pad_tensor
        ub_count = self.tiling_case.tensor_ub_size_list[self.tiling_case.shape_type]

        if self.graph_info.is_last_transpose:
            hit_bound = self.b32_align_size ** 2 > ub_count
            hit_bit = self.get_block_size(self.transpose_tensors[0].dtype) not in [self.b8_block, self.b16_block]
            if hit_bound and hit_bit:
                self.shadow_tensor = self.single_cache_write(_tensor)
                self.schedule[self.shadow_tensor].compute_align(self.shadow_tensor.op.axis[-1], self.align_factor)

        if _tensor is not None and len(_tensor.shape) > 2:
            if self.tiling_case.ub_split_first_idx == 1 or self.tiling_case.ub_split_second_idx == 1:
                self.schedule[_tensor].storage_align(_tensor.op.axis[-3], self.align_factor, 0)

    def _do_pragma(self):
        # occur in last-transpose, depad work in dma: need depad work in ub (wait)
        for i, tensor in zip(self.depad_axis_list, self.depad_tensors):
            before_axes = [tensor.op.axis[j] for j in range(0, i)]
            after_axes = [tensor.op.axis[j] for j in range(i, len(tensor.shape))]
            self._do_group(tensor, before_axes, number=0)
            self._do_group(tensor, after_axes, number=1)

        if self.tiling_case.last_dim_type == 1:
            i = self.iter_ub_first_inner if self.split_i >= self.split_o else self.iter_ub_second_inner
            idx = self.reorder_list.index(i)
            axes = self.reorder_list[idx:]
            self._do_group(self.tiling_tensor, axes, number=0)

    def _transpose_emit_insn(self, tensor, perm):
        emit_idx, insn, perm = self.choose_transpose_insn(tensor.dtype, perm)
        if insn in ["vector_transpose", "phony_insn"]:
            self.vnchwconv_insn_map(tensor, insn, tensor.op.axis[emit_idx], perm)
        else:
            self.emit_insn_map[tensor] = {"scope": tensor.op.axis[emit_idx], "instruction": insn}
            if insn in ["vector_or", ]:
                self.emit_insn_map[tensor].update(dict(attrs={"transpose_opt": 1}))

    def _calc_emit_insn(self):
        self.emit_insn_map.clear()
        self.emit_insn_map[self.mte2_tensor] = {"scope": self.mte2_tensor.op.axis[0], "instruction": "dma_copy"}
        for tensor in self.reshape_tensors:
            self.emit_insn_map[tensor] = {"scope": tensor.op.axis[0], "instruction": "phony_insn"}
        for tensor, perm in zip(self.transpose_tensors, self.permutes):
            self._transpose_emit_insn(tensor, perm)
        for tensor in self.depad_tensors:
            self.emit_insn_map[tensor] = {"scope": tensor.op.axis[0], "instruction": "dma_copy"}

        if self.tiling_case.last_dim_type == 1:
            self.emit_insn_map[self.tiling_tensor] = {"scope": self.ub_inner, "instruction": "dma_copy",
                                                      "attrs": {NO_OVERLAP: "disable"}}
        else:
            model = 3 if self.tiling_case.shape_type != COMMON_ALIGN else 2
            self.emit_insn_map[self.tiling_tensor] = {"scope": self.ub_inner, "instruction": "dma_copy",
                                                      "attrs": {NO_OVERLAP: model, "no_overlap_malloc_buf_for_tail": 0}}

        if self.tiling_case.shape_type == COMMON_ALIGN:
            self.common_align_insn_map(self.remove_pad_tensor, "remove_pad", self.remove_pad_tensor.op.axis[0])

        # extra
        for tensor in self.avoid_conflict_handle_tensors:
            self.emit_insn_map[tensor] = {"scope": tensor.op.axis[0], "instruction": "dma_copy"}

        if self.shadow_tensor is not None:
            self.emit_insn_map[self.shadow_tensor] = {"scope": self.shadow_tensor.op.axis[0], "instruction": "dma_copy"}

    def _analysis_transpose(self):
        # numbers of permutes is 1, maybe []
        # numbers of permutes is more than 1, can't contain []
        work = self.tiling_case.transpose_work
        self.permutes = [self.update_ub_perm(x, transpose_work=work) for x in self.transpose_tensors]
        self.complex2simple_by_transpose()
