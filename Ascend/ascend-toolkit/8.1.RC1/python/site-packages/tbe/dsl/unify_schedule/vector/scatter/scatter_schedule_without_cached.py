#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2022 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
scatter schedule base
"""
import tvm
from tbe.common.context import op_context
from ...constants import Pattern
from ...schedule import Schedule
from .scatter_schedule_base import ScatterBaseSchedule

# STORE AREA
VAR_STORE_UB = 1

# Whether to set conditions in the sch
IS_NEED_SET_COND = True


# 'pylint: disable=R0902, R0903
class ScatterScheduleWithoutCached(ScatterBaseSchedule):
    """
    scatter schedule
    """

    def _do_cache_read(self):
        self._indices_ub = self._schedule.cache_read(self._indices_gm_tensor, self._scope,
                                                     self._in_out_map.get(self._indices_gm_tensor))
        self._update_ub = self._schedule.cache_read(self._update_gm_tensor, self._scope,
                                                    self._in_out_map.get(self._update_gm_tensor))

        if self._store_area == VAR_STORE_UB and not self._is_scatter_update() and not self._is_scatter_nd_op():
            self._var_ub = self._schedule.cache_read_sparse(self._var_gm_tensor, self._scope,
                                                            self._in_out_map.get(self._var_gm_tensor))
        if self._is_need_align_pad:
            self._update_align_pad_ub = self._schedule.cache_read(self._update_ub, self._scope,
                                                                  self._in_out_map.get(self._update_gm_tensor))

        if self._is_scatter_nd_op():
            self._schedule[self._var_gm_tensor].set_scope("global")
            self._schedule[self._out_tensor].set_scope("global")

    def _do_cache_write(self):
        if not self._is_scatter_nd_op() and not self._is_scatter_update():
            self._scatter_ub = self._schedule.cache_write_sparse(self._cache_write_tensor, self._scope)

    def _do_set_store_predicate(self):
        if IS_NEED_SET_COND:
            blk_idx = self._tiling_case["block_tiling_norm_axis"]
            var_len = len(self._var_gm_tensor.shape)
            rank = self._indices_gm_tensor.shape[-1]
            cond = []
            inplace = op_context.get_context().get_addition("build_options")
            is_inplace = inplace and isinstance(inplace, str) and "is_inplace" in inplace
            for i in range(rank.value):
                indice_ele = self._indices_ub[self._out_tensor.op.sparse_axis[0]][i]
                if is_inplace and rank.value == 1:
                    id_ele = self._indices_ub[self._out_tensor.op.sparse_axis[0]][0]
                    indice_ele = id_ele - tvm.floordiv(id_ele, self._var_gm_tensor.shape[0]) * \
                                 self._var_gm_tensor.shape[0]
                if i == blk_idx:
                    cond1 = indice_ele >= self._block * self.block_factor
                    cond2 = indice_ele < (self._block + 1) * self.block_factor
                else:
                    cond1 = indice_ele >= 0
                    cond2 = indice_ele < self._var_gm_tensor.shape[i]
                cond.extend([cond1, cond2])

            if not self._is_scatter_nd_op():
                if not self._is_scatter_update():
                    self._schedule[self._var_ub].set_store_predicate(cond, partition=True)
                    self._schedule[self._scatter_ub].set_store_predicate(cond, partition=True)
                else:
                    self._schedule[self._out_tensor].set_store_predicate(cond, partition=True)
