#!/usr/bin/env python
# -*- coding: UTF-8 -*-
# Copyright 2023-2024 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================

from typing import List

from tbe import tvm
from tbe.dsl.compute.constants import ComputeType
from tbe.dsl.utils import lists
from . import stage_pro


class SchedulePro:
    def __init__(self, ops, outs):
        self._stage_map = {}

        self._tvm_sch = tvm.create_schedule(ops) # type: tvm.Schedule
        self._out_tensors = outs # type: List[tvm.Tensor]
        self._out_stages = lists.unique(self._pro_stage(x) for x in self._out_tensors)

    def __getattr__(self, name):
        return getattr(self._tvm_sch, name)

    def __getitem__(self, k):
        def get_stage_by_op(op):
            if op in self._tvm_sch.stage_map:
                return self._tvm_sch[k]

            for x in self._tvm_sch.stages:
                if op == x.op:
                    return x

            return None

        if isinstance(k, tvm.Tensor):
            v = get_stage_by_op(k.op)
        else:
            v = self._tvm_sch[k]

        if isinstance(v, tvm.Stage):
            return self._pro_stage(v)

        return v

    @property
    def placeholders(self):
        tensors = []
        for x in self.stages:
            if isinstance(x.op, tvm.PlaceholderOp):
                tensors.extend(x.tensors)
        return lists.unique(tensors)

    @property
    def scan_tensors(self):
        convert = lambda x: {"scan": self.get_origin_tensors(self.get_tensors_by_op(x.op)),
                             "init": self.get_origin_tensors(x.op.init),
                             "update": self.get_origin_tensors(x.op.update),
                             "state": self.get_origin_tensors(x.op.state_placeholder),
                             }
        return [convert(x) for x in self.stages if isinstance(x.op, tvm.ScanOp)]

    @property
    def stages(self):
        # type: () -> List[stage_pro.StagePro]
        return [self._pro_stage(x) for x in self._tvm_sch.stages]

    @property
    def tensors(self):
        tensors_ = []
        for op in self._tvm_sch.stage_map.keys():
            tensors_.extend(self.get_tensors_by_op(op))
        return lists.unique(tensors_)

    @property
    def brc_stages(self):
        return [x for x in self.stages if x.is_broadcast()]

    @property
    def reshape_stages(self):
        return [x for x in self.stages if x.is_reshape()]

    @property
    def compute_inline_stages(self):
        return [x for x in self.stages if x.is_compute_inline()]

    @property
    def stage_op_map_tensor_op(self):
        op_map = {}
        for k, v in self._tvm_sch.stage_map.items():
            op_map[v.op] = k
        return op_map

    @classmethod
    def get_tensors_by_op(cls, x):
        return list(x.output(i) for i in range(x.num_outputs))

    def get_stages(self, compute_type=None, scope=None, dtype=None):
        def listize(x):
            return list(x) if isinstance(x, (tuple, list)) else [x]

        stages = self.stages

        if compute_type is not None:
            compute_types = listize(compute_type)
            stages = filter(lambda x: x.compute_type in compute_types, stages)

        if scope is not None:
            scopes = listize(scope)
            stages = filter(lambda x: x.scope in scopes, stages)

        if dtype is not None:
            dtypes = listize(dtype)
            stages = filter(lambda x: x.dtype in dtypes, stages)

        return list(stages)

    def get(self):
        return self._tvm_sch

    def to_tensors(self, stages):
        tensors = []
        op_map = self.stage_op_map_tensor_op
        for x in stages:
            tensors.extend(self.get_tensors_by_op(op_map.get(x.op)))
        return lists.unique(tensors)

    def to_stages(self, tensors):
        return lists.unique(self[x] for x in tensors)

    def get_origin_tensors(self, tensors):
        origin_tensors = []
        op_map = self.stage_op_map_tensor_op

        for a in tensors:
            if a.op in self._tvm_sch.stage_map:
                origin_tensors.append(a)
                continue
            if a.op in op_map:
                origin_tensors.extend(self.get_tensors_by_op(op_map.get(a.op)))

        return lists.unique(origin_tensors)

    def _pro_stage(self, k):
        return self._stage_map.setdefault(k, stage_pro.StagePro(self, k))
