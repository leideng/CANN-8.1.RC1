#!/usr/bin/env python
# -*- coding:utf-8 -*-
# Copyright 2019-2020 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
schedule_agent
"""
from tbe import tvm
from tbe.common.utils.errormgr import error_manager_util

from .util import Compare
from .util import ceil_div
from .util import expand_params
from .util import floor_div


def raise_schedule_agent_err(msg):
    """
    In common component: schedule_agent, [%s] % (msg)
    msg for discribe the error info
    the error info only for schedule_agent's developers
    """
    args_dict = {
        "errCode": "E60108",
        "reason": msg
    }
    msg = error_manager_util.get_error_message(args_dict)
    raise RuntimeError(args_dict, msg)


class AttachMap:
    """
    docstring for  AttachMap
    """

    def __init__(self):

        self._parent_stages = {}
        self._attached_path = {}

    @property
    def attached_path(self):
        """
        get the _attached_path

        Parameters
        ----------

        Returns
        -------
        None
        """
        return self._attached_path

    @property
    def parent_stages(self):
        """
        get the _parent_stages

        Parameters
        ----------

        Returns
        -------
        None
        """
        return self._parent_stages

    def record_attach(self, stage, scope):
        """
        record the attach situation of stage

        Parameters
        ----------
        stage: the processing of compute
        scope: means axis

        Returns
        -------
        None
        """
        if self._attached_path.get(scope) is None:
            self._attached_path[scope] = [stage]
        else:
            self._attached_path.get(scope).append(stage)

    def follow_with(self, stage, parent_stage, scope):
        """
        update the _parent_stages, record the attach

        Parameters
        ----------
        stage: the processing of compute
        parent_stage: the parent tensor
        scope: means axis

        Returns
        -------
        scope: the attached axis
        """
        self._parent_stages[scope] = parent_stage
        self.record_attach(stage, scope)
        return scope

    def record_same_attach(self, stage, ref_stage):
        """
        attach the stage same as ref_stage

        Parameters
        ----------
        stage: the processing of compute
        ref_stage: the reference tensor

        Returns
        -------
        None
        """
        for scope, s_list in self._attached_path.items():
            if ref_stage in s_list:
                self.record_attach(stage, scope)
                return scope
        return None

    def update_scope(self, scope, new_scope):
        """
        replace the scope by new_scope

        Parameters
        ----------
        scope: the old axis
        new_scope: the new axis

        Returns
        -------
        None
        """
        if scope == new_scope:
            return
        child_stages = self._attached_path.get(scope)
        if child_stages is None:
            return

        attached_path = self._attached_path
        if attached_path.get(new_scope) is None:
            attached_path[new_scope] = child_stages
        else:
            attached_path.get(new_scope).extend(child_stages)

        self._attached_path.pop(scope)

        self._parent_stages[new_scope] = self._parent_stages.get(scope)
        return

    def apply(self):
        """
        begin the compute_at operation
        according to _parent_stages and _attached_path

        Parameters
        ----------

        Returns
        -------
        None
        """
        for scope, array_stages in self._attached_path.items():
            parent = self._parent_stages.get(scope)
            pre_scope = None
            for axis in parent.leaf_iter_vars:
                if axis == scope:
                    break
                pre_scope = axis
            if pre_scope is not None:
                for stage in array_stages:
                    stage.compute_at(parent, pre_scope)

    def get_compute_path(self):
        """
        get the axis that the stage compute at
        """
        compute_path = {}
        for scope, array_stages in self._attached_path.items():
            parent = self._parent_stages.get(scope)
            pre_scope = None
            for axis in parent.leaf_iter_vars:
                if axis == scope:
                    break
                pre_scope = axis
            if pre_scope is not None:
                for stage in array_stages:
                    compute_path[stage] = pre_scope
        return compute_path

    def get_attach_dict(self):
        """
        get the tensor that the stage compute at
        """
        attach_dict = {}
        for scope, array_stages in self._attached_path.items():
            parent = self._parent_stages.get(scope)
            for stage in array_stages:
                attach_dict[stage] = parent
        return attach_dict




class ScopeManager:
    """
    docstring for ScopeManager
    keep active tensor same in whole schedule
    """

    def __init__(self, stage, ignore_init=False):
        self._stage = stage
        self._axis_unit = {}
        self._active_scopes = []
        self._axis_split_list = []
        self._origin_axis = []
        self._last_attached = None
        self._scope_intrinsic = None
        if not ignore_init and len(stage.leaf_iter_vars) != len(stage.all_iter_vars):
            raise_schedule_agent_err("Op should be init before schedule")
        for axis in stage.leaf_iter_vars:
            if isinstance(axis.dom.extent, tvm.tir.IntImm):
                self._axis_unit[axis] = [1, axis.dom.extent.value]
            else:
                self._axis_unit[axis] = [1, axis.dom.extent]
            self._active_scopes.append(axis)
            self._origin_axis.append(axis)
            self._axis_split_list.append([axis])

    @property
    def op(self):
        """
        get stage's op
        """
        return self._stage.op

    @property
    def origin_axis(self):
        """
        get stage's _origin_axis
        """
        return self._origin_axis

    @property
    def scope_intrinsic(self):
        """
        get stage's _scope_intrinsic
        """
        return self._scope_intrinsic

    @property
    def last_attached(self):
        """
        get stage's _last_attached
        """
        return self._last_attached

    @staticmethod
    def _update_axis_split_list(axis_list, ax_before, after_outer, after_inner):
        """
        update axis_list after split
        """
        index = axis_list.index(ax_before)
        axis_list[index] = after_inner
        axis_list.insert(index, after_outer)

    def get_axis_unit(self):
        """
        get stage's _axis_unit
        """
        return self._axis_unit

    def reused_by(self, *args):
        """
        stage's original reused_by function
        """
        self._stage.reused_by(*args)

    def split_group(self, parent, factor=None, nparts=None, c_index=1):
        """
        only use in group convolution, split group axis and
        set both g and c in self._active_scopes
        """
        if nparts is None and factor is None:
            raise_schedule_agent_err("factor nparts can not be None")
        if self._axis_unit.get(parent) is None:
            raise_schedule_agent_err("parent scope can not be None")
        unit, extent = self._axis_unit.get(parent)
        outer, inner = [None, None]
        if nparts is not None:
            outer, inner = self._stage.split(parent, nparts=nparts)
            factor = ceil_div(extent, nparts)
            self._axis_unit[inner] = [unit, factor]
            self._axis_unit[outer] = [factor * unit, nparts]
        else:
            outer, inner = self._stage.split(parent, factor=factor)
            self._axis_unit[inner] = [unit, factor]
            self._axis_unit[outer] = [unit * factor, ceil_div(extent, factor)]
        # move g_axis out
        # c_index, 1: NC1HWC0/NCHW, 2: N H*W C
        if c_index == 1:
            self._stage.reorder(outer, self._stage.op.axis[0], inner)
        else:
            self._stage.reorder(outer, self._stage.op.axis[0], self._stage.op.axis[1], inner)
        if parent in self._active_scopes:  # not else
            self._add_g_active_scope(parent, outer, inner)
        self._axis_split_list[c_index] = [inner]
        # add g_axis split list
        self._axis_split_list.insert(0, [outer])

    def split(self, parent, factor=None, nparts=None, split_params=None):
        """
        apply split to scope

        Parameters
        ----------
        parent: Itervar
        factor: int
        nparts: int
        split_params: object of SplitParams, include split_ceil_mode, tail_strategy and active_scope

        Returns
        -------
        outer: Itervar
        inner: Itervar

        """

        if factor is None and nparts is None:
            raise_schedule_agent_err("factor nparts can not be None")

        if self._axis_unit.get(parent) is None:
            raise_schedule_agent_err("parent scope can not be None")

        if not split_params:
            split_params = SplitParam(True, "guard_with_if", "outer")
        if nparts is not None:
            outer, inner = self._split_with_nparts(parent, nparts, split_params)
        else:
            outer, inner = self._split_with_factor(parent, factor, split_params)
        for axis_list in self._axis_split_list:
            if parent in axis_list:
                self._update_axis_split_list(axis_list, parent, outer, inner)
        return outer, inner

    def reorder(self, *args):
        """
        stage's reorder function
        need check if axes in args is valid
        do not need all axised in this scope
        """
        visited_scope = set()
        scopes = list(args)
        leaf_ivars = self._stage.leaf_iter_vars
        valid_scopes = []
        scopes.reverse()
        for axis in scopes:
            if axis is not None \
                    and axis not in visited_scope \
                    and axis in leaf_ivars:
                valid_scopes.append(axis)
                visited_scope.add(axis)
        if len(valid_scopes) <= 1:
            return
        valid_scopes.reverse()
        self._stage.reorder(*valid_scopes)

    def double_buffer(self):
        """
        stage's original double_buffer function
        """
        self._stage.double_buffer()

    def unroll(self, var):
        """
        stage's original unroll function
        """
        self._stage.unroll(var)

    def buffer_align(self, *arg):
        """
        stage's original buffer_align function
        """
        self._stage.buffer_align(*arg)

    def buffer_tile(self, *arg):
        """
        stage's original buffer_tile function
        """
        self._stage.buffer_tile(*arg)

    def pragma(self, var, pragma_type, pragma_value=None):
        """
        stage's original pragma function
        """
        self._stage.pragma(var, pragma_type, pragma_value)

    def storage_align(self, axis, factor, offset):
        """
        stage's original storage_align function
        """
        self._stage.pragma(axis, factor, offset)

    def get_active_scope_and_unit(self):
        """
        get _active_scopes and unit_list

        Returns
        -------
        _active_scopes: the scopes(axis) now used
        unit_list: the split part of axis
        """
        if not self._check_active_scopes(self._active_scopes):
            raise_schedule_agent_err("active itervar should in leaf_iter_vars")
        unit_list = []
        for axis in self._active_scopes:
            unit, _ = self._axis_unit.get(axis)
            unit_list.append(unit)

        return self._active_scopes, unit_list

    def get_active_scopes(self):
        """
        get _active_scopes
        _active_scopes: the scopes(axis) now used
        """
        if not self._check_active_scopes(self._active_scopes):
            raise_schedule_agent_err("active itervar should in leaf_iter_vars")
        return self._active_scopes

    def fuse(self, *axis):
        """
        fuse axises as one axis

        Parameters
        ----------
        axis: axises to be fused

        Returns
        -------
        fuse result
        """
        return self._stage.fuse(*axis)

    def split_hw(self, parent, nparts=None, factor=None):
        """
        split hw as (h, w) axis and add into active scopes

        Parameters
        ----------
        parent: Itervar
        nparts: int
        factor: int
        """
        if nparts is None and factor is None:
            raise_schedule_agent_err("factor and nparts can not be None contemporarily")
        if self._axis_unit.get(parent) is None:
            raise_schedule_agent_err("parent scope can not be None")
        _, extent = self._axis_unit.get(parent)
        if nparts is not None:
            outer, inner = self._stage.split(parent, nparts=nparts)
            factor = ceil_div(extent, nparts)
            self._axis_unit[inner] = [1, factor]
            self._axis_unit[outer] = [1, nparts]
        else:
            outer, inner = self._stage.split(parent, factor=factor)
            self._axis_unit[inner] = [1, factor]
            self._axis_unit[outer] = [1, ceil_div(extent, factor)]
        if parent in self._active_scopes:
            self._add_hw_active_scope(parent, outer, inner)
        # inner is w axis, replace origin hw axis
        self._axis_split_list[-2] = [inner] # g, n, c1, w, c0
        # outer is h axis, insert before w axis
        self._axis_split_list.insert(-2, [outer]) # g, n, c1, h, w, c0

    def get_axis_split_list_and_extend(self, index):
        """
        according to the index get the axis list(after splited) in the index's dimension.
        """
        unit_list = []
        offset_list = []
        for axis in self._axis_split_list[index]:
            # length and offset of the axis
            offset, unit = self._axis_unit.get(axis)
            unit_list.append(unit)
            offset_list.append(offset)
        return self._axis_split_list[index], unit_list, offset_list

    def nlast_scopes(self, n_scope):
        """
        get n last axes of this stage
        """
        if n_scope <= 0:
            raise ValueError("n_scope must >0")

        leaf_ivars = list(self._stage.leaf_iter_vars)
        if n_scope > len(leaf_ivars):
            raise ValueError("n_scope must less equal to leaf_ivars")
        return leaf_ivars[-n_scope::]

    def intrin_scopes(self, nlast=0):
        """
        this function developed for mmad
        split the axis of scope and reorder
        return the nlast axes for emit insn
        """
        n_scope_intrin = len(self._origin_axis)
        nlast = n_scope_intrin if nlast == 0 else nlast

        if nlast < 0 or nlast > len(self._origin_axis):
            raise_schedule_agent_err("nlast must >0 and < %d" %
                                     len(self._origin_axis))
        # find the first split parent-child scope
        axis_maping = {}
        for relation in self._stage.relations:
            if not isinstance(relation, tvm.schedule.Split):
                continue
            if relation.parent in self._origin_axis:
                axis_maping[relation.inner] = relation.parent
        # get the order of outer and intrin scopes
        outer_ivars, inner_ivars = self._get_intrin_scope(axis_maping)
        order_keeped_axis = outer_ivars + inner_ivars
        self._stage.reorder(*order_keeped_axis)
        self._scope_intrinsic = inner_ivars[0]
        return order_keeped_axis[-nlast::]

    def bind_core(self, scope_list, core_num_list):
        """
        bind core: use the chip better
        finally fuse all the outter axes

        Parameters
        ----------
        scope_list: the list that axes to bind
        core_num_list: the list that core use

        Returns
        -------
        axis_to_bind: the axis that bind

        """
        if not isinstance(scope_list, (list, tuple)):
            scope_list = [scope_list]
        if not isinstance(core_num_list, (list, tuple)):
            core_num_list = [core_num_list]
        if not scope_list:  # len(scope_list) == 0
            raise_schedule_agent_err("at least one axis is to bind")
        if len(scope_list) != len(core_num_list):
            raise_schedule_agent_err(
                "len of scope_list and core_num_list should be same")

        if not self._check_active_scopes(scope_list):
            raise_schedule_agent_err("axis should be in leaf_iter_vars")

        old_leaf_ivars = list(self._stage.leaf_iter_vars)
        axis_outers = []
        max_index = 0
        for axis, core_num in zip(scope_list, core_num_list):
            axo, axi = self.split(axis, nparts=core_num)
            index = old_leaf_ivars.index(axis)
            old_leaf_ivars[index] = axi
            max_index = max(max_index, index)
            axis_outers.append(axo)

        reorder_list = axis_outers + old_leaf_ivars[0:max_index + 1:]
        self._stage.reorder(*reorder_list)

        block = tvm.thread_axis("blockIdx.x")
        if len(axis_outers) > 1:
            axis_to_bind = self._stage.fuse(*axis_outers)
        else:  # len(axis_outers) is 1
            axis_to_bind = axis_outers[0]
        self._stage.bind(axis_to_bind, block)
        return axis_to_bind

    def get_superkernel_axis_pragma(self):
        """
        get the axis that superkernel used to pragma
        """
        leaf_ivars = self._stage.leaf_iter_vars
        return leaf_ivars[1]

    def get_bindcore_m_axis(self, split_w=False):
        """
        get the axis that conv1d used to compute al1_size
        c_ddr bindcore axes's sequence:
        [fused_axis, batch_axis_inner,
        n_axis_inner, m_axis_inner, ...]
        if split_w==True, m_axis is hw inner after split hw axis
        Parameters
        ----------
        split_w: split_w scene
        """
        leaf_ivars = self._stage.leaf_iter_vars
        return leaf_ivars[4] if not split_w else leaf_ivars[5]

    def get_relate_scope(self, scope_key, scope_end=None):
        """
        get the axes whose name contain scope_key
        """
        scope_list = []
        for scope in self._stage.leaf_iter_vars:
            if (scope_end is not None) and (scope == scope_end):
                break
            if scope.var.name.find('{}{}'
                                   .format(scope_key.var.name, '.')) == 0:
                scope_list.append(scope)
        return scope_list

    def emit_insn(self, scope, value, attrs=None):
        """
        stage's original storage_align function
        difference is the default axis to emit insn
        """
        if self._scope_intrinsic is None:
            self._scope_intrinsic = scope
        self._stage.emit_insn(scope, value, attrs)

    def set_last_attached(self, scope):
        """
        set stage's _last_attached
        """
        self._last_attached = scope

    def _check_active_scopes(self, ax_list):
        """
        check if axis in stage's leaf_ivars
        """
        leaf_ivars = list(self._stage.leaf_iter_vars)
        for axis in ax_list:
            if axis not in leaf_ivars:
                return False
        return True

    def _add_hw_active_scope(self, ax_before, after_outer, after_inner):
        """
        use in split_w, change active scopes
        """
        index = self._active_scopes.index(ax_before)
        self._update_active_scope(ax_before, after_inner)
        self._active_scopes.insert(index, after_outer)

    def _split_with_nparts(self, parent, nparts, split_params):
        """
        split scopes with nparts
        """
        unit, extent = self._axis_unit.get(parent)
        outer, inner = self._stage.split(parent, nparts=nparts, tail_strategy=split_params.tail_strategy)
        if split_params.split_ceil_mode:
            factor = ceil_div(extent, nparts)
        else:
            factor = floor_div(extent, nparts)

        self._axis_unit[inner] = [unit, factor]
        self._axis_unit[outer] = [factor * unit, nparts]

        if parent in self._active_scopes:
            self._update_active_scope(parent, inner)
        return outer, inner

    def _split_with_factor(self, parent, factor, split_params):
        """
        split scopes with factor
        """
        unit, extent = self._axis_unit.get(parent)
        if isinstance(factor, tvm.Var):
            factor = tvm.tir.Simplify(factor)
        outer, inner = self._stage.split(parent, factor=factor, tail_strategy=split_params.tail_strategy)
        if split_params.split_ceil_mode:
            nparts =  ceil_div(extent, factor)
        else:
            nparts = floor_div(extent, factor)

        self._axis_unit[inner] = [unit, factor]
        self._axis_unit[outer] = [unit * factor, nparts]

        if parent in self._active_scopes:
            active_scope = inner if split_params.active_scope == "inner" else outer
            self._update_active_scope(parent, active_scope)
        return outer, inner

    def _get_intrin_scope(self, axis_maping):
        """
        get the order of outer and intrin scopes

        Parameters:
        axis_maping: first split parent-child scope.

        Returns:

        outer and intrin scopes.
        """
        leaf_ivars = list(self._stage.leaf_iter_vars)
        outer_ivars = []
        inner_ivars = list(self._origin_axis)
        for scope in leaf_ivars:
            if scope in inner_ivars:
                continue
            parent = axis_maping.get(scope)
            if parent is None:  # not a intrin sope
                outer_ivars.append(scope)
            else:  # scope is a intrin scope
                if parent not in inner_ivars:
                    raise_schedule_agent_err("parent scope shound "
                                             "be in inner_ivars")
                offset = inner_ivars.index(parent)
                inner_ivars[offset] = scope

        return outer_ivars, inner_ivars

    def _update_active_scope(self, ax_before, ax_after):
        active_scopess = self._active_scopes
        index = active_scopess.index(ax_before)
        active_scopess[index] = ax_after

    def _add_g_active_scope(self, ax_before, after_outer, after_inner):
        """
        only use in group convolution, add g to active_scopes
        """
        active_scopess = self._active_scopes
        index = active_scopess.index(ax_before)
        active_scopess[index] = after_inner
        active_scopess.insert(0, after_outer)


class ScheduleAgent:
    """
    docstring for ScheduleAgent
    """

    def __init__(self, sch):
        self._sch = sch
        self._attach_map = AttachMap()
        # key=op,active op othen than origin_ops
        self._scope_managers = {}
        self._ignore_init = False

    def __getitem__(self, tensor):
        """
        get scope manager of input tensor

        Parameters
        ----------
        tensor: Tensor

        Returns
        -------
        scope_manager

        """
        if isinstance(tensor, tvm.Tensor):
            key = tensor.op
        else:
            key = tensor
        if self._scope_managers.get(key) is None:
            self._scope_managers[key] = ScopeManager(self._sch[key], self._ignore_init)
        return self._scope_managers.get(key)

    @staticmethod
    def apply_compute(attach_dict, compute_path):
        """
        process the apply by attach_dict/compute_path
        """
        for stage in attach_dict.keys():
            tensor = attach_dict[stage]
            scope = compute_path[stage]
            if scope is not None:
                stage.compute_at(tensor, scope)

    def same_attach(self, tensor_a, tensor_b):
        """
        attached tensor_a  at the scope that the scope tensor_b attached

        Parameters
        ----------
        tensor_a: Tensor
        tensor_b: Tenosr

        Returns
        -------

        """

        sch = self._sch
        return self._attach_map.record_same_attach(sch[tensor_a],
                                                   sch[tensor_b])



    def attach_at(self, tensor, parent, affine_shape, factor_shape=None, ceil_mode_dict=None):
        """
        attach tensor to parent according to the affine_shape

        Parameters
        ----------
        tensor: Tensor
        parent: Tenosr
        affine_shape: shape of tensor affine to parent.
        factor_shape: the factor used for split in attach at, default is None.
        ceil_mode_dict: dict, include factor_ceil_mode, split_ceil_mode, tail_strategy and active_scope.
                        default is None.

        Returns
        -------
        the scope that tensor follow with.
        """
        scopes = self[parent]
        ax_list, unit = scopes.get_active_scope_and_unit()
        factor_list = factor_shape
        factor_ceil_mode_list = expand_params(True, len(affine_shape))
        if ceil_mode_dict and ceil_mode_dict.get("factor_ceil_mode"):
            factor_ceil_mode_list = expand_params(ceil_mode_dict.get("factor_ceil_mode"), len(affine_shape))
        if not factor_shape:
            if len(affine_shape) != len(ax_list):
                raise_schedule_agent_err("len(affine_shape) should be equal to "
                                        "len(shape)+len(reduce_axis) of {} "
                                        .format(parent))
            factor_list = [(ceil_div(i, j) if ceil_mode else floor_div(i, j))
                for i, j, ceil_mode in zip(affine_shape, unit, factor_ceil_mode_list)]

        scope_attach = self._start_attach(factor_list, tensor, parent, ceil_mode_dict)

        return scope_attach

    def root_stage_at(self, parent, scope):
        """
        parent: parent stage
        scope: scope
        """
        stage_array = self._sch.stages
        parent_stage = self._sch[parent.op]
        for stage in stage_array:
            if stage == parent_stage:
                continue
            if stage.attach_type == 1:
                stage.compute_at(parent_stage, scope)

    def apply(self):
        '''
        apply the attach path
        '''

        self.pre_apply()
        self._attach_map.apply()

    def get_compute_path(self):
        """
        get the compute_path
        """
        return self._attach_map.get_compute_path()

    def get_attach_dict(self):
        """
        get the attach_dict
        """
        return self._attach_map.get_attach_dict()

    def update_ignore_init(self, ignore_init=False):
        """
        ignore init
        """
        self._ignore_init = ignore_init

    def update_attach_scope(self, scope, new_scope):
        """
        replace the attach scope by new_scope
        """
        self._attach_map.update_scope(scope, new_scope)

    def pre_apply(self):
        """
        process the scope_intrinsic before apply
        """
        attach_map = self._attach_map
        parent_stages = list(set(attach_map.parent_stages.values()))
        remain_scopes = set(attach_map.attached_path.keys())
        for parent in parent_stages:
            scope_intrinsic = self[parent.origin_op].scope_intrinsic
            if scope_intrinsic is None:
                continue
            leaf_ivars = list(parent.leaf_iter_vars)
            index = leaf_ivars.index(scope_intrinsic)
            un_attachable_scopes = leaf_ivars[index + 1:]
            for scope in list(remain_scopes):
                if scope in un_attachable_scopes:
                    attach_map.update_scope(scope, scope_intrinsic)
                    remain_scopes.remove(scope)


    def apply_var(self, stage):
        """
        get the axis that the stage(tensor) last attach at
        """
        attach_path = self._attach_map.attached_path
        for scope, array_stages in attach_path.items():
            if stage in array_stages:
                return scope
        return None

    def pattern_abc(self,
                    status,
                    tensor_dict
                    ):
        """
        attach tensor_a to tensor_b
        or
        attach tensor_a to tensor_c
        according to the status
        """
        if status is None:
            raise_schedule_agent_err("status {} is invalid".
                                     format(status))
        if isinstance(status, (list, tuple)):
            raise_schedule_agent_err("status {} dtype is invalid".
                                     format(status))

        tensor_a = tensor_dict.get('tensor_a')
        tensor_b = tensor_dict.get('tensor_b')
        tensor_c = tensor_dict.get('tensor_c')
        affine_shape_to_b = tensor_dict.get('affine_shape_to_b')
        affine_shape_to_c = tensor_dict.get('affine_shape_to_c')

        attach = None
        if status == Compare.EQUAL:
            attach = self.same_attach(tensor_a, tensor_b)
        elif status == Compare.LESS_EQ:
            attach = self.attach_at(tensor_a, tensor_b, affine_shape_to_b)
        elif status == Compare.GREATE_EQ:
            attach = self.attach_at(tensor_a, tensor_c, affine_shape_to_c)
        else:
            raise_schedule_agent_err("tiling shape of {} shouldn't "
                                     "be both less and greater than {}".
                                     format(tensor_a, tensor_b))
        return attach

    def _get_axis_info(self, factor_list, parent, ceil_mode_dict):
        """
        get infor of axis.

        Parameters:
        ----------
        factor_list: infor of factor.

        parent: Tensor.

        ceil_mode_dict: include factor_ceil_mode and split_ceil_mode

        Returns
        ----------

        value of axis.
        """
        scopes = self[parent]
        ax_list, _ = scopes.get_active_scope_and_unit()
        axis_outer = []
        axis_intrinsic = []
        axis_ori_unrelate = []

        origin_axis = scopes.origin_axis
        split_ceil_mode_list = expand_params(True, len(factor_list))
        tail_strategy_list = expand_params("guard_with_if", len(factor_list))
        active_scope_list = expand_params("outer", len(factor_list))
        if ceil_mode_dict:
            if ceil_mode_dict.get("split_ceil_mode"):
                split_ceil_mode_list = expand_params(ceil_mode_dict.get("split_ceil_mode"), len(factor_list))
            if ceil_mode_dict.get("tail_strategy"):
                tail_strategy_list = expand_params(ceil_mode_dict.get("tail_strategy"), len(factor_list))
            if ceil_mode_dict.get("active_scope"):
                active_scope_list = expand_params(ceil_mode_dict.get("active_scope"), len(factor_list))

        for factor, axis, split_ceil_mode, tail_strategy, active_scope in zip(
            factor_list, ax_list, split_ceil_mode_list, tail_strategy_list, active_scope_list):
            if factor is not None and (isinstance(factor, (tvm.tir.PrimExpr, tvm.Var))
                                       or factor > 1 or axis in origin_axis):
                split_params = SplitParam(split_ceil_mode, tail_strategy, active_scope)
                axo, axi = scopes.split(axis, factor=factor, split_params=split_params)
                self._attach_map.update_scope(axis, axi)
                axis_outer.append(axo)
                axis_intrinsic.append(axi)
            elif axis in origin_axis:
                axis_ori_unrelate.append(axis)
            else:
                axis_outer.append(axis)

        return axis_outer, axis_intrinsic, axis_ori_unrelate

    def _start_attach(self, factor_list, tensor, parent, attach_param_dict=None):
        """
        get info of scope_attach.

        Parameters:
        ----------
        factor_list: info of factor.

        tensor: infor of tensor.

        parent: Tensor.

        attach_param_dict: dict, include factor_ceil_mode and split_ceil_mode. default is None.

        Returns
        ----------

        scope_attach value.
        """
        axis_outer, axis_intrinsic, axis_ori_unrelate = self._get_axis_info(
            factor_list, parent, attach_param_dict)

        scope_attach = None
        if axis_intrinsic:  # len(axis_intrinsic) > 0:
            reorder_list = axis_outer + axis_ori_unrelate + axis_intrinsic
            self._sch[parent].reorder(*reorder_list)
            scope_attach = axis_intrinsic[0]
            self._attach_map.follow_with(self._sch[tensor],
                                         self._sch[parent],
                                         scope_attach)
            self[parent].set_last_attached(scope_attach)
        elif axis_outer:  # len(axis_outer) > 0:
            scope_attach = self[parent].last_attached
            if scope_attach is not None:  # no else
                self._attach_map.record_attach(self._sch[tensor],
                                               scope_attach)
        else:
            pass

        return scope_attach



class SplitParam:
    """Describe the parameter used for split function in class ScopeManager

    Attributes:
        split_ceil_mode: Whether it needs to use ceil_div or not, only set to false when the factor is divisible.
        tail_strategy: The tail strategy in split. The optional values are "round_up", "guard_with_if" and
                       "shift_inwards". "round_up" and "shift_inwards" will guarantee the same amount of data for
                       tail block and main block, "round_up" read extra data backwards and "shift_inwards" read extra
                       data forwards, "guard_with_if" will keep the original amount of data unchanged.
        active_scope: The axes used for futher split, the optional values are "inner" or "outer"
    """
    def __init__(self, split_ceil_mode=True, tail_strategy="guard_with_if", active_scope="outer") -> None:
        self.split_ceil_mode = split_ceil_mode
        # specify tail_strategy as "round_up" to simplify expression when split_ceil_mode is False.
        self.tail_strategy = tail_strategy if split_ceil_mode else "round_up"
        self.active_scope = active_scope