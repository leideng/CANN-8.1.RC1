#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_vector_single_api_.py
DESC:     provide vector instructions
CREATED:  2021-09-8 18:53:42
"""

from tbe import tvm
from tbe.tik import debug
from tbe.tik.tik_lib.tik_expr import Expr
from tbe.tik.tik_lib.tik_expr_convert import type_convert
from tbe.tik.tik_lib.tik_params import PIPE_V
from tbe.tik.tik_lib.tik_vector_api.tik_vector_name_map import SINGLE_NAME_DICT
from tbe.tik.tik_lib.tik_vector_api.tik_compute_control import ControlOp
from tbe.tik.tik_lib.tik_vector_api.tik_tensor_op import TensorOp
from tbe.tik.tik_lib.tik_vector_api.tik_params_check import SingleCheckParams
from tbe.tik.tik_lib.tik_vector_api.vector_common_util import gen_b64_mask_mode
from tbe.tik.tik_lib.tik_source_info import source_info_decorator
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.tik_lib.tik_mask_concat_ import mask_concat
from tbe.tik.common.tik_get_soc_name import is_compatible_mode
from tbe.tik.common.util import reassign_mask
from tbe.tik.common.util import check_mask1_mask2
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.util import get_bit_len
from tbe.tik.common.tik_get_soc_name import get_block_size


_BLOCK_LEN = 8
_MIN_DST_BLK_STRIDE = 1
_ROUND_TO_NEAREST_ENABLE = 0
_BIT_LEN_16 = 16
_MIN_MASK = 1
_MAX_MASK_N = 129
_MAX_MASK_64 = 65
_DEFAULT_STRIDE = 0
_VCMP_REP_STRIDE = 0


class SingleOpApi:
    """
    Single Vector Ops
    """
    def __init__(self, tik_instance, single_api, mask_o=None):
        super().__init__()
        self.tik_instance = tik_instance
        self.name = SINGLE_NAME_DICT.get(single_api.name)
        self.print_name = single_api.name
        if hasattr(single_api, "api_name"):
            self.name = single_api.api_name
        self.control_op = ControlOp(single_api.mask, single_api.repeat_times, single_api.stride_unit)
        self.dst_tensor_op = TensorOp(single_api.dst, single_api.dst_blk_stride, single_api.dst_rep_stride, "dst")
        self.src_tensor_op = TensorOp(single_api.src, single_api.src_blk_stride, single_api.src_rep_stride, "src")
        self.repeat_times = single_api.repeat_times
        self.stride_unit = single_api.stride_unit
        # debug check instance
        self.check_params = (self.dst_tensor_op, self.src_tensor_op, self.control_op)
        self.single_check_obj = SingleCheckParams(self.print_name, self.check_params, self.name)
        self.mask_o = mask_o

    @debug.vec_single_elewise_func_dec_new
    def gen_code(self):
        """
        code gen

        Returns
        -------
        None
        """
        config = [
            self.repeat_times, self.dst_tensor_op.blk_stride, self.src_tensor_op.blk_stride,
            self.dst_tensor_op.rep_stride, self.src_tensor_op.rep_stride
        ]
        if self.dst_tensor_op.tensor_obj.dtype == "int64":
            mask_mode_list = gen_b64_mask_mode(self.control_op.mask)
            config.extend(mask_mode_list)
        with self.tik_instance.new_scope():
            if TikSocManager.is_v300_610l_soc():
                self.tik_instance.add_source_id()
            instr = tvm.call_extern(self.dst_tensor_op.tensor_obj.dtype, self.name,
                                    self.dst_tensor_op.tensor_obj.access_ptr("w"),
                                    self.src_tensor_op.tensor_obj.access_ptr("r"),
                                    *type_convert(config))
            self.tik_instance.emit(tvm.call_extern("int64", "set_vector_mask", *self.mask_o))
            self.tik_instance.scope_attr(tvm.thread_axis("cce"), "coproc_scope", PIPE_V)
            self.tik_instance.emit(instr)

    @source_info_decorator(depth=2)
    def run_all(self):
        """
        run all_check and code_gen

        Returns
        -------
        None
        """
        mask_o = self.single_check_obj.check_all(self.tik_instance)
        if self.mask_o is None:
            self.mask_o = mask_o
        self.gen_code()


class NanoSingleOpApi(SingleOpApi):
    """
    Single Vector Ops
    """
    def blklen_16_gen_code(self, params_list):
        """
        not compatible, code gen

        Parameter
        ----------
        params_list: list of params

        Returns
        -------
        None
        """
        mask_o, dst, src, dst_blk_stide, src_blk_stride, dst_rep_stride, src_rep_stride = params_list
        config = [self.repeat_times, dst_blk_stide, src_blk_stride, dst_rep_stride, src_rep_stride]
        with self.tik_instance.new_scope():
            instr = tvm.call_extern(dst.dtype, self.name,
                                    dst.access_ptr("w"),
                                    src.access_ptr("r"),
                                    *type_convert(config))
            self.tik_instance.emit(tvm.call_extern("int64", "set_vector_mask", *mask_o))
            self.tik_instance.scope_attr(tvm.thread_axis("cce"), "coproc_scope", PIPE_V)
            self.tik_instance.emit(instr)

    @source_info_decorator(depth=2)
    def run_all(self):
        """
        run all_check and code_gen

        Returns
        -------
        None
        """
        # block_size considered as 32
        if is_compatible_mode():
            self.single_check_obj.check_all(self.tik_instance)
            tensor_bit_len = get_bit_len(self.dst_tensor_op.tensor_obj.dtype)
            one_block_elements = get_block_size() // DTYPE_SIZE[self.dst_tensor_op.tensor_obj.dtype]
            mask1, mask2 = reassign_mask(self.tik_instance, self.control_op.mask, one_block_elements)
            enable_mask1, enable_mask2 = check_mask1_mask2(mask1, mask2)
            if enable_mask1:
                mask_o1 = mask_concat(self.tik_instance, mask1, tensor_bit_len=tensor_bit_len)
                self.blklen_16_gen_code((mask_o1, self.dst_tensor_op.tensor_obj, self.src_tensor_op.tensor_obj,
                                        2 * self.dst_tensor_op.blk_stride, 2 * self.src_tensor_op.blk_stride,
                                        2 * self.dst_tensor_op.rep_stride, 2 * self.src_tensor_op.rep_stride))
            if enable_mask2:
                one_block_elements = self.tik_instance.Scalar(name="one_block_elements", init_value=one_block_elements)
                mask_o2 = mask_concat(self.tik_instance, mask2, tensor_bit_len=tensor_bit_len)
                self.blklen_16_gen_code((mask_o2, self.dst_tensor_op.tensor_obj[one_block_elements:],
                                        self.src_tensor_op.tensor_obj[one_block_elements:],
                                        2 * self.dst_tensor_op.blk_stride, 2 * self.src_tensor_op.blk_stride,
                                        2 * self.dst_tensor_op.rep_stride, 2 * self.src_tensor_op.rep_stride))
        else:
            mask_o = self.single_check_obj.check_all(self.tik_instance)
            self.blklen_16_gen_code((mask_o, self.dst_tensor_op.tensor_obj,
                                    self.src_tensor_op.tensor_obj,
                                    self.dst_tensor_op.blk_stride, self.src_tensor_op.blk_stride,
                                    self.dst_tensor_op.rep_stride, self.src_tensor_op.rep_stride))