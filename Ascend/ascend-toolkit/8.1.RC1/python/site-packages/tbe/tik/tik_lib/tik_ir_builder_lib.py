#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_ir_builder.py
DESC:     Developer API of IR node builder make function for TIK.
CREATED:  2019-08-12 18:53:42
MODIFIED: 2020-12-7 19:17:00
"""
from __future__ import absolute_import as _abs

from tbe import tvm
from tbe.tvm import thread_axis
from tbe.tvm import call_extern
from tbe.tvm import convert
from tbe.tvm import tir
from tbe.tvm.tir.ir_builder import WithScope
from tbe.tvm.ir import PrimType
from tbe.tvm.ir import PointerType
from tbe.tvm.runtime.cce_runtime import PIPELINES
from tbe.common.platform import scope_cbuf
from tbe.common.platform import scope_ubuf
from tbe.common.platform import scope_ca
from tbe.common.platform import scope_cb
from tbe.common.platform import scope_cc
from tbe.common.platform import scope_smask
from tbe.common.platform import scope_reg
from tbe.common.platform import scope_gm
from tbe.common.platform.platform_info import scope_fb0
from tbe.common.platform.platform_info import scope_bt
from tbe.tik import debug
from tbe.tik.common import DTYPE_SIZE
from tbe.tik.common.common_util import is_scalar
from tbe.tik.tik_lib.tik_expr import Expr
from tbe.tik.api.tik_tensor import Tensor
from tbe.tik.api.tik_tensor_addr_list import TensorAddrList
from tbe.tik.api.tik_scalar import Scalar
from tbe.tik.api.tik_scalar_array import ScalarArray
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_check_util import TIK_CONTROL
from tbe.tik.tik_lib.tik_source_info import get_span
from tbe.tik.tik_lib.tik_source_info import source_info_decorator
from tbe.tik.tik_lib.tik_source_info import TikSourceInfo
from tbe.tik.tik_lib.tik_params import LEN_SHAPE_ONE
from tbe.tik.tik_lib.tik_params import RPN_COR_IR
from tbe.tik.tik_lib.tik_buffervar import TikBufferVar
from tbe.tik.debug.util import make_tvm_imm
from tbe.tik.debug.util import safe_get_value
from tbe.tik.common.debug_api import substitute_scalar
from tbe.tik.common.debug_api import substitute_scalar_check
from tbe.tik.common.debug_api import uses_vars
from tbe.tvm.ir import Op

_LAST_ELEMENT = -1

# block num min should greater than 0, less than 65536
_MIN_BLOCK_NUM = 1
_MAX_BLOCK_NUM = 65536

_DEFAULT_THREAD_BLOCK_NUM = 1
_MIN_NIDX = 3
_DEVICE_API = 0

# for type id value
_SERIAL_FOR_TYPE_ID = 0
# elif and else follow an if should greater than 0
_INIT_IFTHENELSE_DEEP = 0

# for if_scope elif_scope else_scope cond status
_COND_FALSE = 0
_COND_TRUE = 1
_COND_OUT_FALSE = 2
_COND_UNKNOW = 3

_SYNC_FLAG = ["pragma_multicore_sync_wait_before",
              "pragma_multicore_subblock_sync_wait_before",
              "pragma_multicore_all_block_sync_after"]


class SubInfo:
    """
    Auxiliary struct to build for_range_subblk_.
    """
    def __init__(self: any, begint: int, endt: int, subblock_num: int, sub_dtype: str) -> None:
        self.begint = begint
        self.endt = endt
        self.name = "i"
        self.thread_num = 1
        self.thread_type = "whole"
        self.subblock_num = subblock_num
        self.sub_dtype = sub_dtype
        self.for_type = "serial"

    @staticmethod
    def get_subblock_id(subblock_num: int) -> any:
        """
        get subblock id
        Parameters
        ----------
        subblock_num: subblock number

        Returns
        -------
        subblock id
        """
        subblock_id = None
        if subblock_num > _DEFAULT_THREAD_BLOCK_NUM:
            subblock_id = thread_axis("subBlockIdx.x")
        return subblock_id

    @staticmethod
    def check_subblock_nest_(has_multi_subblk: bool) -> None:
        """
        check Illegal nest
        Parameters
        ----------
        has_multi_subblk: flag of multi subblock

        Returns
        -------
        None
        """
        if has_multi_subblk:
            TikCheckUtil.raise_error(
                "Nest error:for_range of subblock shold be nested"
                "within for_range of block""")


class TikWithScope(WithScope):
    """
    Auxiliary scope with Inherit from WithScope of ir_builder
    """
    def __init__(self, enter_value, exit_cb, source_info):

        super(TikWithScope, self).__init__(enter_value, exit_cb)
        if isinstance(enter_value, (tuple, list)):
            self._enter_value = [Expr(value) for value in enter_value]
        else:
            self._enter_value = Expr(enter_value)
        self._exit_cb = exit_cb
        self.debug_hint = None
        self.debug_limit = None
        self.source_info = source_info


class ScopeBufferManager:
    """
    Scope buffer manager.
    Scope:for_range,if_scope.else_scope.new_stmt_scope
    """
    def __init__(self):
        self.buffer_map = {
            scope_cbuf: {},
            scope_ubuf: {},
            scope_ca: {},
            scope_cb: {},
            scope_cc: {},
            scope_smask: {},
            scope_fb0: {},
            scope_bt: {}
        }
        self.tensor_list = []

    def add_tensor(self, tensor, size):
        """
        new Tensor application  in this scope

        Parameters
        ----------
        tensor: Tensor application

        size : int, Tensor used buffer size

        Returns
        -------
        NO return
        """
        self.__check_tensor(tensor)
        if hasattr(tensor, "reuse_list"):
            if tensor.reuse_list is None:
                self.buffer_map.get(tensor.scope)[tensor] = size
        else:
            self.buffer_map.get(tensor.scope)[tensor] = size
        self.tensor_list.append(tensor)

    @debug.del_tensor_decorator
    def del_tensor(self, tensor):
        """
        when the scope lifecycle is in the end, tensor should be released.

        Parameters
        ----------
        tensor: tensor should be released in the end of the scope lifecycle

        Returns
        -------
        return:NO return
        """
        self.__check_tensor(tensor)
        if hasattr(tensor, "reuse_list") and tensor.reuse_list is not None:
            tensor.disable_tensor()
        else:
            if self.buffer_map.get(tensor.scope).get(tensor) is None:
                TikCheckUtil.raise_error("Tensor %s is not in this scope" % tensor)
            del self.buffer_map.get(tensor.scope)[tensor]
            tensor.disable_tensor()

    def get_scope_buffer_used(self):
        """
        Counting tensors size in this scope

        Parameters
        ----------

        Returns
        -------
        return: map
        buffer_count: L0A/B/C,L1,UB buffer used size in the scope.
        """
        buffer_count = {scope_cbuf: 0, scope_ubuf: 0, scope_ca: 0, scope_cb: 0, scope_cc: 0,
                        scope_smask: 0, scope_fb0: 0, scope_bt: 0}
        for buffer_scope in self.buffer_map:
            for tensor_size in self.buffer_map[buffer_scope].values():
                buffer_count[buffer_scope] += tensor_size
        return buffer_count

    def __check_tensor(self, tensor):
        TikCheckUtil.check_type_match(tensor, (Tensor, TensorAddrList),
                                      "input tensor(%s) should be Tensor or TensorAddrList" % str(type(tensor)))

        if isinstance(tensor, Tensor):
            TikCheckUtil.check_var_in_list(
                tensor.scope, self.buffer_map,
                "input tensor's scope should be scope_cbuf, scope_ubuf, scope_ca, scope_cb, scope_cc or scope_smask")
        else:
            TikCheckUtil.check_equality(tensor.scope, scope_ubuf, "input tensoraddrlist's scope should scope_ubuf")


class CodeBufferManager:
    """
    when tensor is applied, tensor is managed in this class
    """
    def __init__(self):
        self.scope_stack = [ScopeBufferManager()]
        self.dprofile = None
        self.total_buffer = None
        self.total_reg = None
        self.double_buffer_enable_stack_ = [False]
        self.double_buffer_thread_num = 2

    def new_scope(self):
        """
        when new scope is applied, the new scope should be managed
        """
        self.scope_stack.append(ScopeBufferManager())

    def del_scope(self):
        """
        when lifecycle of the scope is in the end, this scope should be deleted.
        """
        del_scope_buffer = self.scope_stack.pop()
        for del_buffer in del_scope_buffer.tensor_list:
            del_scope_buffer.del_tensor(del_buffer)

    def buffer_used(self):
        """
        count the buffers size

        -------
        return: buffer_count: L0A/B/C,L1,UB buffer used size.
        """
        buffer_count = {scope_cbuf: 0, scope_ubuf: 0, scope_ca: 0, scope_cb: 0, scope_cc: 0,
                        scope_smask: 0, scope_fb0: 0, scope_bt: 0}
        for sbm in self.scope_stack:
            buffer_count_tmp = sbm.get_scope_buffer_used()
            for scope in buffer_count:
                if buffer_count_tmp.get(scope) is not None:
                    buffer_count[scope] += buffer_count_tmp.get(scope)
        return buffer_count

    def buffer_aviable(self):
        """
        count how much buffer memory is available

        -------
        return:None or Map, left_tesnor: L0A/B/C,L1,UB buffer available size.
        """
        if self.total_buffer is not None:
            left_tensor = {scope_cbuf: 0, scope_ubuf: 0, scope_ca: 0, scope_cb: 0, scope_cc: 0,
                           scope_smask: 0, scope_fb0: 0, scope_bt: 0}
            buffer_count = self.buffer_used()
            for scope in self.total_buffer:
                left_tensor[scope] = self.total_buffer[scope] - buffer_count.get(scope)
            return left_tensor
        return None

    def new_tensor(self, tensor):
        """
        when tensor is applied,tensor is be checked and be added in scope manage.

        Parameters
        ----------
        tensor:The tensor is applied in the scope
        """
        aviable_tensor = self.buffer_aviable()
        if aviable_tensor is not None:
            if self.double_buffer_enable_stack_[-1] is True:
                error_msg = "Tensor %s appiles buffer size(%sB) more than avaiable buffer size(%sB)." % \
                            (tensor.name, tensor.double_buffer_size(self.double_buffer_thread_num),
                             aviable_tensor.get(tensor.scope))
                TikCheckUtil.check_le(tensor.double_buffer_size(self.double_buffer_thread_num),
                                      aviable_tensor.get(tensor.scope), error_msg)
                double_buffer_size = tensor.double_buffer_size(self.double_buffer_thread_num)
                self.scope_stack[-1].add_tensor(tensor, double_buffer_size)
            else:
                tensor_buffer_size = Expr(tensor.buffer_size).eval_value()
                aviable_tensor_size = Expr(aviable_tensor.get(tensor.scope)).eval_value()
                buf_size = tensor.buffer_size

                # if given start addr of current tensor, overflow check is diff
                if hasattr(tensor, "start_addr") and tensor.start_addr is not None:
                    buf_size = self._get_buf_size_for_new_tensor(tensor, aviable_tensor_size)
                    aviable_tensor_size = self.total_buffer[tensor.scope] - tensor.start_addr
                if tensor_buffer_size is not None and aviable_tensor_size is not None:
                    error_msg = "Tensor %s appiles buffer size(%dB) more than available buffer size(%dB)." % \
                                (tensor.name, tensor_buffer_size, aviable_tensor_size)
                    TikCheckUtil.check_le(tensor_buffer_size, aviable_tensor_size, error_msg)
                self.scope_stack[-1].add_tensor(tensor, buf_size)

    def get_reg_len(self, scope, dtype):
        """
        get reg len

        Parameters
        ----------
        scope: reg scope: vreg, areg, preg
        dtype: reg dtype
        -------
        return: reg len
        """
        if dtype not in DTYPE_SIZE:
            raise RuntimeError("input data type not support now!")
            # if not v210, total_reg is 0
        total_reg = self.total_reg[scope]
        return total_reg // DTYPE_SIZE[dtype]

    def inject_dprofile(self, dprofile):
        """
        According the D core information, buffers parameters can be known.

        Parameters
        ----------
        dprofile:the D core information
        -------
        return:buffer_map, The D core buffers_information
        """
        self.dprofile = dprofile
        self.total_buffer = self.dprofile.buffer_size_query()
        self.total_reg = self.dprofile.reg_size_query()

    def buffer_print(self):
        """
        print buffer information
        """
        print("buffer used:", self.buffer_used())
        print("buffer available:", self.buffer_aviable())
        print("buffer total:", self.total_buffer)

    def _get_buf_size_for_new_tensor(self, tensor, aviable_tensor_size):
        """
        get buf size for new tensor

        Parameters
        ----------
        tensor: The tensor is applied in the scope
        aviable_tensor_size: aviable_tensor_size
        -------
        return: buf_size
        """
        total_size = self.total_buffer[tensor.scope]
        curr_end_addr = tensor.start_addr + tensor.buffer_size  # current tensor end addr
        last_end_addr = total_size - aviable_tensor_size  # last tensor end addr
        # if last tensor's end addr greater then current tensor end addr, set current tensor size to 0
        if last_end_addr >= curr_end_addr:
            buf_size = 0
        else:  # set current tensor size to the diff of two end addr
            buf_size = curr_end_addr - last_end_addr

        return buf_size


class ScopeScalarManager():
    """
    managing Scalar/ScalarArray in the scope
    Scope:for_range,if_scope.else_scope.new_stmt_scope
    """
    def __init__(self):
        self.scalar_list = []

    @staticmethod
    def _check_scalar(scalar):
        """
        when Scalar/ScalarArray is used in this scope, this scope should be checked

        Parameters
        ----------
        scalar:The Scalar/ScalarArray is applied in this scope.
        """
        TikCheckUtil.check_type_match(
            scalar, (Scalar, ScalarArray), "input(%s) should be Scalar/ScalarArray" % str(type(scalar)))

    def add_scalar(self, scalar):
        """
        Adding Scalar/ScalarArray in this scope.

        Parameters
        ----------
        scalar:The new Scalar/ScalarArray is applied in this scope.
        """
        self._check_scalar(scalar)
        self.scalar_list.append(scalar)

    @debug.del_scalar_decorator
    def del_scalar(self, scalar):
        """
        deleting Scalar/ScalarArray in this scope.

        Parameters
        ----------
        scalar:Scalar/ScalarArray will be deleted in this scope.
        """
        self._check_scalar(scalar)
        self.scalar_list.remove(scalar)
        if isinstance(scalar, Scalar):
            scalar.disable_scalar()
        else:
            scalar.disable_scalar_array()


class CodeScalarManager():
    """
    Scalar/ScalarArray are managed in this class.
    """
    def __init__(self):
        self.scope_stack = [ScopeScalarManager()]

    def new_scope(self):
        """
        When the new scope funtion is used, the new scope should be creaded.
        The new scope functions are for_range, if_scope/else_scope and new_stmt_scope
        """
        self.scope_stack.append(ScopeScalarManager())

    def del_scope(self):
        """
        When this scope lifecycle is in the end, Scalar/ScalarArray of the scope should be deleted.
        """
        del_scope_scalar = self.scope_stack.pop()
        for del_scalar in del_scope_scalar.scalar_list[:]:
            del_scope_scalar.del_scalar(del_scalar)

    def new_scalar(self, scalar):
        """
        When Scalar/ScalarArray is applied, Scalar/ScalarArray should be managed in this scope.

        Parameters
        ----------
        scalar : the new Scalar/ScalarArray is applied in this scope
        """
        self.scope_stack[-1].add_scalar(scalar)


class TikIRBuilderInner:
    """
    TikIRBuilder inner class
    """

    def __init__(self):
        self.source_info = TikSourceInfo()
        self.if_scope_level = 0
        self.if_elif_cond_stack = [_COND_TRUE, ]  # True, False or Unknown
        self.for_scope_level = 0
        self.elif_scope_level = 0
        self.else_scope_level = 0
        self.stmt_scope_level = 0
        # use this to judge whether here is double buffer scope
        self.code_buffer_manager = CodeBufferManager()
        self.code_scalar_manager = CodeScalarManager()

        self.enable_multi_core = False
        self.has_multi_block = False
        # barrier_sync flag
        self.pipe_line_dict = dict(zip(PIPELINES.values(), PIPELINES.keys()))

        # frontend tiling info
        self.tiling_numpy = None
        self.tiling_addr_map = {}
        self.tiling_scalar_map = {}
        self.tiling_value_map = {}
        self.tiling_warning_print = False

    @staticmethod
    def _check_cond_true(cond):
        return cond is True or (isinstance(cond, (int, float)) and cond != 0)

    @staticmethod
    def _check_cond_false(cond):
        return cond is False or (isinstance(cond, (int, float)) and cond == 0)

    @staticmethod
    def _check_pipe_supported(func_name, pipe_name, pipe):
        """
        Check if pipe supported
        :param func_name: function name
        :param pipe_name: pipe name
        :param pipe: pipe
        """
        if func_name == "pipe_barrier" and pipe == "PIPE_ALL":
            return
        if pipe in ["PIPE_S", "PIPE_V", "PIPE_M", "PIPE_MTE1", "PIPE_MTE2", "PIPE_MTE3"]:
            return
        TikCheckUtil.raise_error("Don't support call %s api with param: %s=%s" % (func_name, pipe_name, pipe))

    def add_source_id(self, is_without_vf=False):
        """
        add debug source id for tik1.5 API

        Parameters
        ----------
        is_without_vf: for regbase, pass shouldn't mark vf for the instr if the instr is not vector instr

        Returns
        -------
        None
        """
        if not self.debug_disabled_:
            if not is_without_vf:
                attr = "stmt_source"
            else:
                attr = "stmt_source_without_vf"
            self.scope_attr(tvm.thread_axis("cce"), attr, self.context.debug_source_id)
            self.context.debug_source_id += 1

    def allocate(self, params_list, scope=None, init_value=None, buffer_storage_id=None):
        """
        Create a allocate statement.

        Parameters
        ----------
        params_list: dtype, shape, name
        -            dtype : str, The content data type.
        -            shape : tuple of Expr, The shape of array to be allocated.
        -            name : str, optional, The name of the buffer.
        scope : str, optional, The scope of the buffer.
        init_value: tuple pr list, optional, The init value for the buffer
        buffer_storage_id : tensor index for reuse/no_reuse

        Returns
        -------
        buffer: BufferVar, The buffer var representing the buffer.
        """
        # check dtype is str
        dtype, shape, name = params_list
        TikCheckUtil.check_type_match(dtype, str, "dtype(%s) should be str" % str(type(dtype)))
        buffer_var = tir.expr.Var(name, PointerType(PrimType(dtype), scope))

        if not isinstance(shape, (list, tuple, tvm.ir.container.Array)):
            shape = [shape]

        _allocate_func_loc = get_span()
        if init_value is None:

            def _allocate_func_init_none(pre_stmt):
                tmp_allocate = tvm.tir.Allocate(buffer_var, dtype, shape, tvm.const(1, dtype="bool"),
                                                pre_stmt, span=_allocate_func_loc)
                self.source_info.set_node_span(tmp_allocate, span=_allocate_func_loc)
                return tmp_allocate

            self.emit(_allocate_func_init_none)
        else:
            if not isinstance(init_value, (tuple, list)):
                init_value = [init_value]
            TikCheckUtil.check_var_in_list(
                scope, [scope_reg, scope_gm], "init_value only support for register and global")
            TikCheckUtil.check_equality(
                len(shape), LEN_SHAPE_ONE, "length of shape(%d) should be 1" % len(shape))
            TikCheckUtil.check_equality(
                len(init_value), shape[0],
                "length of init_value(%d) should be equal to size of shape(%d)" % (len(init_value), shape[0]))
            init_value = [tvm.const(i, dtype) for i in init_value]

            def _allocate_func_init_not_none(pre_stmt):
                tmp_const = tvm.const(1, dtype="bool")
                tmp_call = tvm.call_extern(dtype, "params", *convert(init_value))
                tmp_allocate = tvm.tir.Allocate(buffer_var, dtype, shape, tmp_const, pre_stmt, new_expr=tmp_call)
                self.source_info.set_node_span(tmp_allocate, span=_allocate_func_loc)
                return tmp_allocate

            self.emit(_allocate_func_init_not_none)
        if buffer_storage_id is not None:
            self.scope_attr(buffer_var, "pragma_buffer_index", call_extern("int64", "buffer_index", buffer_storage_id))
        return TikBufferVar(self, buffer_var, shape, dtype)

    def buffer_print(self):
        """
        print buffer information
        """
        self.code_buffer_manager.buffer_print()

    @source_info_decorator()
    def set_flag(self, pipe, trigger_pipe, event_id):
        """
        Check and creat a set_flag
        :param pipe: waiting pipe
        :param trigger_pipe: waited pipe
        :param event_id: event id
        """
        self._check_set_wait_flag_params("set_flag", pipe, trigger_pipe, event_id)
        instr = tir.Call("uint64", tvm.ir.Op.get("cce.coproc_dep_push"),
                         [self.pipe_line_dict.get(pipe), self.pipe_line_dict.get(trigger_pipe), event_id])
        self.emit(instr)

    @source_info_decorator()
    def wait_flag(self, pipe, trigger_pipe, event_id):
        """
        Check and creat a wait_flag
        :param pipe: waiting pipe
        :param trigger_pipe: waited pipe
        :param event_id: event id
        :return: None
        """
        self._check_set_wait_flag_params("set_flag", pipe, trigger_pipe, event_id)
        instr = tir.Call("uint64", tvm.ir.Op.get("cce.coproc_dep_pop"),
                         [self.pipe_line_dict.get(pipe), self.pipe_line_dict.get(trigger_pipe), event_id])
        self.emit(instr)

    @source_info_decorator()
    def pipe_barrier(self, pipe):
        """
        Creat a pipe_barrier
        """
        self._check_pipe_supported("pipe_barrier", "pipe", pipe)
        instr = tvm.tir.Call("uint64", tvm.ir.Op.get("cce.coproc_sync"), [self.pipe_line_dict[pipe]])
        self.emit(instr)

    def is_tensor_in_scope(self):
        """
        Check scope if has tensor

        Returns
        -------
        True or False
        """
        if ((self.if_scope_level > 0) or (self.for_scope_level > 0) or (self.elif_scope_level > 0) or
                (self.else_scope_level > 0) or (self.stmt_scope_level > 0)):
            return True
        return False

    def is_barrier_in_scope(self):
        """
        Check scope if has tensor

        Returns
        -------
        True or False
        """
        if self.for_scope_level > 0 and self.enable_multi_core is True:
            return True
        return False

    @source_info_decorator()
    def new_scope(self):
        """
        def new scope func
        """
        self._seq_stack.append([])
        _new_scope_source_info = self.source_info.get_source_info()

        # new_scope do not have debug decorator, so must handle source info
        def _exit_cb():
            if TIK_CONTROL.is_user_call:
                self.source_info.register_source_info(source_info=_new_scope_source_info)
                self.source_info.set_not_user_call()
                self.emit(self._pop_seq())
                self.source_info.set_is_user_call()
                self.source_info.clear_source_info()
            else:
                self.emit(self._pop_seq())
        return WithScope(None, _exit_cb)

    @source_info_decorator()
    def scope_attr(self, node, attr_key, value):
        """
        Create an AttrStmt at current scope.
        Parameters
        ----------
        node: Node, The attribute node to annottate on.
        attr_key: str, The key of the attribute type.
        value: Expr, Attribute value.

        Returns
        -------
        no return
        """

        if isinstance(node, tvm.string_types):
            node = tvm.tir.StringImm(node)
        if isinstance(value, tvm.string_types):
            value = tvm.tir.StringImm(value)

        _attr_stmt_loc = get_span()

        def _attr_stmt(pre_stmt):
            if attr_key in _SYNC_FLAG:
                dummy = tvm.call_extern("int32", "dummy_intrin",)
                dummy_intrin = tvm.tir.Evaluate(dummy)
                pre_stmt = tvm.tir.SeqStmt([dummy_intrin, pre_stmt])

            tmp_attr = tvm.tir.AttrStmt(node, attr_key, value, pre_stmt)
            self.source_info.set_node_span(tmp_attr, span=_attr_stmt_loc)
            return tmp_attr

        self.emit(_attr_stmt)

    @source_info_decorator()
    def mov_rpn_cor_ir_to_scalar(self, scalar, rpn_cor_ir):
        """
        Used to move rpn cor ir to scalar
        """
        TikCheckUtil.check_type_match(scalar, Scalar, "input scalar should be Scalar")
        TikCheckUtil.check_equality(scalar.dtype, "int64", "input scalar's dtype should be int64")
        TikCheckUtil.check_is(rpn_cor_ir, RPN_COR_IR, "rpn_cor_ir should be tvm varibale RPN_COR_IR")
        with self.new_scope():
            self.emit(tvm.call_extern(scalar.dtype, "reg_set", scalar.get(),
                                      tvm.call_extern(scalar.dtype, "get_rpn_cor_ir")))

    def curr_cond_is_false(self):
        """
        get the current condition value
        Returns
        -------
        bool
        True: current condition may be true
        False: current condition is False
        """
        cur_scope_level = self._get_cur_scope_level()
        if self.if_elif_cond_stack[cur_scope_level] in (_COND_FALSE, _COND_OUT_FALSE):
            return True
        return False

    def is_break_continue(self):
        """
        check current is_break and is_continue is true or false,
        if is_debug_break or is_debug_continue is True,
        the current code is after tik_break and in the scope, the code not executed.

        Returns
        -------
        bool
        True: current is_break or is_continue is true
        False: current is_break or is_continue is false
        """
        if self.is_break or self.is_continue:
            return True
        return False

    def emit(self, stmt):
        """
        Emit a statement to the end of current scope.
        Parameters
        ----------
        stmt: Stmt or callable. The statement to be emitted or callable that build stmt given body.

        Returns
        -------
        no return
        """
        # extend function of emit, keep consistency of interface, so disable it
        if isinstance(stmt, tvm.expr.Call):
            span_ = get_span()
            stmt = tvm.tir.Evaluate(stmt, span=span_)
            self.source_info.set_node_span(stmt, span=span_)
        if not isinstance(stmt, tvm.tir.stmt.Stmt) and not callable(stmt):
            TikCheckUtil.raise_error("stmt should be type of Stmt or callable")
        self._seq_stack[-1].append(stmt)

    @debug.if_scope_decorator
    def if_scope_(self, cond):
        """
        Create an if scope.
        note: use this function to call if_scope inside!!
        """
        self.if_scope_level += 1
        self._seq_stack.append([])
        self.code_buffer_manager.new_scope()
        self.code_scalar_manager.new_scope()
        cond = self._evaluate_with_const_scalar(cond)
        new_cond = self._merge_if_cond(cond)
        _if_then_else_source_info = self.source_info.get_source_info()

        def _exit_cb():
            self.if_scope_level -= 1
            self.code_buffer_manager.del_scope()
            self.code_scalar_manager.del_scope()
            # check else_scope_level whether or not less than 0
            TikCheckUtil.check_ge(
                self.if_scope_level, 0, "if_scope_level(%d) should be more than 0" % self.if_scope_level)
            if new_cond is _COND_FALSE or new_cond is _COND_OUT_FALSE:
                self._seq_stack.pop()  # here must delete the stack info
                seq = tvm.tir.Evaluate(0)  # create a null stmt
            else:
                seq = self._pop_seq()
            bool_value = Expr(cond, "bool")

            # if then include 2 ir
            tmp_if_then_else = tvm.tir.IfThenElse(bool_value.get(), seq, None)
            self.source_info.set_node_span(tmp_if_then_else)
            self.emit(tmp_if_then_else)

        return TikWithScope(None, _exit_cb, _if_then_else_source_info)

    @debug.elif_scope_decorator
    def elif_scope_(self, cond):
        """
        Create an else if scope.
        note: use this function to call elif_scope inside!!
        """
        self.elif_scope_level += 1
        self._check_else_follow("elif_scope")
        head = self._seq_stack[_LAST_ELEMENT][_LAST_ELEMENT]
        self._seq_stack[_LAST_ELEMENT].pop()
        self._seq_stack.append([])
        self.code_buffer_manager.new_scope()
        self.code_scalar_manager.new_scope()

        _if_then_else_source_info = self.source_info.get_source_info()

        cur_scope_level = self._get_cur_scope_level()
        cond = self._evaluate_with_const_scalar(cond)
        ret_last_cond, cur_cond = self._merge_elif_cond(cond, cur_scope_level)

        def _exit_cb():
            self.elif_scope_level -= 1
            self.code_buffer_manager.del_scope()
            self.code_scalar_manager.del_scope()

            # check elif_scope_level whether or not less than 0
            TikCheckUtil.check_ge(
                self.elif_scope_level, 0, "elif_scope_level(%d) should be more than 0" % self.elif_scope_level)
            if cur_cond is _COND_FALSE or cur_cond is _COND_OUT_FALSE:
                self._seq_stack.pop()  # here must delete the stack info
                seq = tvm.tir.Evaluate(0)  # create a null stmt
            else:
                seq = self._pop_seq()

            bool_value = Expr(cond, "bool")
            # else if include 2 ir
            tmp_if_then_else = tvm.tir.IfThenElse(bool_value.get(), seq, None)
            tmp_if_then_else = self._gen_if_then_else(head, tmp_if_then_else, _INIT_IFTHENELSE_DEEP)
            self.source_info.set_node_span(tmp_if_then_else)
            self.emit(tmp_if_then_else)
            self.if_elif_cond_stack[cur_scope_level] = ret_last_cond

        return TikWithScope(None, _exit_cb, _if_then_else_source_info)

    @debug.else_scope_decorator
    def else_scope_(self):
        """
        Create an else scope.
        note: use this function to call else_scope inside!!
        """
        self.else_scope_level += 1
        self._check_else_follow("else_scope")
        head = self._seq_stack[_LAST_ELEMENT][_LAST_ELEMENT]
        self._seq_stack[_LAST_ELEMENT].pop()
        self._seq_stack.append([])
        self.code_buffer_manager.new_scope()
        self.code_scalar_manager.new_scope()

        cur_scope_level = self._get_cur_scope_level()
        last_cond = self.if_elif_cond_stack[cur_scope_level]
        cur_cond = _COND_UNKNOW
        if last_cond is _COND_TRUE or last_cond is _COND_OUT_FALSE:
            self.if_elif_cond_stack[cur_scope_level] = _COND_FALSE
            cur_cond = _COND_FALSE
        elif last_cond is _COND_FALSE:
            self.if_elif_cond_stack[cur_scope_level] = _COND_TRUE
            cur_cond = _COND_TRUE

        def _exit_cb():
            self.else_scope_level -= 1
            self.code_buffer_manager.del_scope()
            self.code_scalar_manager.del_scope()
            # check else_scope_level whether or not less than 0
            TikCheckUtil.check_ge(
                self.else_scope_level, 0, "else_scope_level(%d) should be more than 0" % self.else_scope_level)
            # else include 1 ir
            if cur_cond is _COND_FALSE:
                self._seq_stack.pop()  # here must delete the stack info
                seq = tvm.tir.Evaluate(0)  # create a null stmt
            else:
                seq = self._pop_seq()
            tmp_if_then_else = self._gen_if_then_else(head, seq, _INIT_IFTHENELSE_DEEP)
            self.source_info.set_node_span(tmp_if_then_else)
            self.emit(tmp_if_then_else)
        return TikWithScope(None, _exit_cb, self.source_info.get_source_info())

    def _merge_if_cond(self, cur_cond):
        """

        Parameters
        ----------
        cur_cond

        Returns
        -------

        """
        ret_cond = _COND_UNKNOW
        cur_scope_level = self._get_cur_scope_level()
        last_cond = self.if_elif_cond_stack[cur_scope_level - 1]
        if last_cond in (_COND_TRUE, _COND_UNKNOW):
            # if outer condition may be true, current condition decide by cur_cond
            if self._check_cond_true(cur_cond):
                if len(self.if_elif_cond_stack) > cur_scope_level:
                    self.if_elif_cond_stack[cur_scope_level] = _COND_TRUE
                else:
                    self.if_elif_cond_stack.append(_COND_TRUE)
                ret_cond = _COND_TRUE
            elif self._check_cond_false(cur_cond):
                if len(self.if_elif_cond_stack) > cur_scope_level:
                    self.if_elif_cond_stack[cur_scope_level] = _COND_FALSE
                else:
                    self.if_elif_cond_stack.append(_COND_FALSE)
                ret_cond = _COND_FALSE
            else:
                if len(self.if_elif_cond_stack) > cur_scope_level:
                    self.if_elif_cond_stack[cur_scope_level] = _COND_UNKNOW
                else:
                    self.if_elif_cond_stack.append(_COND_UNKNOW)
        elif last_cond in (_COND_FALSE, _COND_OUT_FALSE):
            # if outer condition is False, current condition must be outer False
            if len(self.if_elif_cond_stack) > cur_scope_level:
                self.if_elif_cond_stack[cur_scope_level] = _COND_OUT_FALSE
            else:
                self.if_elif_cond_stack.append(_COND_OUT_FALSE)
            ret_cond = _COND_OUT_FALSE
        return ret_cond

    def _get_cur_scope_level(self):
        """
        get the if elif else scope nested depth
        """
        return self.if_scope_level + self.elif_scope_level + self.else_scope_level

    def _merge_elif_cond(self, cur_cond, cur_scope_level):
        """
        according current elif condition and last if or elif condition to create new elif condition
        Parameters
        ----------
        cur_cond: current elif condition
        cur_scope_level: nested depth

        Returns
        -------
        ret_cond: condition for reduction after run this elif
        ret_cur_cond: condition for current elif

        """
        ret_cond = _COND_UNKNOW  # for update current scope after exit elif
        ret_cur_cond = _COND_UNKNOW  # for current elif scope
        last_cond = self.if_elif_cond_stack[cur_scope_level]
        if last_cond is _COND_TRUE:
            # if last_cond is True, current condition must be False
            self.if_elif_cond_stack[cur_scope_level] = _COND_FALSE
            ret_cond = _COND_TRUE
            ret_cur_cond = _COND_FALSE
        elif last_cond is _COND_OUT_FALSE:
            # if outer condition is False, no matter cur_cond is True or False, current condition must be False
            self.if_elif_cond_stack[cur_scope_level] = _COND_OUT_FALSE
            ret_cond = last_cond
            ret_cur_cond = _COND_OUT_FALSE
        elif last_cond in (_COND_FALSE, _COND_UNKNOW):
            # if last_cond is False or unknown, current condition decide by cur_cond
            if self._check_cond_true(cur_cond):
                self.if_elif_cond_stack[cur_scope_level] = _COND_TRUE
                ret_cond = _COND_TRUE  # after exit this elif, last_cond update to True
                ret_cur_cond = _COND_TRUE
            elif self._check_cond_false(cur_cond):
                self.if_elif_cond_stack[cur_scope_level] = _COND_FALSE
                ret_cond = last_cond
                ret_cur_cond = _COND_FALSE
            else:
                self.if_elif_cond_stack[cur_scope_level] = _COND_UNKNOW  # unknown
        return ret_cond, ret_cur_cond

    def _check_set_wait_flag_params(self, func_name, pipe, trigger_pipe, event_id):
        """
        Check set_flag and wait_flag params
        :param func_name: function name
        :param pipe: waiting pipe
        :param trigger_pipe: waited pipe
        :param event_id: event id
        """
        if not self.stmt_scope_stack or not self.stmt_scope_stack[-1][0]:
            TikCheckUtil.raise_error("Only support call %s api in new_stmt_scope with disable the sync" % func_name)
        TikCheckUtil.check_type_match(event_id, int, "event_id should be int, input type is %s." % type(event_id))
        self._check_pipe_supported(func_name, "pipe", pipe)
        self._check_pipe_supported(func_name, "trigger_pipe", trigger_pipe)
        TikCheckUtil.check_not_equality(pipe, trigger_pipe, "pipe and trigger_pipe cannot be the same")

    def _get_tir_expr(self, expr):
        """
        tiling_scalar and offset is const var: return scalar debug_var
        other scalar: return None
        tik_expr: return tvm expr of tik_expr

        return:
        tvm expr
        """
        if is_scalar(expr):
            if self.tiling_scalar_map.get(expr.reg_buffer._buffer_var) is None:
                return None
            offset = safe_get_value(expr.offset, False)
            if isinstance(offset, int):
                new_expr = expr.debug_var[offset]
            else:
                return None
        elif isinstance(expr, Expr):
            new_expr = expr.get()
        else:
            new_expr = expr
        return new_expr

    def _evaluate_with_const_scalar(self, expr):
        """
        frontend expr with tiling_scalar simplify
        """
        if not self._has_tiling_ub or len(self.tiling_scalar_map) == 0:
            return expr

        new_expr = self._get_tir_expr(expr)
        if new_expr is None or not uses_vars(new_expr, list(self.tiling_scalar_map.keys())):
            return expr

        # tiling_scalar_map: [scalar var(dtype is "handle")] to [scalar debug_var]
        # tiling_value_map: [scalar debug_var] to [scalar const value
        var_for_let = []
        value_for_let = []
        for var, value in self.tiling_value_map.items():
            var_for_let.append(var)
            value_for_let.append(make_tvm_imm(var.dtype, value))

        # LetStmt var's dtype should be the same as value's dtype, but scalar var's dtype is handle.
        # replace scalar var by scalar debug_var
        fail_arr = substitute_scalar_check(new_expr, self.tiling_scalar_map, var_for_let, value_for_let)
        if len(fail_arr) > 0:
            return expr
        new_expr = substitute_scalar(new_expr, self.tiling_scalar_map, var_for_let, value_for_let)

        # make LetStmt, replace scalar debug_var by scalar const value
        prev_expr = tvm.tir.Evaluate(new_expr)
        let_ = prev_expr
        for i, var in enumerate(var_for_let):
            let_ = tvm.tir.LetStmt(var, value_for_let[i], prev_expr)
            prev_expr = let_
        result = tvm.tir.Simplify(let_)
        while 'value' in dir(result):
            result = safe_get_value(result)
        return result

    def _set_tiling_scalar_value(self, dst, src):
        """
        bind tiling_scalar with const value from tiling_nunpy
        :param dst: tiling_scalar
        :param src: tiling_ub
        """
        addr = src.old_data * DTYPE_SIZE[src.dtype]
        # ub addr, gm addr
        tiling_addr = self.tiling_addr_map.get(src._get_last_tensor().name)
        if tiling_addr is not None:
            offset = addr - tiling_addr[1] + tiling_addr[0]
            if addr >= tiling_addr[1] and offset < self.tiling_numpy.nbytes:
                buffer = self.tiling_numpy.view("uint8")[offset:]
                dst.const_value = buffer.view(dst.dtype)[0]
            else:
                dst.const_value = 0
                if not self.tiling_warning_print:
                    TikCheckUtil().raise_warning("tiling offset out of range, index: " + str(src.old_data))
                    self.tiling_warning_print = True
            self.tiling_scalar_map[dst.reg_buffer._buffer_var] = dst.debug_var
            self.tiling_value_map[dst.debug_var[dst.offset]] = dst.const_value
