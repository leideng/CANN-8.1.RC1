#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2021. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_dma_ops_api_.py
DESC:     single operations vector instructions for tik 1.5
CREATED:  2021-06-24 18:53:42
MODIFIED: 2021-06-24 19:17:00
"""

from collections import namedtuple
from tbe import tvm
from tbe.common.platform import scope_gm
from tbe.tik.api.tik_tensor import Tensor
from tbe.tik.api.tik_check_api import is_tik_var
from tbe.tik.common.expr_bound_analyzer import check_dst_gm_overflow
from tbe.tik.tik_lib.tik_h_vec_api.common_params_check_ import check_dma_ops_params
from tbe.tik.tik_lib.tik_h_vec_api.common_util_ import set_tik_version_1_5
from tbe.tik.tik_lib.tik_source_info import source_info_decorator
from tbe.tik.debug.decorators_high_vec import data_move_debug_for_high_api
from tbe.tik.tik_lib.tik_h_vec_api.tik_h_vec_api_base_ import TikHVecApiBase


class TikDMAOpsApi(TikHVecApiBase):
    """
    DMA Operation Api
    """

    dma_ops_api = namedtuple("DmaOps", "dst src api_name")
    h_data_move_params = namedtuple('DataMoveParams', ['tik_instance', 'for_var', 'dst', 'src'])

    def __init__(self):
        super(TikDMAOpsApi, self).__init__()
        self.core_arch = None
        self.core_version = None
        self.ir_generator = self
        self.for_var = set()
        self.h_data_move_mem_stamp = []

    @set_tik_version_1_5()
    @data_move_debug_for_high_api
    def dma_ops_code_make(self, code_make_params):
        """
        code maker for DMA ops instruction
        """
        with self.new_scope():
            # for vector instruction in regbase, vf_maker pass will add a "pragma_vf" attr after "stmt_source"
            if (code_make_params.dst.scope == scope_gm or code_make_params.src.scope == scope_gm):
                # for h_data_move(gm, ub) or h_data_move(ub, gm) in regbase,
                # the instruction is not vector instuction, and shouldn't add the "pragma_vf" attr
                self.add_source_id(is_without_vf=True)
            else:
                self.add_source_id(is_without_vf=False)
            self.ir_generator.emit(
                tvm.tir.Evaluate(tvm.call_cce_intrin("int32", code_make_params.api_name,
                                                     code_make_params.dst.info_node, code_make_params.src.info_node)))

    @source_info_decorator()
    def h_data_move(self, dst, src):
        """
        data_move for tik 1.5
        Parameters
        ----------
        dst: Tensor or Tensor slice
        src: Tensor or Tensor slice

        Returns
        -------
        None
        """
        api_name = "h_data_move"
        dma_ops_ins = TikDMAOpsApi.dma_ops_api(dst, src, api_name)
        check_dma_ops_params(dma_ops_ins)
        self.analysis_h_data_move_overflow(dst, src)
        self.dma_ops_code_make(dma_ops_ins)

    def analysis_h_data_move_overflow(self, dst, src):
        """
        analysis h_data_move dst gm overflow and save info to MEM_STAMP
        Parameters
        ----------
        dst: dst tensor
        src: src tensor

        Returns None
        -------

        """
        if dst.scope == scope_gm and isinstance(dst, Tensor):
            dst_original_size = 1
            for dim_val in dst.original_shape:
                if is_tik_var(dim_val):
                    dim_val = dim_val.get()
                dst_original_size *= dim_val
            src_shape = 1
            for dim_val in src.shape:
                if is_tik_var(dim_val):
                    dim_val = dim_val.get()
                src_shape *= dim_val
            dst_offset = dst.offset
            offset_extent_diff_shape = dst_offset + src_shape - dst_original_size
            offset_diff_shape = dst_offset - dst_original_size
            h_data_move_api_ins = self.h_data_move_params(self, self.for_var, dst, src)
            check_dst_gm_overflow(h_data_move_api_ins, offset_extent_diff_shape, offset_diff_shape)
