#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_api_util.py
DESC:     debug context
CREATED:  2019-7-04 20:12:13
MODIFIED: 2019-7-24 10:54:23
"""
from collections import namedtuple
import numpy as np

from tbe import tvm
from tbe.common.platform import intrinsic_check_support
from tbe.common.platform import scope_ubuf
from tbe.common.platform import scope_smask
from tbe.common.platform import scope_vreg
from tbe.tik.api.tik_vector import Vector
from tbe.tik.api.tik_tensor import Tensor
from tbe.tik.tik_lib.tik_expr import Expr
from tbe.tik.api.tik_scalar import Scalar
from tbe.tik.common.util import check_scalar_dtype
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.util import reduce_mul
from tbe.tik.common.tik_get_soc_name import get_soc_name
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.common.common_util import check_vector_stride
from tbe.tik.common.common_util import check_address_align
from tbe.tik.tik_lib.tik_params import MIN_REPEAT_TIMES
from tbe.tik.tik_lib.tik_params import MAX_REPEAT_TIMES
from tbe.tik.tik_lib.tik_params import MASK_COUNTER_MODE_ENABLE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import PIPE_S
from tbe.tik.tik_lib.tik_params import PIPE_MTE1
from tbe.tik.tik_lib.tik_params import MIN_FLOAT16_VALUE
from tbe.tik.tik_lib.tik_params import MAX_FLOAT16_VALUE
from tbe.tik.tik_lib.tik_params import INT8_MIN
from tbe.tik.tik_lib.tik_params import INT8_MAX
from tbe.tik.tik_lib.tik_params import UINT_MIN
from tbe.tik.tik_lib.tik_params import UINT8_MAX
from tbe.tik.tik_lib.tik_params import PAD_MASK
from tbe.tik.tik_lib.tik_params import PADDING_SHIFT_POS
from tbe.tik.tik_lib.tik_params import VSEL_MODE_TENSOR_SCALAR
from tbe.tik.tik_lib.tik_params import VSEL_MODE_DOUBLE_TENSOR_MANY_IT
from tbe.tik.tik_lib.tik_params import MAX_STRIDE_UNIT
from tbe.tik.tik_lib.tik_params import MIN_STRIDE_UNIT
from tbe.tik.tik_lib.tik_params import gen_api_check_statement
from tbe.tik.tik_lib.tik_params import MAX_REP_STRIDE_SINGLE_BYTE
from tbe.tik.tik_lib.tik_params import INT16_MAX
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_source_info import source_info_decorator
from tbe.tik.tik_lib.tik_vector_api.tik_params_check_vdp import check_vdp_overlap
from tbe.tik.tik_lib.tik_vector_api.tik_params_check_vdp import check_vdp_tensor_overflow


def check_tensor_list(tensor, name_list, align=32):
    """
    check tensor_list type(Tensor), scope(ub), dtype(should be same)

    Parameters
    ----------
    tensor: list of tensor_list
    name_list: list of tensor_list name
    align: tensor address align

    Returns
    -------
    None
    """
    TikCheckUtil.check_equality(
        len(tensor), len(name_list),
        "for fuction check_tensor_list, input list length should be same, input"
        " length of tensor.{}, input length of name_list:{}".format(len(tensor), len(name_list)))
    for tensor_list, name in zip(tensor, name_list):
        for index, tensor_member in enumerate(tensor_list):
            TikCheckUtil.check_type_match(
                tensor_member, Tensor,
                "{}[{}] should be tensor, input type: {}".format(name, index, type(tensor_member)))
            TikCheckUtil.check_equality(
                tensor_member.scope, scope_ubuf,
                "{}[{}] scope should be ub, input scope: {}".format(name, index, tensor_member.scope))
            # check UB address align
            msg_name = "src_list[{}]".format(str(index))
            check_address_align((tensor_member,), (msg_name,), align)
            # dtype should be the same as tensor_list[0]
            TikCheckUtil.check_equality(
                tensor_member.dtype, tensor_list[0].dtype,
                "input tensor_list dtype should be the same, input %s[0] dtype: %s, input %s[%d] dtype: %s" %
                (name, tensor_list[0].dtype, name, index, tensor_member.dtype))


def check_repeat_times(repeat_times, max_repeat_times=MAX_REPEAT_TIMES, isdebug=False, mask_mode="normal"):
    """
    check repeat_times dtype, range

    Parameters
    ----------
    repeat_times: numbers of iterations of this instruction
    max_repeat_times: max repeat times, some times set to MAX_REPEAT_TIME_DOUBLE_BYTE
    isdebug: if is debug mode

    Returns
    -------
    None
    """
    if not isdebug:
        TikCheckUtil.check_type_match(
            repeat_times, (int, Scalar, Expr),
            "repeat_times should be int, Scalar or Expr, input type of repeat_times: {}".format(type(repeat_times)))
        check_scalar_dtype(repeat_times, "scalar_repeat_time should be a Scalar or Expr of int/uint")
    if mask_mode == "normal":
        TikCheckUtil.check_in_range_by_dtype(
            repeat_times, msg="repeat_times should be in the range of [%d, %d], input repeat_times: %s"
            % (MIN_REPEAT_TIMES, max_repeat_times, repeat_times), var_range=[MIN_REPEAT_TIMES, max_repeat_times])


def set_ctrl_value(tik_instance, label):
    """
    set CTRL[X] as 1

    Parameters
    ----------
    tik_instance: tik object

    Returns
    -------
    orig_ctrl: original value of CTRL
    """
    # save orig_ctrl
    orig_ctrl = tik_instance.scalar_(dtype="uint64", name="orig_ctrl")
    with tik_instance.new_scope():
        tik_instance.emit(
            tvm.call_extern(orig_ctrl.dtype, "reg_set", orig_ctrl.get(),
                            tvm.call_extern(orig_ctrl.dtype, "get_ctrl")))
    # set CTRL[X] as 1
    with tik_instance.context.freeze():
        ctrl = tik_instance.scalar_(dtype="uint64", name="ctrl")
        ctrl.set_as(orig_ctrl | (1 << label))
    with tik_instance.new_scope():
        tik_instance.emit(tvm.call_extern("uint64", "set_ctrl", ctrl.get()))
    return orig_ctrl


def set_ctrl_counter_mask(tik_instance):
    """
    set CTRL[56] as 1,for counter mask
    """
    return set_ctrl_value(tik_instance, MASK_COUNTER_MODE_ENABLE_SHIFT_POS)


@source_info_decorator(depth=2)
def set_ctrl_vcbd_warp(tik_instance):
    """
    set CTRL[59] as 1,for vcbd warp policy
    """
    return set_ctrl_value(tik_instance, 59)


@source_info_decorator(depth=2)
def reset_ctrl_value(tik_instance, orig_ctrl):
    """
    check repeat_times dtype, range

    Parameters
    ----------
    tik_instance: tik object

    Returns
    -------
    orig_ctrl: original value of CTRL
    """
    with tik_instance.new_scope():
        tik_instance.scope_attr(tvm.thread_axis("cce"), "coproc_scope", PIPE_S)
        tik_instance.emit(
            tvm.call_extern("uint64", "set_ctrl", orig_ctrl.get()))


def set_vsel_cmpmask_for_nano(tik_instance, mode, src0, src1, sel):
    """
    set_cmpmask of vsel for nano soc
    """
    if mode == VSEL_MODE_TENSOR_SCALAR:
        if not isinstance(src1, Scalar):
            src1 = tik_instance.scalar_(src0.dtype, init_value=src1)
        temp_scalar = tik_instance.scalar_("uint64")
        temp_scalar.set_as(src1.reinterpret_cast_to("uint16"))

        tik_instance.set_scalar_to_cmpmask(temp_scalar)
    elif mode == VSEL_MODE_DOUBLE_TENSOR_MANY_IT:
        tik_instance.mov_tensor_to_cmpmask(sel)


def set_vsel_cmpmask(tik_instance, mode, src0, src1, sel):
    """
    set the mask of vsel compare
    """
    with tik_instance.context.freeze():
        if TikSocManager.is_nano_soc():
            set_vsel_cmpmask_for_nano(tik_instance, mode, src0, src1, sel)
            return
        if TikSocManager.is_v300_610l_soc() and mode != 0:
            tik_instance.mov_tensor_to_cmpmask(sel)
            return

        if mode == VSEL_MODE_TENSOR_SCALAR:
            temp_tensor_shape = [8]
            temp_buf = tik_instance.Tensor(src0.dtype, temp_tensor_shape,
                                           name="temp_buf",
                                           scope=scope_ubuf,
                                           enable_buffer_reuse=True,
                                           no_reuse_list=[None])
            if not isinstance(src1, Scalar):
                temp_scalar = tik_instance.scalar_(src0.dtype)
                temp_scalar.set_as(src1)
                temp_buf.set_as(temp_scalar)
            else:
                temp_buf.set_as(src1)
            tik_instance.mov_tensor_to_cmpmask(temp_buf)
        elif mode == VSEL_MODE_DOUBLE_TENSOR_MANY_IT:
            temp_tensor_shape = [2]
            temp_buf = tik_instance.Tensor("int64", temp_tensor_shape, name="temp_buf", scope=scope_ubuf)
            sel_addr = tik_instance.scalar_("int64")
            # fix a bug, must split the operators to two scopes
            # first scope get the tensor address and then set address to scalar
            # second scope copy address value from scalar to tensor
            with tik_instance.new_scope():
                tik_instance.scope_attr(tvm.thread_axis("cce"), "coproc_scope", PIPE_S)
                # get the address of sel
                sel_addr.set_as(tvm.tir.Cast("int64", tvm.call_extern("handle", "", sel.access_ptr("r"))))

            with tik_instance.new_scope():
                # must add the pipe_s
                tik_instance.scope_attr(tvm.thread_axis("cce"), "coproc_scope", PIPE_S)
                # add append_mem for temp_buf cannot same addr with sel
                tik_instance.scope_attr(tvm.thread_axis("cce"), "append_mem",
                                        tvm.call_extern("handle", "mem_vector", sel.access_ptr("r")))
                # set the address value to ub tensor
                temp_buf.set_as(sel_addr)
            tik_instance.mov_tensor_to_cmpmask(temp_buf)


def do_load3d_padding(tik_instance, src, pad_value):
    """
    do padding for load3dv1, load3dv2, depthwise_conv

    Parameters
    ----------
    tik_instance: tik object
    src: src tensor for load3dv1, load3dv2, depthwise_conv
    pad_value:

    Returns
    -------
    None
    """
    if "padding" in tik_instance.global_dict:
        padding = tik_instance.global_dict["padding"]
    else:
        padding = tik_instance.global_scalar(dtype="uint16")
        tik_instance.global_dict["padding"] = padding
    with tik_instance.context.freeze():
        with tik_instance.new_scope():
            if src.dtype == "float16":
                pad_value = np.float16(pad_value)
                pad_value = pad_value.view(np.uint16)
                t_padding = tik_instance.scalar_(dtype="uint16")
                t_padding.set_as(int(pad_value))
            elif src.dtype == "float32":
                padding = tik_instance.global_scalar(dtype="uint32")
                tik_instance.global_dict["padding"] = padding
                pad_value = np.float32(pad_value)
                pad_value = pad_value.view(np.uint32)
                t_padding = tik_instance.scalar_(dtype="uint32")
                t_padding.set_as(int(pad_value))
            else:
                pad_value = np.int8(pad_value) if src.dtype == "int8" else np.uint8(pad_value)
                t_padding = tik_instance.scalar_(dtype="uint16")
                t_padding.set_as(int(pad_value) & PAD_MASK)
                t_padding.set_as(t_padding << PADDING_SHIFT_POS | t_padding)
            tik_instance.scope_attr(tvm.thread_axis("cce"), "if_protect", PIPE_MTE1)
            with tik_instance.if_scope_(padding != t_padding):
                padding.set_as(t_padding)
                # one ir is call_extern
                tik_instance.emit(tvm.call_extern("int64", "set_padding", padding.get()))


def check_stride_unit(stride_unit):
    """
    check param stride_unit

    Parameters
    ----------
    stride_unit : address and offset unit both affect it. default = 0
    core_arch : ai_core architecture

    Returns
    -------
    None
    """
    TikCheckUtil.check_type_match(
        stride_unit, int, "stride_unit should be int, input stride_unit: {}".format(type(stride_unit)))
    if TikSocManager.is_v200_soc() or (TikSocManager.is_v210_soc() and TikSocManager.is_aicore_core()):
        TikCheckUtil.check_in_range_by_dtype(
            stride_unit, msg="stride_unit should be in the range of [%d, %d], "
            "input stride_unit: %s" % (MIN_STRIDE_UNIT, MAX_STRIDE_UNIT, stride_unit),
            var_range=[MIN_STRIDE_UNIT, MAX_STRIDE_UNIT])
    else:
        TikCheckUtil.check_equality(
            stride_unit, MIN_STRIDE_UNIT,
            "{} only support stride_unit=0, input value is {}".format(get_soc_name(), stride_unit))


def check_pad_value(src, pad_value):
    """
    check_pad_value for load3dv1, load3dv2, depthwise_conv

    Parameters
    ----------
    src: src tensor for load3dv1, load3dv2, depthwise_conv
    pad_value:

    Returns
    -------
    None
    """
    if src.dtype == "float16":
        if pad_value < MIN_FLOAT16_VALUE or pad_value > MAX_FLOAT16_VALUE:
            TikCheckUtil.raise_error(
                "when src_fm dtype is f16, pad_value should be in the range"
                " of [-65504, 65504], input value: {}".format(pad_value))
    else:
        TikCheckUtil.check_type_match(
            pad_value, int,
            "when src_fm dtype is {}, pad_value should be int, input type: {}".format(src.dtype, type(pad_value)))
        if src.dtype == "int8":
            TikCheckUtil.check_in_range_by_dtype(
                pad_value, "int8",
                "when src_fm dtype is s8, pad_value should be in the range of "
                "[%d, %d], input value: %s" % (INT8_MIN, INT8_MAX, pad_value))
        else:
            TikCheckUtil.check_in_range_by_dtype(
                pad_value, "uint8",
                "when src_fm dtype is u8, pad_value should be in the range of "
                "[%d, %d], input value: %s" % (UINT_MIN, UINT8_MAX, pad_value))


def check_weight_offset(smask, instr_name, tensor_name):
    """
    if enable weight offset, check smask tensor

    Parameters
    ----------
    smask: smask tensor
    instr_name: name of instrunction
    tensor_name: name of tensor

    Returns
    -------
    None
    """
    TikCheckUtil.raise_error(
        "%s doesn't support enabling weight_offset yet." % instr_name)
    TikCheckUtil.check_type_match(
        smask, Tensor,
        "When weight_offset if enabled, %s should be Tensor, input "
        "type of smask: %s" % (tensor_name, str(type(smask))))
    TikCheckUtil.check_equality(
        smask.scope, scope_smask,
        "%s scope should be SMASK, input scope: %s" % (tensor_name, smask.scope))
    TikCheckUtil.check_equality(
        smask.dtype, "uint16",
        "%s should be uint16, input type: %s" % (tensor_name, smask.dtype))


def check_high_preci_param(high_preci_params):
    """
    check input params of the high precision version

    Parameters
    ----------

    high_preci_params: namedtuple of high_preci_params, dst, src, work_tensor, repeat_times, dst_rep_stride,
    -                  src_rep_stride
    -                  dst : destination operator
    -                  src : source operation
    -                  work_tensor : temporary operation
    -                  repeat_times : Repeated iterations times
    -                  dst_blk_stride : offset of dst operator between different block in one repeat
    -                  src_blk_stride : offset of src operator between different block in one repeat
    -                  dst_rep_stride : offset of dst operator in the same block between two repeats
    -                  src_rep_stride : offset of src operator in the same block between two repeats

    Returns
    -------
    None
    """
    # check repeat
    check_repeat_times(high_preci_params.repeat_times)
    # check strides
    check_vector_stride(None, [high_preci_params.dst_rep_stride, high_preci_params.src_rep_stride],
                        None, MAX_REP_STRIDE_SINGLE_BYTE, ["dst", "src"])
    # check tensor
    TikCheckUtil.check_type_match(high_preci_params.src, Tensor, "src should be tensor")
    TikCheckUtil.check_type_match(high_preci_params.dst, Tensor, "dst should be tensor")
    TikCheckUtil.check_type_match(high_preci_params.work_tensor, Tensor,
                                  "work_tensor should be tensor")
    TikCheckUtil.check_equality(high_preci_params.src.dtype, high_preci_params.dst.dtype,
                                "src's dtype must be same with dst's dtype")
    # check scope
    TikCheckUtil.check_equality(high_preci_params.src.scope, scope_ubuf,
                                "src's scope must be UB")
    TikCheckUtil.check_equality(high_preci_params.dst.scope, scope_ubuf,
                                "dst's scope must be UB")
    TikCheckUtil.check_equality(high_preci_params.work_tensor.scope, scope_ubuf,
                                "work_tensor's scope must be UB")
    check_address_align((high_preci_params.work_tensor, high_preci_params.dst, high_preci_params.src),
                        ("work_tensor", "dst", "src"))


def calculate_vdp_extent(vdp_api):
    """
    calculate vdp's extent
    """
    num_pixel = Expr(vdp_api.num_pixel).eval_value()
    num_max_disparity = Expr(vdp_api.num_max_disparity).eval_value()
    path_mode = Expr(vdp_api.path_mode).eval_value()

    dst_extent = (reduce_mul(vdp_api.dst.original_shape) - vdp_api.dst.offset) * DTYPE_SIZE.get(vdp_api.dst.dtype)
    dst_extent = Expr(dst_extent).get()
    src0_extent = (reduce_mul(vdp_api.src0.original_shape) - vdp_api.src0.offset) * DTYPE_SIZE.get(vdp_api.src0.dtype)
    src0_extent = Expr(src0_extent).get()
    src1_extent = (reduce_mul(vdp_api.src1.original_shape) - vdp_api.src1.offset) * DTYPE_SIZE.get(vdp_api.src1.dtype)

    if any(value is None for value in (num_pixel, num_max_disparity, path_mode)):
        return dst_extent, src0_extent, src1_extent

    if num_max_disparity == 0:
        num_disparity = 128
    else:
        num_disparity = 64

    if num_disparity == 64 and path_mode == 1:
        dst_extent = 2 * num_disparity * num_pixel * DTYPE_SIZE.get(vdp_api.dst.dtype)
        src0_extent = 2 * num_disparity * num_pixel * DTYPE_SIZE.get(vdp_api.src0.dtype)
    else:
        dst_extent = num_disparity * num_pixel * DTYPE_SIZE.get(vdp_api.dst.dtype)
        src0_extent = num_disparity * num_pixel * DTYPE_SIZE.get(vdp_api.src0.dtype)

    if path_mode == 0:
        src1_extent = num_disparity * num_pixel * DTYPE_SIZE.get(vdp_api.src1.dtype)
    else:
        if num_disparity == 128:
            src1_extent = num_disparity * DTYPE_SIZE.get(vdp_api.src1.dtype)
        else:
            src1_extent = 2 * num_disparity * num_pixel * DTYPE_SIZE.get(vdp_api.src1.dtype)
    return dst_extent, src0_extent, src1_extent


def _check_vdp_num_max_disparity_param(num_max_disparity):
    """
    check num_max_disparity param
    """
    TikCheckUtil.check_type_match(
        num_max_disparity, (int, Scalar, Expr),
        "num_max_disparity should be int, Expr or Scalar, input type is"
        " %s" % type(num_max_disparity))
    check_scalar_dtype(num_max_disparity, "scalar_num_max_disparity should be a scalar of int/uint")
    if isinstance(num_max_disparity, int):
        TikCheckUtil.check_var_in_list(
            num_max_disparity, [0, 1], "num_max_disparity should be 0 or 1, input value is %s" % num_max_disparity)


def _check_vdp_num_pixel_param(num_pixel, num_max_disparity):
    """
    check num_pixel param
    """
    # check num_pixel
    min_num_pixel = 1
    TikCheckUtil.check_type_match(
        num_pixel, (int, Scalar, Expr), "num_pixel should be int, Expr or Scalar, input type is %s" % type(num_pixel))
    check_scalar_dtype(num_pixel, "scalar_num_pixel should be a scalar of int/uint")
    TikCheckUtil.check_in_range_by_dtype(
        num_pixel,
        msg="num_pixel should be in the range of [%d, %d], input value is %s" % (min_num_pixel, INT16_MAX, num_pixel),
        var_range=[min_num_pixel, INT16_MAX])

    num_max_disparity = Expr(num_max_disparity).eval_value()
    if num_max_disparity == 1:
        num_pixel = Expr(num_pixel).eval_value()
        if num_pixel is not None:
            TikCheckUtil.check_even(num_pixel, "num_pixel should be even, input value is %s" % num_pixel)


def _check_vdp_p1_p2_param(p1, p2):
    """
    check p1,p2 param
    """
    # check p1
    TikCheckUtil.check_type_match(
        p1, (int, Scalar, Expr), "p1 should be int, Expr or Scalar, input type is %s" % type(p1))
    check_scalar_dtype(p1, "scalar_p1 should be a scalar of int/uint")
    TikCheckUtil.check_in_range_by_dtype(
        p1, msg="p1 should be in the range of [%d, %d], input value is %s"
                % (0, INT16_MAX, p1), var_range=[0, INT16_MAX])

    # check p2
    TikCheckUtil.check_type_match(
        p2, (int, Scalar, Expr),
        "p2 should be int, Expr or Scalar, input type is %s" % type(p2))
    check_scalar_dtype(p2, "scalar_p2 should be a scalar of int/uint")
    TikCheckUtil.check_in_range_by_dtype(
        p2, msg="p2 should be in the range of [%d, %d], input value"
        " is %s" % (0, INT16_MAX, p2), var_range=[0, INT16_MAX])

    p1 = Expr(p1).eval_value()
    p2 = Expr(p2).eval_value()
    if p1 is None or p2 is None:
        return

    TikCheckUtil.check_le(
        p1, p2, "p1 should be less than p2, but p1 is more than p2")
    TikCheckUtil.check_not_equality(
        p1, p2, "p1 should be less than p2, but p1 is equal to p2")


def _check_vdp_offset_pixel_param(num_pixel, num_max_disparity, offset_pixel, path_mode):
    """
    check offset_pixel param
    """
    TikCheckUtil.check_type_match(
        offset_pixel, (int, Scalar, Expr),
        "offset_pixel should be int, Expr or Scalar, input type is %s" % type(offset_pixel))
    check_scalar_dtype(offset_pixel, "scalar_offset_pixel should be a scalar of int/uint")
    num_pixel = Expr(num_pixel).eval_value()
    num_max_disparity = Expr(num_max_disparity).eval_value()
    offset_pixel = Expr(offset_pixel).eval_value()
    path_mode = Expr(path_mode).eval_value()
    if any(value is None for value in (num_pixel, num_max_disparity, offset_pixel, path_mode)):
        return

    if num_max_disparity == 1 and path_mode == 1:
        num_disparity = 64
        offset_value = 2 * num_disparity * num_pixel // 32
        offset_value = Expr(offset_value).eval_value()
        if offset_value is None:
            pass
        TikCheckUtil.check_equality(
            offset_pixel, offset_value,
            "offset_pixel should be %s, input value is %s" % (offset_value, offset_pixel))
    else:
        TikCheckUtil.check_in_range_by_dtype(
            offset_pixel, msg="offset_pixel should be in the range of [%d, %d], input value is %s"
                              % (0, INT16_MAX, offset_pixel), var_range=[0, INT16_MAX])


def _check_vdp_dynamic_addr_range_param(dynamic_addr_range):
    """
    check dynamic_addr_range param
    """
    TikCheckUtil.check_type_match(
        dynamic_addr_range, (int, Scalar, Expr),
        "dynamic_addr_range should be int, Expr or Scalar, input type is %s" % type(dynamic_addr_range))
    check_scalar_dtype(dynamic_addr_range,
                       "scalar_dynamic_addr_range should be a scalar of int/uint")
    # max value is 0b111111111111
    max_value = 4095
    TikCheckUtil.check_in_range_by_dtype(
        dynamic_addr_range, msg="dynamic_addr_range should be in the range of [%d, %d], input value"
        " is %s" % (0, max_value, dynamic_addr_range), var_range=[0, max_value])


def _check_vdp_is_begin_pixel_param(is_begin_pixel):
    """
    check is_begin_pixel param
    """
    TikCheckUtil.check_type_match(
        is_begin_pixel, (int, Scalar, Expr),
        "is_begin_pixel should be int, Expr, Scalar, input type is %s" % type(is_begin_pixel))
    if isinstance(is_begin_pixel, int):
        TikCheckUtil.check_var_in_list(
            is_begin_pixel, [0, 1], "is_begin_pixel only support 0 and 1, input value is %s" % is_begin_pixel)


def _check_vdp_is_path_reverse_param(is_path_reverse):
    """
    check is_path_reverse param
    """
    TikCheckUtil.check_type_match(
        is_path_reverse, (int, Scalar, Expr),
        "is_path_reverse should be int, Expr, Scalar, input type "
        "is %s" % type(is_path_reverse))
    if isinstance(is_path_reverse, int):
        TikCheckUtil.check_var_in_list(
            is_path_reverse, [0, 1], "is_path_reverse only support 0 and 1, input value is %s" % is_path_reverse)


def _check_vdp_path_mode_param(path_mode):
    """
    check path_mode param
    """
    TikCheckUtil.check_type_match(
        path_mode, (int, Scalar, Expr),
        "path_mode should be int, Expr, Scalar, input type "
        "is %s" % type(path_mode))
    if isinstance(path_mode, int):
        TikCheckUtil.check_var_in_list(
            path_mode, [0, 1], "path_mode only support 0 and 1, input value is %s" % path_mode)


def check_vdp_param(vdp_api):
    """
    check params of vdp instr
    """
    # check operator
    TikCheckUtil.check_type_match(vdp_api.dst, Tensor, "dst should be tensor but get %s" % type(vdp_api.dst))
    TikCheckUtil.check_type_match(vdp_api.src0, Tensor, "src0 should be tensor but get %s" % type(vdp_api.src0))
    TikCheckUtil.check_type_match(vdp_api.src1, Tensor, "src1 should be tensor but get %s" % type(vdp_api.src1))

    # check core_arch
    TikCheckUtil.check_equality(
        intrinsic_check_support("Intrinsic_" + "vdp", vdp_api.dst.dtype), True,
        gen_api_check_statement(vdp_api.dst.dtype, "vdp"))

    # check scope
    TikCheckUtil.check_equality(vdp_api.dst.scope, scope_ubuf, "dst's scope must be UB")
    TikCheckUtil.check_equality(vdp_api.src0.scope, scope_ubuf, "src0's scope must be UB")
    TikCheckUtil.check_equality(vdp_api.src1.scope, scope_ubuf, "src1's scope must be UB")
    check_address_align((vdp_api.dst, vdp_api.src0, vdp_api.src1), ("dst", "src0", "src1"))

    # check operator dtype
    TikCheckUtil.check_equality(vdp_api.dst.dtype, vdp_api.src0.dtype,
                                "Intrinsic {}'s src0's dtype should be equal to dst's dtype".format("vdp"))
    TikCheckUtil.check_equality(vdp_api.dst.dtype, vdp_api.src1.dtype,
                                "Intrinsic {}'s src1's dtype should be equal to dst's dtype".format("vdp"))

    # check num_max_disparity
    _check_vdp_num_max_disparity_param(vdp_api.num_max_disparity)

    # check num_pixel
    _check_vdp_num_pixel_param(vdp_api.num_pixel, vdp_api.num_max_disparity)

    # check penalty coefficient
    _check_vdp_p1_p2_param(vdp_api.p1, vdp_api.p2)

    # check offset_pixel
    _check_vdp_offset_pixel_param(vdp_api.num_pixel, vdp_api.num_max_disparity, vdp_api.offset_pixel,
                                  vdp_api.path_mode)

    # check dynamic_addr_range
    _check_vdp_dynamic_addr_range_param(vdp_api.dynamic_addr_range)

    # check is_begin_pixel
    _check_vdp_is_begin_pixel_param(vdp_api.is_begin_pixel)

    # check is_path_reverse
    _check_vdp_is_path_reverse_param(vdp_api.is_path_reverse)

    # check path_mode
    _check_vdp_path_mode_param(vdp_api.path_mode)

    num_pixel = Expr(vdp_api.num_pixel).eval_value()
    num_max_disparity = Expr(vdp_api.num_max_disparity).eval_value()
    path_mode = Expr(vdp_api.path_mode).eval_value()
    dst_offset = Expr(vdp_api.dst.offset).eval_value()
    src0_offset = Expr(vdp_api.src0.offset).eval_value()
    src1_offset = Expr(vdp_api.src1.offset).eval_value()
    # check overflow
    vdp_params_api = namedtuple('VdpOverflowApi', ["dst", "src0", "src1", "num_pixel", "num_max_disparity",
                                                   "path_mode", "dst_offset", "src0_offset", "src1_offset"])

    vdp_overflow_api = vdp_params_api(vdp_api.dst, vdp_api.src0, vdp_api.src1, num_pixel, num_max_disparity,
                                      path_mode, vdp_api.dst.offset, vdp_api.src0.offset, vdp_api.src1.offset)

    check_vdp_tensor_overflow(vdp_overflow_api)

    vdp_overlap_api = vdp_params_api(vdp_api.dst, vdp_api.src0, vdp_api.src1, num_pixel, num_max_disparity,
                                     path_mode, dst_offset, src0_offset, src1_offset)

    # check overlap
    check_vdp_overlap(vdp_overlap_api)


def check_mask_mode(mask_mode):
    """
    check mask_mode

    Parameters
    ---------
    mask_mode: instr param mask_mode

    Returns
    -----
    None
    """
    TikCheckUtil.check_type_match(mask_mode, str, "mask_mode should be str, input type: %s" % type(mask_mode))
    # v100 not support counter_mode
    if TikSocManager.is_v100_soc():
        TikCheckUtil.check_var_in_list(
            mask_mode, ["normal", ], "mask_mode should be 'normal', input mask_mode: %s" % mask_mode)
    else:
        TikCheckUtil.check_var_in_list(
            mask_mode, ["normal", "counter"],
            "mask_mode should be 'normal' or 'counter', input mask_mode: %s" % mask_mode)


def check_vector_list(vector_list, name_list, target_dtype):
    """
    check tensor_list type(Vector),  dtype(should be same)

    Parameters
    ----------
    vector_list: list of vector
    name_list: list of vector_list name
    target_dtype: vector scope

    Returns
    -------
    None
    """
    TikCheckUtil.check_equality(
        len(vector_list), len(name_list),
        "for fuction check_vector_list, input list length should be same, "
        "input length of vector.{}, input length of name_list:{}".format(len(vector_list), len(name_list)))
    for vector, name in zip(vector_list, name_list):
        TikCheckUtil.check_type_match(
            vector, Vector, "{} should be Vector, input type: {}".format(name, type(vector)))
        # dtype should be the same as tensor_list[0]
        if vector.scope == scope_vreg:
            TikCheckUtil.check_equality(
                vector.dtype, target_dtype,
                "input Vector dtype should be the same as ub tensor dtype, input "
                "%s dtype: %s, input ub tensor dtype: %s" % (name, vector.dtype, target_dtype))
