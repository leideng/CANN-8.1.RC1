#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2021. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_reduce_ops_api_.py
DESC:     single operations vector instructions for tik 1.5
CREATED:  2021-06-24 18:53:42
MODIFIED: 2021-06-24 19:17:00
"""

from collections import namedtuple
from tbe import tvm
from tbe.common.platform import intrinsic_check_support
from tbe.common.utils.log import info
from tbe.tik.tik_lib.tik_h_vec_api.common_params_check_ import check_reduce_value_ops_params
from tbe.tik.tik_lib.tik_h_vec_api.common_params_check_ import check_reduce_arg_ops_params
from tbe.tik.tik_lib.tik_h_vec_api.common_util_ import set_tik_version_1_5
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_source_info import source_info_decorator
from tbe.tik.tik_lib.tik_params import gen_api_check_statement
from tbe.tik.tik_lib.tik_h_vec_api.tik_h_vec_api_base_ import TikHVecApiBase
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.api.tik_scalar import Scalar
from tbe.tik.debug.decorators_high_vec import reduce_debug_for_high_api


class TikReduceOpsApi(TikHVecApiBase):
    """
    Reduce Operation Api
    """

    reduce_ops_api = namedtuple("ReduceOps", "dst src axis api_name")

    def __init__(self):
        super(TikReduceOpsApi, self).__init__()
        self.core_arch = None
        self.core_version = None
        self.ir_generator = self

    @source_info_decorator()
    def h_reduce_sum(self, dst, src, axis=None):
        """
        reduce_sum for tik 1.5
        Parameters
        ----------
        dst: Tensor or Tensor slice
        src: Tensor or Tensor slice
        axis: None or int or tuple of ints

        Returns
        -------
        None
        """
        api_name = "h_reduce_sum"
        reduce_ops_api_ins = TikReduceOpsApi.reduce_ops_api(dst, src, axis, api_name)
        check_reduce_value_ops_params(dst, reduce_ops_api_ins)
        TikCheckUtil.check_equality(intrinsic_check_support("Intrinsic_vcadd", src.dtype), True,
                                    gen_api_check_statement(src.dtype, api_name))
        if not (TikSocManager.is_v100_soc() or TikSocManager.is_310b_soc()):
            info(gen_api_check_statement(src.dtype, api_name))
        self._make_code(reduce_ops_api_ins)

    @source_info_decorator()
    def h_reduce_max(self, dst, src, axis=None):
        """
        reduce_max for tik 1.5
        Parameters
        ----------
        dst: Tensor or Tensor slice
        src: Tensor or Tensor slice
        axis: None or int or tuple of ints

        Returns
        -------
        None
        """
        api_name = "h_reduce_max"
        reduce_ops_api_ins = TikReduceOpsApi.reduce_ops_api(dst, src, axis, api_name)
        check_reduce_value_ops_params(dst, reduce_ops_api_ins)
        TikCheckUtil.check_equality(intrinsic_check_support("Intrinsic_vcmax", src.dtype), True,
                                    gen_api_check_statement(src.dtype, api_name))
        if not (TikSocManager.is_v100_soc() or TikSocManager.is_310b_soc()):
            info(gen_api_check_statement(src.dtype, api_name))
        self._make_code(reduce_ops_api_ins)

    @source_info_decorator()
    def h_reduce_min(self, dst, src, axis=None):
        """
        reduce_min for tik 1.5
        Parameters
        ----------
        dst: Tensor or Tensor slice
        src: Tensor or Tensor slice
        axis: None or int or tuple of ints

        Returns
        -------
        None
        """
        api_name = "h_reduce_min"
        reduce_ops_api_ins = TikReduceOpsApi.reduce_ops_api(dst, src, axis, api_name)
        check_reduce_value_ops_params(dst, reduce_ops_api_ins)
        TikCheckUtil.check_equality(intrinsic_check_support("Intrinsic_vcmin", src.dtype), True,
                                    gen_api_check_statement(src.dtype, api_name))
        if not (TikSocManager.is_v100_soc() or TikSocManager.is_310b_soc()):
            info(gen_api_check_statement(src.dtype, api_name))
        self._make_code(reduce_ops_api_ins)

    @source_info_decorator()
    def h_reduce_argmax(self, dst, src, axis=None):
        """
        reduce_argmax for tik 1.5
        Parameters
        ----------
        dst: Tensor or Tensor slice
        src: Tensor or Tensor slice
        axis: None or int

        Returns
        -------
        None
        """
        api_name = "h_reduce_argmax"
        reduce_ops_api_ins = TikReduceOpsApi.reduce_ops_api(dst, src, axis, api_name)
        check_reduce_arg_ops_params(dst, reduce_ops_api_ins)
        TikCheckUtil.check_equality(intrinsic_check_support("Intrinsic_vcmax", src.dtype), True,
                                    gen_api_check_statement(src.dtype, api_name))
        if not TikSocManager.is_v100_soc():
            info(gen_api_check_statement(src.dtype, api_name))
        self._make_code(reduce_ops_api_ins)

    @source_info_decorator()
    def h_reduce_argmin(self, dst, src, axis=None):
        """
        reduce_argmin for tik 1.5
        Parameters
        ----------
        dst: Tensor or Tensor slice
        src: Tensor or Tensor slice
        axis: None or int

        Returns
        -------
        None
        """
        api_name = "h_reduce_argmin"
        reduce_ops_api_ins = TikReduceOpsApi.reduce_ops_api(dst, src, axis, api_name)
        check_reduce_arg_ops_params(dst, reduce_ops_api_ins)
        TikCheckUtil.check_equality(intrinsic_check_support("Intrinsic_vcmin", src.dtype), True,
                                    gen_api_check_statement(src.dtype, api_name))
        if not TikSocManager.is_v100_soc():
            info(gen_api_check_statement(src.dtype, api_name))
        self._make_code(reduce_ops_api_ins)

    @set_tik_version_1_5()
    @reduce_debug_for_high_api
    def _reduce_ops_code_make(self, dst, reduce_ops_params):
        """
        code maker for double ops instruction
        """
        axis = reduce_ops_params.axis
        if axis is None:
            axis = -1
        if isinstance(axis, int):
            axis = [axis]
        axis = tvm.call_cce_intrin("int32", "axis", *axis)
        with self.new_scope():
            self.add_source_id()
            if isinstance(dst, Scalar):
                self.ir_generator.emit(
                    tvm.tir.Evaluate(tvm.call_cce_intrin("int32", reduce_ops_params.api_name,
                                                  dst.get(), reduce_ops_params.src.info_node, axis)))

            else:
                self.ir_generator.emit(
                    tvm.tir.Evaluate(tvm.call_cce_intrin(
                        "int32", reduce_ops_params.api_name,
                        reduce_ops_params.dst.info_node, reduce_ops_params.src.info_node, axis)))

    def _make_code(self, make_code_params):
        """
        code maker, handling the dst is Scalar case
        """
        if isinstance(make_code_params.dst, Scalar):
            tmp_dst = self.Scalar(dtype=make_code_params.dst.dtype)
            self._reduce_ops_code_make(tmp_dst, make_code_params)
            make_code_params.dst.set_as(tmp_dst)
        else:
            self._reduce_ops_code_make(make_code_params.dst, make_code_params)
