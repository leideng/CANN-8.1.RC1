#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     check_over_high_preci_common.py
DESC:     common check file for tik high preci api
CREATED:  2021-12-18 14:02:50
MODIFIED: 2020-12-18 14:22:50
"""
from collections import namedtuple

from tbe.common.platform import scope_ubuf
from tbe.tik.tik_lib.tik_mask_concat_ import mask_concat
from tbe.tik.tik_lib.tik_params import MASK_LOW_IDX
from tbe.tik.tik_lib.tik_params import MASK_HIGH_IDX
from tbe.tik.common.util import is_immediate_number
from tbe.tik.common.util import ceil_div
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.common_util import vector_max_offset_cal
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_expr import BasicExpr


class HighPreciCommonUtil:
    """
    High Preci Common Util
    """

    high_prec_api = namedtuple('HighPreciApi', ["func", "name", "mask", "dst", "src", "work_tensor",
                                                "repeat_times", "dst_rep_stride", "src_rep_stride", "size_factor"])

    vec_high_prec_api = namedtuple('VecHighPreciApi', ['name', 'mask', 'dst', 'src', 'work_tensor', 'repeat_times',
                                                       'dst_rep_stride', 'src_rep_stride', 'tensor_split_size',
                                                       'mask_o'])

    compute_api = namedtuple('ComputeApi', ["func", "name", "mask", "dst", "src", "work_tensor", "repeat_times",
                                            "dst_rep_stride", "src_rep_stride", "fp32_rep_stride", "tmp_tensor_size"])

    @staticmethod
    def _get_wk_tensor_stride_imm(src_rep_stride):
        if src_rep_stride <= 4:
            fp32_rep_stride_1 = src_rep_stride * 2
        else:
            fp32_rep_stride_1 = 8
        return fp32_rep_stride_1

    def fp162fp32_func_compute(self, compute_api):
        """
        fp162fp32 func compute
        """
        src_blk_stride = 1
        tmp_tensor_size = compute_api.tmp_tensor_size
        if compute_api.work_tensor.dtype == "float16":
            tmp_src_tensor = \
                compute_api.work_tensor[0:tmp_tensor_size].reinterpret_cast_to("float32")
            tmp_dst_tensor = \
                compute_api.work_tensor[tmp_tensor_size:tmp_tensor_size * 2].reinterpret_cast_to("float32")
            tmp_work_tensor = \
                compute_api.work_tensor[tmp_tensor_size * 2:].reinterpret_cast_to("float32")
            tmp_tensor_size = tmp_tensor_size * DTYPE_SIZE[compute_api.work_tensor.dtype] // DTYPE_SIZE.get("float32")
        else:
            tmp_src_tensor = compute_api.work_tensor[0:tmp_tensor_size]
            tmp_dst_tensor = compute_api.work_tensor[tmp_tensor_size:tmp_tensor_size * 2]
            tmp_work_tensor = compute_api.work_tensor[tmp_tensor_size * 2:]
        mask_o = mask_concat(self, compute_api.mask, tensor_bit_len=32)
        self.vconv(compute_api.mask, "none", tmp_src_tensor,
                   compute_api.src, compute_api.repeat_times, src_blk_stride, src_blk_stride,
                   compute_api.fp32_rep_stride, compute_api.src_rep_stride,
                   name=compute_api.name, mask_o=mask_o)

        vrec_obj = HighPreciCommonUtil.vec_high_prec_api(
            compute_api.name, compute_api.mask, tmp_dst_tensor, tmp_src_tensor, tmp_work_tensor,
            compute_api.repeat_times, compute_api.fp32_rep_stride, compute_api.fp32_rep_stride, tmp_tensor_size, mask_o)
        compute_api.func(vrec_obj)

        self.vconv(compute_api.mask, "none", compute_api.dst, tmp_dst_tensor,
                   compute_api.repeat_times, src_blk_stride, src_blk_stride,
                   compute_api.dst_rep_stride, compute_api.fp32_rep_stride,
                   name=compute_api.name, mask_o=mask_o)

    def fp162fp32_func_mask_list(self, high_prec_api, fp32_rep_stride):
        """
        fp162fp32 func mask_list
        """
        default_start_offset = 64
        if isinstance(high_prec_api.mask[MASK_LOW_IDX], BasicExpr):
            low_mask = self.scalar_(
                init_value=0, dtype="uint64", name="low_mask")
            high_mask = self.scalar_(
                init_value=0, dtype="uint64", name="high_mask")
            low_mask.set_as(high_prec_api.mask[MASK_HIGH_IDX])
            with self.if_scope(low_mask != 0):
                tmp_tensor_size = self._get_src_extend(
                    [high_mask, high_prec_api.mask[MASK_HIGH_IDX]], (high_prec_api.repeat_times,
                                                                     high_prec_api.src_rep_stride),
                    high_prec_api.work_tensor, high_prec_api.size_factor)

                compute_obj = HighPreciCommonUtil.compute_api(
                    high_prec_api.func, high_prec_api.name, [high_mask, low_mask],
                    high_prec_api.dst[default_start_offset:], high_prec_api.src[default_start_offset:],
                    high_prec_api.work_tensor, high_prec_api.repeat_times, high_prec_api.dst_rep_stride,
                    high_prec_api.src_rep_stride, fp32_rep_stride, tmp_tensor_size)

                self.fp162fp32_func_compute(compute_obj)

            low_mask.set_as(high_prec_api.mask[MASK_LOW_IDX])
            tmp_tensor_size = self._get_src_extend(
                [high_mask, high_prec_api.mask[MASK_LOW_IDX]], (high_prec_api.repeat_times,
                                                                high_prec_api.src_rep_stride),
                high_prec_api.work_tensor, high_prec_api.size_factor)

            compute_obj = HighPreciCommonUtil.compute_api(
                high_prec_api.func, high_prec_api.name, [high_mask, low_mask],
                high_prec_api.dst, high_prec_api.src,
                high_prec_api.work_tensor, high_prec_api.repeat_times, high_prec_api.dst_rep_stride,
                high_prec_api.src_rep_stride, fp32_rep_stride, tmp_tensor_size)

            self.fp162fp32_func_compute(compute_obj)

        else:
            low_mask = high_prec_api.mask[MASK_LOW_IDX]
            high_mask = high_prec_api.mask[MASK_HIGH_IDX]

            if high_mask > 0:
                tmp_tensor_size = self._get_src_extend(
                    [0, high_mask], (high_prec_api.repeat_times, high_prec_api.src_rep_stride),
                    high_prec_api.work_tensor, high_prec_api.size_factor)

                compute_obj = HighPreciCommonUtil.compute_api(
                    high_prec_api.func, high_prec_api.name, [0, high_mask],
                    high_prec_api.dst[default_start_offset:], high_prec_api.src[default_start_offset:],
                    high_prec_api.work_tensor, high_prec_api.repeat_times, high_prec_api.dst_rep_stride,
                    high_prec_api.src_rep_stride, fp32_rep_stride, tmp_tensor_size)

                self.fp162fp32_func_compute(compute_obj)

            tmp_tensor_size = self._get_src_extend(
                [0, low_mask], (high_prec_api.repeat_times, high_prec_api.src_rep_stride),
                high_prec_api.work_tensor, high_prec_api.size_factor)

            compute_obj = HighPreciCommonUtil.compute_api(
                high_prec_api.func, high_prec_api.name, [0, low_mask], high_prec_api.dst, high_prec_api.src,
                high_prec_api.work_tensor, high_prec_api.repeat_times, high_prec_api.dst_rep_stride,
                high_prec_api.src_rep_stride, fp32_rep_stride, tmp_tensor_size)

            self.fp162fp32_func_compute(compute_obj)

    def fp162fp32_func_mask_scalar(self, high_prec_api, fp32_rep_stride):
        """
        fp162fp32 func mask_scalar
        """
        default_start_offset = 64
        with self.if_scope(high_prec_api.mask <= 64):
            tmp_tensor_size = self._get_src_extend(
                high_prec_api.mask, (high_prec_api.repeat_times, high_prec_api.src_rep_stride),
                high_prec_api.work_tensor, high_prec_api.size_factor)

            compute_obj = HighPreciCommonUtil.compute_api(
                high_prec_api.func, high_prec_api.name, high_prec_api.mask,
                high_prec_api.dst, high_prec_api.src,
                high_prec_api.work_tensor, high_prec_api.repeat_times, high_prec_api.dst_rep_stride,
                high_prec_api.src_rep_stride, fp32_rep_stride, tmp_tensor_size)

            self.fp162fp32_func_compute(compute_obj)

        with self.else_scope():
            low_mask = self.scalar_(
                init_value=64, dtype="uint64", name="low_mask")
            high_mask = self.scalar_(
                init_value=0, dtype="uint64", name="high_mask")
            high_mask.set_as(high_prec_api.mask - 64)

            tmp_tensor_size = self._get_src_extend(
                high_mask, (high_prec_api.repeat_times, high_prec_api.src_rep_stride),
                high_prec_api.work_tensor, high_prec_api.size_factor)

            compute_obj = HighPreciCommonUtil.compute_api(
                high_prec_api.func, high_prec_api.name, high_mask,
                high_prec_api.dst[default_start_offset:], high_prec_api.src[default_start_offset:],
                high_prec_api.work_tensor, high_prec_api.repeat_times, high_prec_api.dst_rep_stride,
                high_prec_api.src_rep_stride, fp32_rep_stride, tmp_tensor_size)

            self.fp162fp32_func_compute(compute_obj)

            tmp_tensor_size = self._get_src_extend(
                low_mask, (high_prec_api.repeat_times, high_prec_api.src_rep_stride),
                high_prec_api.work_tensor, high_prec_api.size_factor)

            compute_obj = HighPreciCommonUtil.compute_api(
                high_prec_api.func, high_prec_api.name, low_mask,
                high_prec_api.dst, high_prec_api.src,
                high_prec_api.work_tensor, high_prec_api.repeat_times, high_prec_api.dst_rep_stride,
                high_prec_api.src_rep_stride, fp32_rep_stride, tmp_tensor_size)

            self.fp162fp32_func_compute(compute_obj)

    def fp162fp32_func_mask_imm_entry(self, high_prec_api, fp32_rep_stride):
        """
        fp162fp32 func mask_imm_entry
        Parameters
        ----------
        fp162fp32_param

        Returns
        -------
        None
        """
        self._fp162fp32_func_mask_imm(high_prec_api, fp32_rep_stride, high_prec_api.work_tensor)

    def fp162fp32_high_preci_func(self, high_prec_api):
        """
        fp162fp32 high preci func
        Parameters
        ----------
        high_prec_api

        Returns
        -------
        None
        """
        if is_immediate_number(high_prec_api.src_rep_stride):
            fp32_rep_stride = self._get_wk_tensor_stride_imm(high_prec_api.src_rep_stride)
        else:
            fp32_rep_stride = self._get_wk_tensor_stride_scalar(high_prec_api.src_rep_stride)

        if isinstance(high_prec_api.mask, (list, tuple)):
            self.fp162fp32_func_mask_list(high_prec_api, fp32_rep_stride)
        elif is_immediate_number(high_prec_api.mask):
            self.fp162fp32_func_mask_imm_entry(high_prec_api, fp32_rep_stride)
        elif isinstance(high_prec_api.mask, BasicExpr):
            self.fp162fp32_func_mask_scalar(high_prec_api, fp32_rep_stride)

    def get_wk_tensor_extend(self, mask, dtype, repeat_times, src_rep_stride):
        """
        get work tensor size single
        """
        block_len = 32 // DTYPE_SIZE[dtype]
        if isinstance(mask, (tuple, list)):
            if not isinstance(
                    mask[MASK_LOW_IDX], BasicExpr):
                wk_tensor_extend = vector_max_offset_cal(
                    (mask, dtype, block_len, repeat_times, 1, src_rep_stride))
                wk_tensor_extend = ceil_div(wk_tensor_extend,
                                            block_len) * block_len
            else:
                # mask_list_scalar
                wk_tensor_extend = self.scalar_(
                    init_value=0, dtype="uint64", name="wk_tensor_extend")
                mask_len = self.scalar_(init_value=0,
                                        dtype="uint64", name="mask_len")
                self._get_mask_len(mask, mask_len)
                # get extend
                with self.if_scope(mask_len % block_len == 0):
                    max_extend = (repeat_times - 1) * src_rep_stride * block_len + \
                                 (mask_len // block_len - 1) * block_len + \
                                 block_len
                    wk_tensor_extend.set_as(max_extend)
                with self.else_scope():
                    max_extend = (repeat_times - 1) * src_rep_stride * block_len + \
                                 (mask_len // block_len) * block_len + \
                                 mask_len % block_len
                    max_extend = ceil_div(max_extend, block_len) * block_len
                    wk_tensor_extend.set_as(max_extend)

        else:
            wk_tensor_extend = self._get_extend_not_list(mask, repeat_times,
                                                         src_rep_stride, dtype)
        return wk_tensor_extend

    def _fp162fp32_func_mask_imm(self, high_prec_api, fp32_rep_stride, work_tensor):
        default_start_offset = 64
        if high_prec_api.mask < 64:
            tmp_tensor_size = self._get_src_extend(
                high_prec_api.mask, (high_prec_api.repeat_times, high_prec_api.src_rep_stride),
                work_tensor, high_prec_api.size_factor)

            compute_obj = HighPreciCommonUtil.compute_api(
                high_prec_api.func, high_prec_api.name, high_prec_api.mask,
                high_prec_api.dst, high_prec_api.src, work_tensor, high_prec_api.repeat_times,
                high_prec_api.dst_rep_stride, high_prec_api.src_rep_stride, fp32_rep_stride, tmp_tensor_size)

            self.fp162fp32_func_compute(compute_obj)
        else:
            low_mask = 64
            high_mask = high_prec_api.mask - 64
            if high_mask > 0:
                tmp_tensor_size = self._get_src_extend(
                    high_mask, (high_prec_api.repeat_times, high_prec_api.src_rep_stride),
                    work_tensor, high_prec_api.size_factor)

                compute_obj = HighPreciCommonUtil.compute_api(
                    high_prec_api.func, high_prec_api.name, high_mask, high_prec_api.dst[default_start_offset:],
                    high_prec_api.src[default_start_offset:], work_tensor,
                    high_prec_api.repeat_times, high_prec_api.dst_rep_stride,
                    high_prec_api.src_rep_stride, fp32_rep_stride, tmp_tensor_size)

                self.fp162fp32_func_compute(compute_obj)

            tmp_tensor_size = self._get_src_extend(
                low_mask, (high_prec_api.repeat_times, high_prec_api.src_rep_stride),
                work_tensor, high_prec_api.size_factor)

            compute_obj = HighPreciCommonUtil.compute_api(
                high_prec_api.func, high_prec_api.name, low_mask, high_prec_api.dst, high_prec_api.src,
                work_tensor, high_prec_api.repeat_times, high_prec_api.dst_rep_stride,
                high_prec_api.src_rep_stride, fp32_rep_stride, tmp_tensor_size)

            self.fp162fp32_func_compute(compute_obj)

    def _get_wk_tensor_stride_scalar(self, src_rep_stride):
        fp32_rep_stride = self.scalar_(
            init_value=0, dtype="int32")
        with self.if_scope(src_rep_stride < 4):
            fp32_rep_stride.set_as(src_rep_stride * 2)
        with self.else_scope():
            fp32_rep_stride.set_as(8)
        return fp32_rep_stride

    def _get_src_extend(self, mask, repeat_list, work_tensor, size_factor):
        defualt_src_dtype = "float16"
        repeat_times, src_rep_stride = repeat_list
        src_data_size = self.get_wk_tensor_extend(mask, defualt_src_dtype,
                                                  repeat_times, src_rep_stride)
        if work_tensor.dtype == "float16":
            tmp_tensor_size = src_data_size * 2
        else:
            tmp_tensor_size = src_data_size
        needed_tensor_size = tmp_tensor_size * size_factor
        work_tensor_size = work_tensor.size
        if is_immediate_number((needed_tensor_size, work_tensor_size)):
            TikCheckUtil.check_ge(work_tensor_size, needed_tensor_size,
                                  "Input work tensor size(%d) must be more "
                                  "than needed size(%d)" %
                                  (work_tensor_size, needed_tensor_size))
        return tmp_tensor_size

    def _get_mask_len(self, mask, mask_len):
        # get mask_len
        with self.if_scope(mask[MASK_HIGH_IDX] == 0):
            with self.for_range(0, 64) as index:
                with self.if_scope(
                        (mask[MASK_LOW_IDX] >> index) & 1 == 1):
                    mask_len.set_as(index + 1)
        with self.else_scope():
            with self.for_range(0, 64) as index:
                with self.if_scope(
                        (mask[MASK_HIGH_IDX] >> index) & 1 == 1):
                    mask_len.set_as(64 + index + 1)

    def _get_extend_not_list(self, mask, repeat_times, src_rep_stride, dtype):
        """get work tensor extend when mask not list"""
        block_len = 32 // DTYPE_SIZE[dtype]
        if isinstance(mask, BasicExpr):
            wk_tensor_extend = self.scalar_(
                init_value=0, dtype="uint64", name="wk_tensor_extend0")
            with self.if_scope(mask % block_len == 0):
                max_extend = (repeat_times - 1) * src_rep_stride * block_len + \
                             (mask // block_len - 1) * block_len + block_len
                wk_tensor_extend.set_as(max_extend)
            with self.else_scope():
                max_extend = (repeat_times - 1) * src_rep_stride * block_len + \
                             (mask // block_len) * block_len + mask % block_len
                max_extend = ceil_div(max_extend, block_len) * block_len
                wk_tensor_extend.set_as(max_extend)
        else:
            wk_tensor_extend = vector_max_offset_cal(
                (mask, dtype, block_len, repeat_times, 1, src_rep_stride))
            wk_tensor_extend = ceil_div(wk_tensor_extend, block_len) * block_len
        return wk_tensor_extend
