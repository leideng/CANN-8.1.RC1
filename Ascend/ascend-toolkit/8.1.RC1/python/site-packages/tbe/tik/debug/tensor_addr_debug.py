#!/usr/bin/env python
# -*- coding:utf-8 -*-

"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_build.py
DESC:     tik build
CREATED:  2021-7-20 20:12:13
MODIFIED: 2021-7-29 15:04:45
"""
from __future__ import print_function

from functools import reduce
import numpy as np

from tbe.common.platform.platform_info import get_soc_spec
from tbe.tik.common.util import SCOPE_SIZE_MAP
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_api_constants import SCOPE_MAP
from tbe.tik.debug.statement import STMT
from tbe.tik.debug.intrinsic_tensor import static_shape_dims
from tbe.tik.debug.intrinsic_tensor import check_tensor_buffer_shape
from tbe.tik.common.util import DTYPE_SIZE


def cal_addr_static_parameters(tensor, context):
    """
    set tensotaddrlist context static parameters
    """
    static_size, static_dims = static_shape_dims(tensor.dimensions, context)
    static_strides = [context.evaluate_expr(i) for i in tensor.strides]
    static_data = context.evaluate_expr(tensor.data)

    static_addr_offset = context.evaluate_expr(tensor.addr_offset)

    # update tensoraddrlist offset according debug result, for tensor API offset()
    tensor.static_data = static_data

    context.buffer2static_parameters[id(tensor)] = \
        {"static_dims": static_dims,
         "static_size": static_size,
         "static_strides": static_strides,
         "static_data": static_data,
         "static_addr_offset": static_addr_offset}

    for i in static_size:
        if i <= 0:
            TikCheckUtil.raise_error("invalid size input, size: %s" % i)
    if tensor.scope in SCOPE_SIZE_MAP:
        get_size = get_soc_spec(SCOPE_SIZE_MAP[tensor.scope])
        if context.evaluate_expr(tensor.size) > get_size:
            TikCheckUtil.raise_error("Tensor is too large for %s" % SCOPE_MAP[tensor.scope])


class TensorAddrDef(STMT):
    """
    def tensoraddrlist
    """
    def __init__(self, source_info, tensor, tik_debugger):
        """
        Initialize class TensorAddrDef

        Parameters
        ----------
        source_info:source code information, It represents the relationship of current node with source code

        tensor:source tensoraddrlist

        Returns
        ----------
        No returns
        """
        super(TensorAddrDef, self).__init__(source_info, tik_debugger)
        self.tensor = tensor

    def eval_(self, context):
        """
        Eval function: evaluate all of self.function

        Parameters
        ----------
        context:information of debugger, store all of debugger's information

        Returns
        ----------
        No returns
        """
        cal_addr_static_parameters(self.tensor, context)
        static_size = context.buffer2static_parameters[id(self.tensor)]['static_size']
        self.check_tensor_max_men_size(static_size)
        np_array = None
        # for input tensoraddrlist, the tensoraddrlist buffer data from input feed_dict
        for key, value in context.placeholders.items():
            if self.tensor.buffer == value:
                input_value = context.feed_dict_tensor[key]
                np_array = np.ascontiguousarray(input_value)
                context.add_tensor(self.tensor, np_array)  # set the buffer array with input_value

                tensor_buffer_shape = tuple(static_size)
                tensor_buffer = context.tensor_buffer.get_npbuffer_by_tvmbuffer(self.tensor.buffer)

                check_tensor_buffer_shape(tensor_buffer_shape, tensor_buffer, self.tensor)

                return
        context.add_tensor(self.tensor, np_array)

    def check_tensor_max_men_size(self, static_size):
        """
        check tensor max memory size
        Parameters
        ----------
        static_size: static size

        Returns
        -------

        """
        if not self.tensor.is_static_shape and \
                self.tensor.max_mem_size is not None:
            total_num = reduce(lambda i, j: i * j, static_size)
            if self.tensor.max_mem_size < total_num * DTYPE_SIZE[self.tensor.dtype]:
                TikCheckUtil.raise_error("max_mem_size is too small.")


class TensorAddrProxyDef(STMT):
    """
    def tensoraddrlist proxy
    """
    def __init__(self, source_info, tensor, tik_debugger):
        """
        Initialize class TensorAddrProxyDef

        Parameters
        ----------
        source_info:source code information, It represents the relationship of current node with source code

        tensor:tensoraddrlist proxy

        Returns
        ----------
        No returns
        """
        super(TensorAddrProxyDef, self).__init__(source_info, tik_debugger)
        self.tensor = tensor
        self.last_tensor = tensor.last_tensor

    def eval_(self, context):
        """
        Eval function: evaluate all of self.function

        Parameters
        ----------
        context:information of debugger, store all of debugger's information

        Returns
        ----------
        No returns
        """
        cal_addr_static_parameters(self.tensor, context)

        # check parameter for getitem tik 1.0 case
        if self.tensor.is_reshape and self.tensor.is_getitem:
            self._check_parameter_for_getitem(context)
        # check parameter for reshape case
        elif self.tensor.is_reshape:
            self.check_params(context)
        # check parameter for reinterpret_cast_to case
        if self.tensor.dtype != self.last_tensor.dtype:
            self._check_parameter_for_reinterpret_cast_to(context)

    def _check_parameter_for_getitem(self, context):
        """
        check parameter for getitem tik 1.0 case
        """
        last_static_strides = context.buffer2static_parameters[id(self.last_tensor)]["static_strides"]
        last_static_size = context.buffer2static_parameters[id(self.last_tensor)]["static_size"]
        for i in range(1, len(last_static_strides)):
            if last_static_strides[i] * last_static_size[i] != last_static_strides[i - 1]:
                TikCheckUtil.raise_error(
                    "Getitem need flatten, but the tensor is not "
                    "continuous after slicing.")

    def _check_parameter_for_reinterpret_cast_to(self, context):
        """
        check parameter for reinterpret_cast_to case
        """
        last_static_strides = context.buffer2static_parameters[id(self.last_tensor)]["static_strides"]
        last_static_dims = context.buffer2static_parameters[id(self.last_tensor)]["static_dims"]
        if last_static_strides[-1] != 1:
            TikCheckUtil.raise_error("Last stride should be equal to 1 when do reinterpret_cast_to")

        if DTYPE_SIZE[self.tensor.dtype] > \
                DTYPE_SIZE[self.last_tensor.dtype]:
            dtype_factor = DTYPE_SIZE[self.tensor.dtype] // \
                           DTYPE_SIZE[self.last_tensor.dtype]
            last_dim_offset = last_static_dims[-1].stop - last_static_dims[-1].start
            if last_dim_offset % dtype_factor != 0:
                TikCheckUtil.raise_error("Last dimension can't be divided")
