#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_vector_debug_.py
DESC:     provide params
CREATED:  2019-04-18 18:53:42
MODIFIED: 2020-12-7 19:17:00
"""

from tbe.tik.common.common_util import vec_template_align
from tbe.tik.debug.statement import STMT
from tbe.tik.debug.sim import Encoder
from tbe.tik.debug.util import copy_tensor_to_model
from tbe.tik.debug.util import set_vector_mask
from tbe.tik.debug.util import cvt_float_to_uint
from tbe.tik.debug.sim.util import TempEnv
from tbe.tik.tik_lib.tik_params import ONE_REP_BYTE_SIZE
from tbe.tik.tik_lib.tik_params import REPEAT_SHIFT_POS
from tbe.tik.tik_lib.tik_params import MAX_REPEAT_TIMES
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.debug.debug_encoder import VEC_CMP_OP_ENCODER
from tbe.tik.debug.debug_encoder import VCMPV_TYPE_ENCODER
from tbe.tik.debug.debug_encoder import VCMPVS_TYPE_ENCODER
from tbe.tik.debug.debug_encoder import VCMPVS_CMP_OP_ENCODER
from tbe.tik.debug.debug_encoder import VEC_DATA_TYPE_ENCODING_V200
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.util import get_bit_len
from tbe.tik.debug.util import VEC_DATA_TYPE_ENCODING
from tbe.tik.common.common_check_func import check_sel_overflow
from tbe.tik.debug.simd import MODE_SHIFT_POS
from tbe.tik.debug.simd import VCONV_TYPE_ENCODING
from tbe.tik.debug.simd import VCONV_RND_SRC_DST_ENCODING
from tbe.tik.debug.simd import VCONV_DST_ENCODING
from tbe.tik.debug.simd import VCONV_SRC_ENCODING
from tbe.tik.debug.simd import VCONV_RND_ENCODING
from tbe.tik.common.common_util import is_tensor
from tbe.tik.common.common_check_func import concate_deqscale_vconv
from tbe.tik.debug.simd import set_mask_counter_mode
from tbe.tik.debug.util import get_dtype_bit_width
from tbe.tik.tik_lib.tik_params import STRIDE_UNIT_SHIFT_POS
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.debug.util import copy_tensor_to_model_get_addr
from tbe.tik.tik_lib.tik_params import ALIGNED_ADDR
from tbe.tik.tik_lib.tik_params import DEQSCALE_46BIT_MASK
from tbe.tik.tik_lib.tik_params import DEQSCALE_46BIT_SHIFT_POS
from tbe.tik.tik_lib.tik_params import SRC_BLOCK_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import DST_REPEAT_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import SRC_REPEAT_STRIDE_SHIFT_POS

_SRC_BLK_STRIDE_SHIFT_POS = 8
_SRC1_BLK_STRIDE_SHIFT_POS = 16
_DST_REPEAT_STRIDE_SHIFT_POS = 24
_SRC_REPEAT_STRIDE_SHIFT_POS = 32
_SRC1_REPEAT_STRIDE_SHIFT_POS = 40
_MIN_REPEAT_TIMES = 0
_ENCODER = Encoder()

_VMULCONV_DTYPE_ENCODING = {'int8': 0b01, 'uint8': 0b10}


class NewVcmp(STMT):
    """
    this template only have vector
    """

    def __init__(self, source_info, op_obj, tik_debugger):
        super(NewVcmp, self).__init__(source_info, tik_debugger)
        self.op_obj = op_obj
        self.op_obj = op_obj
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """

        self.op_obj.src0_tensor_op.set_context(context)
        self.op_obj.src1_tensor_op.set_context(context)

        mask = self.op_obj.control_op.mask
        align, tensor_bit_len = self.op_obj.vcmp_check_obj.check_all(self.op_obj.tik_instance, True)

        set_vector_mask(mask, context, tensor_bit_len=tensor_bit_len)
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return
        temp_env = TempEnv()

        xn_idx, _, src0_buffer_size, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src0_tensor_op.tensor_obj, align, access_mode='r')
        xm_idx, _, src1_buffer_size, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src1_tensor_op.tensor_obj, align, access_mode='r')

        # check overflow
        self.op_obj.src0_tensor_op.check_read_mem_out_of_bounds(src0_buffer_size, self.op_obj.control_op)
        self.op_obj.src1_tensor_op.check_read_mem_out_of_bounds(src1_buffer_size, self.op_obj.control_op)

        param = context.encoder.new_param()
        param.condOp = VEC_CMP_OP_ENCODER[self.op_obj.name.split('_')[1]]
        param.type = VEC_DATA_TYPE_ENCODING_V200[self.op_obj.src0_tensor_op.tensor_obj.dtype]
        param.xn = xn_idx
        param.xm = xm_idx
        param.xt = self.create_gpr_x_t(context, temp_env)

        instr = context.encoder.gen_vcmpx(param)

        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        # check stride

        xt_idx = temp_env.alloc_register()
        x_t = 0
        x_t |= context.evaluate_expr(self.op_obj.src0_tensor_op.blk_stride) << _SRC_BLK_STRIDE_SHIFT_POS
        x_t |= context.evaluate_expr(self.op_obj.src1_tensor_op.blk_stride) << _SRC1_BLK_STRIDE_SHIFT_POS
        x_t |= 1 << REPEAT_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)
        return xt_idx


class NewVcmpv(STMT):
    """
    this template only have vector
    """

    def __init__(self, source_info, op_obj, tik_debugger):
        super(NewVcmpv, self).__init__(source_info, tik_debugger)
        self.op_obj = op_obj
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return
        self.op_obj.dst_tensor_op.set_context(context)
        self.op_obj.src0_tensor_op.set_context(context)
        self.op_obj.src1_tensor_op.set_context(context)

        temp_env = TempEnv()
        align = vec_template_align(self.op_obj.src0_tensor_op.tensor_obj.dtype)

        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.op_obj.dst_tensor_op.tensor_obj, align, access_mode='w')

        param = context.encoder.new_param()
        param.condOp = VEC_CMP_OP_ENCODER[self.op_obj.name.split('_')[1]]
        param.type = VCMPV_TYPE_ENCODER[self.op_obj.src0_tensor_op.tensor_obj.dtype]
        param.xd = xd_idx
        param.xt = self.create_gpr_x_t(context, temp_env)
        param.xn, param.xm = self.get_src_idx(context, temp_env, align)

        if TikSocManager.is_910b_soc()\
                and self.op_obj.src0_tensor_op.tensor_obj.dtype == 'int32':
            instr = context.encoder.gen_vcmpvx_s32_eq(param)
        else:
            instr = context.encoder.gen_vcmpvx(param)

        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

        context.model.read_memory(dst_addr, self.op_obj.dst_tensor_op.tensor_obj.scope, dst_ptr, dst_alloc_size)

    def get_src_idx(self, context, temp_env, align):
        """
        get src xn_idx and xm_idx and check tensor overflow

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment
        align : the align addr

        Returns
        -------
        xn_idx, xm_idx
        """
        xn_idx, _, src0_buffer_size, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src0_tensor_op.tensor_obj, align, access_mode='r')

        xm_idx, _, src1_buffer_size, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src1_tensor_op.tensor_obj, align, access_mode='r')

        # for vcmpv instr, mask is related to type
        self.op_obj.control_op.mask = ONE_REP_BYTE_SIZE // DTYPE_SIZE[self.op_obj.src0_tensor_op.tensor_obj.dtype]
        self.op_obj.src0_tensor_op.check_read_mem_out_of_bounds(src0_buffer_size, self.op_obj.control_op)

        self.op_obj.src1_tensor_op.check_read_mem_out_of_bounds(src1_buffer_size, self.op_obj.control_op)
        return xn_idx, xm_idx

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)
        # check repeat
        TikCheckUtil.check_in_range_by_dtype(
            repeat, msg="Variable out of interval", var_range=[_MIN_REPEAT_TIMES, MAX_REPEAT_TIMES])

        # check blk, rep, overlap
        self.op_obj.vcmpv_check_obj.check_all(True)

        xt_idx = temp_env.alloc_register()
        x_t = 0
        x_t |= context.evaluate_expr(self.op_obj.src0_tensor_op.blk_stride) << _SRC_BLK_STRIDE_SHIFT_POS
        x_t |= context.evaluate_expr(self.op_obj.src1_tensor_op.blk_stride) << _SRC1_BLK_STRIDE_SHIFT_POS
        x_t |= repeat << REPEAT_SHIFT_POS
        x_t |= context.evaluate_expr(self.op_obj.src0_tensor_op.rep_stride) << _SRC_REPEAT_STRIDE_SHIFT_POS
        x_t |= context.evaluate_expr(self.op_obj.src1_tensor_op.rep_stride) << _SRC1_REPEAT_STRIDE_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)

        return xt_idx


class NewVcmpvs(STMT):
    """
    this template only have vector
    """

    def __init__(self, source_info, op_obj, tik_debugger):
        super(NewVcmpvs, self).__init__(source_info, tik_debugger)
        self.op_obj = op_obj
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """

        self.op_obj.dst_tensor_op.set_context(context)
        self.op_obj.src_tensor_op.set_context(context)
        self.op_obj.control_op.mask = ONE_REP_BYTE_SIZE // DTYPE_SIZE[self.op_obj.src_tensor_op.tensor_obj.dtype]

        align = vec_template_align(self.op_obj.src_tensor_op.tensor_obj.dtype)
        temp_env = TempEnv()
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            temp_env.check_mem_access(context.model, False)
            return
        xn_idx, _, src_buffer_size, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src_tensor_op.tensor_obj, align, access_mode='r')

        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.op_obj.dst_tensor_op.tensor_obj, align, access_mode='w')
        param = context.encoder.new_param()
        param.condOp = VEC_CMP_OP_ENCODER[self.op_obj.name.split('_')[1]]
        param.type = VCMPVS_TYPE_ENCODER[self.op_obj.src_tensor_op.tensor_obj.dtype]
        param.xd = xd_idx
        param.xn = xn_idx
        param.xm = self.create_gpr_x_m(context, temp_env)
        param.xt = self.create_gpr_x_t(context, temp_env)
        self.op_obj.src_tensor_op.check_read_mem_out_of_bounds(src_buffer_size, self.op_obj.control_op)

        if TikSocManager.is_910b_soc() and self.op_obj.src_tensor_op.tensor_obj.dtype == 'int32':
            param.condOp = VCMPVS_CMP_OP_ENCODER[self.op_obj.name.split('_')[1]]
            instr = context.encoder.gen_vcmpvsx_s32_eq(param)
        else:
            instr = context.encoder.gen_vcmpvsx(param)

        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

        context.model.read_memory(dst_addr, self.op_obj.dst_tensor_op.tensor_obj.scope, dst_ptr, dst_alloc_size)

    def create_gpr_x_m(self, context, temp_env):
        """
        create general purpose register x_m

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment

        Returns
        -------
        xm_idx
        """
        scalar = self.op_obj.scalar_op.context_get_scalar(context)
        xm_idx = temp_env.alloc_register()
        x_m = cvt_float_to_uint(self.op_obj.src_tensor_op.tensor_obj.dtype, scalar)

        context.model.write_gpr(xm_idx, x_m)
        return xm_idx

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)
        # check repeat
        TikCheckUtil.check_in_range_by_dtype(
            repeat, msg="Variable out of interval", var_range=[_MIN_REPEAT_TIMES, MAX_REPEAT_TIMES])
        # check repeat, blk, rep, overlap
        self.op_obj.vcmpvs_check_obj.check_all(True)

        xt_idx = temp_env.alloc_register()
        x_t = 0
        x_t |= context.evaluate_expr(self.op_obj.src_tensor_op.blk_stride) << _SRC1_BLK_STRIDE_SHIFT_POS
        x_t |= repeat << REPEAT_SHIFT_POS
        x_t |= context.evaluate_expr(self.op_obj.src_tensor_op.rep_stride) << _SRC1_REPEAT_STRIDE_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)

        return xt_idx


class Vsel(STMT):
    """
    this template only have vector
    """

    def __init__(self, source_info, op_obj, tik_debugger):
        super(Vsel, self).__init__(source_info, tik_debugger)
        self.op_obj = op_obj
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return
        self.op_obj.dst_tensor_op.set_context(context)
        self.op_obj.src0_tensor_op.set_context(context)
        if self.op_obj.mode in (0, 2):
            self.op_obj.src1_tensor_op.set_context(context)
        else:
            self.op_obj.src1_tensor_op.context = context
            self.op_obj.src1_tensor_op.blk_stride_value = context.evaluate_expr(self.op_obj.src1_tensor_op.blk_stride)
            self.op_obj.src1_tensor_op.rep_stride_value = context.evaluate_expr(self.op_obj.src1_tensor_op.rep_stride)
        tensor_bit_len = max(get_bit_len(self.op_obj.src0_tensor_op.tensor_obj.dtype),
                             get_bit_len(self.op_obj.dst_tensor_op.tensor_obj.dtype))
        set_vector_mask(self.op_obj.control_op.mask, context,
                        tensor_bit_len=tensor_bit_len)
        mode = context.evaluate_expr(self.op_obj.mode)
        temp_env = TempEnv()

        align = vec_template_align(self.op_obj.src0_tensor_op.tensor_obj.dtype)

        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.op_obj.dst_tensor_op.tensor_obj, align, access_mode='w')
        xn_idx, _, src0_alloc_size, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src0_tensor_op.tensor_obj, align, access_mode='r')

        param = context.encoder.new_param()
        param.type = VEC_DATA_TYPE_ENCODING[self.op_obj.src0_tensor_op.tensor_obj.dtype]
        param.xd = xd_idx
        param.xn = xn_idx
        param.xt = self.create_gpr_x_t(context, temp_env, tensor_bit_len)
        # check overflow
        self.op_obj.src0_tensor_op.check_read_mem_out_of_bounds(src0_alloc_size, self.op_obj.control_op)
        param.xm = self.diff_mode_idx(context, temp_env, mode)

        instr = context.encoder.gen_vselx(param)

        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

        context.model.read_memory(dst_addr, self.op_obj.dst_tensor_op.tensor_obj.scope, dst_ptr,
                                  dst_alloc_size)

    def diff_mode_idx(self, context, temp_env, mode):
        """
        different mode for xm_idx

        Parameters
        ----------
        context : the stack context
        temp_env: temp environment
        mode: vsel mode

        Returns
        -------
        xm_idx
        """
        mask_align = 32
        align = vec_template_align(self.op_obj.src0_tensor_op.tensor_obj.dtype)
        xm_idx = -1
        if mode == 0:
            xm_idx, _, src1_alloc_size, _ = copy_tensor_to_model(
                context, temp_env, self.op_obj.src1_tensor_op.tensor_obj, align, access_mode='r')

            self.op_obj.src1_tensor_op.check_read_mem_out_of_bounds(src1_alloc_size, self.op_obj.control_op)
        elif mode == 1:
            xm_idx, _, _, _ = copy_tensor_to_model(
                context, temp_env, self.op_obj.sel, mask_align, access_mode='r')

            cmp_constant = context.evaluate_expr(self.op_obj.src1_tensor_op.tensor_obj)
            context.model.write_spr('CMPMASK0',
                                    cvt_float_to_uint(self.op_obj.src0_tensor_op.tensor_obj.dtype, cmp_constant))
        elif mode == 2:
            xm_idx, _, src1_alloc_size, _ = copy_tensor_to_model(
                context, temp_env, self.op_obj.src1_tensor_op.tensor_obj, align, access_mode='r')

            self.op_obj.src1_tensor_op.check_read_mem_out_of_bounds(src1_alloc_size, self.op_obj.control_op)
            cmp_idx, _, _, _ = copy_tensor_to_model(
                context, temp_env, self.op_obj.sel, mask_align, access_mode='r')

            cmp_addr = context.model.read_gpr(cmp_idx)
            context.model.write_spr('CMPMASK0', cmp_addr)

        return xm_idx

    def create_gpr_x_t(self, context, temp_env, tensor_bit_len):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)
        # check repeat
        TikCheckUtil.check_in_range_by_dtype(
            repeat, msg="Variable out of interval", var_range=[_MIN_REPEAT_TIMES, MAX_REPEAT_TIMES])

        # check blk, rep, overlap
        self.op_obj.vsel_check_obj.check_all(self.op_obj.tik_instance, context, True)
        # check sel overlap and overflow
        if self.op_obj.mode in (1, 2):
            if self.op_obj.dst_tensor_op.tensor_obj.buffer == self.op_obj.sel.buffer:
                self.op_obj.vsel_check_obj.check_sel_dst_overlap(tensor_bit_len)

            check_sel_overflow(self.op_obj.dst_tensor_op.tensor_obj, self.op_obj.src0_tensor_op.tensor_obj,
                               self.op_obj.sel, self.op_obj.dst_tensor_op.mask_value, repeat)

        xt_idx = temp_env.alloc_register()
        x_t = self.op_obj.dst_tensor_op.blk_stride_value
        x_t |= self.op_obj.src0_tensor_op.blk_stride_value << _SRC_BLK_STRIDE_SHIFT_POS
        x_t |= self.op_obj.src1_tensor_op.blk_stride_value << _SRC1_BLK_STRIDE_SHIFT_POS
        x_t |= self.op_obj.dst_tensor_op.rep_stride_value << _DST_REPEAT_STRIDE_SHIFT_POS
        x_t |= self.op_obj.src0_tensor_op.rep_stride_value << _SRC_REPEAT_STRIDE_SHIFT_POS
        x_t |= self.op_obj.src1_tensor_op.rep_stride_value << _SRC1_REPEAT_STRIDE_SHIFT_POS
        x_t |= context.evaluate_expr(self.op_obj.mode) << MODE_SHIFT_POS
        x_t |= repeat << REPEAT_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)

        return xt_idx


class VReduce(STMT):
    """
    VReduce instruction
    """

    def __init__(self, source_info, op_obj, rsvd_scalar):
        super(VReduce, self).__init__(source_info, op_obj.tik_instance.context.tik_debugger)
        self.op_obj = op_obj
        self.rsvd_scalar = rsvd_scalar
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            if self.rsvd_scalar is not None:
                align = DTYPE_SIZE.get(self.op_obj.dst_tensor_op.tensor_obj.dtype)
                ar_count = context.model.read_spr('AR') // align
                context.update_var(self.rsvd_scalar, ar_count)
            return
        orig_ctrl_value = None

        # only counter mode, mask is effective
        if self.op_obj.control_op.mask_mode == "counter":
            orig_ctrl_value = set_mask_counter_mode(context)
            set_vector_mask(self.op_obj.control_op.mask, context, self.op_obj.control_op.mask_mode,
                            tensor_bit_len=get_bit_len(self.op_obj.src0_tensor_op.tensor_obj.dtype))
        align = vec_template_align(self.op_obj.dst_tensor_op.tensor_obj.dtype)
        temp_env = TempEnv()

        xd_idx1, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.op_obj.dst_tensor_op.tensor_obj, align, access_mode='w')
        xn_idx2, _, _, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src0_tensor_op.tensor_obj, align, access_mode='r')

        # check blk_stride, rep_stride, overflow, overlap
        self.op_obj.vreduce_check_obj.check_all(True, context)

        param = context.encoder.new_param()
        param.type = self.get_type_encoding()
        param.xd = xd_idx1
        param.xn = xn_idx2
        param.xm, pattern = self.create_gpr_x_m(context, temp_env, align)
        param.xt = self.create_gpr_x_t(context, temp_env, pattern)

        instr = context.encoder.gen_vreduce(param)
        if self.op_obj.print_name == "vreducev2":
            instr = instr & 0xFFFFFFFE  # for 910B, last bit of instr code is 0

        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

        # mask: counter_mode, reset CTRL as orig_ctrl_value
        if self.op_obj.control_op.mask_mode == "counter":
            context.model.write_spr('CTRL', orig_ctrl_value)

        if self.rsvd_scalar is not None:
            context.update_var(self.rsvd_scalar,
                               context.model.read_spr('RSVD_CNT'))

        context.model.read_memory(
            dst_addr, self.op_obj.dst_tensor_op.tensor_obj.scope, dst_ptr, dst_alloc_size)

    def get_type_encoding(self):
        """
        get type encoding code
        """
        bit_width = get_dtype_bit_width(self.op_obj.src0_tensor_op.tensor_obj.dtype)
        if bit_width == '16':
            type_encoding = 0
        else:
            type_encoding = 1

        return type_encoding

    def create_gpr_x_m(self, context, temp_env, align):
        """
        create general purpose register x_m

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment
        align : align addr

        Returns
        -------
        xm_idx, pattern
        """
        if is_tensor(self.op_obj.src1_tensor_op.tensor_obj):
            pattern = 0
            xm_idx, *_ = copy_tensor_to_model(
                context, temp_env, self.op_obj.src1_tensor_op.tensor_obj, align, access_mode='r')
        else:
            pattern = context.evaluate_expr(self.op_obj.src1_tensor_op.tensor_obj)
            xm_idx = temp_env.alloc_register()
        return xm_idx, pattern

    def create_gpr_x_t(self, context, temp_env, pattern):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        pattern: the instr's pattern
        input_params: the input parameters' value

        Returns
        -------
        xt_idx
        """
        pattern_shift_pos = 16
        xt_idx = temp_env.alloc_register()
        x_t = 0
        if self.op_obj.print_name == "vreducev2":
            src0_rep_stride_shift_pos = 24
            # repeat high 8-bits
            x_t |= ((self.op_obj.dst_tensor_op.repeat_times_value & 0xFF00) >> 8) << REPEAT_SHIFT_POS
            x_t |= self.op_obj.src0_tensor_op.rep_stride_value << src0_rep_stride_shift_pos
            x_t |= self.op_obj.src0_tensor_op.blk_stride_value << _SRC_BLK_STRIDE_SHIFT_POS
            x_t |= self.op_obj.src1_tensor_op.rep_stride_value << _SRC1_REPEAT_STRIDE_SHIFT_POS
            x_t |= pattern << pattern_shift_pos
            x_t |= self.op_obj.dst_tensor_op.repeat_times_value & 0xFF  # repeat low 8-bits
        else:
            x_t |= context.evaluate_expr(self.op_obj.control_op.stride_unit) << STRIDE_UNIT_SHIFT_POS
            x_t |= self.op_obj.dst_tensor_op.repeat_times_value << REPEAT_SHIFT_POS
            x_t |= self.op_obj.src0_tensor_op.rep_stride_value << _SRC_REPEAT_STRIDE_SHIFT_POS
            x_t |= self.op_obj.src0_tensor_op.blk_stride_value << _SRC_BLK_STRIDE_SHIFT_POS
            x_t |= self.op_obj.src1_tensor_op.rep_stride_value << _SRC1_REPEAT_STRIDE_SHIFT_POS
            x_t |= pattern << pattern_shift_pos

        context.model.write_gpr(xt_idx, x_t)
        return xt_idx


class VconvNew(STMT):
    """
    Vconv instruction
    """

    def __init__(self, source_info, op_obj, tik_debugger):
        super(VconvNew, self).__init__(source_info, tik_debugger)
        self.op_obj = op_obj
        self.round_method = op_obj.round_mode
        if self.round_method == 'none':
            self.round_method = ''
        if self.round_method == 'ceiling':
            self.round_method = 'ceil'
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return
        self.op_obj.dst_tensor_op.context = context
        self.op_obj.src_tensor_op.context = context
        temp_env = TempEnv()
        mask = self.op_obj.control_op.mask
        set_vector_mask(mask, context, tensor_bit_len=max(get_bit_len(self.op_obj.dst_tensor_op.tensor_obj.dtype),
                                                          get_bit_len(self.op_obj.src_tensor_op.tensor_obj.dtype)))
        deq_mode = self.set_spr_deqscale(context, temp_env)

        src_align = vec_template_align(self.op_obj.src_tensor_op.tensor_obj.dtype)
        dst_align = vec_template_align(self.op_obj.dst_tensor_op.tensor_obj.dtype)

        xn_idx, _, _, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src_tensor_op.tensor_obj, src_align, access_mode='r')
        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.op_obj.dst_tensor_op.tensor_obj, dst_align, access_mode='w')

        instr_list = [context, deq_mode, xd_idx, xn_idx, temp_env]
        if TikSocManager.is_910b_soc():
            instr = self.gen_vconvx_instr_910b(instr_list)
        else:
            instr = self.gen_vconvx_instr(instr_list)

        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)
        context.model.read_memory(dst_addr, self.op_obj.dst_tensor_op.tensor_obj.scope, dst_ptr, dst_alloc_size)

    def set_spr_deqscale(self, context, temp_env):
        """
        set special purpose register DEQSCALE

        Parameters
        ----------
        context : the stack context
        temp_env: temp environment

        Returns
        -------
        deq_mode
        """
        deq_mode = ''
        if self.op_obj.src_tensor_op.tensor_obj.dtype == 'int32' and \
                self.op_obj.dst_tensor_op.tensor_obj.dtype == 'float16':
            if self.op_obj.deqscale_op.tensor_obj is None:
                TikCheckUtil.raise_error('vconv deq scale is None!')
            deq_scale = context.evaluate_expr(self.op_obj.deqscale_op.tensor_obj)
            deq_mode = 'DEQ'
            bin_deq_scale = cvt_float_to_uint(self.op_obj.dst_tensor_op.tensor_obj.dtype, deq_scale)
            context.model.write_spr('DEQSCALE', bin_deq_scale)
        if self.op_obj.src_tensor_op.tensor_obj.dtype == 'int16' and self.op_obj.dst_tensor_op.tensor_obj.dtype \
                in ('int8', 'uint8'):
            if isinstance(self.op_obj.deqscale_op.tensor_obj, (list, tuple)):
                bit_46 = int(self.op_obj.dst_tensor_op.tensor_obj.dtype == "int8")
                deq_scale = (context.evaluate_expr(i) for i in self.op_obj.deqscale_op.tensor_obj)
                self.op_obj.deqscale_op.tensor_obj = concate_deqscale_vconv(deq_scale, bit_46)
            if is_tensor(self.op_obj.deqscale_op.tensor_obj):
                deq_mode = 'VDEQs162b8'
                deq_addr = copy_tensor_to_model_get_addr(context, temp_env, self.op_obj.deqscale_op.tensor_obj,
                                                         ALIGNED_ADDR, access_mode='r')
                deq_addr = deq_addr // ALIGNED_ADDR
                context.model.write_spr('DEQSCALE', deq_addr)
            else:
                deq_mode = 'DEQs162b8'
                self.check_deqscale(context)
                context.model.write_spr('DEQSCALE',
                                        context.evaluate_expr(self.op_obj.deqscale_op.tensor_obj))
        return deq_mode

    def check_deqscale(self, context):
        """
        make deqscale[46] consistent with dst.dtype, for deqs162b8 mode

        Parameters
        ----------
        None

        Returns
        -------
        None
        """
        deq_46 = (context.evaluate_expr(self.op_obj.deqscale_op.tensor_obj) &
                  DEQSCALE_46BIT_MASK) >> DEQSCALE_46BIT_SHIFT_POS
        if self.op_obj.dst_tensor_op.tensor_obj.dtype == "int8":
            # check deqscale[46]=1 which indicate the result is signed
            TikCheckUtil.check_equality(deq_46, 1, "deqscale[46] bit should be 1 when converting int16 to int8")
        elif self.op_obj.dst_tensor_op.tensor_obj.dtype == "uint8":
            # check deqscale[46]=0 which indicate the result is unsigned
            TikCheckUtil.check_equality(deq_46, 0, "deqscale[46] bit should be 0 when converting int16 to uint8")

    def gen_vconvx_instr(self, instr_list):
        """
        generate instruction for vconv before v220
        """
        context, deq_mode, xd_idx, xn_idx, temp_env = instr_list
        param = context.encoder.new_param()
        param.convType = self.get_conv_type(deq_mode)
        # v200
        if self.op_obj.ldst_high_half is not None:
            param.h = context.evaluate_expr(self.op_obj.ldst_high_half)
        param.xd = xd_idx
        param.xn = xn_idx
        param.xt = self.create_gpr_x_t(context, temp_env)

        instr = context.encoder.gen_vconvx(param)
        return instr

    def get_conv_type(self, deq_mode):
        """
        get conv_type

        Parameters
        ----------
        deq_mode

        Returns
        -------
        conv_type
        """
        if deq_mode != '':
            conv_type = VCONV_TYPE_ENCODING[(deq_mode,)]
        elif self.round_method not in ('', None):
            conv_type = VCONV_TYPE_ENCODING[self.op_obj.src_tensor_op.tensor_obj.dtype,
                                            self.op_obj.dst_tensor_op.tensor_obj.dtype, self.round_method]
        else:
            conv_type = VCONV_TYPE_ENCODING[self.op_obj.src_tensor_op.tensor_obj.dtype,
                                            self.op_obj.dst_tensor_op.tensor_obj.dtype]

        return conv_type

    def gen_vconvx_instr_910b(self, instr_list):
        """
        generate instruction for vconv for v220
        """
        context, deq_mode, xd_idx, xn_idx, temp_env = instr_list
        param = context.encoder.new_param()
        # param.convType[0:3] -> #SRC
        # param.convType[3:7] -> #DST
        # param.h -> #ROUND_MODE
        param.convType, param.h = self.get_conv_type_and_h(deq_mode, context.evaluate_expr(self.op_obj.ldst_high_half))
        param.xd = xd_idx
        param.xn = xn_idx
        param.xt = self.create_gpr_x_t(context, temp_env)

        instr = context.encoder.gen_vconvx_910b(param)
        return instr

    def get_conv_type_and_h(self, deq_mode, ldst_high_half):
        """
        get conv_type for Ascend910B

        Parameters
        ----------
        deq_mode
        ldst_high_half

        Returns
        -------
        conv_type, rnd(h)
        """
        if deq_mode != '':
            # rnd_src_dst[7:10] -> rnd
            # rnd_src_dst[4:7] -> src
            # rnd_src_dst[0:4] -> dst
            rnd_src_dst = VCONV_RND_SRC_DST_ENCODING[(deq_mode, str(int(ldst_high_half)))]
            src = (rnd_src_dst >> 4) & 0b111
            dst = rnd_src_dst & 0b1111
            conv_type = src | (dst << 3)
            rnd = rnd_src_dst >> 7
        else:
            rnd = VCONV_RND_ENCODING[self.round_method]
            src = VCONV_SRC_ENCODING[self.op_obj.src_tensor_op.tensor_obj.dtype]
            dst = VCONV_DST_ENCODING[self.op_obj.dst_tensor_op.tensor_obj.dtype]
            conv_type = src | (dst << 3)

        return conv_type, rnd

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)
        # check repeat_times value
        TikCheckUtil.check_in_range_by_dtype(
            repeat, msg="repeat_times should be in the range of [%s, %s], input repeat_times: %s"
            % (_MIN_REPEAT_TIMES, MAX_REPEAT_TIMES, repeat), var_range=[_MIN_REPEAT_TIMES, MAX_REPEAT_TIMES])
        # check strides, overlap, overflow
        self.op_obj.vonv_check_obj.check_all(self.op_obj.tik_instance, True, context)

        xt_idx = temp_env.alloc_register()
        x_t = self.op_obj.dst_tensor_op.blk_stride_value
        x_t |= self.op_obj.src_tensor_op.blk_stride_value << SRC_BLOCK_STRIDE_SHIFT_POS
        x_t |= context.evaluate_expr(self.op_obj.control_op.stride_unit) << STRIDE_UNIT_SHIFT_POS
        x_t |= repeat << REPEAT_SHIFT_POS
        x_t |= self.op_obj.dst_tensor_op.rep_stride_value << DST_REPEAT_STRIDE_SHIFT_POS
        x_t |= self.op_obj.src_tensor_op.rep_stride_value << SRC_REPEAT_STRIDE_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)

        return xt_idx
