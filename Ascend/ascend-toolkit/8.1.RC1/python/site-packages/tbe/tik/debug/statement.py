#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     statement.py
DESC:     Create some stmt class
CREATED:  2019-04-18 18:53:42
MODIFIED: 2020-12-7 19:17:00
"""
from __future__ import print_function
import sys
import numpy as np

from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.common_util import is_tensor
from tbe.tik.common.common_util import is_tensor_addr_list
from tbe.tik.tik_lib.tik_check_util import get_traceback_msg
from tbe.tik.debug.util import get_flatten_idx
from tbe.tik.debug.util import get_dtype_bit_width
from tbe.tik.debug.util import make_tvm_imm
from tbe.tik.debug.util import copy_tensor_to_model
from tbe.tik.debug.sim.util import TempEnv
from tbe.tik.tik_lib.tik_params import CUR_FRAME_IDX
from tbe.tik.tik_lib.tik_source_info import most_recent_traceback
from tbe.tik.tik_lib.tik_expr import BasicExpr
from tbe.tik.tik_lib.tik_expr import get_float16_range_value
from tbe.tik.tik_lib.tik_expr import Expr
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_check_util import stack
from tbe.tik.tik_lib.tik_check_util import ERROR_MSG_LEVEL
from tbe.tik.debug.npbuffer import get_uninited_buffer


class TikDebug:
    """
    Class for tik_debugger and force_interactive variable
    """

    def __init__(self):
        self.force_interactive = False
        self.stdin = None  # for multi-core cmd input
        self.stdout = None  # for multi-core msg output
        self.cmd_queue = None  # for multi-core get cmd from main process by Queue
        self.resp_msg_queue = None  # for multi-core response result to main process by Queue
        self.block_idx_list = []  # save block index of all interactive process
        self.cur_block_idx = None  # current interactive process, multi-process shared
        self.is_interactive = None  # current process whether interactive
        self.is_single_core = True  # current process whether is single-core
        self.block_begin = 0  # block nums start for multi-core
        self.block_end = 1  # block nums end for multi-core
        self.block_index = None  # block index for multi-core
        self.all_block_status = []  # status of all cores for multi-core


class TikBreakPoint:
    """
    Class TikeBreakPoint
    """

    def __init__(self, ast_node, breakpoint_id):  # , is_single_core, block_nums):
        """
        Initialize class TikBreakPoint

        Parameters
        ----------
        ast_node: Node of Abstract Syntax Trees, This is a Class STMT instance.
        breakpoint_id: break point id

        Returns
        ----------
        No returns
        """
        # self.id must corresponds to Varresolver.visit_Name.node.id
        # in statement.py
        self.enabled = True
        self.id = breakpoint_id
        self.ast_node = ast_node

    def __eq__(self, other):
        """
        Judge to is other break point's id equal to self's id.

        Parameters
        ----------
        other:Other break point instances

        Returns
        ----------
        False or True
        """
        if not other:
            return False
        return self.id == other.id

    def show_msg(self, is_single_core, block_nums, block_end):
        """
        Display the break point.

        Parameters
        ----------
        No parameters

        Returns
        ----------
        id:break point id.
        disp:yes or no to display
        source_file:file name of source_info
        source_line_no:line number of source_info
        """
        source_info = self.ast_node.source_info
        if self.enabled:
            disp = 'yes  '
        else:
            disp = 'no   '
        # for multi-core msg show
        if (not is_single_core and len(block_nums) > 0) or not isinstance(block_end, int):
            msg = '%-4dbreakpoint   %s at %s:%d of block %s' % (
                self.id, disp, source_info[CUR_FRAME_IDX].get("filename"),
                source_info[CUR_FRAME_IDX].get("line_no"), block_nums)
        else:
            msg = '%-4dbreakpoint   %s at %s:%d' % (
                self.id, disp, source_info[CUR_FRAME_IDX].get("filename"),
                source_info[CUR_FRAME_IDX].get("line_no"))
        print(msg)

    def debug_print(self, prefix=""):
        """
        Print debug break point

        Parameters
        ----------
        prefix:This is a empty parameter.

        Returns
        ----------
        No returns
        """
        print(prefix, end='')
        source_info = self.ast_node.source_info
        print("breakpoint id=%d %s:%d ast_node=%s" %
              (self.id, source_info[CUR_FRAME_IDX].get("filename"),
               source_info[CUR_FRAME_IDX].get("line_no"),
               type(self.ast_node).__name__))


class STMT:
    """
    Base Class for dbg_instances, used for building the debug AST
    """

    def __init__(self, source_info, tik_debugger):
        """
        Initalize class STMT.

        Parameters
        ----------
        source_info:source code information. It represents the relationship of current node with source code

        Returns
        ----------
        No returns
        """
        self.source_info = source_info
        self.parent = None
        self.break_point = None
        self.trace_event = 'statement'
        self.traceable = True
        self.frozen = False

        if tik_debugger:
            tik_debugger.register_debug_info(self.source_info, self)

    @staticmethod
    def eval_(context):
        """
        eval_ function
        implement by subclass
        """

    def evaluate(self, context, allow_print=True):
        """
        evaluate function

        Parameters
        ----------
        context:information of debugger, store all of debugger's information
        allow_print:If allow print current line info for next/continue

        Returns
        ----------
        No returns
        """
        if context.tik_debugger and self.traceable:
            context.tik_debugger.trace(context, self, 'pre-%s' % self.trace_event, allow_print=allow_print)

        try:
            # if is_debug_break or is_debug_continue is True,
            # the current eval_ is after tik_break and in the scope, the eval_ not executed.
            if not context.is_debug_break and not context.is_debug_continue:
                self.eval_(context)
        except DebugReturnException:
            pass
        except (RuntimeError, ValueError, OSError) as ex:
            print(get_traceback_msg(stack(depth=1), ERROR_MSG_LEVEL.err_msg_level))
            # remove first element of list: "Traceback:"
            print(get_traceback_msg(most_recent_traceback(), ERROR_MSG_LEVEL.err_msg_level)[1:])
            # in the interactive mode, enter cmdline ,
            # let user do some debug job
            if context.interactive:
                print(ex)
                context.tik_debugger.running = False
                context.tik_debugger.trace(context, self, 'exception')
            else:
                # if not in interactive model, raise SystemExit exception
                # this exception will catch by Context.eval_
                sys.exit(ex)

    def set_parent(self, parent):
        """
        Add the parent AST node

        Parameters
        ----------
        parent:the parent AST node

        Returns
        ----------
        No returns
        """
        if self.parent:
            msg = "Parent exist: %s, %s" % (id(self.parent), type(self.parent))
            print(msg)
            TikCheckUtil.raise_error(msg)
        self.parent = parent


def replace_obj(ctx, obj, visited):
    """
    Recusive replace tik obj

    Parameters
    ----------
    ctx:Class context instance
    obj:Object
    visited:list, A list of visited

    Returns
    ----------
    np_arr:NumpyBuffer
    ctx.evaluate_expr():A Expression
    replace_container:Type container
    """
    npbuf = ctx.get_value(obj)
    if npbuf is not None:
        # this is a tensor
        np_arr = npbuf.buffer
        return np_arr

    if isinstance(obj, BasicExpr):
        return ctx.evaluate_expr(obj)

    if isinstance(obj, (tuple, list)):
        return replace_container(ctx, obj, visited)

    return None


def eval_or_cache(ctx, obj, visited):
    """
    Eval or cache function

    Parameters
    ----------
    ctx:Class context instance
    obj:Object
    visited:list, A list of visited

    Returns
    ----------
    visited:list, A list of visited
    replaced:Returns of function replace_obj
    """
    key = id(obj)
    if key in visited:
        return visited[key]

    replaced = replace_obj(ctx, obj, visited)
    visited[key] = replaced
    return replaced


def replace_container(ctx, container, visited):
    """
    Replace container function

    Parameters
    ----------
    ctx:Class context instance

    container:(tuple, list), A container object

    visited:list, A list of visited

    Returns
    ----------
    None
    type(container)
    """
    if isinstance(container, (list, tuple)):
        temp_l = []
        for contain in container:
            temp_l.append(eval_or_cache(ctx, contain, visited))
        return type(container)(temp_l)

    return None


class DebugReturnException(Exception):
    """
    Class return debug exception
    """


class Return(STMT):
    """
    Class Return inherits from STMT
    """

    @staticmethod
    def eval_(context):
        """
        Eval function
        """
        raise DebugReturnException()


# scalar : scalar by value (implict conversion happens)
# scalar : tensor by ref (binary reinterpretation)
class SetScalar(STMT):
    """
    Class SetScalar inherits from STMT.
    To set scalar
    """

    def __init__(self, source_info, scalar, value, tik_debugger):
        """
        Initialize class SetScalar

        Parameters
        ----------
        source_info:source code information, It represents the relationship of current node with source code

        scalar:a type of scalar

        value:the value of scalar

        Returns
        ----------
        No returns
        """

        super(SetScalar, self).__init__(source_info, tik_debugger)
        self.scalar = scalar
        self.debug_var = scalar.debug_var
        self.dtype = self.debug_var[0].dtype
        if self.dtype == "float16":
            if isinstance(value, (int, float, Expr)):
                result_value = Expr(value).eval_value()
                if result_value is not None:
                    value = get_float16_range_value(result_value)
        self.value = value
        self.i = None

    def eval_(self, context):
        """
        Eval function
        evaluate all of self.function

        Parameters
        ----------
        context:information of debugger, store all of debugger's information

        Returns
        ----------
        No returns
        """
        if is_tensor(self.value):
            tensor = self.value
            src_bitwidth = int(get_dtype_bit_width(tensor.dtype))
            dst_bitwidth = int(get_dtype_bit_width(self.dtype))
            tensor_buffer = context.tensor_buffer.get_npbuffer_by_tvmbuffer(
                tensor.buffer).buffer
            flatten_np = tensor_buffer.reshape(-1).view(tensor.dtype)
            flatten_idx = get_flatten_idx(tensor, context)
            if flatten_idx >= len(flatten_np):
                TikCheckUtil.raise_error(
                    'IndexError: index {idx} out of range [0, {length})'.format(
                        idx=flatten_idx, length=len(flatten_np)))

            if dst_bitwidth >= src_bitwidth:
                ratio = dst_bitwidth // src_bitwidth
                r_value = flatten_np[flatten_idx: flatten_idx + ratio].view(
                    self.dtype)[0]
            else:
                r_value = np.asarray([flatten_np[flatten_idx]]) \
                    .view(self.dtype)[0]
            self.i = make_tvm_imm(self.dtype, r_value)
            update_var_to_debug = self.i
        else:
            if isinstance(self.value, BasicExpr):
                self.i = context.evaluate_expr(self.value)
                update_var_to_debug = make_tvm_imm(self.dtype, self.i)
            else:
                self.i = make_tvm_imm(self.dtype, self.value)
                update_var_to_debug = self.i

        offset = context.evaluate_expr(self.scalar.offset)
        context.update_var(self.debug_var[offset], self.i)
        # set value to None means the scalar is unavaliable, no need update to VM debug
        if self.value is not None:
            context.update_var_to_vm(self.scalar.reg_buffer.asobject(), update_var_to_debug, offset)

    def set_value(self, value):
        """
        set self.value
        """
        self.value = value


class GetitemScalarArray(STMT):
    """
    Class GetitemScalarArray inherits from STMT.
    ScalarArray getitem
    """

    def __init__(self, source_info, scalar_array, index_in, tik_debugger):
        """
        Initialize class GetitemScalarArray

        Parameters
        ----------
        source_info:source code information, It represents the relationship of current node with source code

        index_in:getitem index

        Returns
        ----------
        No returns
        """

        super(GetitemScalarArray, self).__init__(source_info, tik_debugger)
        self.scalar_array = scalar_array
        self.index_in = index_in

    def eval_(self, context):
        """
        Eval function
        evaluate all of self.function

        Parameters
        ----------
        context:information of debugger, store all of debugger's information

        Returns
        ----------
        No returns
        """
        index_in_eval = context.evaluate_expr(self.index_in)
        if index_in_eval < 0 or index_in_eval >= self.scalar_array.length:
            TikCheckUtil.raise_error(
                "index(%d) out of range, it should be in range [0, %d)." %
                (index_in_eval, self.scalar_array.length))


# tensor : scalar by ref
# tensor : tensor by ref
class SetTensor(STMT):
    """
    Class SetTensor inherits from STMT
    To set Tensor
    """

    def __init__(self, source_info, tensor, value, tik_debugger):
        """
        Initialize class SetTensor

        Parameters
        ----------
        source_info:source code information, It represents the relationship of current node with source code

        tensor:a type of tensor

        value:the value of tensor

        Returns
        ----------
        No returns
        """
        super(SetTensor, self).__init__(source_info, tik_debugger)
        self.tensor = tensor
        self.dtype = tensor.dtype
        self.value = value

    def _get_flatten(self, context):
        dst_tensor = self.tensor
        dst_tensor_buffer = context.tensor_buffer.get_npbuffer_by_tvmbuffer(
            dst_tensor.buffer).buffer
        dst_flatten_np = dst_tensor_buffer.reshape(-1).view(dst_tensor.dtype)
        dst_flatten_idx = get_flatten_idx(dst_tensor, context)
        if dst_flatten_idx >= len(dst_flatten_np):
            TikCheckUtil.raise_error(
                'IndexError: index {idx} out of range [0, {length})'.format(
                    idx=dst_flatten_idx, length=len(dst_flatten_np)))
        return dst_flatten_np, dst_flatten_idx

    def eval_(self, context):
        """
        Eval function
        evaluate all of self.function

        Parameters
        ----------
        context:information of debugger, store all of debugger's information

        Returns
        ----------
        No returns
        """
        dst_flatten_np, dst_flatten_idx = self._get_flatten(context)
        if is_tensor(self.value):
            self.eval_value_tensor(context, dst_flatten_np, dst_flatten_idx)
        else:
            if isinstance(self.value, BasicExpr):
                self.eval_value_scalar_expr(context, dst_flatten_np,
                                            dst_flatten_idx)
            else:
                dst_flatten_np[dst_flatten_idx] = self.value

    def eval_value_tensor(self, context, dst_flatten_np, dst_flatten_idx):
        """
        Eval function
        evaluate self.value when it's tensor

        Parameters
        ----------
        context:information of debugger, store all of debugger's information

        dst_flatten_np

        dst_flatten_idx

        Returns
        ----------
        dst_flatten_np
        """
        src_bitwidth = int(get_dtype_bit_width(self.value.dtype))
        dst_bitwidth = int(get_dtype_bit_width(self.dtype))
        src_tensor = self.value
        src_tensor_buffer = context.tensor_buffer.get_npbuffer_by_tvmbuffer(
            src_tensor.buffer).buffer
        src_flatten_np = src_tensor_buffer.reshape(-1).view(src_tensor.dtype)
        src_flatten_idx = get_flatten_idx(src_tensor, context)
        if src_flatten_idx >= len(src_flatten_np):
            TikCheckUtil.raise_error(
                'IndexError: index {idx} out of range [0, {length})'.format(
                    idx=src_flatten_idx, length=len(src_flatten_np)))
        py_value = src_flatten_np[src_flatten_idx]
        np_value = getattr(np, self.value.dtype)(py_value)

        if dst_bitwidth == src_bitwidth:
            dst_flatten_np[dst_flatten_idx] = py_value
        elif dst_bitwidth < src_bitwidth:
            ratio = src_bitwidth // dst_bitwidth
            dst_flatten_np[dst_flatten_idx: dst_flatten_idx + ratio] = np_value
        else:
            np_tmp_arr = np.asarray([dst_flatten_np[dst_flatten_idx]]) \
                .view(self.dtype)
            np_tmp_arr[0] = np_value
            dst_flatten_np[dst_flatten_idx] = np_tmp_arr.view(
                self.value.dtype)[0]

        return dst_flatten_np

    def eval_value_scalar_expr(self, context, dst_flatten_np, dst_flatten_idx):
        """
        Eval function
        evaluate self.value when it's scalar or expr

        Parameters
        ----------
        context:information of debugger, store all of debugger's information

        dst_flatten_np

        dst_flatten_idx

        Returns
        ----------
        dst_flatten_np
        """
        src_bitwidth = int(get_dtype_bit_width(self.value.dtype))
        dst_bitwidth = int(get_dtype_bit_width(str(dst_flatten_np.dtype)))
        py_value = context.evaluate_expr(self.value)

        if dst_bitwidth == src_bitwidth:
            dst_flatten_np[dst_flatten_idx] = py_value
        elif dst_bitwidth < src_bitwidth:
            np_value = getattr(np, self.value.dtype)([py_value])
            ratio = src_bitwidth // dst_bitwidth
            dst_flatten_np[dst_flatten_idx: dst_flatten_idx + ratio] = \
                np_value.view(str(dst_flatten_np.dtype))
        else:
            np_value = getattr(np, self.value.dtype)(py_value)
            np_tmp_arr = np.asarray([dst_flatten_np[dst_flatten_idx]]) \
                .view(self.value.dtype)
            np_tmp_arr[0] = np_value
            dst_flatten_np[dst_flatten_idx] = np_tmp_arr.view(
                dst_flatten_np.dtype)[0]
        return dst_flatten_np


class SetTensorAddr(SetTensor):
    """
    Class SetTensorAddr inherits from STMT
    To set Tensor
    """

    def eval_(self, context):
        """
        Eval function
        evaluate all of self.function

        Parameters
        ----------
        context:information of debugger, store all of debugger's information

        Returns
        ----------
        No returns
        """

        dst_flatten_np, dst_flatten_idx = self._get_flatten(context)
        if is_tensor(self.value) or is_tensor_addr_list(self.value):
            self.eval_value_tensor(context, dst_flatten_np, dst_flatten_idx)
        else:
            if isinstance(self.value, BasicExpr):
                self.eval_value_scalar_expr(context, dst_flatten_np, dst_flatten_idx)
            else:
                dst_flatten_np[dst_flatten_idx] = self.value


class DelLoopVar(STMT):
    """
    Class class DelLoopVar(STMT):
    inherits from STMT
    To del Loop Var
    """

    def __init__(self, source_info, loop_var, tik_debugger):
        """
        Initialize class DelLoopVar

        Parameters
        ----------
        source_info:source code information, It represents the relationship of current node with source code

        loop_var:loop var used in for range

        Returns
        ----------
        No returns
        """
        super(DelLoopVar, self).__init__(source_info, tik_debugger)
        self.loop_var = loop_var

    def eval_(self, context):
        """
        Eval function
        evaluate all of self.function

        Parameters
        ----------
        context:information of debugger, store all of debugger's information

        Returns
        ----------
        No returns
        """
        context.update_var(self.loop_var, None)


# tensor : scalar by ref
# tensor : tensor by ref
class GetAddr(STMT):
    """
    Class SetTensor inherits from STMT
    To set Tensor
    """

    def __init__(self, source_info, tensor, value, tik_debugger):
        """
        Initialize class SetTensor

        Parameters
        ----------
        source_info:source code information, It represents the relationship of current node with source code

        tensor:a type of tensor

        value:the value of tensor

        Returns
        ----------
        No returns
        """
        super(GetAddr, self).__init__(source_info, tik_debugger)
        self.value = value
        self.tensor = tensor
        self.dtype = tensor.dtype

    def eval_(self, context):
        """
        Eval function
        evaluate all of self.function

        Parameters
        ----------
        context:information of debugger, store all of debugger's information

        Returns
        ----------
        No returns
        """
        dst_tensor = self.tensor
        dst_tensor_buffer = context.tensor_buffer.get_npbuffer_by_tvmbuffer(dst_tensor.buffer).buffer
        dst_flatten_np = dst_tensor_buffer.reshape(-1).view(dst_tensor.dtype)
        dst_flatten_idx = get_flatten_idx(dst_tensor, context)
        if dst_flatten_idx >= len(dst_flatten_np):
            TikCheckUtil.raise_error('IndexError: index {idx} out of range [0, {length})'.format(
                idx=dst_flatten_idx, length=len(dst_flatten_np)))

        self.eval_value_tensor(context, dst_flatten_np, dst_flatten_idx)

    def eval_value_tensor(self, context, dst_flatten_np, dst_flatten_idx):
        """
        Eval function
        evaluate self.value when it's tensor

        Parameters
        ----------
        context:information of debugger, store all of debugger's information

        dst_flatten_np

        dst_flatten_idx

        Returns
        ----------
        dst_flatten_np
        """
        temp_env = TempEnv()
        src_tensor = self.value
        src_tensor_buffer = context.tensor_buffer.get_npbuffer_by_tvmbuffer(
            src_tensor.buffer).buffer
        src_flatten_np = src_tensor_buffer.reshape(-1).view(src_tensor.dtype)
        src_flatten_idx = get_flatten_idx(src_tensor, context)
        old_check_align = temp_env.check_align
        temp_env.check_align = False
        _, dst_addr, dst_alloc_size, _ = copy_tensor_to_model(
            context, temp_env, src_tensor, 4, access_mode='r')
        temp_env.check_align = old_check_align
        if self.value.buffer not in context.buffer_list:
            context.buffer_list.append(self.value.buffer)
            context.buffer_cache[self.value] = [dst_addr, dst_alloc_size, src_flatten_idx]
        # calculate src address in buffer_cache: calculate allocated size before current cache
        dst_addr = 0
        for key, value in context.buffer_cache.items():
            if key.buffer != self.value.buffer:
                dst_addr += value[1]
            else:
                break
        if src_flatten_idx >= len(src_flatten_np):
            TikCheckUtil.raise_error(
                'IndexError: index {idx} out of range [0, {length})'.format(
                    idx=src_flatten_idx, length=len(src_flatten_np)))
        py_value = dst_addr + src_flatten_idx * DTYPE_SIZE[self.value.dtype]

        dst_flatten_np[dst_flatten_idx] = py_value


class VectorDef(STMT):
    """
    def vector
    """

    def __init__(self, source_info, vector, tik_debugger):
        """
        Initialize class VectorDef

        Parameters
        ----------
        source_info:source code information, It represents the relationship of current node with source code

        tensor:source tensor

        Returns
        ----------
        No returns
        """
        super(VectorDef, self).__init__(source_info, tik_debugger)
        self.vector = vector

    def eval_(self, context):
        """
        Eval function
        evaluate all of self.function

        Parameters
        ----------
        context:information of debugger, store all of debugger's information

        Returns
        ----------
        No returns
        """
        vector_buffer = context.get_vector_value(self.vector)
        if vector_buffer.buffer is None:
            vector_buffer.buffer = get_uninited_buffer(
                (context, vector_buffer.shape, vector_buffer.dtype),
                context.init_mode, context.init_value)
