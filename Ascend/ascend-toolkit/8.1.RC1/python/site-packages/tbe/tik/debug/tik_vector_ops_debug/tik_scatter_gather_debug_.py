#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_scatter_gather_debug_.py
DESC:     provide params
CREATED:  2021-11-23 16:40:42
MODIFIED: 2021-11-29 15:17:35
"""
from tbe.tik.debug.sim.util import TempEnv
from tbe.tik.debug.util import get_dtype_size
from tbe.tik.debug.util import copy_tensor_to_model
from tbe.tik.debug.util import set_vector_mask
from tbe.tik.debug.util import get_dtype_bit_width
from tbe.tik.debug.statement import STMT
from tbe.tik.debug.simd import set_mask_counter_mode
from tbe.tik.common.common_util import vec_template_align
from tbe.tik.common.common_check_func import split_rep_stride
from tbe.tik.common.util import get_bit_len
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.util import reduce_mul
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_params import ALIGNED_ADDR
from tbe.tik.tik_lib.tik_params import MAX_BLK_STRIDE_SINGLE_BYTE
from tbe.tik.tik_lib.tik_params import MAX_REP_STRIDE_12_BITS
from tbe.tik.tik_lib.tik_params import ONE_REP_BYTE_SIZE
from tbe.tik.tik_lib.tik_params import MAX_INT32_VALUE
from tbe.tik.tik_lib.tik_params import INDEX_IN_START
from tbe.tik.tik_lib.tik_params import MASK_VALUE_64
from tbe.tik.tik_lib.tik_params import MASK_VALUE_128
from tbe.tik.tik_lib.tik_params import DST_REPEAT_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import SRC_REPEAT_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import STRIDE_UNIT_SHIFT_POS
from tbe.tik.tik_lib.tik_params import REPEAT_SHIFT_POS
from tbe.tik.tik_lib.tik_params import MAX_REP_STRIDE_SINGLE_BYTE
from tbe.tik.tik_lib.tik_params import MAX_REPEAT_TIMES

_VSCATTER_TYPE = {
    2: 0b0,
    4: 0b1
}
_DST_BLK_STRIDE_SHIFT_POS = 40
_DST_REPEAT_STRIDE_HIGH_SHIFT_POS = 52


class VScatter(STMT):
    """
    VScatter instruction
    """

    def __init__(self, source_info, op_obj):
        super(VScatter, self).__init__(source_info, op_obj.tik_instance.context.tik_debugger)
        self.op_obj = op_obj
        self.base_addr = op_obj.base_addr
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return
        self.op_obj.dst_tensor_op.set_context(context)
        self.op_obj.dst_offset_tensor_op.set_context(context)
        self.op_obj.src_tensor_op.set_context(context)
        self.op_obj.src_tensor_op.set_rep_stride_value()
        mask = self.op_obj.control_op.mask

        src_dtype_size = get_dtype_size(self.op_obj.src_tensor_op.tensor_obj.dtype)
        src_align = src_dtype_size
        temp_env = TempEnv()

        _, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.op_obj.dst_tensor_op.tensor_obj, ALIGNED_ADDR, access_mode="w")
        xd_idx, _, dst_offset_size, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.dst_offset_tensor_op.tensor_obj, src_align, access_mode="r")
        orig_ctrl_value = None
        if self.op_obj.control_op.mask_mode == "counter":
            orig_ctrl_value = set_mask_counter_mode(context)

        set_vector_mask(mask, context, self.op_obj.control_op.mask_mode,
                        tensor_bit_len=max(get_bit_len(self.op_obj.dst_tensor_op.tensor_obj.dtype),
                                           get_bit_len(self.op_obj.src_tensor_op.tensor_obj.dtype)))
        param = context.encoder.new_param()
        param.xd = xd_idx
        param.xt = self.create_gpr_x_t(context, temp_env, dst_addr)
        param.xn = self.create_gpr_x_n(context, temp_env, src_align, dst_offset_size)
        param.type = _VSCATTER_TYPE.get(src_dtype_size)
        instr = context.encoder.gen_vscatter(param)
        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

        # mask: counter_mode, reset CTRL as orig_ctrl_value
        if self.op_obj.control_op.mask_mode == "counter":
            context.model.write_spr('CTRL', orig_ctrl_value)
        context.model.read_memory(dst_addr, self.op_obj.dst_tensor_op.tensor_obj.scope, dst_ptr, dst_alloc_size)

    def create_gpr_x_n(self, context, temp_env, src_align, dst_offset_size):
        """
        create general purpose register x_n

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        src_align : src tensor addr align byte

        dst_offset_size: dst_offset buffer size

        Returns
        -------
        xt_idx
        """
        xn_idx, _, src_buffer_size, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src_tensor_op.tensor_obj, src_align, access_mode="r")

        if self.op_obj.control_op.mask_mode == "normal":
            # all elements in src are read even their mask bits are invalid
            if get_dtype_bit_width(self.op_obj.src_tensor_op.tensor_obj.dtype) == '32':
                mask_len = MASK_VALUE_64
            else:
                mask_len = MASK_VALUE_128
        else:
            mask_len = self.op_obj.control_op.mask
        stride_unit = context.evaluate_expr(self.op_obj.control_op.stride_unit)
        # stride_unit: 0,1 for stride, unit is 32B
        self.op_obj.dst_offset_tensor_op.blk_stride = 1
        self.op_obj.dst_offset_tensor_op.rep_stride = 8
        self.op_obj.control_op.mask = mask_len
        # check dst_offset read mem.
        # change offset dtype temporarily, for check overflow
        self.op_obj.control_op.stride_unit = 0
        self.op_obj.dst_offset_tensor_op.tensor_obj.dtype = self.op_obj.src_tensor_op.tensor_obj.dtype
        self.op_obj.dst_offset_tensor_op.check_read_mem_out_of_bounds(dst_offset_size, self.op_obj.control_op)
        # reset dst_offset dtype: int32
        self.op_obj.control_op.stride_unit = stride_unit
        self.op_obj.dst_offset_tensor_op.tensor_obj.dtype = "int32"

        if stride_unit in (2, 3):
            # stide_unit:2,3 for gap, unit is element
            self.op_obj.src_tensor_op.blk_stride = 0
        self.op_obj.src_tensor_op.check_read_mem_out_of_bounds(src_buffer_size, self.op_obj.control_op)
        return xn_idx

    def create_gpr_x_t(self, context, temp_env, dst_addr):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        dst_addr : dst tensor addr

        Returns
        -------
        xt_idx
        """

        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)
        base_addr = context.evaluate_expr(self.base_addr)

        base_addr_offset = base_addr + dst_addr

        # default dst_rep_stride: 0
        dst_rep_stride = 0
        src_rep_stride = context.evaluate_expr(self.op_obj.src_tensor_op.rep_stride)

        # check repeat_times
        TikCheckUtil.check_in_range_by_dtype(
            repeat, msg="repeat_times should be in the range of [%d, %d], input repeat_times: %s"
            % (0, MAX_REPEAT_TIMES, repeat), var_range=[0, MAX_REPEAT_TIMES])
        # check strides
        self.op_obj.src_tensor_op.check_tensor_op_rep_stride(MAX_REP_STRIDE_SINGLE_BYTE)
        TikCheckUtil.check_in_range_by_dtype(
            base_addr, msg="base_addr should be in range of [%d, %d]. input base_addr: %s"
            % (INDEX_IN_START, MAX_INT32_VALUE, base_addr), var_range=[INDEX_IN_START, MAX_INT32_VALUE])
        # check valid
        dst_scope_size = reduce_mul(self.op_obj.dst_tensor_op.tensor_obj.original_shape) * get_dtype_size(
            self.op_obj.dst_tensor_op.tensor_obj.dtype)
        TikCheckUtil.check_le(base_addr, context.evaluate_expr(dst_scope_size),
                              "base_addr should be less equal than dst tensor's buffer size: %s,"
                              " input base_add: %s" % (dst_scope_size, base_addr))

        xt_idx = temp_env.alloc_register()
        x_t = int(base_addr_offset)
        x_t |= dst_rep_stride << DST_REPEAT_STRIDE_SHIFT_POS
        x_t |= src_rep_stride << SRC_REPEAT_STRIDE_SHIFT_POS
        x_t |= context.evaluate_expr(self.op_obj.control_op.stride_unit) << STRIDE_UNIT_SHIFT_POS
        x_t |= repeat << REPEAT_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)
        return xt_idx


class VGather(STMT):
    """
    VGather instruction
    """

    def __init__(self, source_info, op_obj):
        super(VGather, self).__init__(source_info, op_obj.tik_instance.context.tik_debugger)
        self.op_obj = op_obj
        self.base_addr = op_obj.base_addr
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return
        self.op_obj.dst_tensor_op.set_context(context)
        self.op_obj.src_offset_tensor_op.set_context(context)
        self.op_obj.src_tensor_op.set_context(context)
        self.op_obj.dst_tensor_op.set_rep_stride_value()
        mask = self.op_obj.control_op.mask

        dst_align = get_dtype_size(self.op_obj.dst_tensor_op.tensor_obj.dtype)
        temp_env = TempEnv()

        _, src_addr, _, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src_tensor_op.tensor_obj, ALIGNED_ADDR, access_mode="r")

        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.op_obj.dst_tensor_op.tensor_obj, dst_align, access_mode="w")

        orig_ctrl_value = None
        if self.op_obj.control_op.mask_mode == "counter":
            orig_ctrl_value = set_mask_counter_mode(context)

        set_vector_mask(mask, context, self.op_obj.control_op.mask_mode,
                        tensor_bit_len=max(get_bit_len(self.op_obj.src_tensor_op.tensor_obj.dtype),
                                           get_bit_len(self.op_obj.dst_tensor_op.tensor_obj.dtype)))

        param = context.encoder.new_param()
        param.xd = xd_idx
        param.xt = self.create_gpr_x_t(context, temp_env, src_addr)
        param.xn = self.create_gpr_x_n(context, temp_env)
        param.type = _VSCATTER_TYPE.get(get_dtype_size(self.op_obj.dst_tensor_op.tensor_obj.dtype))

        instr = context.encoder.gen_vgather(param)

        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

        # mask: counter_mode, reset CTRL as orig_ctrl_value
        if self.op_obj.control_op.mask_mode == "counter":
            context.model.write_spr('CTRL', orig_ctrl_value)

        context.model.read_memory(
            dst_addr, self.op_obj.dst_tensor_op.tensor_obj.scope, dst_ptr, dst_alloc_size)

    def create_gpr_x_n(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment

        Returns
        -------
        xn_idx
        """
        xn_idx, _, src_offset_buffer_size, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src_offset_tensor_op.tensor_obj, ALIGNED_ADDR, access_mode="r")

        self.op_obj.src_offset_tensor_op.blk_stride = 1
        self.op_obj.src_offset_tensor_op.rep_stride = 8
        # stride_unit: 0,1 for stride, unit is 32B.
        if self.op_obj.control_op.mask_mode == "normal":
            # all elements in src are read even their mask bits are invalid
            if get_dtype_bit_width(self.op_obj.src_tensor_op.tensor_obj.dtype) == '32':
                self.op_obj.control_op.mask = MASK_VALUE_64
            else:
                self.op_obj.control_op.mask = MASK_VALUE_128
        # check src_offset read mem.
        # change offset dtype temporarily, for check overflow
        self.op_obj.src_offset_tensor_op.tensor_obj.dtype = self.op_obj.src_tensor_op.tensor_obj.dtype
        self.op_obj.src_offset_tensor_op.check_read_mem_out_of_bounds(src_offset_buffer_size, self.op_obj.control_op)
        # reset src_offset dtype: int32
        self.op_obj.src_offset_tensor_op.tensor_obj.dtype = "int32"

        return xn_idx

    def create_gpr_x_t(self, context, temp_env, src_addr):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment
        src_addr : src tensor addr

        Returns
        -------
        xt_idx
        """
        base_addr = context.evaluate_expr(self.base_addr)
        base_addr_offset = base_addr + src_addr
        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)
        dst_rep_stride = context.evaluate_expr(self.op_obj.dst_tensor_op.rep_stride)
        # default src_rep_stride: 0
        src_rep_stride = 0

        # check repeat_times
        TikCheckUtil.check_in_range_by_dtype(
            repeat, msg="repeat_times should be in the range of [%d, %d], input repeat_times: %s"
            % (0, MAX_REPEAT_TIMES, repeat),
            var_range=[0, MAX_REPEAT_TIMES])
        # check strides
        self.op_obj.dst_tensor_op.check_tensor_op_rep_stride(MAX_REP_STRIDE_SINGLE_BYTE)

        # check base_addr
        # 2**31 - 1 is max base_addr, 31 bit len
        TikCheckUtil.check_in_range_by_dtype(
            base_addr, msg="base_addr should be in range of [%d, %d]. input base_addr: %s"
            % (INDEX_IN_START, MAX_INT32_VALUE, base_addr), var_range=[INDEX_IN_START, MAX_INT32_VALUE])
        # check valid
        src_scope_size = reduce_mul(self.op_obj.src_tensor_op.tensor_obj.original_shape) * get_dtype_size(
            self.op_obj.dst_tensor_op.tensor_obj.dtype)
        TikCheckUtil.check_le(base_addr, context.evaluate_expr(src_scope_size),
                              "base_addr should be less equal than src tensor's buffer size: %s, input base_add: %s"
                              % (src_scope_size, base_addr))

        xt_idx = temp_env.alloc_register()
        x_t = int(base_addr_offset)
        x_t |= dst_rep_stride << DST_REPEAT_STRIDE_SHIFT_POS
        x_t |= src_rep_stride << SRC_REPEAT_STRIDE_SHIFT_POS
        x_t |= context.evaluate_expr(self.op_obj.control_op.stride_unit) << STRIDE_UNIT_SHIFT_POS
        x_t |= repeat << REPEAT_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)
        return xt_idx


class VGatherb(STMT):
    """
    VGatherb instruction
    """

    def __init__(self, source_info, op_obj):
        super(VGatherb, self).__init__(source_info, op_obj.tik_instance.context.tik_debugger)
        self.op_obj = op_obj
        self.mask = ONE_REP_BYTE_SIZE // DTYPE_SIZE.get(self.op_obj.dst_tensor_op.tensor_obj.dtype)
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        self.op_obj.dst_tensor_op.set_context(context)
        self.op_obj.src_offsets_tensor_op.set_context(context)
        self.op_obj.src_offsets_tensor_op.set_repeat_times(self.op_obj.control_op.repeat_times)
        self.op_obj.src_offsets_tensor_op.set_original_shape()

        temp_env = TempEnv()

        # check UB addr 32B align
        self.op_obj.dst_tensor_op.check_tensor_op_address_align(self.op_obj.name)
        self.op_obj.src_tensor_op.check_tensor_op_address_align(self.op_obj.name)
        self.op_obj.src_offsets_tensor_op.check_tensor_op_address_align(self.op_obj.name)
        align = vec_template_align(self.op_obj.src_tensor_op.tensor_obj.dtype)

        self.op_obj.src_offsets_tensor_op.chenk_debug_repeat_times()

        # check strides
        self.op_obj.dst_tensor_op.set_rep_stride_value()
        self.op_obj.dst_tensor_op.set_blk_stride_value()
        self.op_obj.dst_tensor_op.check_tensor_op_blk_stride(MAX_BLK_STRIDE_SINGLE_BYTE)
        self.op_obj.dst_tensor_op.check_tensor_op_rep_stride(MAX_REP_STRIDE_12_BITS)

        # check dst tensor overflow
        self.op_obj.dst_tensor_op.check_vgatherb_tensor_overflow(
            self.op_obj.print_name,
            self.op_obj.src_tensor_op, self.op_obj.control_op, context)
        # check src_offsets overflow.
        self.op_obj.src_offsets_tensor_op.check_vgatherb_overflow_with_fixed_length(self.op_obj.control_op)
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return

        _, src_addr, _, _ = copy_tensor_to_model(
            context, temp_env,  self.op_obj.src_tensor_op.tensor_obj, ALIGNED_ADDR, access_mode="r")
        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env,  self.op_obj.dst_tensor_op.tensor_obj, align, access_mode="w")

        param = context.encoder.new_param()
        param.xd = xd_idx

        param.xn = self.create_gpr_x_n(context, temp_env)
        param.xt = self.create_gpr_x_t(context, temp_env, src_addr)
        param.type = 0
        param.subOp = 0b011

        instr = context.encoder.gen_vgatherb(param)
        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

        context.model.read_memory(dst_addr, self.op_obj.dst_tensor_op.tensor_obj.scope, dst_ptr, dst_alloc_size)

    def create_gpr_x_n(self, context, temp_env):
        """
        create general purpose register x_n

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment

        Returns
        -------
        xn_idx
        """
        align = get_dtype_size(self.op_obj.src_offsets_tensor_op.tensor_obj.dtype)
        xn_idx, _, _, _ = copy_tensor_to_model(context, temp_env,
                                               self.op_obj.src_offsets_tensor_op.tensor_obj, align, access_mode="r")

        return xn_idx

    def create_gpr_x_t(self, context, temp_env, src_addr):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment
        src_addr : src tensor addr

        Returns
        -------
        xt_idx
        """
        dst_blk_stride = context.evaluate_expr(self.op_obj.dst_tensor_op.blk_stride)
        dst_rep_stride = context.evaluate_expr(self.op_obj.dst_tensor_op.rep_stride)
        base_addr = context.evaluate_expr(self.op_obj.src_tensor_op.tensor_obj.offset)
        base_addr_offset = base_addr * DTYPE_SIZE.get(self.op_obj.src_tensor_op.tensor_obj.dtype)
        base_addr_offset = base_addr_offset + src_addr

        xt_idx = temp_env.alloc_register()
        dst_rep_stride_low, dst_rep_stride_high = split_rep_stride(dst_rep_stride)
        x_t = int(base_addr_offset)
        x_t |= dst_rep_stride_low << DST_REPEAT_STRIDE_SHIFT_POS
        x_t |= dst_blk_stride << _DST_BLK_STRIDE_SHIFT_POS
        x_t |= dst_rep_stride_high << _DST_REPEAT_STRIDE_HIGH_SHIFT_POS
        x_t |= self.op_obj.src_offsets_tensor_op.repeat_times_value << REPEAT_SHIFT_POS
        context.model.write_gpr(xt_idx, x_t)
        return xt_idx
