#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     intrinsic_v210.py
DESC:     debug intrinsic_v210
CREATED:  2019-7-04 20:12:13
MODIFIED: 2019-7-24 10:54:23
"""

from tbe.tik.tik_lib.tik_params import MAX_COEFF
from tbe.tik.common.common_util import check_param_type_range
from tbe.tik.debug.intrinsic_v210_common import FIFR1_TYPE
from tbe.tik.debug.intrinsic_v210_common import VEC_SCALAR_ELEWISE_TYPE_BITS
from tbe.tik.debug.intrinsic_v210_common import eval_expr_seq
from tbe.common.platform import scope_wreg
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.util import reduce_mul
from tbe.tik.common.util import WDTYPE_TO_DTYPE
from tbe.tik.debug.statement import STMT
from tbe.tik.debug.util import copy_tensor_to_model
from tbe.tik.debug.sim.util import TempEnv
from tbe.tik.debug.util import get_flatten_idx
from tbe.tik.debug.util import VecRegType
from tbe.tik.tik_lib.tik_expr import Expr
from tbe.tik.tik_lib.tik_params import WREG_START_INDEX
from tbe.tik.tik_lib.tik_params import DTYPE_IMM_MIN
from tbe.tik.tik_lib.tik_params import DTYPE_IMM_MAX
from tbe.tik.tik_lib.tik_params import VL_T_MAP
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.debug.intrinsic_v210_common import VEC_TYPE_BITS
from tbe.tik.debug.intrinsic_v210_common import VCI_TYPE_BITS
from tbe.tik.debug.intrinsic_v210_common import V300_INSTR_OP1_CODE
from tbe.tik.debug.intrinsic_v210_common import V300_INSTR_REGTYPE_CODE
from tbe.tik.debug.intrinsic_v210_common import VEC_TYPE_THREE_BITS
from tbe.tik.debug.intrinsic_v210_common import WIDE_TYPE_THREE_BITS
from tbe.tik.debug.intrinsic_v210_common import WIDE_VD_INDEX_BITS
from tbe.tik.debug.intrinsic_v210_common import SOURCE_REGISTER1
from tbe.tik.debug.intrinsic_v210_common import PARAMETERS
from tbe.tik.debug.intrinsic_v210_common import V210_INSTR_OP1_CODE
from tbe.tik.debug.intrinsic_v210_common import dst_register
from tbe.tik.debug.intrinsic_v210_common import get_and_write_share_spr
from tbe.tik.debug.intrinsic_v210_common import set_param_loop_vex_num_dtype
from tbe.tik.debug.intrinsic_v210_common import create_vloop_info
from tbe.tik.debug.intrinsic_v210_common import execute_all_instr


def check_fifr_overflow(context, fifr_params, line_num, dst_stride, src_stride):
    """
    check fifr param and  tensor overflow  dst, src, window_size dst_offset, src_offset, api_name
    """
    dst_offset = context.evaluate_expr(fifr_params.dst.offset)
    src_offset = context.evaluate_expr(fifr_params.src.offset)
    # check overflow
    if fifr_params.window_size == 0:
        win_size = 3
    else:
        win_size = 5
    vl_static = 64
    # check src
    need_ele = (line_num - 1) * (src_stride * 32 // DTYPE_SIZE[fifr_params.src.dtype]) + \
               (vl_static + win_size - 1)
    src_extent_offset = Expr(src_offset + need_ele).eval_value()
    src_total_size = reduce_mul(fifr_params.src.original_shape)
    if src_extent_offset is not None:
        TikCheckUtil.check_le(
            src_extent_offset, src_total_size,
            "%s's src tensor overflow, src need %s element, but only "
            "%s" % (fifr_params.api_name, src_extent_offset, src_total_size))
    # check dst
    dst_need = vl_static + (line_num - win_size) * dst_stride * 32 // DTYPE_SIZE[fifr_params.dst.dtype]
    dst_extent_offset = Expr(dst_offset + dst_need).eval_value()
    dst_total_size = reduce_mul(fifr_params.dst.original_shape)
    if dst_extent_offset is not None:
        TikCheckUtil.check_le(
            dst_extent_offset, dst_total_size,
            "%s's dst tensor overflow, dst need %s element, but only "
            "%s" % (fifr_params.api_name, dst_extent_offset, dst_total_size))


class Fifr1(STMT):
    """
    DataMove instruction
    """

    def __init__(self, source_info, fifr1_params, tik_instance):
        super(Fifr1, self).__init__(source_info, tik_instance.context.tik_debugger)
        self.dst = fifr1_params.dst
        self.src = fifr1_params.src
        self.window_size = fifr1_params.window_size
        self.line_num = fifr1_params.line_num
        self.dst_stride = fifr1_params.dst_stride
        self.src_stride = fifr1_params.src_stride
        self.r1c1 = fifr1_params.r1c1
        self.r1c2 = fifr1_params.r1c2
        self.r1c3 = fifr1_params.r1c3
        self.r1c4 = fifr1_params.r1c4
        self.r1c5 = fifr1_params.r1c5
        self.r1t = fifr1_params.r1t
        self.r2t = fifr1_params.r2t
        self.r3t = fifr1_params.r3t
        self.r4t = fifr1_params.r4t
        self.r5t = fifr1_params.r5t
        self.rsah = fifr1_params.rsah
        self.rsa = fifr1_params.rsa
        self.api_name = "vector_filter1d"

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        temp_env = TempEnv()
        # dst and src are 32B align
        align = 32
        xn_idx, _, _, _ = copy_tensor_to_model(
            context, temp_env, self.src, align, access_mode='r')

        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.dst, align, access_mode='w')
        param = context.encoder.new_vec_param()
        param.xdIdx = xd_idx
        param.xnIdx = xn_idx
        param.xmIdx = self.create_gpr_x_m(context, temp_env)
        param.xtIdx = self.create_gpr_x_t(context, temp_env)
        param.type = FIFR1_TYPE.get(self.src.dtype)
        instr_h32 = context.encoder.gen_fifr1_h32(param)
        context.model.step(instr_h32)
        instr_l32 = context.encoder.gen_fifr1_l32(param)
        context.model.step(instr_l32)
        temp_env.check_mem_access(context.model, False)

        context.model.read_memory(
            dst_addr, self.dst.scope, dst_ptr, dst_alloc_size)

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        r1t, r2t, r3t, r4t, r5t, rsah, rsa, *_ = \
            eval_expr_seq(context, (self.r1t, self.r2t, self.r3t, self.r4t, self.r5t, self.rsah, self.rsa))
        # check coeff
        check_param_type_range(
            [r1t, r2t, r3t, r4t, r5t],
            [-16, -16, -16, -16, -16],
            [15, 15, 15, 15, 15],
            ["r1t", "r2t", "r3t", "r4t", "r5t"], self.api_name)
        # check sid
        check_param_type_range([rsah, rsa], [0, 0],
                               [7, 7], ["rsah", "rsa"], self.api_name)
        xt_idx = temp_env.alloc_register()
        x_t = (r1t & MAX_COEFF)
        x_t |= (r2t & MAX_COEFF) << 5
        x_t |= (r3t & MAX_COEFF) << 10
        x_t |= (r4t & MAX_COEFF) << 15
        x_t |= (r5t & MAX_COEFF) << 20
        x_t |= rsah << 25
        x_t |= rsa << 28

        context.model.write_gpr(xt_idx, x_t)

        return xt_idx

    def check_line_num_tensor_stride(self, line_num, dst_stride, src_stride):
        """
        check line num and tensor stride
        Parameters
        ----------
        line_num
        dst_stride
        src_stride

        Returns
        -------

        """
        line_num_min = (3, 5)
        # check line_num, dst_stride, src_stride
        check_param_type_range(
            [line_num, dst_stride, src_stride],
            [line_num_min[self.window_size], 0, 0], [255, 255, 255],
            ["line_num", "dst_stride", "src_stride"], self.api_name)

    def create_gpr_x_m(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """

        r1c1, r1c2, r1c3, r1c4, r1c5, line_num, dst_stride, src_stride, *_ = \
            eval_expr_seq(
                context, (self.r1c1, self.r1c2, self.r1c3,
                          self.r1c4, self.r1c5,
                          self.line_num, self.dst_stride,
                          self.src_stride))
        self.check_line_num_tensor_stride(line_num, dst_stride, src_stride)
        # check overflow
        check_fifr_overflow(context, self, line_num, dst_stride, src_stride)
        # check coeff
        check_param_type_range(
            [r1c1, r1c2, r1c3, r1c4, r1c5],
            [-16, -16, -16, -16, -16],
            [15, 15, 15, 15, 15],
            ["r1c1", "r1c2", "r1c3", "r1c4", "r1c5"], self.api_name)

        xm_idx = temp_env.alloc_register()
        x_m = context.evaluate_expr(self.window_size)
        x_m |= src_stride << 8
        x_m |= line_num << 16
        x_m |= dst_stride << 24

        x_m |= (r1c1 & MAX_COEFF) << 32
        x_m |= (r1c2 & MAX_COEFF) << 37
        x_m |= (r1c3 & MAX_COEFF) << 42
        x_m |= (r1c4 & MAX_COEFF) << 47
        x_m |= (r1c5 & MAX_COEFF) << 52
        context.model.write_gpr(xm_idx, x_m)

        return xm_idx


class FmaxFmin(STMT):
    """
    MaxFilter/MinFilter instruction
    """

    def __init__(self, source_info, fmaxmin_params, tik_instance):
        super(FmaxFmin, self).__init__(source_info, tik_instance.context.tik_debugger)
        self.dst = fmaxmin_params.dst
        self.src = fmaxmin_params.src
        self.window_size = fmaxmin_params.window_size
        self.line_num = fmaxmin_params.line_num
        self.dst_stride = fmaxmin_params.dst_stride
        self.src_stride = fmaxmin_params.src_stride
        self.instr_name = fmaxmin_params.instr_name
        self.api_name = None
        if self.instr_name == "maxfilter":
            self.api_name = "vector_filter_max"
        elif self.instr_name == "minfilter":
            self.api_name = "vector_filter_min"
        self.fmaxmin_params = fmaxmin_params

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        temp_env = TempEnv()
        # dst and src are 32B align
        align = 32
        xn_idx, _, _, _ = copy_tensor_to_model(context, temp_env, self.src, align, access_mode='r')

        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.dst, align, access_mode='w')
        param = context.encoder.new_vec_param()
        param.xdIdx = xd_idx
        param.xnIdx = xn_idx
        param.xmIdx = self.create_gpr_x_m(context, temp_env)
        param.type = 0
        if self.instr_name == "maxfilter":
            param.op1 = 0x8
        elif self.instr_name == "minfilter":
            param.op1 = 0x9
        instr_h32 = context.encoder.gen_fifr1_h32(param)
        context.model.step(instr_h32)

        instr_l32 = context.encoder.gen_fmaxfmin_l32(param)
        context.model.step(instr_l32)
        temp_env.check_mem_access(context.model, False)

        context.model.read_memory(
            dst_addr, self.dst.scope, dst_ptr, dst_alloc_size)

    def check_line_num_tensor_stride(self, line_num, dst_stride, src_stride):
        """
        check line num and tensor stride
        Parameters
        ----------
        line_num
        dst_stride
        src_stride

        Returns
        -------

        """
        line_num_min = (3, 5)
        # check line_num, dst_stride, src_stride
        check_param_type_range(
            [line_num, dst_stride, src_stride],
            [line_num_min[self.window_size], 0, 0], [255, 255, 255],
            ["line_num", "dst_stride", "src_stride"], self.api_name)

    def create_gpr_x_m(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        line_num = context.evaluate_expr(self.line_num)
        dst_stride = context.evaluate_expr(self.dst_stride)
        src_stride = context.evaluate_expr(self.src_stride)
        self.check_line_num_tensor_stride(line_num, dst_stride, src_stride)
        # check overflow
        check_fifr_overflow(context, self, line_num, dst_stride, src_stride)

        xm_idx = temp_env.alloc_register()
        x_m = context.evaluate_expr(self.window_size)
        x_m |= src_stride << 8
        x_m |= line_num << 16
        x_m |= dst_stride << 24
        context.model.write_gpr(xm_idx, x_m)

        return xm_idx


class VectorVpd(STMT):
    """
    Vector Vpd instruction, only for set the vector buffer value
    """

    def __init__(self, source_info, vec_mask, dtype, tik_debugger):
        super(VectorVpd, self).__init__(source_info, tik_debugger)
        self.mask = vec_mask
        self.dtype = dtype

    def set_pd_index(self, context):
        """
        set Pd index
        Returns
        -------

        """
        context.vpd_preg_full(self.mask, self.dtype)

    def eval_(self, context):
        """
        VectorVpd eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        self.set_pd_index(context)

        # update the register cache state to true
        context.set_vector_state(self.mask, is_valid=True)
        context.free_all_register()


class VectorElewiseScalar(STMT):
    """
    Vector Elewise Scalar instruction
    """

    def __init__(self, source_info, vector_params, tik_debugger):
        super(VectorElewiseScalar, self).__init__(source_info, tik_debugger)
        self.dst = vector_params.dst
        self.src = vector_params.src
        self.mask = vector_params.mask
        self.scalar_value = vector_params.scalar
        self.instr_name = vector_params.name

    def set_param(self, context, param):
        """
        set param
        Parameters
        ----------
        context
        param

        Returns
        -------

        """
        # vsadds only support s16
        if self.instr_name == "vectorized_vsadds":
            param.type = PARAMETERS.get(self.instr_name)  # 0b000
        elif self.instr_name in ["vectorized_vaxpy", "vectorized_vrnds", "vectorized_vlrelu"]:
            if TikSocManager.is_v300_610l_soc():
                param.type = VEC_TYPE_THREE_BITS.get(self.dst.dtype)
            else:
                param.type = PARAMETERS.get(self.instr_name) | VEC_SCALAR_ELEWISE_TYPE_BITS.get(self.src.dtype)
        else:
            param.type = VEC_TYPE_THREE_BITS.get(self.dst.dtype)
        if TikSocManager.is_v300_610l_soc():
            param.op1 = V300_INSTR_OP1_CODE.get(self.instr_name)
        else:
            param.op1 = V210_INSTR_OP1_CODE.get(self.instr_name)
        pg_idx = context.alloc_p_register(self.mask, dtype=self.src.dtype)
        param.pgIdx = pg_idx

        vd_idx = context.alloc_v_register(self.dst)
        param.vdIdx = vd_idx

        vn_idx = context.alloc_v_register(self.src)
        param.vnIdx = vn_idx
        return param, vd_idx

    def eval_(self, context):
        """
        Vector ElewiseScalar eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        TempEnv()
        param = set_param_loop_vex_num_dtype(context, self.dst.dtype, 0, 1)
        instr_list = create_vloop_info(context, param)
        sm_idx = get_and_write_share_spr(context, self.scalar_value,
                                         self.dst.dtype)
        param.smIdx = sm_idx
        param, vd_idx = self.set_param(context, param)

        if TikSocManager.is_v300_610l_soc() and self.instr_name == "vectorized_vrnds":
            param.type = VCI_TYPE_BITS.get(self.dst.dtype)

        instr = context.encoder.gen_vector_elewise_scalar(param)
        execute_all_instr(context, instr_list, instr)

        dst_register(context, (self.dst, vd_idx, VecRegType.V_REG), self.mask)
        context.set_vector_state(self.dst, is_valid=True)
        context.free_all_register()


class VectorInitial(STMT):
    """
    Vector vbr/vci instruction
    """

    def __init__(self, source_info, ini_params, tik_debugger):
        super(VectorInitial, self).__init__(source_info, tik_debugger)
        self.dst = ini_params.dst
        self.init_value = ini_params.src
        self.instr_name = ini_params.name
        self.api_name = ini_params.api_name

    def set_param(self, context, param):
        """
        set param
        Parameters
        ----------
        context
        param

        Returns
        -------

        """
        if self.instr_name == "vectorized_vci":
            if TikSocManager.is_v300_610l_soc():
                param.type = VEC_TYPE_THREE_BITS.get(self.dst.dtype)
            else:
                param.type = VCI_TYPE_BITS.get(self.dst.dtype)
            # just use vmIdx to pass param to encoder mode,
            # not real Vm's index
            param.vmIdx = SOURCE_REGISTER1.get(self.instr_name + "_" +
                                               self.dst.dtype)
        else:
            param.type = VEC_TYPE_BITS.get(self.dst.dtype)
            # just use vmIdx to pass param to encoder mode,
            # not real Vm's index
            param.vmIdx = SOURCE_REGISTER1.get(self.instr_name)

        vd_idx = context.alloc_v_register(self.dst)
        param.vdIdx = vd_idx
        return param, vd_idx

    def eval_(self, context):
        """
        Vector Initial eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        param = set_param_loop_vex_num_dtype(context, self.dst.dtype, 0, 1)
        instr_list = create_vloop_info(context, param)
        init_value = context.evaluate_expr(self.init_value)
        src_dtype = self.dst.dtype
        src_range = [DTYPE_IMM_MIN.get(src_dtype), DTYPE_IMM_MAX.get(src_dtype)]
        if not TikSocManager.is_v300_610l_soc():
            if self.instr_name == "vectorized_vci":
                if src_dtype == "float16":
                    src_dtype = "uint16"
                    # float16 sn is unsigned int16, fp16 only has 10bit mantissa, so Sn must be less then 2**11 - 128
                    src_range = [0, 1920]
                elif src_dtype == "float32":
                    src_dtype = "uint32"
                    # float32 sn is unsigned int32, fp32 only has 23bit mantissa, so Sn must be less then 2**23 - 64
                    src_range = [0, 16777152]

        # only check data range
        if src_dtype in ("float16", "uint16", "uint32"):
            err_msg = "Intrinsic {}'s src should be in range [{}, {}]". \
                format(self.api_name, src_range[0], src_range[1])
            TikCheckUtil.check_in_range_by_dtype(init_value, src_dtype, msg=err_msg, var_range=src_range)

        sn_idx = get_and_write_share_spr(context, init_value,
                                         src_dtype)
        param.snIdx = sn_idx
        param, vd_idx = self.set_param(context, param)
        if TikSocManager.is_v300_610l_soc():
            if self.instr_name == "vectorized_vci":
                instr = context.encoder.gen_vector_vci_v300(param)
            else:
                instr = context.encoder.gen_vector_vbr_v300(param)
        else:
            instr = context.encoder.gen_vector_initial(param)
        execute_all_instr(context, instr_list, instr)
        dst_register(context, (self.dst, vd_idx, VecRegType.V_REG))
        context.set_vector_state(self.dst, is_valid=True)
        context.free_all_register()


class VectorVscatter(STMT):
    """
    Vector vscatter instruction
    """

    def __init__(self, source_info, vscatter_params, tik_debugger):
        super(VectorVscatter, self).__init__(source_info, tik_debugger)
        # dst is vector
        self.dst = vscatter_params.dst
        # src0 is ub, src0 is the read dst buffer
        self.src0 = vscatter_params.src0
        # src1 is vector
        self.src1 = vscatter_params.src1
        self.mask = vscatter_params.mask

    def set_param(self, context, param):
        """
        set param
        Parameters
        ----------
        context
        param

        Returns
        -------

        """
        pg_idx = context.alloc_p_register(self.mask, dtype=self.src1.dtype)
        param.pgIdx = pg_idx

        vd_idx = context.alloc_v_register(self.src0)
        param.vdIdx = vd_idx

        # Vn can only be selected in range from V0 to V15
        vn_idx = context.alloc_v_register(self.src1)
        param.vnIdx = vn_idx

        if self.dst.dtype in ["int32", "float32", "uint32"]:
            param.op1 = V210_INSTR_OP1_CODE.get("vectorized_vscatter") + 1
        else:
            param.op1 = V210_INSTR_OP1_CODE.get("vectorized_vscatter")

        # amIdx not real Am index, only for pass parameter
        if self.dst.dtype in ["int16", "uint16", "float16"]:
            param.amIdx = 1
        else:
            param.amIdx = 0
        param.loop = 0
        return param

    def eval_(self, context):
        """
        Vector Vscatter eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        temp_env = TempEnv(require_xt=False)
        param = set_param_loop_vex_num_dtype(context, self.dst.dtype, 0, 1)
        instr_list = create_vloop_info(context, param)

        # [sn] is UB address, it's need 32B aligned
        align = 32
        offset = get_flatten_idx(self.dst, context)
        _, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.dst, align, access_mode='r')
        sn_idx = get_and_write_share_spr(
            context, dst_addr + offset * DTYPE_SIZE.get(self.src0.dtype), "uint32")
        param.snIdx = sn_idx
        param = self.set_param(context, param)

        param.type = VEC_TYPE_BITS.get(self.dst.dtype)
        if TikSocManager.is_v300_610l_soc():
            param.isV300 = True

        instr = context.encoder.gen_vector_vscatter(param)
        instr_list.append(instr)
        context.model.step_all(context, instr_list, len(instr_list))

        # check_mem_access failed, cannot find gm
        context.model.read_memory(dst_addr, self.dst.scope, dst_ptr,
                                  dst_alloc_size)
        context.free_all_register()


class VectorVslide(STMT):
    """
    Vector Vslide instruction
    """

    def __init__(self, source_info, vslide_params, tik_debugger):
        super(VectorVslide, self).__init__(source_info, tik_debugger)
        self.instr_name = vslide_params.name
        self.dst = vslide_params.dst
        self.src0 = vslide_params.src0
        self.src1 = vslide_params.src1
        self.slide_size = vslide_params.slide_size

    def set_param(self, context, param):
        """
        set param
        Parameters
        ----------
        context
        param

        Returns
        -------

        """
        param.type = PARAMETERS.get(self.instr_name) | VEC_TYPE_BITS.get(self.dst.dtype)
        vd_idx = context.alloc_v_register(self.dst)
        param.vdIdx = vd_idx
        vn0_idx, vn1_idx = context.alloc_v_register(self.src0, is_even=True)
        context.init_vreg_according_cache(self.src1, vn1_idx)
        param.vnIdx = vn0_idx
        param.pgIdx = 0  # no preg, init to 0

        # get sm register index and init it with slide_size
        sm_idx = get_and_write_share_spr(context, self.slide_size, "int16")
        param.smIdx = sm_idx
        param.op1 = V210_INSTR_OP1_CODE.get(self.instr_name)
        return param, vd_idx

    def eval_(self, context):
        """
        Vector Vslide eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        param = set_param_loop_vex_num_dtype(context, self.dst.dtype, 0, 1)
        instr_list = create_vloop_info(context, param)

        # check slide_size value
        slide_size = context.evaluate_expr(self.slide_size)
        vl_t = VL_T_MAP.get(self.dst.dtype)
        TikCheckUtil.check_in_range_by_dtype(
            slide_size, msg="Instruction vector_vslide's slide_size must be in [%d, %d]" % (0, vl_t),
            var_range=[0, vl_t])
        param, vd_idx = self.set_param(context, param)
        if TikSocManager.is_v300_610l_soc():
            instr = context.encoder.gen_vector_vslidev300(param)
        else:
            instr = context.encoder.gen_vector_elewise_scalar(param)
        execute_all_instr(context, instr_list, instr)
        dst_register(context, (self.dst, vd_idx, VecRegType.V_REG), is_merging=False)
        context.set_vector_state(self.dst, is_valid=True)
        context.free_all_register()


class VectorVcbmaxVcbmin(STMT):
    """
    Vector Vcbmax Vcbmin instructions
    """

    def __init__(self, source_info, vcb_params, tik_debugger):
        super(VectorVcbmaxVcbmin, self).__init__(source_info, tik_debugger)
        self.dst0 = vcb_params.dst
        self.dst1 = vcb_params.dst1
        self.src = vcb_params.src
        self.mask = vcb_params.mask
        self.instr_name = vcb_params.name

    def set_param(self, context, param):
        """
        set param
        Parameters
        ----------
        context
        param

        Returns
        -------

        """
        if TikSocManager.is_v300_610l_soc():
            param.op1 = V300_INSTR_OP1_CODE.get(self.instr_name)
        else:
            param.op1 = V210_INSTR_OP1_CODE.get(self.instr_name)
        param.type = VEC_TYPE_THREE_BITS.get(self.dst0.dtype)
        pg_idx = context.alloc_p_register(self.mask, dtype=self.src.dtype)
        param.pgIdx = pg_idx

        vd_idx = context.alloc_v_register(self.dst0)
        param.vdIdx = vd_idx
        pd_idx = context.alloc_p_register(self.dst1)
        param.pdIdx = pd_idx

        vn_idx = context.alloc_v_register(self.src)
        param.vnIdx = vn_idx
        return param, vd_idx, pd_idx

    def eval_(self, context):
        """
        Vector Vcbmax/Vcbmin eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        param = set_param_loop_vex_num_dtype(context, self.dst0.dtype, 0, 1)
        instr_list = create_vloop_info(context, param)

        param, vd_idx, pd_idx = self.set_param(context, param)

        instr = context.encoder.gen_vector_vcbmax_vcbmin(param)
        instr_list.append(instr)
        context.model.step_all(context, instr_list, len(instr_list))

        dst_register(context, (self.dst0, vd_idx, VecRegType.V_REG))

        value_buffer1 = context.get_vector_value(self.dst1).buffer
        flatten_np1 = value_buffer1.reshape(-1)
        if TikSocManager.is_v300_610l_soc():
            context.model.read_vec_register_by_idx(VecRegType.P_REG, pd_idx, flatten_np1.ctypes.data,
                                                   len(flatten_np1) * DTYPE_SIZE[self.dst1.dtype])
        else:
            pd_idx_rename = context.model.get_vec_register_index(pd_idx, VecRegType.P_REG)
            context.model.read_vec_register(pd_idx_rename, flatten_np1.ctypes.data, len(flatten_np1))
        context.set_vector_state(self.dst0, is_valid=True)
        context.set_vector_state(self.dst1, is_valid=True)
        context.free_all_register()


class VectorElewise(STMT):
    """
    Vector Elewise instruction
    """

    def __init__(self, source_info, vector_params, instr_name, tik_debugger):
        super(VectorElewise, self).__init__(source_info, tik_debugger)
        self.dst = vector_params.dst
        self.src0 = vector_params.src0
        self.src1 = vector_params.src1
        self.mask = vector_params.mask
        self.instr_name = instr_name

    def set_param(self, context, param):
        """
        set param
        Parameters
        ----------
        context
        param

        Returns
        -------

        """
        instr_name = self.instr_name
        if TikSocManager.is_v210_soc() and self.dst.scope == scope_wreg and "vectorized_wadd" not in self.instr_name:
            instr_name = self.instr_name + "_" + self.src0.dtype

        if TikSocManager.is_v300_610l_soc():
            param.op1 = V300_INSTR_OP1_CODE.get(instr_name)
            param.regType = V300_INSTR_REGTYPE_CODE.get(instr_name)
        else:
            param.op1 = V210_INSTR_OP1_CODE.get(instr_name)
        param.type = VEC_TYPE_THREE_BITS.get(self.src0.dtype)

        if TikSocManager.is_v210_soc() and self.dst.scope == scope_wreg:
            if "vectorized_wadd" in self.instr_name:
                param.type |= WIDE_TYPE_THREE_BITS.get(instr_name)
            else:
                param.type = WIDE_TYPE_THREE_BITS.get(instr_name)

        pg_idx = context.alloc_p_register(self.mask, dtype=self.src0.dtype)
        param.pgIdx = pg_idx
        vd_idx = context.alloc_v_register(self.dst)
        param.vdIdx = vd_idx
        if self.dst.scope == scope_wreg and not TikSocManager.is_v300_610l_soc():
            param.vdIdx |= WIDE_VD_INDEX_BITS.get(instr_name)

        vn_idx = context.alloc_v_register(self.src0)
        param.vnIdx = vn_idx
        vm_idx = context.alloc_v_register(self.src1)
        param.vmIdx = vm_idx
        return param, vd_idx

    def eval_(self, context):
        """
        Vector Elewise eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        TempEnv()
        param = set_param_loop_vex_num_dtype(context, self.src0.dtype, 0, 1)
        instr_list = create_vloop_info(context, param)

        param, vd_idx = self.set_param(context, param)

        instr = context.encoder.gen_vector_elewise(param)
        instr_list.append(instr)
        context.model.step_all(context, instr_list, len(instr_list))

        value_buffer = context.get_vector_value(self.dst).buffer
        flatten_np = value_buffer.reshape(-1)

        if self.dst.scope == scope_wreg:
            if TikSocManager.is_v300_610l_soc():
                dst_register(context, (self.dst, vd_idx, VecRegType.W_REG), self.mask)
            else:
                vd_idx_rename = vd_idx + WREG_START_INDEX
                dst_dtype = WDTYPE_TO_DTYPE.get(self.dst.dtype)
                context.model.read_vec_register(vd_idx_rename, flatten_np.ctypes.data,
                                                len(flatten_np) * DTYPE_SIZE.get(dst_dtype))
        else:
            dst_dtype = self.dst.dtype
            if TikSocManager.is_v300_610l_soc():
                dst_register(context, (self.dst, vd_idx, VecRegType.V_REG), self.mask)
            else:
                vd_idx_rename = context.model.get_vec_register_index(vd_idx, VecRegType.V_REG)
                context.model.read_vec_register(vd_idx_rename, flatten_np.ctypes.data,
                                                len(flatten_np) * DTYPE_SIZE.get(dst_dtype))

        context.set_vector_state(self.dst, is_valid=True)
        context.free_all_register()
