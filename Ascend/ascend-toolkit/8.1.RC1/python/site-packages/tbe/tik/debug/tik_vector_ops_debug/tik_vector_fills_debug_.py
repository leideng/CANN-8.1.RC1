#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_vector_debug_.py
DESC:     provide params
CREATED:  2019-04-18 18:53:42
MODIFIED: 2020-12-7 19:17:00
"""
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.common.common_util import vec_template_align
from tbe.tik.common.common_check_func import check_address_align_with_context
from tbe.tik.common.util import get_bit_len
from tbe.tik.debug.statement import STMT
from tbe.tik.debug.simd import set_mask_counter_mode
from tbe.tik.debug.simd import _VSCATTER_TYPE
from tbe.tik.debug.simd import _SRC1_BLK_STRIDE_SHIFT_POS
from tbe.tik.debug.simd import _VPADD_DST_REP_SHIFT_POS
from tbe.tik.debug.simd import _SRC1_REPEAT_STRIDE_SHIFT_POS
from tbe.tik.debug.simd import MODE_SHIFT_POS
from tbe.tik.debug.simd import _PAD_SIDE_SHIFT_BIT_POS
from tbe.tik.debug.simd import _INSTR_SHIFT_POS
from tbe.tik.debug.simd import _VCI_DTYPE
from tbe.tik.debug.simd import _DST_DTYPE_SHIFT_POS
from tbe.tik.debug.simd import _PARAM_XD_SHIFT_POS
from tbe.tik.debug.simd import _PARAM_XN_SHIFT_POS
from tbe.tik.debug.simd import _PARAM_XT_SHIFT_POS
from tbe.tik.debug.simd import _INSTR_OR_VALUE
from tbe.tik.debug.util import copy_tensor_to_model
from tbe.tik.debug.util import get_flatten_idx
from tbe.tik.debug.util import get_dtype_size
from tbe.tik.debug.util import set_vector_mask
from tbe.tik.debug.util import VEC_DATA_TYPE_ENCODING
from tbe.tik.debug.util import get_dtype_bit_width
from tbe.tik.debug.util import cvt_float_to_uint
from tbe.tik.debug.sim.util import TempEnv
from tbe.tik.tik_lib.tik_params import REPEAT_SHIFT_POS
from tbe.tik.tik_lib.tik_params import ONE_REP_BYTE_SIZE
from tbe.tik.tik_lib.tik_params import BLK_NUM_PER_REP
from tbe.tik.tik_lib.tik_params import SHIFT_BIT_POS_52
from tbe.tik.tik_lib.tik_params import MAX_BLK_STRIDE_SINGLE_BYTE
from tbe.tik.tik_lib.tik_params import MAX_REP_STRIDE_12_BITS
from tbe.tik.tik_lib.tik_params import MASK_VALUE_64
from tbe.tik.tik_lib.tik_params import MASK_VALUE_128
from tbe.tik.tik_lib.tik_params import STRIDE_UNIT_SHIFT_POS
from tbe.tik.tik_lib.tik_params import DST_REPEAT_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import MAX_BLK_STRIDE_DOUBLE_BYTE
from tbe.tik.tik_lib.tik_params import MAX_REPEAT_TIMES
from tbe.tik.tik_lib.tik_params import MAX_REP_STRIDE_SINGLE_BYTE
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.common_check_func import split_rep_stride


class NewVectorScalarEltwise(STMT):
    """
    this template only have vector
    """

    def __init__(self, source_info, op_obj, tik_debugger=None):
        super(NewVectorScalarEltwise, self).__init__(source_info, tik_debugger)
        self.op_obj = op_obj
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return

        self.op_obj.dst_tensor_op.set_context(context)

        mask = self.op_obj.control_op.mask
        if self.op_obj.control_op.mask_mode == "counter":
            orig_ctrl_value = set_mask_counter_mode(context)
        else:
            orig_ctrl_value = ""

        set_vector_mask(mask, context, mask_mode=self.op_obj.control_op.mask_mode,
                        tensor_bit_len=get_bit_len(self.op_obj.dst_tensor_op.tensor_obj.dtype))
        temp_env = TempEnv()
        align = vec_template_align(self.op_obj.dst_tensor_op.tensor_obj.dtype)

        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.op_obj.dst_tensor_op.tensor_obj, align, access_mode='w')

        bit_width = get_dtype_bit_width(self.op_obj.dst_tensor_op.tensor_obj.dtype)
        dtype = 'uint' + bit_width

        param = context.encoder.new_param()
        param.type = VEC_DATA_TYPE_ENCODING[dtype]
        param.xd = xd_idx
        param.xn = self.create_gpr_x_n(context, temp_env)
        param.xt = self.create_gpr_x_t(context, temp_env)

        instr = context.encoder.gen_move_vx(param)

        if self.op_obj.name == 'vci':
            # init instr pos
            instr = 65
            instr = instr << _INSTR_SHIFT_POS
            instr |= _VCI_DTYPE[self.op_obj.dst_tensor_op.tensor_obj.dtype] << _DST_DTYPE_SHIFT_POS
            instr |= param.xd << _PARAM_XD_SHIFT_POS
            instr |= param.xn << _PARAM_XN_SHIFT_POS
            instr |= param.xt << _PARAM_XT_SHIFT_POS
            instr |= _INSTR_OR_VALUE

        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

        if self.op_obj.control_op.mask_mode == "counter":
            context.model.write_spr('CTRL', orig_ctrl_value)

        context.model.read_memory(dst_addr, self.op_obj.dst_tensor_op.tensor_obj.scope, dst_ptr,
                                  dst_alloc_size)

    def create_gpr_x_n(self, context, temp_env):
        """
        create general purpose register x_n

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xn_idx
        """
        scalar = self.op_obj.scalar_op.context_get_scalar(context)

        xn_idx = temp_env.alloc_register()
        x_n = cvt_float_to_uint(self.op_obj.dst_tensor_op.tensor_obj.dtype, scalar)

        context.model.write_gpr(xn_idx, x_n)

        return xn_idx

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)

        # check params
        TikCheckUtil.check_in_range_by_dtype(
            repeat, msg="repeat_times should be in the range of [%d, %d], input repeat_times is %s"
            % (0, MAX_REPEAT_TIMES, repeat),
            var_range=[0, MAX_REPEAT_TIMES])

        # check stride
        self.op_obj.dst_tensor_op.set_rep_stride_value()
        self.op_obj.dst_tensor_op.set_blk_stride_value()
        self.op_obj.dst_tensor_op.check_tensor_op_rep_stride(MAX_REP_STRIDE_SINGLE_BYTE)
        self.op_obj.dst_tensor_op.check_tensor_op_blk_stride(MAX_BLK_STRIDE_DOUBLE_BYTE)

        stride_unit = context.evaluate_expr(self.op_obj.control_op.stride_unit)

        xt_idx = temp_env.alloc_register()
        x_t = context.evaluate_expr(self.op_obj.dst_tensor_op.blk_stride)
        x_t |= stride_unit << STRIDE_UNIT_SHIFT_POS
        x_t |= repeat << REPEAT_SHIFT_POS
        x_t |= context.evaluate_expr(self.op_obj.dst_tensor_op.rep_stride) << DST_REPEAT_STRIDE_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)

        return xt_idx


class VPadding(STMT):
    """
    Vpadding instruction
    """

    def __init__(self, source_info, op_obj):
        super(VPadding, self).__init__(source_info, op_obj.tik_instance.context.tik_debugger)
        self.op_obj = op_obj

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        self.op_obj.dst_tensor_op.set_context(context)
        self.op_obj.src_tensor_op.set_context(context)

        mask = self.op_obj.control_op.mask
        orig_ctrl_value = None
        if self.op_obj.control_op.mask_mode == "counter":
            orig_ctrl_value = set_mask_counter_mode(context)

        set_vector_mask(mask, context, self.op_obj.control_op.mask_mode,
                        tensor_bit_len=max(get_bit_len(self.op_obj.dst_tensor_op.tensor_obj.dtype),
                                           get_bit_len(self.op_obj.src_tensor_op.tensor_obj.dtype)))

        align = vec_template_align(self.op_obj.dst_tensor_op.tensor_obj.dtype)
        temp_env = TempEnv()

        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.op_obj.dst_tensor_op.tensor_obj, align, access_mode='w')

        bit_width = get_dtype_bit_width(self.op_obj.src_tensor_op.tensor_obj.dtype)
        if bit_width == '16':
            type_encoding = 0
        else:
            type_encoding = 1

        param = context.encoder.new_param()
        param.type = type_encoding
        param.xd = xd_idx
        param.xt = self.create_gpr_x_t(context, temp_env)
        param.xn = self.create_gpr_x_n(context, temp_env, align, bit_width)

        instr = context.encoder.gen_vpadding(param)

        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

        # mask: counter_mode, reset CTRL as orig_ctrl_value
        if self.op_obj.control_op.mask_mode == "counter":
            context.model.write_spr('CTRL', orig_ctrl_value)

        context.model.read_memory(
            dst_addr, self.op_obj.dst_tensor_op.tensor_obj.scope, dst_ptr, dst_alloc_size)

    def create_gpr_x_n(self, context, temp_env, align, bit_width):
        """
        create general purpose register x_n

        Parameters
        ----------
        bit_width: bit width
        align: align
        context : the stack context
        temp_env : the temp environment

        Returns
        -------
        xn_idx
        """
        xn_idx, _, src_buffer_size, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src_tensor_op.tensor_obj, align, access_mode='r')
        mask = self.op_obj.control_op.mask
        if self.op_obj.control_op.mask_mode == "normal":
            # all elements in src are read even their mask bits are invalid
            if bit_width == '32':
                self.op_obj.control_op.mask = MASK_VALUE_64
            else:
                self.op_obj.control_op.mask = MASK_VALUE_128
        self.op_obj.src_tensor_op.check_read_mem_out_of_bounds(src_buffer_size, self.op_obj.control_op)
        self.op_obj.control_op.mask = mask
        return xn_idx

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)
        dst_block_stride = context.evaluate_expr(self.op_obj.dst_tensor_op.blk_stride)
        src_block_stride = context.evaluate_expr(self.op_obj.src_tensor_op.blk_stride)
        dst_repeat_stride = context.evaluate_expr(self.op_obj.dst_tensor_op.rep_stride)
        src_repeat_stride = context.evaluate_expr(self.op_obj.src_tensor_op.rep_stride)

        tensor_bit_len = max(get_bit_len(self.op_obj.dst_tensor_op.tensor_obj.dtype),
                             get_bit_len(self.op_obj.src_tensor_op.tensor_obj.dtype),)
        self.op_obj.vpadding_check_obj.check_debug_common_params(tensor_bit_len)

        xt_idx = temp_env.alloc_register()
        x_t = dst_block_stride
        x_t |= src_block_stride << _SRC1_BLK_STRIDE_SHIFT_POS
        x_t |= dst_repeat_stride << _VPADD_DST_REP_SHIFT_POS
        x_t |= src_repeat_stride << _SRC1_REPEAT_STRIDE_SHIFT_POS
        x_t |= self.op_obj.pad_mode << MODE_SHIFT_POS
        x_t |= (0 if self.op_obj.pad_side == 'left' else 1) << _PAD_SIDE_SHIFT_BIT_POS
        x_t |= context.evaluate_expr(self.op_obj.control_op.stride_unit) << STRIDE_UNIT_SHIFT_POS
        x_t |= repeat << REPEAT_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)

        return xt_idx


class VBrcb(STMT):
    """
    VGather instruction
    """

    def __init__(self, source_info, op_obj):
        super(VBrcb, self).__init__(source_info, op_obj.tik_instance.context.tik_debugger)
        self.op_obj = op_obj
        self.mask = ONE_REP_BYTE_SIZE // DTYPE_SIZE.get(self.op_obj.dst_tensor_op.tensor_obj.dtype)
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        self.op_obj.dst_tensor_op.set_context(context)
        self.op_obj.src_tensor_op.context = context
        self.op_obj.src_tensor_op.eval_offset()

        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)
        # check UB address 32B align
        align = vec_template_align(self.op_obj.src_tensor_op.tensor_obj.dtype)
        # v300 610l support no-32-bit align
        if not TikSocManager.is_v300_610l_soc():
            check_address_align_with_context(
                context,
                (self.op_obj.src_tensor_op.tensor_obj, self.op_obj.dst_tensor_op.tensor_obj),
                ("src", "dst"), align
            )
        # check repeat_times range
        TikCheckUtil.check_in_range_by_dtype(
            repeat, msg="repeat_times should be in the range of [%d, %d], input repeat_times: %s"
            % (0, MAX_REPEAT_TIMES, repeat), var_range=[0, MAX_REPEAT_TIMES])
        self.op_obj.dst_tensor_op.set_rep_stride_value()
        self.op_obj.dst_tensor_op.set_blk_stride_value()
        self.op_obj.dst_tensor_op.check_tensor_op_valid(self.op_obj.name, MAX_BLK_STRIDE_SINGLE_BYTE,
                                                        MAX_REP_STRIDE_12_BITS, align)
        # check address overlap
        self.check_debug_address_overlap(context)

        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return

        temp_env = TempEnv()
        xn_idx, _, src_buffer_size, _ = copy_tensor_to_model(
            context, temp_env, self.op_obj.src_tensor_op.tensor_obj, align, access_mode='r')
        xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, self.op_obj.dst_tensor_op.tensor_obj, align, access_mode="w")

        # check overflow.
        self.check_src_tensor_debug_overflow(context, src_buffer_size)
        self.op_obj.dst_tensor_op.check_read_mem_out_of_bounds(dst_alloc_size, self.op_obj.control_op)

        param = context.encoder.new_param()
        param.xd = xd_idx
        param.xt = self.create_gpr_x_t(context, temp_env)
        param.xn = xn_idx
        get_src_dtype_size = DTYPE_SIZE.get(self.op_obj.src_tensor_op.tensor_obj.dtype)
        param.type = _VSCATTER_TYPE.get(get_src_dtype_size)

        instr = context.encoder.gen_vbrcb(param)

        context.model.step(instr)
        temp_env.check_mem_access(context.model, False)

        context.model.read_memory(dst_addr, self.op_obj.dst_tensor_op.tensor_obj.scope, dst_ptr, dst_alloc_size)

    def check_debug_address_overlap(self, context):
        """
        check debug address overlap
        """
        src_offset = context.evaluate_expr(self.op_obj.src_tensor_op.tensor_obj.offset)
        dst_offset = context.evaluate_expr(self.op_obj.dst_tensor_op.tensor_obj.offset)
        self.op_obj.dst_tensor_op.check_vbcb_overlapping(self.op_obj.control_op, self.op_obj.src_tensor_op, dst_offset,
                                                         src_offset)

    def check_src_tensor_debug_overflow(self, context, src_buffer_size):
        """
        check tensor overflow
        """
        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)
        offset = get_flatten_idx(self.op_obj.src_tensor_op.tensor_obj, context)
        expected_size = repeat * BLK_NUM_PER_REP + offset
        total_size = src_buffer_size // get_dtype_size(self.op_obj.src_tensor_op.tensor_obj.dtype)

        if expected_size > total_size:
            TikCheckUtil.raise_error("src need read %s elements, but only %s elements space"
                                     % (expected_size, total_size))

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context
        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)
        dst_blk_stride = context.evaluate_expr(self.op_obj.dst_tensor_op.blk_stride)
        dst_rep_stride = context.evaluate_expr(self.op_obj.dst_tensor_op.rep_stride)

        dst_rep_stride_low, dst_rep_stride_high = split_rep_stride(dst_rep_stride)
        xt_idx = temp_env.alloc_register()
        x_t = dst_blk_stride
        x_t |= dst_rep_stride_low << DST_REPEAT_STRIDE_SHIFT_POS
        x_t |= dst_rep_stride_high << SHIFT_BIT_POS_52
        x_t |= repeat << REPEAT_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)
        return xt_idx
