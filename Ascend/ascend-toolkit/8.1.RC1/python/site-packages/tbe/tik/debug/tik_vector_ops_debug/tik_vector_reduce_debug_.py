#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_vector_reduce_debug_.py
DESC:     reduce debug class
CREATED:  2021-11-04 17:07
MODIFIED: 2021-11-04 17:07
"""

from collections import namedtuple
import numpy as np
from tbe.tik.debug.simd import eval_mask
from tbe.tik.debug.simd import VEC_WHOLE_REDUCE_ENCODER
from tbe.tik.debug.util import VEC_DATA_TYPE_ENCODING
from tbe.tik.debug.util import get_dtype_size
from tbe.tik.debug.util import copy_tensor_to_model
from tbe.tik.debug.util import set_vector_mask
from tbe.tik.debug.simd import set_mask_counter_mode
from tbe.tik.debug.sim.instr_encoder import Encoder
from tbe.tik.debug.sim.util import TempEnv
from tbe.tik.debug.statement import STMT
from tbe.tik.debug.debug_encoder import VEC_DATA_TYPE_ENCODING_V200
from tbe.tik.tik_lib.tik_expr import is_basic_expr
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.common.util import DTYPE_SIZE
from tbe.tik.common.util import get_bit_len
from tbe.tik.common.util import ceil_div
from tbe.tik.common.common_util import vec_template_align
from tbe.tik.common.common_check_func import check_mask_valid
from tbe.tik.tik_lib.tik_params import MIN_STRIDE_UNIT
from tbe.tik.tik_lib.tik_params import MAX_VREDUCE_REPEAT_TIMES
from tbe.tik.tik_lib.tik_params import DEFAULT_STRIDE
from tbe.tik.tik_lib.tik_params import SRC_BLOCK_STRIDE_SHIFT_POS
from tbe.tik.tik_lib.tik_params import REPEAT_SHIFT_POS
from tbe.tik.tik_lib.tik_params import STRIDE_UNIT_SHIFT_POS
from tbe.tik.tik_lib.tik_params import MAX_REPEAT_TIMES
from tbe.tik.tik_lib.tik_params import MIN_REPEAT_TIMES
from tbe.tik.tik_lib.tik_params import ONE_REP_BYTE_SIZE
from tbe.tik.tik_lib.tik_params import MAX_REP_STRIDE_DOUBLE_BYTE
from tbe.tik.tik_lib.tik_params import ONE_BLK_SIZE
from tbe.tik.tik_lib.tik_params import BLK_NUM_PER_REP
from tbe.tik.tik_lib.tik_params import ONE_BYTE_BIT_LEN
from tbe.tik.tik_lib.tik_params import MASK_VALUE_ZERO
from tbe.tik.tik_lib.tik_params import VREDUCE_PER_REP_OUTPUT
from tbe.tik.tik_lib.tik_params import VREDUCE_MIN_REPEAT_TIMES
from tbe.tik.tik_lib.tik_params import VREDUCE_DEFAULT_DST_REP_STRIDE
from tbe.tik.tik_lib.tik_params import VREDUCE_DEFAULT_SRC_BLK_STRIDE
from tbe.tik.tik_lib.tik_params import VREDUCE_DEFAULT_SRC_REP_STRIDE
from tbe.tik.tik_lib.tik_params import VREDUCE_DST_ALIGN
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager

_DEFAULT_STRIDE = 1
_DEFAULT_BLOCK_LEN = 1
_ENCODER = Encoder()
_SRC_REPEAT_STRIDE_SHIFT_POS = 32
_VEC_DATA_TYPE_ENCODING_V200 = {
    'int32': 0b00, 'float16': 0b01,
    'int16': 0b10, 'float32': 0b11
}


class VReduceAdd(STMT):
    """
    VReduceAdd instruction
    """

    def __init__(self, source_info, op_obj):
        super().__init__(source_info, op_obj.tik_instance.context.tik_debugger)
        self.op_obj = op_obj
        self.context = None
        self.repeat_times = self.op_obj.control_op.repeat_times
        self.mask = self.op_obj.control_op.mask
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id

    @staticmethod
    def check_params(cur_repeat_times, src_rep_stride):
        """
        check params
        :param cur_repeat_times:
        :param src_rep_stride:
        :return:
        """
        TikCheckUtil.check_in_range_by_dtype(
            cur_repeat_times, msg="repeat_times should be in the range of [%d, %d], input value is %s"
            % (MIN_REPEAT_TIMES, MAX_VREDUCE_REPEAT_TIMES, cur_repeat_times),
            var_range=[MIN_REPEAT_TIMES, MAX_VREDUCE_REPEAT_TIMES])
        TikCheckUtil.check_in_range_by_dtype(
            src_rep_stride, msg="src_rep_stride should be in the range of [%d, %d], input value is %s"
            % (DEFAULT_STRIDE, MAX_REP_STRIDE_DOUBLE_BYTE, str(src_rep_stride)),
            var_range=[DEFAULT_STRIDE, MAX_REP_STRIDE_DOUBLE_BYTE])

    def set_acc_val_to_dst(self, vcadd_eval_params_ins, max_rep_times_offset):
        """
        set acc_val register to dst
        Parameters
        ----------
        max_rep_times_offset: start offset of full 255 repeat times
        vcadd_eval_params_ins: vcadd eval params tuple

        Returns
        -------

        """
        sr_value = self.context.model.read_spr('ACC_VAL')
        dst_tvm_buffer = \
            self.context.tensor_buffer.get_npbuffer_by_tvmbuffer(vcadd_eval_params_ins.dst.buffer)
        dst_tensor = dst_tvm_buffer.buffer.reshape(-1).view(vcadd_eval_params_ins.dst.dtype)
        dst_tensor_offset = self.context.evaluate_expr(vcadd_eval_params_ins.dst.offset)
        dst_tensor[dst_tensor_offset + max_rep_times_offset] = \
            np.array([sr_value]).view(self.op_obj.reduce_check_obj.dst.dtype)[0]

    def set_params_check_mem(self, params_tuple):
        """
        set params and check read mem out of bounds
        Parameters
        ----------
        params_tuple

        Returns
        -------

        """
        param, vcadd_eval_params_ins, temp_env, src_align, src_offset = params_tuple
        param.xn, _, src_alloc_size, _ = copy_tensor_to_model(
            self.context, temp_env, vcadd_eval_params_ins.src_op.tensor_obj, src_align, access_mode='r')
        param.type = VEC_DATA_TYPE_ENCODING[vcadd_eval_params_ins.src_op.tensor_obj.dtype]
        param.xt = self._vcadd_create_gpr_x_t(vcadd_eval_params_ins, temp_env)
        # check read mem out of bounds
        vcadd_eval_params_ins.src_op.check_read_mem_out_of_bounds(
            src_alloc_size, self.op_obj.control_op, ori_offset=src_offset)

    def check_reduce_add_address_align(self):
        """
        check address align
        :return:
        """
        if TikSocManager.is_v100_soc():
            for tensor, name in zip((self.op_obj.reduce_check_obj.work_tensor, self.op_obj.reduce_check_obj.dst,
                                     self.op_obj.reduce_check_obj.src),
                                    ("work_tensor", "dst", "src")):
                tensor_start = self.context.evaluate_expr(tensor.offset)
                if tensor_start * DTYPE_SIZE[tensor.dtype] % ONE_BLK_SIZE != 0:
                    TikCheckUtil.raise_error(
                        "Address align error, %s is not 32 align" % name)

    def check_reduce_add_overlap(self, cur_repeat_times):
        """
        check overlap, cause other overlaps will be checked in vcadd_eval
        the check will not be repeated here
        :param cur_repeat_times: repeat times
        :return:
        """

        if self.op_obj.reduce_check_obj.work_tensor.buffer == self.op_obj.reduce_check_obj.dst.buffer:
            work_tensor_start = self.context.evaluate_expr(self.op_obj.reduce_check_obj.work_tensor.offset)
            work_tensor_stop = self.context.evaluate_expr(
                cur_repeat_times + self.op_obj.reduce_check_obj.work_tensor.offset)
            dst_start = self.context.evaluate_expr(self.op_obj.reduce_check_obj.dst.offset)
            if max(work_tensor_start, dst_start) < \
                    min(work_tensor_stop, dst_start + 1):
                TikCheckUtil.raise_error("vec_reduce_add work_tensor and dst "
                                         "address overlapping error.")

    def vec_reduce_add_not_910b_soc(self, elements_per_repeat, cur_repeat_times):
        """
        not 910B soc version reduce add
        Parameters
        ----------
        elements_per_repeat: one repeat elements number
        cur_repeat_times: cur repeat times

        Returns
        -------

        """
        while cur_repeat_times > 1:
            pre_elements = cur_repeat_times
            cur_repeat_times = ceil_div(pre_elements, elements_per_repeat)

            if cur_repeat_times == 1:

                self._vcadd_eval((pre_elements, "normal", self.op_obj.reduce_check_obj.dst,
                                  self.op_obj.work_tensor_op, cur_repeat_times,
                                  BLK_NUM_PER_REP))
            else:
                if TikSocManager.is_v200_soc() or TikSocManager.is_v210_soc():
                    self._vcadd_eval((pre_elements, "counter",
                                      self.op_obj.reduce_check_obj.work_tensor,
                                      self.op_obj.work_tensor_op, cur_repeat_times,
                                      BLK_NUM_PER_REP))
                else:
                    tmp_mask = pre_elements % elements_per_repeat

                    if tmp_mask == MASK_VALUE_ZERO:

                        self._vcadd_eval((elements_per_repeat, "normal",
                                          self.op_obj.reduce_check_obj.work_tensor,
                                          self.op_obj.work_tensor_op, cur_repeat_times,
                                          BLK_NUM_PER_REP))
                    else:

                        self._vcadd_eval((elements_per_repeat, "normal",
                                          self.op_obj.reduce_check_obj.work_tensor,
                                          self.op_obj.work_tensor_op, cur_repeat_times - 1,
                                          BLK_NUM_PER_REP))

                        self._vcadd_eval((tmp_mask, "normal",
                                          self.op_obj.reduce_check_obj.work_tensor,
                                          self.op_obj.work_tensor_op,
                                          1, BLK_NUM_PER_REP),
                                         dst_offset=cur_repeat_times - 1,
                                         src_offset=elements_per_repeat * (cur_repeat_times - 1))

    def check_work_tensor_size(self, cur_repeat_times):
        """
        check work tensor is space
        Parameters
        ----------
        cur_repeat_times: cur repeat times

        Returns
        -------

        """
        if TikSocManager.is_910b_soc() and cur_repeat_times > MAX_REPEAT_TIMES:
            temp_env = TempEnv()
            align = vec_template_align(self.op_obj.reduce_check_obj.work_tensor.dtype)
            _, _, dst_alloc_size, _ = copy_tensor_to_model(
                self.context, temp_env, self.op_obj.reduce_check_obj.work_tensor, align, access_mode='r')
            work_tensor_need = ceil_div(
                cur_repeat_times, MAX_REPEAT_TIMES) + self.op_obj.reduce_check_obj.work_tensor.offset
            total_size = dst_alloc_size // get_dtype_size(self.op_obj.reduce_check_obj.work_tensor.dtype)
            if work_tensor_need > total_size:
                TikCheckUtil.raise_error("AccessViolation: tensor %s need read %s elements, but only %s elements space"
                                         % (self.op_obj.reduce_check_obj.work_tensor.name,
                                            work_tensor_need, total_size))

    def init_var(self, context):
        """
        init context and op_obj attr
        Parameters
        ----------
        context: debug context

        Returns
        -------

        """
        self.context = context
        self.op_obj.src_tensor_op.context = self.context
        self.op_obj.work_tensor_op.context = self.context
        self.op_obj.control_op.mask = self.mask
        self.op_obj.control_op.repeat_times = self.repeat_times

    def eval_(self, context):
        """
        VReduceAdd eval
        Parameters
        ----------
        context: tik context

        Returns
        -------
        no returns
        """
        self.init_var(context)
        src_rep_stride = self.context.evaluate_expr(self.op_obj.src_tensor_op.rep_stride)
        cur_repeat_times = self.context.evaluate_expr(self.op_obj.control_op.repeat_times)
        self.check_params(cur_repeat_times, src_rep_stride)
        self.check_reduce_add_address_align()
        if not TikSocManager.is_v300_610l_soc():
            self.check_reduce_add_overlap(cur_repeat_times)
        self.check_work_tensor_size(cur_repeat_times)
        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return

        if cur_repeat_times == 1:
            self._vcadd_eval((self.op_obj.control_op.mask, "normal",
                              self.op_obj.reduce_check_obj.dst, self.op_obj.src_tensor_op,
                              cur_repeat_times, src_rep_stride))
            return
        self._vec_reduce_add_first_add(cur_repeat_times, src_rep_stride)

        operator_byte_size = get_bit_len(self.op_obj.reduce_check_obj.src.dtype) // ONE_BYTE_BIT_LEN
        elements_per_repeat = ONE_REP_BYTE_SIZE // operator_byte_size

        if TikSocManager.is_910b_soc():
            if cur_repeat_times > MAX_REPEAT_TIMES:
                last_add_mask = ceil_div(cur_repeat_times, MAX_REPEAT_TIMES)
                last_add_repeat_time = 1
                self._vcadd_eval((last_add_mask, "normal", self.op_obj.reduce_check_obj.dst,
                                  self.op_obj.work_tensor_op, last_add_repeat_time,
                                  BLK_NUM_PER_REP))

        else:
            self.vec_reduce_add_not_910b_soc(elements_per_repeat, cur_repeat_times)

    def _vcadd_create_gpr_x_t(self, create_gpr_params, temp_env):
        """
        create general purpose register x_t for vcadd function
        """
        # check params
        TikCheckUtil.check_in_range_by_dtype(
            create_gpr_params.repeat_times, msg="repeat_times should be in the range of [%d, %d], input value is %s"
            % (0, MAX_REPEAT_TIMES, str(create_gpr_params.repeat_times)),
            var_range=[0, MAX_REPEAT_TIMES])

        # check address overlap
        self.op_obj.control_op.mask = eval_mask(create_gpr_params.mask, self.context)
        if create_gpr_params.src_op.tensor_obj.buffer == create_gpr_params.dst.buffer:
            if create_gpr_params.repeat_times == 1:
                create_gpr_params.src_op.blk_stride_value = _DEFAULT_STRIDE
            else:
                create_gpr_params.src_op.blk_stride_value = 0
            block_list = [_DEFAULT_BLOCK_LEN,
                          ONE_REP_BYTE_SIZE // max(get_bit_len(create_gpr_params.dst.dtype),
                                                   get_bit_len(create_gpr_params.src_op.tensor_obj.dtype))]
            create_gpr_params.src_op.check_address_overlapping(
                "vcadd", self.op_obj.control_op, create_gpr_params.src_op, block_list)

        xt_idx = temp_env.alloc_register()
        x_t = _DEFAULT_STRIDE
        x_t |= _DEFAULT_STRIDE << SRC_BLOCK_STRIDE_SHIFT_POS
        x_t |= MIN_STRIDE_UNIT << STRIDE_UNIT_SHIFT_POS
        x_t |= create_gpr_params.repeat_times << REPEAT_SHIFT_POS
        x_t |= create_gpr_params.src_rep_stride << _SRC_REPEAT_STRIDE_SHIFT_POS

        self.context.model.write_gpr(xt_idx, x_t)

        return xt_idx

    def _vcadd_eval(self, eval_params, dst_offset=0, src_offset=0, max_rep_times_offset=0):
        """
        vcadd part eval function
        """
        vcadd_eval_params = namedtuple("VcaddEval", "mask mask_mode dst src_op repeat_times src_rep_stride")
        vcadd_eval_params_ins = vcadd_eval_params(*eval_params)
        self.op_obj.control_op.mask_mode = vcadd_eval_params_ins.mask_mode
        self.op_obj.control_op.repeat_times = vcadd_eval_params_ins.repeat_times
        self.op_obj.control_op.mask = vcadd_eval_params_ins.mask

        if vcadd_eval_params_ins.repeat_times == 0:
            return
        temp_env = TempEnv()
        if vcadd_eval_params_ins.mask_mode == "counter":
            orig_ctrl_value = set_mask_counter_mode(self.context)
        set_vector_mask(vcadd_eval_params_ins.mask, self.context,
                        mask_mode=vcadd_eval_params_ins.mask_mode,
                        tensor_bit_len=get_bit_len(vcadd_eval_params_ins.src_op.tensor_obj.dtype))

        temp_env.offset = dst_offset
        src_align = vec_template_align(vcadd_eval_params_ins.src_op.tensor_obj.dtype)
        param = _ENCODER.new_param()
        param.xd, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            self.context, temp_env, vcadd_eval_params_ins.dst,
            get_dtype_size(vcadd_eval_params_ins.src_op.tensor_obj.dtype), access_mode='w')
        temp_env.offset = src_offset
        self.set_params_check_mem((param, vcadd_eval_params_ins, temp_env, src_align, src_offset))

        if TikSocManager.is_910b_soc():
            self.context.model.step(_ENCODER.gen_vcadd_910b(param))

        else:
            self.context.model.step(_ENCODER.gen_vcadd(param))

        temp_env.check_mem_access(self.context.model, False)

        # mask: counter_mode, reset CTRL as orig_ctrl_value
        if vcadd_eval_params_ins.mask_mode == "counter":
            self.context.model.write_spr('CTRL', orig_ctrl_value)

        if TikSocManager.is_910b_soc():
            self.set_acc_val_to_dst(vcadd_eval_params_ins, max_rep_times_offset)

        else:
            self.context.model.read_memory(dst_addr, vcadd_eval_params_ins.dst.scope, dst_ptr, dst_alloc_size)

    def _vec_reduce_add_first_add(self, repeat_times, src_rep_stride):
        """
        vec reduce add first add
        :param repeat_times: repeat times
        :param src_rep_stride: src repeat stride
        :return:
        """

        if TikSocManager.is_v100_soc():
            elements_per_block = ONE_BLK_SIZE // DTYPE_SIZE.get(self.op_obj.reduce_check_obj.src.dtype)
            # in order to align the first address of dst, 32B align
            max_repeat_times = MAX_REPEAT_TIMES - elements_per_block + 1
        else:
            max_repeat_times = MAX_REPEAT_TIMES
        for_times = repeat_times // max_repeat_times
        left_repeat_times = repeat_times % max_repeat_times
        max_repeat_offset = \
            max_repeat_times * (src_rep_stride * ONE_BLK_SIZE) // DTYPE_SIZE.get(self.op_obj.reduce_check_obj.src.dtype)

        if TikSocManager.is_910b_soc() and repeat_times <= max_repeat_times:

            self._vcadd_eval((self.op_obj.control_op.mask, "normal", self.op_obj.reduce_check_obj.dst,
                              self.op_obj.src_tensor_op, repeat_times, src_rep_stride))
        else:
            for index in range(for_times):
                src_start_index = index * max_repeat_offset
                self._vcadd_eval((self.op_obj.control_op.mask, "normal",
                                  self.op_obj.reduce_check_obj.work_tensor,
                                  self.op_obj.src_tensor_op, max_repeat_times, src_rep_stride),
                                 dst_offset=index * max_repeat_times,
                                 src_offset=src_start_index, max_rep_times_offset=index)

            if left_repeat_times > 0:
                src_index = for_times * max_repeat_offset
                self._vcadd_eval((self.op_obj.control_op.mask, "normal",
                                  self.op_obj.reduce_check_obj.work_tensor,
                                  self.op_obj.src_tensor_op, left_repeat_times, src_rep_stride),
                                 dst_offset=for_times * max_repeat_times, src_offset=src_index,
                                 max_rep_times_offset=for_times)


class VecAllReduce(STMT):
    """
    vector all reduce, group reduce, pair reduce has \
    no difference to the debugger
    """

    def __init__(self, source_info, op_obj):
        super().__init__(source_info, op_obj.tik_instance.context.tik_debugger)
        self.op_obj = op_obj
        self.context = None
        self.repeat_times = self.op_obj.control_op.repeat_times
        self.mask = self.op_obj.control_op.mask
        if TikSocManager.is_v300_610l_soc():
            self.source_id = op_obj.tik_instance.context.debug_source_id
        
    @staticmethod
    def get_first_step_tensor_offset(index, max_repeat_times, src_rep_stride, dtype_len):
        """
        get fir step tensor offset
        :return:
        """
        dst_offset = index * max_repeat_times * VREDUCE_PER_REP_OUTPUT
        src_offset = index * max_repeat_times * src_rep_stride * ONE_BLK_SIZE // dtype_len
        return dst_offset, src_offset

    def vreduce_cal_index_iter4(self, iter4_params, iter3_params):
        """
        iteration4
        :param iter3_params:
        :param iter4_params:
        :return:
        """
        it4_mask = self.op_obj.reduce_check_obj.vreduce_create_mask(
            iter4_params.it3_output_count // VREDUCE_PER_REP_OUTPUT)

        self._vreduce_eval((it4_mask, self.op_obj.reduce_check_obj.work_tensor,
                            self.op_obj.work_tensor_op, VREDUCE_MIN_REPEAT_TIMES,
                            VREDUCE_DEFAULT_SRC_REP_STRIDE),
                           iter4_params.it4_start_pos, iter3_params.it3_start_pos)
        np_work_tensor_index_4 = iter4_params.work_tensor_offset + iter4_params.it4_start_pos
        res_value = iter4_params.np_work_tensor[np_work_tensor_index_4]
        it4_index = iter4_params.np_work_tensor[np_work_tensor_index_4 + 1].view(iter3_params.index_type)
        np_work_tensor_index_3 = iter4_params.work_tensor_offset + iter3_params.it3_start_pos + it4_index
        it3_index = iter4_params.np_work_tensor[np_work_tensor_index_3 + 1].view(iter3_params.index_type)
        idx_offset = it3_index + it4_index // VREDUCE_PER_REP_OUTPUT * iter3_params.element_num_per_rep
        np_work_tensor_index_2 = iter4_params.work_tensor_offset + iter3_params.it2_start_pos + idx_offset
        it2_index = iter4_params.np_work_tensor[np_work_tensor_index_2 + 1].view(iter3_params.index_type)
        idx_offset = it2_index + idx_offset // VREDUCE_PER_REP_OUTPUT * iter3_params.element_num_per_rep
        np_work_tensor_index_1 = iter4_params.work_tensor_offset + idx_offset
        it1_index = iter4_params.np_work_tensor[np_work_tensor_index_1 + 1].view(iter3_params.index_type)
        idx_offset = it1_index + idx_offset // VREDUCE_PER_REP_OUTPUT * iter4_params.offset_num_per_rep

        res_index = np.array((idx_offset, )).view(self.op_obj.reduce_check_obj.dst.dtype)[0]
        return res_index, res_value

    def vreduce_cal_index_iter3_it2_eq(self, np_work_tensor, work_tensor_offset, iter3_params, offset_num_per_rep):
        """
        when iter3_params.it2_output_count == VREDUCE_PER_REP_OUTPUT
        :param np_work_tensor:
        :param work_tensor_offset:
        :param iter3_params:
        :param offset_num_per_rep:
        :return:
        """
        res_value = np_work_tensor[work_tensor_offset + iter3_params.it2_start_pos]
        it2_index = np_work_tensor[work_tensor_offset + iter3_params.it2_start_pos + 1] \
            .view(iter3_params.index_type)
        it1_index_1 = work_tensor_offset + it2_index + 1
        it1_index = np_work_tensor[it1_index_1]. \
            view(iter3_params.index_type)
        pre_num = offset_num_per_rep * (it2_index // VREDUCE_PER_REP_OUTPUT)
        res_index = np.array([pre_num + it1_index]).view(self.op_obj.reduce_check_obj.dst.dtype)[0]
        return res_index, res_value

    def vreduce_cal_index_iter3_index_and_val(
            self, np_work_tensor, work_tensor_offset, offset_num_per_rep, iter3_params):
        """
        cal index iter3 get index and val
        :param np_work_tensor:
        :param work_tensor_offset:
        :param offset_num_per_rep:
        :param iter3_params:
        :return:
        """
        it3_mask = self.op_obj.reduce_check_obj.vreduce_create_mask(
            iter3_params.it2_output_count // VREDUCE_PER_REP_OUTPUT)
        self._vreduce_eval((it3_mask, self.op_obj.reduce_check_obj.work_tensor,
                            self.op_obj.work_tensor_op,
                            VREDUCE_MIN_REPEAT_TIMES, VREDUCE_DEFAULT_SRC_REP_STRIDE),
                           iter3_params.it3_start_pos, iter3_params.it2_start_pos)
        it3_index = np_work_tensor[
            work_tensor_offset + iter3_params.it3_start_pos + 1].view(iter3_params.index_type)
        res_value = np_work_tensor[work_tensor_offset + iter3_params.it3_start_pos]
        it2_index_1 = work_tensor_offset + iter3_params.it2_start_pos + it3_index + 1
        it2_index = np_work_tensor[it2_index_1].view(iter3_params.index_type)
        it1_index_1 = work_tensor_offset + iter3_params.element_num_per_rep * (it3_index // VREDUCE_PER_REP_OUTPUT)
        it1_index = np_work_tensor[
            it1_index_1 + it2_index + 1].view(iter3_params.index_type)
        pre_num = offset_num_per_rep * (
                iter3_params.element_num_per_rep *
                (it3_index // VREDUCE_PER_REP_OUTPUT) + it2_index) // VREDUCE_PER_REP_OUTPUT
        res_index = np.array([pre_num + it1_index]
                             ).view(self.op_obj.reduce_check_obj.dst.dtype)[0]
        return res_index, res_value

    def vreduce_cal_index_iter3(self, iter3_params):
        """
        iteration3
        :param iter3_params:
        :return:
        """
        offset_num_per_rep = ONE_BLK_SIZE // iter3_params.dtype_size * iter3_params.rep_stride
        tvm_buffer = self.context.tensor_buffer.get_npbuffer_by_tvmbuffer(
            self.op_obj.reduce_check_obj.work_tensor.buffer)
        np_work_tensor = tvm_buffer.buffer.reshape(-1).view(
            self.op_obj.reduce_check_obj.work_tensor.dtype)
        work_tensor_offset = self.context.evaluate_expr(
            self.op_obj.reduce_check_obj.work_tensor.offset)

        if iter3_params.it2_output_count == VREDUCE_PER_REP_OUTPUT:
            res_index, res_value = self.vreduce_cal_index_iter3_it2_eq(
                np_work_tensor, work_tensor_offset, iter3_params, offset_num_per_rep)
        else:
            if iter3_params.it2_output_count > iter3_params.element_num_per_rep:
                it3_output_count, it4_start_pos = \
                    self._vreduce_body_cal((iter3_params.it2_output_count,
                                            iter3_params.element_num_per_rep, iter3_params.it2_start_pos,
                                            iter3_params.it3_start_pos, iter3_params.dtype_size))
                it4_params = namedtuple(
                    "It4Params", "it3_output_count it4_start_pos np_work_tensor work_tensor_offset offset_num_per_rep")
                it4_params_ins = it4_params(
                    it3_output_count, it4_start_pos, np_work_tensor, work_tensor_offset, offset_num_per_rep)
                res_index, res_value = self.vreduce_cal_index_iter4(it4_params_ins, iter3_params)
            else:
                res_index, res_value = self.vreduce_cal_index_iter3_index_and_val(
                    np_work_tensor, work_tensor_offset, offset_num_per_rep, iter3_params)

        return res_value, res_index

    def vreduce_cal_index_iter2(self, cal_index_iter2_params_ins):
        """
        iteration2
        :return:
        """
        # iteration2
        it2_start_pos = self.op_obj.reduce_check_obj.align_start_pos(cal_index_iter2_params_ins.it1_output_count,
                                                                     cal_index_iter2_params_ins.dtype_size)
        it2_output_count, it3_start_pos = \
            self._vreduce_body_cal((cal_index_iter2_params_ins.it1_output_count,
                                    cal_index_iter2_params_ins.element_num_per_rep, 0, it2_start_pos,
                                    cal_index_iter2_params_ins.dtype_size))

        if get_bit_len(self.op_obj.reduce_check_obj.src.dtype) == 16:
            index_type = "uint16"
        else:
            index_type = "uint32"
        cal_index_params = namedtuple("CalIndexParams", "dtype_size rep_stride it2_output_count"
                                                        " it2_start_pos index_type element_num_per_rep it3_start_pos")
        cal_index_params_ins = cal_index_params(
            cal_index_iter2_params_ins.dtype_size,
            cal_index_iter2_params_ins.rep_stride, it2_output_count, it2_start_pos,
            index_type, cal_index_iter2_params_ins.element_num_per_rep, it3_start_pos)

        dst_tvm_buffer = self.context.tensor_buffer.get_npbuffer_by_tvmbuffer(
            self.op_obj.reduce_check_obj.dst.buffer)
        dst_tensor = dst_tvm_buffer.buffer.reshape(-1).view(self.op_obj.reduce_check_obj.dst.dtype)
        dst_offset = self.context.evaluate_expr(self.op_obj.reduce_check_obj.dst.offset)
        # res value, res index
        dst_tensor[dst_offset], dst_tensor[dst_offset + 1] = self.vreduce_cal_index_iter3(cal_index_params_ins)

    def create_gpr_x_t(self, context, temp_env, gpr_params):
        """
        create general purpose register x_t

        Parameters
        ----------
        gpr_params
        context : the stack context

        temp_env : the temp environment
        Returns
        -------
        xt_idx
        """
        # check address overlap
        stride_unit = 0
        mask_value = eval_mask(self.op_obj.control_op.mask, context)
        self.op_obj.control_op.mask = mask_value
        if self.op_obj.reduce_check_obj.src.buffer == self.op_obj.reduce_check_obj.work_tensor.buffer:
            name = "vec_reduce_min" if self.op_obj.name == "vcmin" else "vec_reduce_max"
            block_list = [_DEFAULT_BLOCK_LEN,
                          ONE_REP_BYTE_SIZE // max(get_bit_len(gpr_params.dst.dtype),
                                                   get_bit_len(gpr_params.src_op.tensor_obj.dtype))]
            gpr_params.src_op.check_address_overlapping(
                name, self.op_obj.control_op, gpr_params.src_op, block_list)

        x_t = VREDUCE_DEFAULT_DST_REP_STRIDE
        x_t |= VREDUCE_DEFAULT_SRC_BLK_STRIDE << SRC_BLOCK_STRIDE_SHIFT_POS
        x_t |= stride_unit << STRIDE_UNIT_SHIFT_POS
        x_t |= gpr_params.repeat_times << REPEAT_SHIFT_POS
        x_t |= gpr_params.src_rep_stride << _SRC_REPEAT_STRIDE_SHIFT_POS
        xt_idx = temp_env.alloc_register()
        context.model.write_gpr(xt_idx, x_t)
        return xt_idx

    def set_temp_env(self, temp_params, dst_offset=0, src_offset=0):
        """
        set temp env
        :return:
        """
        temp_env = TempEnv()
        params = namedtuple("TempParams", "dst_align src_align mask dst src_op repeat_times src_rep_stride")
        params_ins = params(*temp_params)
        temp_env.offset = dst_offset
        param = _ENCODER.new_param()
        param.xd, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            self.context, temp_env, params_ins.dst, params_ins.dst_align, access_mode='w')
        temp_env.offset = src_offset
        xn_idx, _, src_alloc_size, _ = copy_tensor_to_model(
            self.context, temp_env, params_ins.src_op.tensor_obj, params_ins.src_align, access_mode='r')

        param.type = VEC_DATA_TYPE_ENCODING_V200.get(params_ins.src_op.tensor_obj.dtype)
        param.xt = self.create_gpr_x_t(self.context, temp_env, params_ins)
        param.xn = xn_idx

        params_ins.src_op.check_read_mem_out_of_bounds(
            src_alloc_size, self.op_obj.control_op, ori_offset=src_offset)
        instr = VEC_WHOLE_REDUCE_ENCODER.get(self.op_obj.name)(param)
        self.context.model.step(instr)
        temp_env.check_mem_access(self.context.model, False)

        self.context.model.read_memory(dst_addr, params_ins.dst.scope, dst_ptr, dst_alloc_size)

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        self.context = context
        self.op_obj.src_tensor_op.context = self.context
        self.op_obj.work_tensor_op.context = self.context
        self.op_obj.control_op.mask = self.mask
        self.op_obj.control_op.repeat_times = self.repeat_times
        repeat_times = self.context.evaluate_expr(self.op_obj.control_op.repeat_times)
        src_rep_stride = self.context.evaluate_expr(self.op_obj.src_tensor_op.rep_stride)
        # check params
        self.op_obj.reduce_check_obj.check_vreduce_repeat_times(repeat_times, self.op_obj.cal_index,
                                                                self.op_obj.reduce_check_obj.src.dtype)
        mask_value = eval_mask(self.op_obj.control_op.mask, context)
        check_mask_valid(np.array(mask_value).view("uint64").tolist(),
                         get_bit_len(self.op_obj.reduce_check_obj.src.dtype))
        TikCheckUtil.check_in_range_by_dtype(
            src_rep_stride, msg="src_rep_stride should be in the range of [%d, %d], input src_rep_stride: %s"
            % (DEFAULT_STRIDE, MAX_REP_STRIDE_DOUBLE_BYTE, src_rep_stride),
            var_range=[DEFAULT_STRIDE, MAX_REP_STRIDE_DOUBLE_BYTE])
        if self.op_obj.cal_index:
            self.op_obj.reduce_check_obj.check_dtype_overflow(
                repeat_times, self.op_obj.reduce_check_obj.src, src_rep_stride)

        src_offset = self.context.evaluate_expr(self.op_obj.reduce_check_obj.src.offset)
        rep_is_scalar = is_basic_expr(self.op_obj.control_op.repeat_times)
        if not TikSocManager.is_v300_610l_soc():
            self.op_obj.reduce_check_obj.check_space_overflow(
                (mask_value, self.op_obj.reduce_check_obj.dst, self.op_obj.reduce_check_obj.work_tensor,
                 self.op_obj.reduce_check_obj.src,
                 self.context.evaluate_expr(self.op_obj.reduce_check_obj.dst.offset),
                 self.context.evaluate_expr(self.op_obj.reduce_check_obj.work_tensor.offset),
                 src_offset, repeat_times, src_rep_stride),
                self.op_obj.cal_index, rep_is_scalar)

        if TikSocManager.is_v300_610l_soc():
            context.step_next(self.source_id)
            return

        self._first_step(repeat_times, src_rep_stride)

        if self.op_obj.cal_index:
            self._vreduce_cal_index(repeat_times, src_rep_stride)
        else:
            dtype_len = DTYPE_SIZE[self.op_obj.reduce_check_obj.src.dtype]
            # second step
            cur_data = self._second_step(
                self.op_obj.reduce_check_obj.work_tensor, self.op_obj.work_tensor_op,
                repeat_times * VREDUCE_PER_REP_OUTPUT)
            one_rep_data = ONE_REP_BYTE_SIZE // dtype_len
            # third step
            if cur_data <= one_rep_data:
                self._third_step((self.op_obj.reduce_check_obj.dst, self.op_obj.reduce_check_obj.work_tensor,
                                  self.op_obj.work_tensor_op, cur_data))
                return

            # second second step
            cur_data = self._second_step(self.op_obj.reduce_check_obj.work_tensor,
                                         self.op_obj.work_tensor_op, cur_data)
            new_repeat_times = cur_data * dtype_len // ONE_REP_BYTE_SIZE
            # second third step
            if new_repeat_times <= 1:
                self._third_step((self.op_obj.reduce_check_obj.dst, self.op_obj.reduce_check_obj.work_tensor,
                                  self.op_obj.work_tensor_op, cur_data))

    def _vreduce_eval(self, reduce_eval_params, dst_offset=0, src_offset=0):
        """
        reduce eval
        :param reduce_eval_params:
        :param dst_offset:
        :param src_offset:
        :return:
        """
        mask, dst, src_op, repeat_times, _ = reduce_eval_params
        self.op_obj.control_op.mask = mask
        self.op_obj.control_op.repeat_times = repeat_times
        set_vector_mask(
            mask, self.context, tensor_bit_len=max(get_bit_len(dst.dtype), get_bit_len(src_op.tensor_obj.dtype)))
        self.set_temp_env(
            (VREDUCE_DST_ALIGN.get(self.op_obj.name), vec_template_align(src_op.tensor_obj.dtype), *reduce_eval_params),
            dst_offset=dst_offset, src_offset=src_offset)

    def _first_step(self, repeat_times, src_rep_stride):
        """
        first step
        :param repeat_times:
        :param src_rep_stride:
        :return:
        """
        max_repeat_times = self.context.evaluate_expr(MAX_REPEAT_TIMES)
        for_range_times = repeat_times // max_repeat_times
        dtype_len = DTYPE_SIZE.get(self.op_obj.reduce_check_obj.src.dtype)
        for index in range(0, for_range_times):
            dst_offset, src_offset = self.get_first_step_tensor_offset(
                index, max_repeat_times, src_rep_stride, dtype_len)
            self._vreduce_eval((self.op_obj.control_op.mask,
                                self.op_obj.reduce_check_obj.work_tensor, self.op_obj.src_tensor_op,
                                max_repeat_times, src_rep_stride), dst_offset=dst_offset,
                               src_offset=src_offset)

        left_repeat_times = repeat_times % max_repeat_times
        if left_repeat_times > 0:
            dst_offset, src_offset = self.get_first_step_tensor_offset(
                for_range_times, max_repeat_times, src_rep_stride, dtype_len)
            self._vreduce_eval(
                (self.op_obj.control_op.mask,
                 self.op_obj.reduce_check_obj.work_tensor, self.op_obj.src_tensor_op,
                 left_repeat_times, src_rep_stride), dst_offset=dst_offset, src_offset=src_offset)

    def _second_step(self, dst, src_op, cur_data):
        """
        second step
        :param dst: dst tensor
        :param src_op: src tensor op
        :param cur_data: current data
        :return:
        """
        dtype_len = DTYPE_SIZE[src_op.tensor_obj.dtype]
        new_repeat_times = cur_data * dtype_len // ONE_REP_BYTE_SIZE
        if new_repeat_times >= 1:
            new_mask = self.op_obj.reduce_check_obj.vreduce_create_mask(ONE_REP_BYTE_SIZE // dtype_len //
                                                                        VREDUCE_PER_REP_OUTPUT)
            self._vreduce_eval((new_mask, dst,
                                src_op, new_repeat_times,
                                VREDUCE_DEFAULT_SRC_REP_STRIDE))

        left_data = cur_data % (ONE_REP_BYTE_SIZE // dtype_len)

        if left_data > 0:
            new_mask = self.op_obj.reduce_check_obj.vreduce_create_mask(left_data // VREDUCE_PER_REP_OUTPUT)
            self._vreduce_eval((new_mask, dst, src_op,
                                VREDUCE_MIN_REPEAT_TIMES,
                                VREDUCE_DEFAULT_SRC_REP_STRIDE),
                               new_repeat_times * VREDUCE_PER_REP_OUTPUT,
                               new_repeat_times * ONE_REP_BYTE_SIZE // dtype_len)
            # have tail, new_repeat_times used to calculate output data num
            new_repeat_times += 1
        return new_repeat_times * VREDUCE_PER_REP_OUTPUT

    def _vreduce_body_cal(self, vreduce_body_cal_params):
        body_cal_params = namedtuple(
            "BodyCalParams", "pre_data_count element_num_per_rep pre_start_pos cur_start_pos dtype_size")
        body_cal_params_ins = body_cal_params(*vreduce_body_cal_params)

        ex_body_repeat_times = body_cal_params_ins.pre_data_count // body_cal_params_ins.element_num_per_rep
        ex_tail_num_count = body_cal_params_ins.pre_data_count % body_cal_params_ins.element_num_per_rep
        ex_body_output_count = 0
        if ex_body_repeat_times != 0:
            if get_bit_len(self.op_obj.reduce_check_obj.src.dtype) == 16:
                body_mask = [int("01" * 32, 2), int("01" * 32, 2)]
            else:
                body_mask = [0, int("01" * 32, 2)]

            self._vreduce_eval((body_mask, self.op_obj.reduce_check_obj.work_tensor,
                                self.op_obj.work_tensor_op, ex_body_repeat_times,
                                VREDUCE_DEFAULT_SRC_REP_STRIDE), body_cal_params_ins.cur_start_pos,
                               body_cal_params_ins.pre_start_pos)
            ex_body_output_count = VREDUCE_PER_REP_OUTPUT * ex_body_repeat_times
        ex_tail_output_count = 0
        if ex_tail_num_count != 0:
            tail_mask = self.op_obj.reduce_check_obj.vreduce_create_mask(ex_tail_num_count //
                                                                         VREDUCE_PER_REP_OUTPUT)
            self._vreduce_eval((tail_mask, self.op_obj.reduce_check_obj.work_tensor,
                                self.op_obj.work_tensor_op, VREDUCE_MIN_REPEAT_TIMES,
                                VREDUCE_DEFAULT_SRC_REP_STRIDE),
                               body_cal_params_ins.cur_start_pos + ex_body_output_count,
                               body_cal_params_ins.pre_start_pos + body_cal_params_ins.element_num_per_rep *
                               ex_body_repeat_times)
            ex_tail_output_count = VREDUCE_PER_REP_OUTPUT
        output_count = ex_body_output_count + ex_tail_output_count
        next_start_pos = self.op_obj.reduce_check_obj.align_start_pos(body_cal_params_ins.cur_start_pos +
                                                                      output_count, body_cal_params_ins.dtype_size)
        return output_count, next_start_pos

    def _vreduce_cal_index(self, repeat_times, rep_stride):
        """
        reduce cal index
        :param repeat_times:
        :param rep_stride:
        :return:
        """
        it1_output_count = VREDUCE_PER_REP_OUTPUT * repeat_times
        dtype_size = DTYPE_SIZE[self.op_obj.reduce_check_obj.src.dtype]
        element_num_per_rep = ONE_REP_BYTE_SIZE // dtype_size
        cal_index_iter2_params = namedtuple(
            "Iter2", "it1_output_count dtype_size element_num_per_rep rep_stride")
        cal_index_iter2_params_ins = \
            cal_index_iter2_params(it1_output_count, dtype_size, element_num_per_rep, rep_stride)
        self.vreduce_cal_index_iter2(cal_index_iter2_params_ins)

    def _third_step(self, third_step_params):
        """
        third step
        :param third_step_params:
        :return:
        """
        dst, work_tensor, src_op, cur_data = third_step_params
        if cur_data > 0:
            new_mask = self.op_obj.reduce_check_obj.vreduce_create_mask(
                cur_data // VREDUCE_PER_REP_OUTPUT)
            self._vreduce_eval((new_mask, work_tensor,
                                src_op, VREDUCE_MIN_REPEAT_TIMES,
                                VREDUCE_DEFAULT_SRC_REP_STRIDE))
            # save result to dst
            dst_tvm_buffer = self.context.tensor_buffer.get_npbuffer_by_tvmbuffer(
                work_tensor.buffer)
            np_work_tensor = dst_tvm_buffer.buffer.reshape(-1).view(work_tensor.dtype)
            np_work_tensor_offset = self.context.evaluate_expr(work_tensor.offset)
            dst_tensor_tvm_buffer = self.context.tensor_buffer.get_npbuffer_by_tvmbuffer(
                dst.buffer)
            dst_tensor = dst_tensor_tvm_buffer.buffer.reshape(-1).view(dst.dtype)
            dst_offset = self.context.evaluate_expr(dst.offset)
            dst_tensor[dst_offset] = np_work_tensor[np_work_tensor_offset]
