#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     __init__.py
DESC:     make debug a module
CREATED:  2019-7-04 20:12:13
MODIFIED: 2020-12-7 19:17:00
"""

import copy
import ctypes
import numpy as np
from tbe.tik.common.common_util import is_tensor_addr_list
from tbe.tik.common.util import reduce_mul
from tbe.tik.tik_lib.tik_params import TIK_VERSION_1_5
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_source_info import source_info_decorator
from tbe.tik.debug.context import Context
from tbe.tik.debugger import TikDebugger
from tbe.tik.debug.intrinsic_print import PrintExpr
from tbe.tik.debug.tikdbg.codemapping import get_caller_context
from tbe.tik.debug.npbuffer import create_shared_array_by_np_array
from tbe.tik.debug.decorators import tensor_set_as_decorator
from tbe.tik.debug.decorators import build_cce_decorator
from tbe.tik.debug.decorators import else_scope_decorator
from tbe.tik.debug.decorators import for_range_decorator
from tbe.tik.debug.decorators import block_barrier_decorator
from tbe.tik.debug.decorators import for_range_sub_decorator
from tbe.tik.debug.decorators import if_scope_decorator
from tbe.tik.debug.decorators import elif_scope_decorator
from tbe.tik.debug.decorators import rpn_cor_diag_decorator
from tbe.tik.debug.decorators import scalar_set_as_decorator
from tbe.tik.debug.decorators import tik_return_decorator
from tbe.tik.debug.decorators import tensor_register
from tbe.tik.debug.decorators import scalar_register
from tbe.tik.debug.decorators import set_2d_decorator
from tbe.tik.debug.decorators import get_ctrl_bits
from tbe.tik.debug.decorators import atomic_add_to_scalar
from tbe.tik.debug.decorators import load_smask_decorator
from tbe.tik.debug.decorators import vector_register
from tbe.tik.debug.decorators import tensor_get_addr_decorator
from tbe.tik.debug.decorators import del_tensor_decorator
from tbe.tik.debug.decorators import del_scalar_decorator
from tbe.tik.debug.decorators import del_loop_var_decorator
from tbe.tik.debug.decorators import scalar_array_register
from tbe.tik.debug.decorators import scalar_array_set_as_decorator
from tbe.tik.debug.decorators import get_status_bits
from tbe.tik.debug.decorators import tensor_addr_register
from tbe.tik.debug.decorators import tensor_addr_set_as_decorator
from tbe.tik.debug.tik_vector_ops_debug.tik_vector_debug import vec_single_elewise_func_dec_new
from tbe.tik.debug.tik_vector_ops_debug.tik_vector_debug import vec_scalar_elewise_func_dec_new


class NumpyPrintSet:
    """
    set numpy print options and error set
    """
    def __init__(self, threshold):
        self.threshold = threshold
        # save default print option
        self.default_print = np.get_printoptions()
        # save default how floating-point errors are handled
        self.default_err = np.geterr()

    def __enter__(self):
        # set print options and errors handled
        np.set_printoptions(threshold=self.threshold)
        np.seterr(all='raise')

    def __exit__(self, exc_type, exc_val, exc_tb):
        # reset to default
        np.set_printoptions(**self.default_print)
        np.seterr(**self.default_err)


class Tikdb:
    """
    tik debug class
    """

    def __init__(self, tik_instance, disable_debug):
        """
        init with tik_instance

        Parameters
        ----------
        tik_instance : an instance of tik
        """
        self.context = Context(tik_instance.d_profiling)
        self.tik_instance = tik_instance
        if not disable_debug:
            self.tik_debugger = TikDebugger()
            self.context.tik_debugger = self.tik_debugger
            self.context.tik_debug = self.tik_debugger.tik_debug
        else:
            self.tik_debugger = None

    def __del__(self):
        self.tik_debugger = None
        self.tik_instance = None
        self.context = None

    @staticmethod
    def _update_np_array_value(addr_list_np_array_raw_array_map, addr_list_array_size_map, addr_list_array_dtype_map):
        for array_addr in addr_list_np_array_raw_array_map.keys():
            np_shape = addr_list_array_size_map[array_addr]
            np_dtype = addr_list_array_dtype_map[array_addr]
            array_size_bytes = reduce_mul(np_shape) * np_dtype.itemsize
            tensor_buffer = (ctypes.c_char * array_size_bytes).from_address(array_addr)
            ele_nums = reduce_mul(np_shape)
            flatten_np = np.ndarray((ele_nums,), dtype=np_dtype, buffer=tensor_buffer).reshape(np_shape)
            flatten_np[:] = addr_list_np_array_raw_array_map[array_addr][:]

    @staticmethod
    def _trans_np_array_to_shared_array(debug_feed_dict, tensor_name, addr_list_np_array_raw_array_map,
                                        addr_list_array_size_map, addr_list_array_dtype_map):
        addr_list = []
        # feed_dict[t.name]: np list -> np_addr list
        for np_value in debug_feed_dict.get(tensor_name):
            array_addr = np_value.__array_interface__["data"][0]
            if array_addr not in addr_list_np_array_raw_array_map:
                # record the numpy array info
                addr_list_array_size_map[array_addr] = np_value.shape
                addr_list_array_dtype_map[array_addr] = np_value.dtype

                # create a shared numpy array for debug
                raw_array_np = create_shared_array_by_np_array(np_value)
                addr_list_np_array_raw_array_map[array_addr] = raw_array_np
                addr_list.append(raw_array_np.__array_interface__["data"][0])
            else:
                raw_array_np = addr_list_np_array_raw_array_map[array_addr]
                addr_list.append(raw_array_np.__array_interface__["data"][0])
        debug_feed_dict[tensor_name] = addr_list

    @source_info_decorator()
    def start_debug(self, feed_dict, interactive=True, desc_tensor=None):
        """
        start debug

        Parameters
        ----------
        feed_dict : symbol dict
        interactive : if interactive , True/False
        desc_tensor: A list is used to specify a special tensor's name for save the gm tensor info.
        Returns
        -------
        None
        """
        debug_feed_dict = copy.copy(feed_dict)
        addr_list_np_array_raw_array_map = {}
        addr_list_array_size_map = {}
        addr_list_array_dtype_map = {}

        # inputs TensorAddrList, np list --> np_addr list
        for t in self.tik_instance.last_inputs:
            tensor_name = t.name
            if is_tensor_addr_list(t):
                self._trans_np_array_to_shared_array(debug_feed_dict, tensor_name, addr_list_np_array_raw_array_map,
                                                     addr_list_array_size_map, addr_list_array_dtype_map)
            # for description Tensor, first element is GM Tensor Addr, others is Gm Tensor info,
            # for example, shape, dtype, dims
            if desc_tensor and tensor_name in desc_tensor:
                if len(debug_feed_dict.get(tensor_name)) != 2:
                    raise RuntimeError("when feed_dict's key in desc_tensor, it's value's data len must be 2")
                src_arr = debug_feed_dict.get(tensor_name)[0]
                tmp_shape = src_arr.shape
                src_arr = src_arr.flatten()
                src_arr[0] = debug_feed_dict.get(tensor_name)[1].__array_interface__["data"][0]
                src_arr.resize(tmp_shape)
                debug_feed_dict[tensor_name] = src_arr

        if self.tik_instance.debug_disabled:
            TikCheckUtil.raise_error(
                'Debug function is disabled,'
                ' please try to open it when you define the tik_instance.')
        if self.tik_instance.context.debug_source_id > 1:
            if self.context.debug_vm_ctx is None:
                TikCheckUtil.raise_error('Context debug_vm_ctx not created, cannot run debug')
            self.context.get_actual_source_num_from_vm()
        else:
            # if no use tik1.5 API, free debug_vm_ctx
            self.context.free_debug_vm()

        # set is_in_debug equal to True to not check life cycle
        self.tik_instance.is_in_debug = True

        if self.context.vector_list:
            for vector in self.context.vector_list:
                self.context.add_vector(vector)

        self.context.interactive = interactive
        # self.tik_debug has be inited in __init__(), if not in interactive statue, set to None
        if not interactive:
            self.context.tik_debugger = None

        # set threshold of numpy print equals to 100000000, bigger than default
        np_print_threshold = 100000000
        with NumpyPrintSet(np_print_threshold):
            ret = self.context.eval_(debug_feed_dict, self.tik_instance.tik_version)

            # update the TensorAddrList output GM numpy array value, value from RawArray
            self._update_np_array_value(addr_list_np_array_raw_array_map, addr_list_array_size_map,
                                        addr_list_array_dtype_map)
            self.context.free()  # free context for free numpy buffer array
            return ret

    @source_info_decorator()
    def debug_print(self, expr):
        """
        print when start debug

        Parameters
        ----------
        expr : str, user input

        Returns
        -------
        None
        """
        TikCheckUtil.check_type_match(expr, str, 'expr must be a string')
        print_stmt = PrintExpr(get_caller_context(), expr, self.tik_debugger)
        self.context.curr_scope().add_stmt(print_stmt)
