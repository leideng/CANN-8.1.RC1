#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.
FILE:     tik_vector_data_transform_debug_.py
DESC:     this file contains many data_transform debug
CREATED:  2021-12-15 10:50:08
MODIFIED: 2021-12-15 10:50:08
"""
from tbe.tik.common.common_util import vec_template_align
from tbe.tik.debug.sim.util import TempEnv
from tbe.tik.debug.simd import _ENCODER
from tbe.tik.debug.simd import _MAX_PARAM_TYPE
from tbe.tik.debug.statement import STMT
from tbe.tik.debug.util import copy_tensor_to_model
from tbe.tik.debug.util import get_dtype_bit_width
from tbe.tik.debug.util import VEC_DATA_TYPE_ENCODING
from tbe.tik.tik_lib.tik_check_util import TikCheckUtil
from tbe.tik.tik_lib.tik_params import VTRANSPOSE_REQUIRED_ELEMENT
from tbe.tik.tik_lib.tik_params import VA0_INDEX
from tbe.tik.tik_lib.tik_params import ONE_BLK_SIZE
from tbe.tik.tik_lib.tik_params import MAX_REPEAT_TIMES
from tbe.tik.tik_lib.tik_params import REPEAT_SHIFT_POS
from tbe.tik.tik_lib.tik_params import MAX_REP_STRIDE_DOUBLE_BYTE
from tbe.tik.tik_lib.tik_params import PER_TRANSPOSE_DATA_SIZE
from tbe.tik.tik_lib.tik_params import ALIGNED_ADDR
from tbe.tik.tik_lib.tik_params import MIN_VNCHWTRANS_STRIDE
from tbe.tik.tik_lib.tik_params import MAX_VNCHWTRANS_STRIDE
from tbe.tik.tik_lib.tik_params import MAX_VNCHWTRANS_REPEAT_TIMES
from tbe.tik.tik_lib.tik_params import MIN_REPEAT_TIMES
from tbe.tik.tik_lib.tik_soc_manager import TikSocManager
from tbe.tik.tik_lib.tik_vector_api.tik_params_check_fills import VecTransCheckParams
from tbe.tik.tik_lib.tik_vector_api.tik_params_check_fills import VnchwconvCheckParams


def check_vec_trans_params_range(repeat_times, dst_rep_stride, src_rep_stride):
    """
    used to check the range of params of vec_trans

    Parameters
    ----------
    repeat_times : Repeated iterations times
    dst_rep_stride : offset of dst operator between adjacent iterations, offset unit is 512B
    src_rep_stride : offset of src operator between adjacent iterations, offset unit is 512B

    Returns
    -------
    Nones
    """
    TikCheckUtil.check_in_range_by_dtype(
        repeat_times, msg="repeat_times should be in the range of [%s, %s], input repeat_times: %s"
        % (MIN_REPEAT_TIMES, MAX_VNCHWTRANS_REPEAT_TIMES, repeat_times),
        var_range=[MIN_REPEAT_TIMES, MAX_VNCHWTRANS_REPEAT_TIMES])
    TikCheckUtil.check_in_range_by_dtype(
        dst_rep_stride, msg="dst_rep_stride should be in the range of [%s, %s], input dst_rep_stride: %s"
        % (MIN_VNCHWTRANS_STRIDE, MAX_VNCHWTRANS_STRIDE, dst_rep_stride),
        var_range=[MIN_VNCHWTRANS_STRIDE, MAX_VNCHWTRANS_STRIDE])
    TikCheckUtil.check_in_range_by_dtype(
        src_rep_stride, msg="src_rep_stride should be in the range of [%s, %s], input src_rep_stride: %s"
        % (MIN_VNCHWTRANS_STRIDE, MAX_VNCHWTRANS_STRIDE, src_rep_stride),
        var_range=[MIN_VNCHWTRANS_STRIDE, MAX_VNCHWTRANS_STRIDE])


def _get_dst_addr_set_list(context, temp_env, dst_list, spec_instr=False):
    """
    get dst_addr_set and dst_addr_list

    Parameters
    ----------
    context : the stack context

    temp_env : the temp environment

    dst_list

    Returns
    -------
    dst_addr_set

    dst_addr_list
    """
    dst_addr_set = set()
    dst_addr_list = []

    for dst in dst_list:
        if spec_instr and TikSocManager.is_v100_soc():
            # for v100 pvmodel, dst is rw mode;
            access_mode = 'rw'
        else:
            # for v200 pvmodel, dst is only w mode
            access_mode = 'w'

        old_require_xt = temp_env.require_xt
        temp_env.require_xt = False
        _, dst_buffer_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
            context, temp_env, dst, ALIGNED_ADDR, access_mode)
        temp_env.require_xt = old_require_xt

        dst_addr_set.add(
            (dst.scope, dst_buffer_addr, dst_alloc_size, dst_ptr))
        dst_addr = temp_env.get_tensor_addr(context, dst, access_mode)

        dst_addr_list.append(dst_addr)

    return dst_addr_set, dst_addr_list


def _get_src_addr_list(context, temp_env, src_list):
    """
    get src_addr_list

    Parameters
    ----------
    context : the stack context

    temp_env : the temp environment

    Returns
    -------
    src_addr_list
    """
    src_addr_list = []

    for src in src_list:
        old_require_xt = temp_env.require_xt
        temp_env.require_xt = False
        copy_tensor_to_model(context, temp_env, src, ALIGNED_ADDR, access_mode='r')
        temp_env.require_xt = old_require_xt
        src_addr = temp_env.get_tensor_addr(context, src, access_mode='r')
        src_addr_list.append(src_addr)

    return src_addr_list


def _create_va_reg(context, temp_env, addr_list):
    """
    create va register, the relationships between va register and addr_list are as follows:
    vad: dst_addr_list
    van: src0_addr_list
    vam: src1_addr_list

    Parameters
    ----------
    context : the stack context

    temp_env : the temp environment

    Returns
    -------
    src_addr_list
    """
    if len(addr_list) == 16:
        # 16 need two successive VA register
        va_id, va_id1 = temp_env.alloc_va_register(2)
        context.model.write_va(va_id, addr_list[0:8])
        context.model.write_va(va_id1, addr_list[8:16])
    else:
        va_id = temp_env.alloc_va_register()
        context.model.write_va(va_id, addr_list)

    return va_id


class VnchwTrans(STMT):
    """
    VnchwTrans instruction
    """

    def __init__(self, source_info, op_obj):
        super(VnchwTrans, self).__init__(source_info, op_obj.tik_instance.context.tik_debugger)
        self.op_obj = op_obj

    @staticmethod
    def vnchwtrans_deal(repeat_times, dst_tensor_op, src_tensor_op, context):
        """
        run the instruction

        Parameters
        ----------
        repeat_times : repeat_times
        dst_tensor_op : dst_tensor_op
        src_tensor_op : src_tensor_op
        context : context

        Returns
        -------
        None
        """
        for i in range(repeat_times):
            temp_env = TempEnv()
            # align is 32B
            align = vec_template_align(dst_tensor_op.tensor_obj.dtype)
            temp_env.offset = src_tensor_op.rep_stride * PER_TRANSPOSE_DATA_SIZE * i
            xn_idx, _, _, _ = copy_tensor_to_model(
                context, temp_env, src_tensor_op.tensor_obj, align=align, access_mode='r')
            temp_env.offset = dst_tensor_op.rep_stride * PER_TRANSPOSE_DATA_SIZE * i
            xd_idx, dst_addr, dst_alloc_size, dst_ptr = copy_tensor_to_model(
                context, temp_env, dst_tensor_op.tensor_obj, align=align, access_mode='w')

            param = context.encoder.new_param()
            param.type = VEC_DATA_TYPE_ENCODING[src_tensor_op.tensor_obj.dtype]
            param.xd = xd_idx
            param.xn = xn_idx
            param.isV300 = int(TikSocManager.is_310b_610l_soc())
            context.model.step(context.encoder.gen_vtranspose(param))
            temp_env.check_mem_access(context.model, True)
            context.model.read_memory(dst_addr, dst_tensor_op.tensor_obj.scope, dst_ptr, dst_alloc_size)

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        self.op_obj.dst_tensor_op.context = context
        self.op_obj.dst_tensor_op.set_rep_stride_value()
        self.op_obj.dst_tensor_op.eval_offset()

        self.op_obj.src_tensor_op.context = context
        self.op_obj.src_tensor_op.set_rep_stride_value()
        self.op_obj.src_tensor_op.eval_offset()

        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)

        check_vec_trans_params_range(repeat, self.op_obj.dst_tensor_op.rep_stride_value,
                                     self.op_obj.src_tensor_op.rep_stride_value)
        # check tensor overflow
        VecTransCheckParams.check_new_vec_trans_overflow(self.op_obj.dst_tensor_op, self.op_obj.src_tensor_op,
                                                         self.op_obj.control_op)
        self.vnchwtrans_deal(repeat, self.op_obj.dst_tensor_op, self.op_obj.src_tensor_op, context)


class Vnchwconv(STMT):
    """
    Vnchwconv instruction
    """

    def __init__(self, source_info, op_obj):
        super(Vnchwconv, self).__init__(source_info, op_obj.tik_instance.context.tik_debugger)
        self.op_obj = op_obj
        self.name = op_obj.name
        if self.name is None:
            self.name = "vnchwconv"

    def eval_(self, context):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context

        Returns
        -------
        None
        """
        self.op_obj.dst_tensor_op.context = context
        self.op_obj.src_tensor_op.context = context
        self.op_obj.dst_tensor_op.set_repeat_times(self.op_obj.control_op.repeat_times)
        self.op_obj.src_tensor_op.set_repeat_times(self.op_obj.control_op.repeat_times)
        if self.op_obj.dst_tensor_op.repeat_times_value == 1:
            self.op_obj.dst_tensor_op.set_rep_stride_value(0)
            self.op_obj.src_tensor_op.set_rep_stride_value(0)
        else:
            self.op_obj.dst_tensor_op.set_rep_stride_value()
            self.op_obj.src_tensor_op.set_rep_stride_value()
        temp_env = TempEnv()

        dst_addr_set = self.get_param(context, temp_env)

        src_read_offset = 0
        dst_write_offset = 0
        if self.op_obj.dst_tensor_op.repeat_times_value == 1:
            src_read_offset = self.op_obj.src_tensor_op.rep_stride_value * ONE_BLK_SIZE
            dst_write_offset = self.op_obj.dst_tensor_op.rep_stride_value * ONE_BLK_SIZE

        if self.op_obj.src_high_half is True and self.op_obj.src_tensor_op.tensor_obj[0].dtype in ["int8", "uint8"]:
            src_read_offset += 16
        if self.op_obj.dst_high_half is True and self.op_obj.dst_tensor_op.tensor_obj[0].dtype in ["int8", "uint8"]:
            dst_write_offset += 16

        src_tensor_nums = len(self.op_obj.src_tensor_op.tensor_obj)
        dst_tensor_nums = len(self.op_obj.dst_tensor_op.tensor_obj)
        temp_env.check_mem_access_vnchwconv(context.model, tensor_nums_list=[src_tensor_nums, dst_tensor_nums],
                                            src_read_offset=src_read_offset, dst_store_offset=dst_write_offset)
        for scope, buffer_addr, alloc_size, ptr in dst_addr_set:
            context.model.read_memory(buffer_addr, scope, ptr, alloc_size)

    def get_param(self, context, temp_env):
        """
        run the instruction

        Parameters
        ----------
        context : the stack context
        temp_env : temp_env

        Returns
        -------
        dst_addr_set
        """
        src_addr_list = _get_src_addr_list(context, temp_env, self.op_obj.src_tensor_op.tensor_obj)
        dst_addr_set, dst_addr_list = _get_dst_addr_set_list(
            context, temp_env, self.op_obj.dst_tensor_op.tensor_obj, spec_instr=True)

        # we treat b16 as uint16 ...
        ditc_dtype = get_dtype_bit_width(self.op_obj.src_tensor_op.tensor_obj[VA0_INDEX].dtype)
        dtype = 'uint' + ditc_dtype
        param = _ENCODER.new_param()
        param.type = VEC_DATA_TYPE_ENCODING.get(dtype)
        TikCheckUtil.check_in_range_by_dtype(param.type, var_range=[0, _MAX_PARAM_TYPE])
        param.vad = _create_va_reg(context, temp_env, dst_addr_list)
        param.van = _create_va_reg(context, temp_env, src_addr_list)
        param.xt = self.create_gpr_x_t(context, temp_env)
        param.srcH = self.op_obj.src_high_half
        param.dstH = self.op_obj.dst_high_half
        param.isV300 = int(TikSocManager.is_310b_610l_soc())
        instr = _ENCODER.gen_vnchwconv(param)
        context.model.step(instr)
        return dst_addr_set

    def create_gpr_x_t(self, context, temp_env):
        """
        create general purpose register x_t

        Parameters
        ----------
        context : the stack context

        temp_env : the temp environment

        Returns
        -------
        xt_idx
        """
        repeat = context.evaluate_expr(self.op_obj.control_op.repeat_times)
        # check repeat
        TikCheckUtil.check_in_range_by_dtype(
            repeat, msg="repeat_times should be in the range of [%s, %s], input value is %s"
            % (0, MAX_REPEAT_TIMES, str(repeat)), var_range=[0, MAX_REPEAT_TIMES])

        # check strides
        self.op_obj.dst_tensor_op.check_tensor_op_rep_stride(MAX_REP_STRIDE_DOUBLE_BYTE)
        self.op_obj.src_tensor_op.check_tensor_op_rep_stride(MAX_REP_STRIDE_DOUBLE_BYTE)

        # check address overlapping
        msg = "dst_list and src_list"
        params_list = (self.op_obj.dst_tensor_op, self.op_obj.src_tensor_op, self.op_obj.control_op,
                       self.op_obj.dst_high_half, self.op_obj.src_high_half)
        VnchwconvCheckParams(self.name, params_list).check_vnchwconv_overlap(msg, self.op_obj.dst_high_half,
                                                                             self.op_obj.src_high_half, context)
        src_rep_stride_shift_pos = 16

        xt_idx = temp_env.alloc_register()
        x_t = self.op_obj.dst_tensor_op.rep_stride_value
        x_t |= self.op_obj.src_tensor_op.rep_stride_value << src_rep_stride_shift_pos
        x_t |= repeat << REPEAT_SHIFT_POS

        context.model.write_gpr(xt_idx, x_t)

        return xt_idx
