#!/usr/bin/env python
# -*- coding: UTF-8 -*-
# Copyright 2019-2023 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
fusion pass handler
"""

from copy import deepcopy
from tbe.common.register import fusion_pass_mgr
from tbe.common.register.class_manager import GraphInfo
from tbe.common.register.class_manager import OpInfo
from tbe.common.register.class_manager import AttrInfo
from tbe.common.register.class_manager import InputInfo
from tbe.common.register.class_manager import TensorInfo


def assemble_tensor_info(tensor_desc):
    """
    create tensor info obj by tensor desc dict

    Parameters
    ----------
    tensor_desc : dict
        tensor desc

    Returns
    -------
    tensor_info : TensorInfo
        tensor info
    """
    tensor_info = TensorInfo()
    if tensor_desc is None:
        return tensor_info
    tensor_info._id = tensor_desc.get("name")
    tensor_info._dtype = tensor_desc.get("data_type")
    tensor_info._format = tensor_desc.get("format")
    if tensor_desc.get("shape", []) != "NULL":
        tensor_info._shape = tensor_desc.get("shape", [])
    else:
        tensor_info._is_shape_null = True
    tensor_info._range = tensor_desc.get("range", [])
    tensor_info._ori_format = tensor_desc.get("ori_format")
    tensor_info._ori_dtype = tensor_desc.get("ori_data_type")
    if tensor_desc.get("ori_shape", []) != "NULL":
        tensor_info._ori_shape = tensor_desc.get("ori_shape", [])
    tensor_info._ori_range = tensor_desc.get("ori_range", [])
    return tensor_info


def is_dynamic_shape_of_graph_info(graph_info):
    if graph_info is None:
        return
    for op_info in graph_info.get_op_list():
        for output_info in op_info.get_output_list():
            if output_info.get_shape() is None or len(output_info.get_shape()) == 0:
                continue
            for dim in output_info.get_shape():
                if dim < 0:
                    graph_info._is_dynamic_shape = True
                    return


def generate_op_info(op, all_input_names, all_data_output_names, outer_input_list, outer_output_list):
    is_data = op.get("type") == "Data"
    op_info = OpInfo()
    op_info._impl_mode = op.get("op_impl_mode")
    op_info._pattern = op.get("pattern")
    op_info._op_type = op.get("type")
    op_info._id = op.get("name")
    if not is_data and op.get("input_desc") is not None and len(op.get("input_desc")) > 0:
        for input_desc in op.get("input_desc"):
            input_info = InputInfo()
            if input_desc is None:
                input_info._edge_type = "None"
                op_info.add_input(input_info)
                continue
            input_info._edge_id = input_desc.get("name")
            if input_info.get_edge_id() in all_data_output_names:
                input_info._edge_type = "Data"
            else:
                input_info._edge_type = "Operator"
            op_info.add_input(input_info)
    if op.get("output_desc") is not None and len(op.get("output_desc")) > 0:
        for output_desc in op.get("output_desc"):
            output_info = assemble_tensor_info(output_desc)
            op_info.add_output(output_info)
            # add input info for graph info
            if is_data:
                outer_input_list.append(output_info)
            # add output info for graph info
            if output_desc.get("name") is not None and output_desc.get("name") not in all_input_names:
                outer_output_list.append(output_info)

    is_deal_attr = not is_data and op.get("attr_info_desc") is not None and len(op.get("attr_info_desc")) > 0
    if is_deal_attr:
        for attr_desc in op.get("attr_info_desc"):
            if attr_desc is None:
                continue
            attr_info = AttrInfo()
            attr_info._name = attr_desc.get("name")
            attr_info._dtype = attr_desc.get("dtype")
            attr_info._value = attr_desc.get("value")
            op_info.add_attr(attr_info)
    
    return op_info


def generate_graph_info(op_list):
    """
    convert from op list(dict) to graph info(obj)

    Parameters
    ----------
    op_list : dict
        op list info

    Returns
    -------
    graph_info : GraphInfo
        graph info
    """
    if op_list is None or len(op_list) == 0:
        return None

    all_input_names = []
    all_data_output_names = []
    for op in op_list:
        if op.get("type") == "Data":
            if op.get("output_desc") is not None and len(op.get("output_desc")) > 0:
                output_desc = op.get("output_desc")[0]
                if output_desc.get("name") is not None:
                    all_data_output_names.append(output_desc.get("name"))
        else:
            if op.get("input_desc") is not None and len(op.get("input_desc")) > 0:
                for input_desc in op.get("input_desc"):
                    if input_desc is not None and input_desc.get("name") is not None:
                        all_input_names.append(input_desc.get("name"))

    outer_input_list = []
    outer_output_list = []
    op_info_list = []
    for op in op_list:
        op_info = generate_op_info(op, all_input_names, all_data_output_names, outer_input_list, outer_output_list)
        op_info_list.append(op_info)

    graph_info = GraphInfo()
    graph_info._input_list = outer_input_list
    graph_info._output_list = outer_output_list
    graph_info._op_list = op_info_list
    is_dynamic_shape_of_graph_info(graph_info)
    return graph_info


def refresh_tensor_info(tensor_desc, tensor_info):
    """
    refresh tensor desc dict by tensor info

    Parameters
    ----------
    tensor_desc : dict
        tensor desc
    tensor_info : TensorInfo
        tensor info

    Returns
    -------
    """
    if tensor_desc is None or tensor_info is None:
        return
    tensor_desc["data_type"] = tensor_info.get_dtype()
    tensor_desc["format"] = tensor_info.get_format()
    if not tensor_info.is_shape_null():
        tensor_desc["shape"] = tensor_info.get_shape()
    tensor_desc["ori_range"] = tensor_info.get_ori_range()
    tensor_desc["ori_format"] = tensor_info.get_ori_format()
    tensor_desc["ori_data_type"] = tensor_info.get_ori_dtype()
    tensor_desc["range"] = tensor_info.get_range()
    tensor_desc["ori_shape"] = tensor_info.get_ori_shape()


def refresh_single_op(op, all_tensor_dict):
    is_data = op.get("type") == "Data"
    if not is_data and op.get("input_desc") is not None:
        for input_desc in op.get("input_desc"):
            if input_desc is None:
                continue
            if input_desc.get("name") is not None and input_desc.get("name") in all_tensor_dict:
                input_tensor_info = all_tensor_dict.get(input_desc.get("name"))
                if not input_tensor_info.is_only_update_data():
                    refresh_tensor_info(input_desc, input_tensor_info)
    if op.get("output_desc") is not None:
        for output_desc in op.get("output_desc"):
            if output_desc.get("name") is not None and output_desc.get("name") in all_tensor_dict:
                output_tensor_info = all_tensor_dict.get(output_desc.get("name"))
                if is_data or not output_tensor_info.is_only_update_data():
                    refresh_tensor_info(output_desc, output_tensor_info)


def refresh_op_list(graph_info, op_list):
    """
    refresh op_list by graph info

    Parameters
    ----------
    op_list : dict
        op list info
    graph_info : GraphInfo
        graph info

    Returns
    -------
    """
    is_graph_info_invalid = graph_info is None or graph_info.get_op_list() is None or len(graph_info.get_op_list()) == 0
    if is_graph_info_invalid:
        return

    is_op_list_invalid = op_list is None or len(op_list) == 0
    if is_op_list_invalid:
        return

    # collect all output mapping
    all_tensor_dict = {}
    for op_info in graph_info.get_op_list():
        if op_info is None:
            continue
        for output_info in op_info.get_output_list():
            if output_info.get_id() is not None:
                all_tensor_dict[output_info.get_id()] = output_info

    for op in op_list:
        refresh_single_op(op, all_tensor_dict)


def collect_op_pattern_and_op_type(graph_info):
    """
    collect op pattern list and op type list from graph_info

    Parameters
    ----------
    graph_info : GraphInfo
        graph info

    Returns
    -------
    op_pattern_list : list
        op pattern list
    op_type_list : list
        op type list
    """
    op_type_list = []
    op_pattern_list = []
    if graph_info is None:
        return op_pattern_list, op_type_list
    if len(graph_info.get_op_list()) == 0:
        return op_pattern_list, op_type_list
    for op_info in graph_info.get_op_list():
        if op_info.get_op_type() == "Data":
            continue
        if op_info.get_pattern() is not None:
            op_pattern_list.append(op_info.get_pattern())
        if op_info.get_op_type() is not None:
            op_type_list.append(op_info.get_op_type())
    return op_pattern_list, op_type_list


def match_fusion_pass(pass_info, op_pattern_list, op_type_list):
    """
    match the op_pattern_list and op_type_list from graph info with the data of fusion pass info

    Parameters
    ----------
    pass_info : GraphInfo
        fusion pass info
    op_pattern_list : list
        op pattern list from graph info
    op_type_list : list
        op type list from graph info

    Returns
    -------
    is matched : bool
        is this fusion pass match with the graph info
    """
    import tbe.common.utils.log as logger
    if pass_info is None:
        logger.warn("Graph info is None.")
        return False
    if len(pass_info.get_op_pattern_list()) == 0 and len(pass_info.get_op_type_list()) == 0:
        logger.warn("No fusion pattern or op type is specified for this pass.")
        return False

    if len(pass_info.get_op_pattern_list()) > 0:
        pass_pattern_list = deepcopy(pass_info.get_op_pattern_list())
        for op_pattern in op_pattern_list:
            if op_pattern in pass_pattern_list:
                pass_pattern_list.remove(op_pattern)
        if len(pass_pattern_list) > 0:
            logger.debug("This pass[%s] is not matched for op pattern is not matched.", pass_info.get_func_name())
            return False

    if len(pass_info.get_op_type_list()) > 0:
        pass_type_list = deepcopy(pass_info.get_op_type_list())
        for op_type in op_type_list:
            if op_type in pass_type_list:
                pass_type_list.remove(op_type)
        if len(pass_type_list) > 0:
            logger.debug("This pass[%s] is not matched for op type is not matched.", pass_info.get_func_name())
            return False

    return True


def handle_fusion_pass(op_list):
    """
    handle fusion pass

    Parameters
    ----------
    op_list : dict
        op list dict

    Returns
    -------
    """
    import tbe.common.utils.log as logger
    fusion_pass_list = fusion_pass_mgr.get_fusion_pass_list_by_stage()
    if fusion_pass_list is None or len(fusion_pass_list) == 0:
        logger.debug("Fusion pass list of build stage is empty.")
        return
    graph_info = generate_graph_info(op_list)
    if graph_info is None:
        logger.warn("Fail to generate graph info.")
        return

    logger.debug("Before fusion pass, display graph info...")
    graph_info.display()

    op_pattern_list, op_type_list = collect_op_pattern_and_op_type(graph_info)
    for pass_info in fusion_pass_list:
        if not match_fusion_pass(pass_info, op_pattern_list, op_type_list):
            logger.debug("Fusion pass[%s] is not matched.", pass_info.get_func_name())
            continue
        logger.debug("Begin to handle fusion pass[%s].", pass_info.get_func_name())
        func = pass_info.get_func()
        if func is None:
            logger.debug("Function of fusion pass[%s] is none.", pass_info.get_func_name())
            continue
        func(graph_info)
        logger.debug("Finish the fusion pass[%s].", pass_info.get_func_name())

    logger.debug("After fusion pass, display graph info...")
    graph_info.display()
    refresh_op_list(graph_info, op_list)
