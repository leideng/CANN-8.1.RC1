#!/usr/bin/env python3
# -*- coding:utf-8 -*-
# Copyright 2019-2020 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
rl bank, generate schedule from built-in bank or custom bank
"""
import ast
import datetime
import json
import os
from typing import Union
from typing import List
from typing import Tuple
from typing import Dict
from typing import Any
from dataclasses import make_dataclass

from tbe import tvm
from tbe.common.platform.platform_info import get_soc_spec
from tbe.common.platform import SHORT_SOC_VERSION
from tbe.common.platform import FULL_SOC_VERSION
from tbe.common.platform import AICORE_TYPE
from tbe.common.platform import CORE_NUM
from tbe.common.context import op_context
from tbe.common.rl_bank.bank_cfg import create_dir
from tbe.common.rl_bank.bank_cfg import DTYPE_INDEX
from tbe.common.rl_bank.bank_cfg import TAG_INDEX
from tbe.common.rl_bank.bank_cfg import SPEC_ATTR_KEY
from tbe.common.rl_bank.bank_cfg import OPEN_FILE_MODES_640
from tbe.common.rl_bank.bank_cfg import WRITE_FILE_FLAGS
from tbe.common.rl_bank.bank_cfg import LocalLock
from tbe.common.rl_bank.rl_op_filter import rl_op_filter
from tbe.common.rl_bank.withdraw import gen_sch_by_cheque
from tbe.common.rl_bank.withdraw import withdraw
from tbe.common.rl_bank import bank_manager
from tbe.common.buildcfg import get_current_build_config
from tbe.common.utils import log
from tbe.dsl.base import operation
from tbe.dsl.static_schedule.util import gen_dfs_tensor_map
from tbe.dsl.static_schedule.util import get_reduce_axis_num

FILE_PATH = os.path.dirname(os.path.realpath(__file__))

RL_BANK_DICT = {}
# rl bank version should include te/pass/rl version
RL_BANK_VERSION = 'v001'
RL_STATIC_TILING_KEY = 0xffffffffffffffff
RL_BANK_VALUE_LENGTH_OLD = 2
RL_BANK_CHEQUE_INDEX = 0
RL_BANK_TICK_INDEX = 1
RL_BANK_OP_INFO_INDEX = 2

OLD_USR_ASCEND_PATH = "/usr/local/Ascend"
ASCEND_OPP_PATH = "ASCEND_OPP_PATH"
OPP_DATA_RL = "opp/data/rl/"
ASCEND_DATA_RL = "data/rl/"
BUILT_IN_DATA_RL = "built-in/data/rl"
OPP_VENDORS_CUST_DATA_RL = "vendors/customize/data/rl/"
ATC_DATA_RL = "atc/data/rl/"
FWK_DATA_RL = "fwkacllib/data/rl/"

# soc dict for rl alternative bank
RL_BANK_ALTERNATIVE = {
    "Ascend910PremiumA": ["Ascend910ProA", "Ascend910A"],
    "Ascend910ProA": ["Ascend910A", "Ascend910PremiumA"],
    "Ascend910A": ["Ascend910ProA", "Ascend910PremiumA"],
    "Ascend910ProB": ["Ascend910B"],
    "Ascend910B": ["Ascend910ProB"],
    "Ascend910B1": ["Ascend910B2"],
    "Ascend910B2": ["Ascend910B1"],
    "Ascend910B2C": ["Ascend910B2", "Ascend910B1"],
    "Ascend910B3": ["Ascend910B4", "Ascend910B5"],
    "Ascend910B4": ["Ascend910B5", "Ascend910B3"],
    "Ascend910B4-1": ["Ascend910B4", "Ascend910B5", "Ascend910B3"],
    "Ascend910B5": ["Ascend910B4", "Ascend910B3"],
    "Ascend610Lite": ["BS9SX2AA", "MC61AM21AA", "BS9SX2AB", "MC61AM21AB"],
    "BS9SX2AA": ["Ascend610Lite", "MC61AM21AA", "BS9SX2AB", "MC61AM21AB"],
    "MC61AM21AA": ["Ascend610Lite", "BS9SX2AA", "BS9SX2AB", "MC61AM21AB"],
    "BS9SX2AB": ["Ascend610Lite", "BS9SX2AA", "MC61AM21AA", "MC61AM21AB"],
    "MC61AM21AB": ["Ascend610Lite", "BS9SX2AA", "BS9SX2AB", "MC61AM21AA"],
}

SocInfo = make_dataclass("SocInfo", ["soc_version", "full_soc_version"])


def shape_to_list(shape: Union[List, Tuple]) -> List[int]:
    """
    translate tvm.shape to list type in python
    :param shape: tensor shape
    :return: shape in list
    """
    shape_new = []
    for i in shape:
        if isinstance(i, (tvm.tir.IntImm, tvm.tir.expr.ConstExpr)):
            shape_new.append(i.value)
        elif isinstance(i, tvm.Var):
            shape_new.append(-1)
        else:
            shape_new.append(i)

    return shape_new


def gen_attr_feature(tensor: object, curr_tensor_info_list: list) -> None:
    """
    gen_attr_feature
    :param tensor:
    :param curr_tensor_info_list:
    :return:
    """
    if bool(tensor.op.attrs) and any((attr in tensor.op.attrs for attr in SPEC_ATTR_KEY)):
        curr_tensor_info_list.append([])
        for attr in SPEC_ATTR_KEY:
            if attr not in tensor.op.attrs:
                continue
            if attr == "L1_addr_offset":
                cheque_value = 0
            else:
                cheque_value = tensor.op.attrs[attr]
            curr_tensor_info_list[-1].append([SPEC_ATTR_KEY.index(attr), cheque_value])


def gen_axis_feature(tensor: object, curr_tensor_info_list: list) -> None:
    """
    gen_axis_feature
    :param tensor:
    :param curr_tensor_info_list:
    :return:
    """
    if isinstance(tensor.op, tvm.PlaceholderOp):
        # Placeholder has no axis, use shape
        curr_tensor_info_list.append(shape_to_list(tensor.op.shape))
        curr_tensor_info_list.append([])
    else:
        # output shape
        axis_value_list = []
        for axis in tensor.op.axis:
            if hasattr(axis.dom.extent, "value"):
                axis_value_list.append(axis.dom.extent.value)
            else:
                axis_value_list.append(-1)
        curr_tensor_info_list.append(axis_value_list)
        # reduce axis idx
        reduce_axis_idx_list = []
        try:
            if tensor.op.reduce_axis:
                reduce_axis_idx_list = get_reduce_axis_num(tensor)
        except (AttributeError, IndexError) as excp:
            log.warn("can not get reducec_axis_idx_list:%s", str(excp))
        finally:
            pass
        curr_tensor_info_list.append(reduce_axis_idx_list)


def gen_tensor_feature(dfs_tensor_list: list) -> str:
    """
    gen_tensor_feature
    :param dfs_tensor_list:
    :return: str(feature_list) or ""
    """
    feature_list = []
    depends_map = {}
    # get all tensor
    for tensor_idx, tensor in enumerate(dfs_tensor_list):
        if not isinstance(tensor, tvm.Tensor):
            return ""
        # olny support for PlaceholderOp and ComputeOp
        if not isinstance(tensor.op, (tvm.PlaceholderOp, tvm.ComputeOp)):
            return ""
        curr_tensor_info_list = []
        # ===tag===
        op_tag = tensor.op.tag.split("|")[0] if tensor.op.tag else ""
        if op_tag not in TAG_INDEX:
            log.debug("op_tag %s not in TAG_INDEX", op_tag)
            return ""
        curr_tensor_info_list.append(TAG_INDEX[op_tag])

        # op attrs info
        gen_attr_feature(tensor, curr_tensor_info_list)

        # ===axis===
        gen_axis_feature(tensor, curr_tensor_info_list)

        # elewise_binary_vcmpv_xx dsl静态场景下输出均为bool，
        # 但tvm.schedule pickle时会将bool转成uint1这里先规避处理下'''
        output_dtype = tensor.op.output(0).dtype
        if tensor.op.tag.startswith(
                "elewise_binary_vcmpv_") and output_dtype == "uint1":
            output_dtype = "bool"
        curr_tensor_info_list.append(DTYPE_INDEX[output_dtype])

        # ===depens===
        for input_tensor in tensor.op.input_tensors:
            depends_map.setdefault(input_tensor.op.name, []).append(tensor_idx)
        curr_tensor_info_list.append(depends_map.get(tensor.op.name, []))

        feature_list.append(curr_tensor_info_list)

    return str(feature_list)


def _get_rl_bank_key(output_tensors: list, op_info: dict = None) -> str:
    """
    get tmp rl bank key for final_bank_key
    :param output_tensors:
    :param op_info:
    :return: bank_key or ""
    """
    # try to get dfs_tensor_list from op_info by auto_schedule
    dfs_tensor_list = []
    if op_info and op_info.get("dfs_tensor_list", None):
        dfs_tensor_list = op_info["dfs_tensor_list"]

    try:
        if not dfs_tensor_list:
            dfs_tensor_list = get_dfs_tensor_list(output_tensors)
        bank_key = gen_tensor_feature(dfs_tensor_list)
    except Exception as excp:  # pylint: disable=broad-except
        log.warn("can not get bank_key: %s", str(excp))
        return ""
    finally:
        pass

    log.debug("get bank_key: %s.", bank_key)
    return bank_key


def get_rl_bank_key(output_tensors_list: list, op_info: dict = None) -> str:
    """
    generate bank_key from tensor info
    tensor_info_list, one for one tensor:tag，output shape，
    output dtype，reduce_axis，depends
    :param output_tensors_list:
    :param op_info:
    :return: final_bank_key
    """
    final_bank_key = ""
    if isinstance(output_tensors_list, list) and isinstance(output_tensors_list[0], list):
        for output_tensors in output_tensors_list:
            curr_bank_key = _get_rl_bank_key(output_tensors, op_info=op_info)
            if not curr_bank_key:
                return ""
            final_bank_key += curr_bank_key
    else:
        return _get_rl_bank_key(output_tensors_list, op_info=op_info)
    return final_bank_key


def trans_bank_dict(ori_dict: dict, direction: str) -> dict:
    """
    trans_from_bank_dict
    :param ori_dict:
    :param direction:
    :return: new_dict
    """
    trans_func = json.loads if direction == "from" else json.dumps
    new_dict = {}
    for key, value in ori_dict.items():
        if value == 'tmpl' and direction == "from":
            new_dict[key] = ('tmpl', 0)
        else:
            new_dict[key] = trans_func(value)
    return new_dict


def write_bank(bank_json_path: str, bank_content: dict) -> None:
    """
    write bank
    :param bank_json_path: 知识库路径
    :param bank_content: 知识库内容
    :return:
    """
    create_dir(os.path.dirname(bank_json_path))
    log.debug("write bank content to %s.", bank_json_path)
    local_lock = LocalLock(bank_json_path)
    local_lock.lock()
    with os.fdopen(os.open(bank_json_path, WRITE_FILE_FLAGS, OPEN_FILE_MODES_640), 'w') as outfile:
        json.dump(bank_content, outfile, sort_keys=True, indent=4)
    os.chmod(bank_json_path, OPEN_FILE_MODES_640)
    log.info("RL tune info: bank file is updated successfully to %s.", bank_json_path)
    local_lock.unlock()


def get_bank_value(bank_key: str, bank_content: dict) -> (list, int, str):
    """
    get bank value from bank content according to bank key
    :param bank_key:
    :param bank_content:
    :return:
    """
    bank_value = bank_content.get(bank_key, ([], 0, ""))
    if isinstance(bank_value, str):
        try:
            bank_value = json.loads(bank_value)
        except (ValueError, AttributeError) as exception:
            log.error("RL tune info: Cannot load bank value, %s", exception)
            bank_value = ([], 0, "")
        finally:
            pass
    if len(bank_value) == RL_BANK_VALUE_LENGTH_OLD:
        cheque, tick = bank_value
        bank_value = (cheque, tick, "")
    return bank_value


def add_case(outputs: list, cheque: list, tick: int, bank_json_path: str, op_info_str: str) -> bool:
    """
    add cheque to specify bank path
    :param outputs:
    :param cheque:
    :param tick:
    :param bank_json_path:
    :param op_info_str: kernel_name@op_type@shape
    :return: T/F
    """
    bank_key = get_rl_bank_key(outputs)
    if not bank_key:
        return False
    if os.path.exists(bank_json_path):
        with open(bank_json_path) as json_file:
            base_key_actions_dict = json.load(json_file)
    else:
        base_key_actions_dict = {}
    # both of key and value are string
    if bank_key in base_key_actions_dict:
        old_tick = get_bank_value(bank_key, base_key_actions_dict)[RL_BANK_TICK_INDEX]
        if old_tick and old_tick <= tick:
            log.warn("RL tune info: op_info: %s, old_tick: %s, new_tick: %s, better cheque has been in bank!",
                    op_info_str, old_tick, tick)
            return False

    if isinstance(outputs, list) and isinstance(outputs[0], list):
        cheque_list = []
        for i, output_tensors in enumerate(outputs):
            cheque_list += cheque[i]
            curr_bank_key = get_rl_bank_key(output_tensors)
            if not curr_bank_key:
                continue
            base_key_actions_dict.update({curr_bank_key: json.dumps((cheque[i], tick, op_info_str))})
    else:
        cheque_list = cheque
    base_key_actions_dict.update({bank_key: json.dumps((cheque_list, tick, op_info_str))})
    write_bank(bank_json_path, base_key_actions_dict)
    return True


def get_dfs_tensor_list(out_tensors: list) -> list:
    """
    get_dfs_tensor_list
    :param out_tensors:
    :return: dfs_tensor_list
    """
    if not isinstance(out_tensors, list):
        out_tensors = [out_tensors]

    dfs_tensor_list, _, _, _ = gen_dfs_tensor_map(out_tensors)

    return dfs_tensor_list


def get_bank_path_from_cxt() -> str:
    """
    get bank path from context
    :return: spec_bank
    """
    spec_bank = ""
    context = op_context.get_context()
    if context:
        spec_bank = context.get_addition("op_bank_path")
    log.info("get op_bank_path from op_context: %s.", spec_bank)
    return spec_bank


def get_custom_rl_path() -> (bool, str):
    '''
    get_custom_bank_path
    :return: spec_valid, base_dir
    '''
    spec_bank = os.getenv("TUNE_BANK_PATH", "")  # pylint: disable=invalid-envvar-default
    if not spec_bank:
        spec_bank = get_bank_path_from_cxt()
    if not spec_bank: # if TUNE_BANK_PATH does not exist, using ${ASCEND_CACHE_PATH}/aoe_data instead
        spec_bank = os.getenv("ASCEND_CACHE_PATH", "")
        if spec_bank:
            spec_bank = os.path.join(spec_bank, "aoe_data")
    base_dir = ''
    spec_valid = False
    if spec_bank:
        spec_bank = os.path.realpath(spec_bank)
        if os.path.isdir(spec_bank) and os.access(spec_bank, os.R_OK | os.W_OK | os.X_OK):
            base_dir = spec_bank
            spec_valid = True

    # if not assign custom bank dir, use default bank dir
    if not base_dir:
        base_dir = get_default_rl_path(custom=True)
        if spec_bank:
            raise RuntimeError("TUNE_BANK_PATH or ASCEND_CACHE_PATH: %s is not available, please check!" % spec_bank)

    return spec_valid, base_dir


def get_default_rl_path(custom: bool = False) -> str:
    """
    get_default_bank_path
    :return:
    """
    # parse ASCEND_OPP_PATH to get bank install path
    opp_path = os.getenv("ASCEND_OPP_PATH", "")
    if not opp_path:
        log.warn("RL exception occur: Failed to get opp path, please check your ASCEND_OPP_PATH in env.")

    if not os.path.exists(opp_path) or custom:
        base_dir = os.path.join(os.getenv("HOME", ""), "Ascend/latest/data/aoe/custom/op")
    else: # ASCEND_OPP_PATH exit and built-in
        base_dir = os.path.realpath(os.path.join(opp_path, BUILT_IN_DATA_RL))
        if not os.path.exists(base_dir):
            base_dir = os.path.realpath(os.path.join(opp_path, "data/rl"))
    log.debug("default_rl_path: %s.", base_dir)
    return base_dir


def get_old_rl_path() -> str:
    """
    get old rl path
    :return:
    """
    base_dir = ""
    # parse LD_LIBRARY_PATH to get bank install path
    ld_library_env = os.getenv("LD_LIBRARY_PATH", "")
    for env_item in ld_library_env.split(":"):
        env_item = env_item.strip()
        if not os.path.exists(env_item):
            continue
        if os.path.realpath(env_item).endswith("/fwkacllib/lib64") or os.path.realpath(env_item).endswith("/atc/lib64"):
            base_dir = env_item.rstrip("/")[:-5]
            break
    if not base_dir:
        # fwkacllib or atc not in env LD_LIBRARY_PATH
        return ""
    base_dir = os.path.realpath(os.path.join(base_dir, "data/rl"))
    log.debug("old default_rl_path: %s.", base_dir)
    return base_dir


def custom_bank_name_match(json_name: str, bank_name: str) -> bool:
    """
    match custom bank name
    :param json_name:
    :param bank_name:
    :return:
    """
    if not json_name.endswith('.json'):
        return False
    if json_name.startswith(bank_name):
        return True
    # 兼容之前的CustomBank
    if bank_name.startswith("Ascend910A_") and json_name.startswith(bank_name.replace('Ascend910A_', "Ascend910_")):
        return True
    if bank_name.startswith("Ascend910B_") and json_name.startswith(bank_name.replace('Ascend910B_', "Ascend910_")):
        return True
    return False


def read_one_custom_bank(custom_bank_dir: str, custom_bank: dict, bank_files: list, bank_json: str) -> None:
    """
    read one bank file from custom_bank_dir
    :param custom_bank_dir:
    :param custom_bank:
    :param bank_files:
    """
    bank_file = os.path.join(custom_bank_dir, bank_json)
    bank_files.append(bank_file)
    if not os.path.isfile(bank_file) or not os.path.getsize(bank_file):
        log.warn("can not read one custom bank, custom bank file: %s is empty or not a file.", bank_file)
        return
    log.debug("read one custom bank begin, the custom bank file: %s.", bank_file)
    try:
        with open(bank_file) as fh_bank:
            tmp_bank = json.load(fh_bank)
    except (ValueError, TypeError) as excp:
        log.warn("can not read one custom bank, custom bank file: %s json format is illegal, excp_msg: %s",
                 bank_file, repr(excp))
    finally:
        pass
    tmp_bank = trans_bank_dict(tmp_bank, "from")
    for key in tmp_bank:
        tick = get_bank_value(key, tmp_bank)[RL_BANK_TICK_INDEX]
        if key in custom_bank and custom_bank.get(key)[1] <= tick and custom_bank.get(key)[1] > 0:
            continue
        custom_bank[key] = tmp_bank.get(key)


def read_custom_bank(custom_bank_dir: str, bank_name: str) -> (dict, list):
    """
    read custom bank, maybe there are more than 1 files.
    :param custom_bank_dir:
    :param bank_name:
    :return: custom_bank, bank_files
    """
    custom_bank = {}
    bank_files = []
    for bank_json in os.listdir(custom_bank_dir):
        if custom_bank_name_match(bank_json, bank_name):
            read_one_custom_bank(custom_bank_dir, custom_bank, bank_files, bank_json)
    return custom_bank, bank_files


def update_bank_dict(bank_update_to: dict, bank_update_from: dict) -> None:
    """
    update bank dict
    :param bank_update_to:
    :param bank_update_from:
    :return:
    """
    for key in bank_update_from:
        tick = get_bank_value(key, bank_update_from)[RL_BANK_TICK_INDEX]
        if key not in bank_update_to or (key in bank_update_to and tick < bank_update_to[key][1]):
            bank_update_to[key] = bank_update_from[key]


def merge_custom_bank(custom_bank_dir: str,
                      bank_files: list,
                      bank_name: str,
                      custom_bank: dict,
                      merge_flag : bool = True) -> None:
    """
    if custom bank files > 1, merge them
    :param custom_bank_dir:
    :param bank_files: origin custom bank files
    :param bank_name: bank_name
    :param custom_bank: custom bank dict
    :return:
    """
    if not merge_flag:
        return
    if len(bank_files) > 1:
        for bank_file in bank_files:
            os.remove(bank_file)
        time_stamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')
        custom_bank_file = '{}_{}.json'.format(bank_name, time_stamp)
        custom_bank_path = os.path.join(custom_bank_dir, custom_bank_file)
        custom_bank = trans_bank_dict(custom_bank, "to")
        local_lock = LocalLock(custom_bank_path)
        local_lock.lock()
        with os.fdopen(os.open(custom_bank_path, WRITE_FILE_FLAGS, OPEN_FILE_MODES_640), 'w') as bank_fh:
            json.dump(custom_bank, bank_fh, sort_keys=True, indent=4)
        local_lock.unlock()
        log.info("bank files %s are merged into one: %s.", ", ".join(bank_files), custom_bank_path)


def get_bank_name(op_mode: str = '', full_soc_version: str = "") -> str:
    """
    get bank name
    :param op_mode: '' is default value, use it to spell bank prefix
    :return: the name of bank
    """
    full_soc_version = full_soc_version if full_soc_version else get_soc_spec(FULL_SOC_VERSION)
    aicore_type = get_soc_spec(AICORE_TYPE)
    core_num = get_soc_spec(CORE_NUM)
    bank_name = '{}_{}_{}_{}'.format(full_soc_version, aicore_type, core_num, RL_BANK_VERSION)
    if op_mode:
        bank_name = '{}_{}'.format(op_mode, bank_name)
    log.info("get bank name, RL bank name: %s.", bank_name)
    return bank_name


def satisfy_bank(base_tick: int, tick: int, check_type: str = 'in') -> bool:
    """
    如果想要加入Bank，则需要满足以下条件：
    1，绝对值相差大于5us
    2，绝对值相差大于100或比例小于0.85
    如果想要留在Bank，则只需要满足
    1，绝对值相差大于20或比例小于0.9
    :param base_tick:
    :param tick:
    :param check_type: in or stay。
    :return: T/F
    """
    if check_type == 'in':
        if tick and \
                base_tick and \
                base_tick - tick >= 5 and \
                (base_tick - tick >= 100 or tick / base_tick <= 0.95):
            return True
    else:
        if tick and \
                base_tick and \
                (base_tick - tick >= 20 or tick / base_tick <= 0.9):
            return True
    return False


def check_force_update(force_update: bool) -> None:
    """
    check whether force update or not
    :param force_update:
    """
    spec_bank = get_bank_path_from_cxt()
    if spec_bank:
        spec_bank = os.path.realpath(spec_bank)
        if os.path.isdir(spec_bank) and os.access(spec_bank, os.R_OK | os.W_OK | os.X_OK):
            force_update = True
            log.info("force update bank_dict, as op bank path is given: %s.", spec_bank)
            return force_update
    return force_update


def get_custom_bank_dirs(soc_version: str, full_soc_version: str) -> list:
    """
    get custom bank dirs
    :param soc_version:
    :return: custom_bank_dirs
    """
    # if assign TUNE_BANK_PATH, custom bank path is BANK_PATH/soc_version/rl
    spec_valid, custom_bank_base_dir = get_custom_rl_path()
    custom_bank_dirs = []
    custom_bank_dirs.append(os.path.join(custom_bank_base_dir, full_soc_version, 'vector'))
    if spec_valid:
        # 指定tune_bank_path的情况，为了兼容老版本，同时读取3个路径：
        # 1,<TUNE_BANK_PATH>/<SOC_VERSION>/rl
        # 2,<TUNE_BANK_PATH>/<SOC_VERSION>/custom
        # 3,/usr/local/Ascend/atc/data/rl/<SOC_VERSION>/custom
        for bank_type in ['custom', 'rl']:
            custom_bank_dirs.append(os.path.join(custom_bank_base_dir, soc_version, bank_type))

    else:
        old_custom_bank_dirs = get_previous_bank_paths()
        custom_bank_dirs.extend(old_custom_bank_dirs)

    log.info("query custom bank dirs: %s.", ", ".join(custom_bank_dirs))
    return custom_bank_dirs


def get_built_in_bank_path(soc_version: str, bank_name: str) -> str:
    """
    get built-in bank path
    :param soc_version:
    :param bank_name:
    :return: built_in_bank_path
    """
    built_in_base_dir = get_default_rl_path()
    built_in_bank_path = os.path.join(built_in_base_dir, soc_version,
        "%s.json" % bank_name if BUILT_IN_DATA_RL in built_in_base_dir else "built-in/%s.json" % bank_name)

    if not os.path.exists(built_in_bank_path):
        built_in_base_dir = get_default_rl_path(custom=True)
        built_in_bank_path = os.path.join(built_in_base_dir, soc_version, "built-in/%s.json" % bank_name)

    log.info("query built-in bank path: %s", built_in_bank_path)
    return built_in_bank_path


def get_custom_bank_file(bank_name: str, soc_version: str, full_soc_version: str, merge_flag : bool = True) -> bool:
    """
    get_custom_bank
    return True if a custom file is exist
    """
    custom_bank_exist = False
    custom_bank_dirs = get_custom_bank_dirs(soc_version, full_soc_version)
    custom_bank = {}
    for custom_bank_dir in custom_bank_dirs:
        if os.path.isdir(custom_bank_dir):
            cur_custom_bank, bank_files = read_custom_bank(custom_bank_dir, bank_name)
            custom_bank_exist = True if bank_files else custom_bank_exist
            merge_custom_bank(custom_bank_dir, bank_files, bank_name, cur_custom_bank, merge_flag)
            update_bank_dict(custom_bank, cur_custom_bank)
            if custom_bank:
                log.info("RL bank query info: success read custom bank from path [%s]", custom_bank_dir)
                break

    if custom_bank:
        RL_BANK_DICT[bank_name]["custom"] = custom_bank
    else:
        log.debug("RL bank query info: no custom bank is loaded, bank_name: %s, soc_version: %s.",
            bank_name, soc_version)
    return custom_bank_exist


def get_built_in_bank_file(bank_name: str, soc_version: str) -> bool:
    """
    get built in bank file
    """
    built_in_bank_exist = False
    built_in_bank_path = get_built_in_bank_path(soc_version, bank_name)
    log.debug("RL bank query info: start read built-in bank from path [%s].", built_in_bank_path)
    if os.path.exists(built_in_bank_path):
        built_in_bank_exist = True
        with open(built_in_bank_path) as json_file:
            RL_BANK_DICT[bank_name]["built-in"] = trans_bank_dict(json.load(json_file), "from")
        log.info("RL bank query info: success read built-in bank from path [%s].", built_in_bank_path)
    return built_in_bank_exist


def get_bank_dict(bank_name: str,
                  soc_info : object,
                  force_update: bool = False,
                  search_type: str = "",
                  merge_flag : bool = True) -> tuple:
    """
    get_bank_dict
    :param bank_name:
    :param soc_info:
    :param force_update:
    :param search_type:
    :param merge_flag:
    :return: T/F
    """
    rl_bank_exists = False
    new_force_update = check_force_update(force_update)

    # if already get RL_BANK_DICT, just return
    if bank_name in RL_BANK_DICT and not new_force_update:
        return True, True

    # init RL_BANK_DICT with key of bank_name
    RL_BANK_DICT[bank_name] = {} if not search_type or not RL_BANK_DICT.get(bank_name) else RL_BANK_DICT.get(bank_name)

    # if custom or built-in search type and has load
    if not search_type and  RL_BANK_DICT.get(bank_name, {}).get(search_type, {}):
        return True, True

    # get custom bank directories
    if not search_type or search_type == "custom":
        if get_custom_bank_file(bank_name, soc_info.soc_version, soc_info.full_soc_version, merge_flag):
            rl_bank_exists = True

    # get built-in bank file
    if not search_type or search_type == "built_in":
        if get_built_in_bank_file(bank_name, soc_info.soc_version):
            rl_bank_exists = True
    return True, rl_bank_exists


def get_cheque_from_bank(bank_name: str, rl_bank_key: str, bank_type: str, dynamic: bool = False) -> List:
    """
    get_cheque_from_bank
    :param bank_name: the name of bank
    :param rl_bank_key: search key
    :param bank_type: built_in, custom
    :param dynamic: False is default value
    :return: cheque
    """
    bank_dict = RL_BANK_DICT.get(bank_name, {}).get(bank_type, {})
    if dynamic:
        cheque_list = bank_dict.get(rl_bank_key, [])
        return cheque_list, ""

    cheque = get_bank_value(rl_bank_key, bank_dict)[RL_BANK_CHEQUE_INDEX]
    op_info_str = get_bank_value(rl_bank_key, bank_dict)[RL_BANK_OP_INFO_INDEX]
    return cheque, op_info_str


def get_cheque(out_tensors: List, op_info: Dict, op_infos: Dict, context: object, dynamic: bool = False) -> List:
    """
    get_cheque
    :param out_tensors:op compute output tensors
    :param op_info:op info contain dfs tensor list
    :param op_infos: op_name, kernel_name, op_mode
    :param context object
    :param dynamic: False is default value
    :return: cheque from bank
    """
    op_name = op_infos.get("op_name", "")
    kernel_name = op_infos.get("kernel_name", "")
    op_mode = op_infos.get("op_mode", "")

    op_mode_str = ''
    if dynamic:
        op_mode_str = 'dynamic'
    elif op_mode in ('static', 'dynamic'):
        op_mode_str = op_mode

    soc_version, full_soc_version, alter_soc_versions = get_all_soc_info()
    bank_names = [get_bank_name(op_mode_str, full_soc_version)]
    soc_info = SocInfo(soc_version, full_soc_version)
    ret, _ = get_bank_dict(bank_names[0], soc_info, merge_flag=False)
    if alter_soc_versions:
        bank_exist = get_bank_dict_alter(op_mode_str, soc_version, alter_soc_versions)
        bank_names.extend(bank_exist)
    if not ret:
        log.debug("RL bank query info: op_name: %s, kernel_name: %s can not get bank dict.", op_name, kernel_name)
        return []

    # get_rl_bank_key by op_name
    rl_bank_key = get_rl_bank_key(out_tensors, op_info=op_info)
    if not rl_bank_key:
        log.debug("RL bank query info: op_name: %s, kernel_name: %s can not get get_rl_bank_key.", op_name, kernel_name)
        return []

    ret, cheque = get_cheque_from_bank_cache(rl_bank_key)
    if ret:
        log.debug("RL bank query info: op_name: %s, kernel_name: %s, strategy from cache %s.", op_name, kernel_name,
                  cheque)
        return cheque

    hit_bank = False
    for bank_name in bank_names:
        cheque = get_cheque_from_one_bank(bank_name, rl_bank_key, dynamic, op_name, kernel_name)
        if cheque:
            hit_bank = True
            break

    log.info("RL bank query info: hit bank status: %s, op_name: %s, kernel_name: %s.", hit_bank, op_name, kernel_name)
    report_hit_status(hit_bank, op_infos, context)
    log.debug("RL bank query info: %s strategy from bank: %s.", kernel_name, cheque)
    log.debug("RL bank query info: %s strategy's rl_bank_key: %s.", kernel_name, rl_bank_key)
    return cheque


def get_bank_dict_alter(op_mode_str: str, soc_version: str, alter_soc_versions: list) -> list:
    """
    get bank dict for alter socversion
    """
    bank_name_exist = []
    for alter_soc_version in alter_soc_versions:
        bank_name = get_bank_name(op_mode_str, alter_soc_version)
        soc_info = SocInfo(soc_version, alter_soc_version)
        _, file_exist = get_bank_dict(bank_name, soc_info, merge_flag=False)
        if file_exist and bank_name not in bank_name_exist:
            bank_name_exist.append(bank_name)
    return bank_name_exist


def get_all_soc_info() -> tuple:
    """
    check wether hit bank or not
    :param rl_bank_key: rl bank key of op
    :param kernel_name: kernel name
    :return: hit_res
    """
    soc_version = get_soc_spec(SHORT_SOC_VERSION)
    full_soc_version = get_soc_spec(FULL_SOC_VERSION)
    alter_soc_versions = []
    if full_soc_version in RL_BANK_ALTERNATIVE:
        alter_soc_versions.extend(RL_BANK_ALTERNATIVE[full_soc_version])
    return soc_version, full_soc_version, alter_soc_versions


def check_bank_hit(rl_bank_key: List, kernel_name: str) -> bool:
    """
    check wether hit bank or not
    :param rl_bank_key: rl bank key of op
    :param kernel_name: kernel name
    :return: hit_res
    """
    log.debug("check_bank_hit, op: %s, rl_bank_key: %s", kernel_name, rl_bank_key)
    # get custom bank directories
    soc_version, full_soc_version, alter_soc_versions = get_all_soc_info()
    hit_ret, _ = check_bank_hit_soc_version(rl_bank_key, kernel_name, soc_version, full_soc_version)
    if hit_ret:
        return True

    for alter_soc_version in alter_soc_versions:
        hit_ret, file_ret = check_bank_hit_soc_version(rl_bank_key, kernel_name, soc_version, alter_soc_version)
        if hit_ret:
            return True
    return False


def check_bank_hit_soc_version(rl_bank_key: List,
                               kernel_name: str,
                               soc_version: str,
                               full_soc_version: str,
                               search_type: str = "") -> tuple:
    """
    check wether hit bank in soc version or not
    :param rl_bank_key: rl bank key of op
    :param kernel_name: kernel name
    :return: hit_res
    """
    hit_res = False
    file_exist = False
    custom_bank_dirs = get_custom_bank_dirs(soc_version, full_soc_version)
    bank_name = get_bank_name(full_soc_version=full_soc_version)
    # read custom bank content and match with rl bank key
    if not search_type or search_type == "custom":
        for custom_bank_dir in custom_bank_dirs:
            if os.path.isdir(custom_bank_dir):
                cur_custom_bank, bank_files = read_custom_bank(custom_bank_dir, bank_name)
                file_exist = True if bank_files else file_exist
                if rl_bank_key in cur_custom_bank:
                    hit_res = True
                    log.info("RL tune info: op %s hit custom bank: %s", kernel_name, custom_bank_dir)
                    return hit_res, True

    # get built-in bank file
    if not search_type or search_type == "built_in":
        built_in_bank_path = get_built_in_bank_path(soc_version, bank_name)
        # read built-in bank content and match with rl bank key
        if os.path.exists(built_in_bank_path):
            file_exist = True
            with open(built_in_bank_path) as json_file:
                built_in_bank_content = trans_bank_dict(json.load(json_file), "from")
            if rl_bank_key in built_in_bank_content:
                hit_res = True
                log.info("RL tune info: op %s hit built-in bank: %s", kernel_name, built_in_bank_path)

    return hit_res, file_exist


def get_cheque_from_bank_cache(rl_bank_key: str) -> Union[Tuple[bool, Any], Tuple[bool, list]]:
    """
    get_cheque_from_bank_cache
    :param rl_bank_key
    :return:
    """
    from tbe.common.tiling.get_tiling_cube import BANK_CACHE
    if BANK_CACHE:
        log.debug("get cheque from BANK_CACHE addr: %s, value: %s", id(BANK_CACHE), BANK_CACHE)
        spec_cheque = ast.literal_eval(BANK_CACHE)
        if isinstance(spec_cheque, dict) and spec_cheque.get("rl_cheque", {}).get(rl_bank_key, []):
            cheque = spec_cheque["rl_cheque"][rl_bank_key]
            if cheque:
                log.info("get cheque from BANK_CACHE %s", cheque)
                return True, cheque
    return False, []


def get_cheque_from_one_bank(bank_name: str, rl_bank_key: str, dynamic: bool, op_name: str = "",
                             kernel_name: str = "") -> List:
    """
    get_check_from_bank
    :param bank_name:
    :param rl_bank_key:
    :param dynamic:
    :param op_name
    :param kernel_name
    :return:
    """
    cheque, op_info_str = get_cheque_from_bank(bank_name, rl_bank_key, "custom", dynamic)
    if cheque:
        log.info("RL bank query info match: op_name=%s hit custom bank: %s, kernel_name: %s.",
                 op_name, bank_name, kernel_name)
        log.info("RL bank query info match: op_info=%s from custom bank: %s.", op_info_str, bank_name)
        return cheque

    cheque, op_info_str = get_cheque_from_bank(bank_name, rl_bank_key, "built-in", dynamic)
    if cheque:
        log.info("RL bank query info match: op_name=%s hit built-in bank: %s, kernel_name: %s.",
                 op_name, bank_name, kernel_name)
        log.info("RL bank query info match: op_info=%s from built-in bank: %s.", op_info_str, bank_name)
        return cheque

    log.info("RL bank query info match: op_name: %s, kernel_name: %s, not hit bank.", op_name, kernel_name)
    return []


def report_hit_status(hit_bank: bool, op_infos: Dict, context: object) -> None:
    """
    report op hit bank status
    :param hit_bank: True for hit bank, False for not hit bank
    :param op_name
    :param kernel_name
    :param context
    :return:
    """
    op_name = op_infos.get("op_name", "")
    kernel_name = op_infos.get("kernel_name", "")
    op_type = op_infos.get("op_type", None)

    if not context:
        log.info("report_hit_status: op_name: %s, context: %s.", op_name, str(context))
        return

    if not op_name:
        log.warn("report_hit_status: get invalid op_name: %s.", op_name)
        return

    if not op_type:
        log.warn("report_hit_status: op %s get invalid op_type.", op_name)
        return

    if not rl_op_filter.optype_check_support(op_type, kernel_name):
        log.debug("report_hit_status: op %s is not supported by rl tune", op_name)
        return

    context.add_build_json_result("KBHit", hit_bank)
    if hit_bank:
        log.info("op_name: %s hit bank result: %s report succ.", op_name, hit_bank)
    else:
        log.debug("op_name: %s hit bank result: %s report succ.", op_name, hit_bank)


def get_op_context_infos():
    """
    :
    """
    op_name = ""
    kernel_name = ""
    op_type = []
    context_ori = op_context.get_context()
    if context_ori:
        op_name = context_ori.get_addition("op_name")
        if not op_name:
            log.warn("get invalid op_name: %s", op_name)
            op_name = ""
        op_info_obj_list = context_ori.get_op_info()
        if isinstance(op_info_obj_list, list) and len(op_info_obj_list) >= 1:
            kernel_name = op_info_obj_list[0].kernel_name
            for op in op_info_obj_list:
                op_type.append(op.op_type)

    op_infos = {"op_name": op_name, "kernel_name": kernel_name, "op_type": op_type}
    return context_ori, op_infos


def query_rl_bank(out_tensors: list, op_info: list = None, sync_tensor: list = None) -> (bool, Union[object, None]):
    """
    query_rl_bank, report hit status before return
    :param out_tensors:op compute output tensors
    :param op_info:op info contain dfs tensor list
    :return:
    """
    op_info_dfs_tensor_list = []
    if op_info is not None:
        op_info_dfs_tensor_list = op_info.get("dfs_tensor_list", "")
    context_ori, op_infos = get_op_context_infos()
    op_name = op_infos.get("op_name", "")
    kernel_name = op_infos.get("kernel_name", "")
    log.debug("RL bank query info: query rl bank begin, op_name: %s, kernel_name: %s, out_tensors: %s,"
                "op_info_dfs_tensor_list: %s.", op_name, kernel_name, out_tensors, op_info_dfs_tensor_list)
    context = operation.get_context()
    op_mode = context.get_mode() if context else ''

    op_infos["op_mode"] = op_mode
    cheque = get_cheque(out_tensors, op_info=op_info, op_infos=op_infos, context=context_ori, dynamic=False)
    if cheque == 'tmpl':
        log.debug("RL bank query info: op_name: %s, kernel_name: %s, get cheque end, cheque is tmpl.",
                    op_name, kernel_name)
        return True, None
    if not cheque:
        log.debug("RL bank query info: op_name: %s, kernel_name: %s, get cheque end, cheque is %s.",
                    op_name, kernel_name, cheque)
        return False, None
    # get rl schedule
    get_obj_status, rl_schedule_obj = get_rl_sch(cheque, out_tensors, sync_tensor, op_mode)
    if not get_obj_status:
        log.warn("RL bank query info: can not get rl sch, op_name %s, kernel_name %s, cheque: %s.",
                 op_name, kernel_name, cheque)

    log.debug("RL bank query info: transform cheque to sch: %s.", get_obj_status)
    return get_obj_status, rl_schedule_obj


def get_rl_sch(cheque: list,
               out_tensors: list,
               sync_tensor: list,
               op_mode: str) -> (bool, Union[object, None]):
    """
    get rl schedule obj
    :param cheque:
    :param out_tensors:
    :param sync_tensor:
    :param op_mode:
    :return: T/F, rl_schedule_obj/None
    """
    args = [out_tensors, cheque, sync_tensor]
    if op_mode in ("static", "dynamic"):
        args.append(True)

    try:
        ret, rl_schedule_obj = gen_sch_by_cheque(*args)
        return ret, rl_schedule_obj
    except Exception as excp:
        log.warn("RL exception occur: can not gen sch by cheque, excp_msg: %s.", repr(excp))
        return False, None
    finally:
        pass


def query_dynamic_rl_bank(out_tensors: List, op_info: Dict = None,
                          sync_tensor: List = None) -> Tuple[bool, Tuple[List, List]]:
    """
    query_dynamic_rl_bank
    :param out_tensors:op compute output tensors
    :param op_info:op info contain dfs tensor list
    :param sync_tensor:
    :return:
    """
    schedule_list = []
    var_axis_value_list = []
    context_ori, op_infos = get_op_context_infos()
    op_name = op_infos.get("op_name", "")
    kernel_name = op_infos.get("kernel_name", "")
    log.debug("RL bank query info: query dynamic rl bank begin, op_name: %s, kernel_name: %s.", op_name, kernel_name)

    cheque_lists = get_cheque(out_tensors, op_info, op_infos, context_ori, dynamic=True)

    if cheque_lists:
        get_schedule_by_cheque_lists(cheque_lists, out_tensors, schedule_list, sync_tensor, var_axis_value_list)

    if schedule_list:
        return True, (schedule_list, var_axis_value_list)
    return False, (schedule_list, var_axis_value_list)


def get_schedule_by_cheque_lists(cheque_lists: List, out_tensors: List, schedule_list: List, sync_tensor: List,
                                 var_axis_value_list: List) -> None:
    """
    get_schedule_by_cheque
    :param cheque_lists:
    :param out_tensors:op compute output tensors
    :param schedule_list:
    :param sync_tensor:
    :param var_axis_value_list:
    :return:
    """
    for i, cheque_list in enumerate(cheque_lists):
        cheque, var_axis_value = cheque_list
        ret, rl_schedule_obj = gen_sch_by_cheque(out_tensors, cheque, sync_tensor, dynamic=True)
        if ret:
            schedule_list.append(rl_schedule_obj)
            index_var_axis_value = list(var_axis_value)
            index_var_axis_value.append(i)
            var_axis_value_list.append(index_var_axis_value)


def update_bank(op_mode: str = '') -> bool:
    """
    update_bank
    :param dynamic: True or False, False is default value
    :param op_mode: '' is default value, use it to spell bank name
    :return: True for success, False for failed
    """
    soc_info = SocInfo(get_soc_spec(SHORT_SOC_VERSION), get_soc_spec(FULL_SOC_VERSION))
    bank_name = get_bank_name(op_mode=op_mode)
    ret, _ = get_bank_dict(bank_name, soc_info, force_update=True)
    return ret


def dynamic_bank_proc(output_tensors: List, sync_tensor: List = None) -> Tuple[List, List]:
    """
    dynamic_bank_proc
    :param output_tensors: output tensors
    :param sync_tensor: None
    :return: schedule info
    """
    bank_manager.set_op_res(output_tensors)

    schedule_list = []
    var_axis_value_list = []
    no_hit = bank_manager.get_bank_hit_info()
    if no_hit:
        return (schedule_list, var_axis_value_list)

    ret, sch_info = query_dynamic_rl_bank(output_tensors, sync_tensor=sync_tensor)
    if not ret:
        return (schedule_list, var_axis_value_list)
    return sch_info


def tik_dsl_bank_proc(output_tensors: List, sync_tensor: List = None,
                      dynamic: bool = False) -> Union[Tuple[List, Any],
                                                    Tuple[List, Tuple[List, List]], Tuple[List, None]]:
    """
    tik dsl op get res and bank
    :param output_tensors: output tensors
    :param sync_tensor: None
    :param dynamic: True or False, False is default value
    :return: output_tensors, schedule
    """
    if get_current_build_config("enable_op_prebuild"):
        return op_prebuild_proc(output_tensors, dynamic)

    if dynamic:
        sch_info = dynamic_bank_proc(output_tensors, sync_tensor)
        return output_tensors, sch_info

    return static_op_bank_proc(output_tensors, sync_tensor)


def op_prebuild_proc(output_tensors: List, dynamic: bool=False) -> Tuple[list, Any]:
    """
    enable_op_prebuild is True, get output and schedule
    :param output_tensors: output tensors
    :param dynamic: True or False, False is default value
    :return:
    """
    res_op = []
    sch = [[], []]
    if not dynamic:
        if isinstance(output_tensors, list):
            for res in output_tensors:
                res_op.append(res.op)
        else:
            res_op.append(output_tensors.op)
        sch = tvm.create_schedule(res_op)
    return output_tensors, sch


def static_op_bank_proc(output_tensors: List, sync_tensor: List) -> Union[Tuple[list, Any], Tuple[list, None]]:
    """
    static_op_bank_proc is original for static_op
    :param output_tensors: output tensors
    :param sync_tensor:
    :return:
    """
    res_index = bank_manager.get_res_index()
    cheque_list = bank_manager.get_cheque_list(res_index=res_index)
    if cheque_list:
        sch, _ = withdraw(output_tensors, cheque_list, sync_tensor=sync_tensor)
        if hasattr(sch, "tbe_compile_para"):
            bank_manager.set_tik_build_config(sch.tbe_compile_para)
        return output_tensors, sch

    # for RL tune getting op res
    bank_manager.set_op_res(output_tensors)

    no_hit = bank_manager.get_bank_hit_info()
    if no_hit:
        return output_tensors, None

    _, sch = query_rl_bank(output_tensors, sync_tensor=sync_tensor)
    if sch:
        if hasattr(sch, "tbe_compile_para"):
            bank_manager.set_tik_build_config(sch.tbe_compile_para)
        return output_tensors, sch

    return output_tensors, None


def get_previous_bank_paths() -> list:
    """
    get previous version bank paths
    """
    home_path = os.getenv("HOME", "")
    if not home_path:
        log.warn("HOME in environmental variable is not set!")
    home_path = os.path.join(home_path, "Ascend")
    ascend_home_path = os.getenv("ASCEND_HOME_PATH", "")
    if not ascend_home_path:
        log.warn("ASCEND_HOME_PATH in environmental variable is not set!")
    old_ascend_opp_vendors_cust_path = os.path.join(os.environ.get(ASCEND_OPP_PATH, ""), OPP_VENDORS_CUST_DATA_RL)
    old_ascend_opp_data_path = os.path.join(os.environ.get(ASCEND_OPP_PATH, ""), ASCEND_DATA_RL)
    old_home_opp_data_path = os.path.join(home_path, OPP_DATA_RL)
    old_ascend_home_opp_data_path = os.path.join(ascend_home_path, OPP_DATA_RL)
    old_ascend_atc_data_path = os.path.join(OLD_USR_ASCEND_PATH, ATC_DATA_RL)
    old_home_atc_data_path = os.path.join(home_path, ATC_DATA_RL)
    old_ascend_home_atc_data_path = os.path.join(ascend_home_path, ATC_DATA_RL)
    old_ascend_fwk_data_path = os.path.join(OLD_USR_ASCEND_PATH, FWK_DATA_RL)
    old_home_fwk_data_path = os.path.join(home_path, FWK_DATA_RL)
    old_ascend_home_fwk_data_path = os.path.join(ascend_home_path, FWK_DATA_RL)
    old_rl_data_path = [old_ascend_home_opp_data_path, old_ascend_opp_vendors_cust_path, old_ascend_opp_data_path,
        old_home_opp_data_path, old_ascend_home_atc_data_path, old_ascend_home_fwk_data_path, old_ascend_atc_data_path,
        old_ascend_fwk_data_path, old_home_atc_data_path, old_home_fwk_data_path]

    soc_version = get_soc_spec(SHORT_SOC_VERSION)
    old_rl_custom_path = []
    for path in old_rl_data_path:
        full_path = os.path.join(path, soc_version) if \
            OPP_VENDORS_CUST_DATA_RL in path else os.path.join(path, soc_version, "custom")
        old_rl_custom_path.append(os.path.realpath(full_path))

    return old_rl_custom_path


def reset_repository() -> None:
    """
    Reload repository

    """
    RL_BANK_DICT.clear()
