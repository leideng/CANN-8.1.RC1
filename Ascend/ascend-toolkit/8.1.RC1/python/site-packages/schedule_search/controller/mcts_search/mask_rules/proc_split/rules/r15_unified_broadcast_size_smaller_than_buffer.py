#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
import numpy as np

from schedule_search import log
from schedule_search import comm
from schedule_search.controller.mcts_search.features import SEARCH_N
from schedule_search.controller.mcts_search.features import UB_BUFFER_SIZE
from schedule_search.ts_env.tensor_cfg import AXIS_CNT
from schedule_search.ts_env.tensor_cfg import ActionTensorCfg


def determine_whether_to_use_unified_broadcast(progress):
    stages_info = progress.op_schedule_info.stages_info
    shape_str = progress.op_schedule_info.shape
    shape_cnt = progress.op_schedule_info.shape_cnt
    is_broadcast = False

    def _get_shape_from_str(shape, cnt):
        shape_list = shape.split('_')
        shape_list = list(zip(*(iter(shape_list),) * cnt))
        shape_ori = shape_list[0]
        for one_shape in shape_list[1:]:
            if one_shape != shape_ori:
                return shape_ori, one_shape
        return shape_ori, shape_ori

    def last_axis_broadcast(shape_a, shape_b):

        if len(shape_a) != len(shape_b):
            return False

        cnt = len(shape_a)
        broadcast_axis = []
        for i in range(0, cnt):
            if shape_a[i] != shape_b[i]:
                broadcast_axis.append(i)

        if len(broadcast_axis) == 1 and broadcast_axis[0] == cnt - 1:
            return True

        return False

    for stage_info in stages_info:
        if stage_info.get('tag', '') == "broadcast_for_tensor":
            is_broadcast = True
            break

    shape_x, shape_y = _get_shape_from_str(shape_str, shape_cnt)

    if is_broadcast and last_axis_broadcast(shape_x, shape_y):
        return True

    return False


def get_dtype_bytes(dtype):
    """
    get_align_factor
    """
    # base on the diff data type, get the align_factor
    if dtype in ('int8', 'uint8'):
        dtype_bytes = 1
    elif dtype in ('float16', 'int16', 'uint16'):
        dtype_bytes = 2
    else:
        dtype_bytes = 4
    return dtype_bytes


def proc(progress, action_mask): # pylint: disable=R0912
    """
    broadcast which used vtranspose, make sure:
    repeat_time * 225 < ub_max_size
    """
    if progress.c_op in comm.MAD_OP_ID_LIST:
        return action_mask

    if not determine_whether_to_use_unified_broadcast(progress):
        return action_mask

    total_factor_size = 1
    # 算上reduce的stage
    for stage_index in range(progress.stage_num - 1, -1, -1):
        feature_vec = progress.op_schedule_info.feature_tensor[stage_index]
        if np.sum(feature_vec[AXIS_CNT:2 * AXIS_CNT]) > 0 \
                or stage_index == progress.stage_num - 1:
            curr_stage_nonzero_axes = progress.get_nonzero_axes(stage_index)
            # 如果是当前stage的采样，则只统计到当前axis_Index，否则统计到0
            if stage_index == progress.todo.stage_index:
                start_index = progress.todo.axis_index
            else:
                start_index = -1
            for idx in range(
                    len(curr_stage_nonzero_axes) - 1, start_index, -1):
                total_factor_size *= progress.action_tensor[stage_index][idx]

    # 获取当前factor
    factor_index = \
        ActionTensorCfg.split_factor_s + \
        progress.todo.cache_layer * AXIS_CNT + \
        progress.todo.axis_index
    factor = progress.action_tensor[progress.todo.stage_index][factor_index]

    align_factor = 32
    stages = list(progress.op_schedule_info.schedule_obj.stages)
    stage = stages[progress.todo.stage_index]
    stage_dtype = stage.op.output(0).dtype
    dtype_byte_size = get_dtype_bytes(stage_dtype)

    # 前端指令映射中的判断条件，满足即不采用vtranspose的方案
    if int(total_factor_size * dtype_byte_size % align_factor) == 0:
        return action_mask

    # vtranspose需要占用的ub空间，每次repeat需要占用16*16
    unify_broadcast_need_buffer_size = (factor // 16 - 4) * 256
    if unify_broadcast_need_buffer_size < 0 or dtype_byte_size != 2:
        return action_mask

    unify_broadcast_buiffer_size = UB_BUFFER_SIZE - unify_broadcast_need_buffer_size
    log.dbg("total_factor_size:%s factor:%s factor_index:%s UB_BUFFER_SIZE:%s",
            total_factor_size, factor, factor_index, UB_BUFFER_SIZE)
    for i in range(SEARCH_N):
        next_factor \
            = factor + pow(SEARCH_N, progress.todo.sub_action_index) * i
        if total_factor_size * next_factor > unify_broadcast_buiffer_size:
            action_mask[i] = 0

    # 全0的场景，保留第一位
    if sum(action_mask) == 0:
        action_mask[0] = 1
    log.dbg("r15 action_mask:%s", action_mask)

    return action_mask
