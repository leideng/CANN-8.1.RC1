#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
from schedule_search import log
from schedule_search import comm
from schedule_search import soc_cfg
from schedule_search.util import get_dtype_size
from schedule_search.ts_env.tensor_cfg import ActionTensorCfg
from schedule_search.ts_env.tensor_cfg import AXIS_CNT
from schedule_search.controller.mcts_search.features import SEARCH_N
from schedule_search.ts_env.tensor_to_code.t2c_util import C_SIZE
from schedule_search.ts_env.tensor_to_code.t2c_util import L0_CACHE_LAYER
from schedule_search.ts_env.tensor_to_code.t2c_util import gemm_identify


def condition_check(progress):
    '''
    :param progress:
    :return:
    '''
    # 非gemm不处理
    if progress.c_op not in comm.MAD_OP_ID_LIST:
        return False

    # 非L0的tiling不做mask
    if progress.todo.cache_layer != L0_CACHE_LAYER:
        return False

    return True


def get_start_axis_index(progress):
    '''
    :param progress:
    :return:
    '''
    has_batch, _ = gemm_identify(progress.op_schedule_info)
    start_axis_index = 1 if has_batch else 0
    return start_axis_index


def get_l0_buffer_size(progress):
    '''
    :param progress:
    :return:
    '''
    l0a_buffer = soc_cfg.get_l0a_size()
    l0b_buffer = soc_cfg.get_l0b_size()
    l0c_buffer = soc_cfg.get_l0c_size()

    last_stage_index = progress.stage_num - 1
    last_stage_dtype = progress.op_schedule_info.schedule_obj.stages[
        last_stage_index].op.output(0).dtype
    dtype_size = get_dtype_size(last_stage_dtype)
    double_buffer_size = 2
    # 两根规格轴大小
    c_size = C_SIZE * C_SIZE

    l0a_size = l0a_buffer / c_size / dtype_size / double_buffer_size
    l0b_size = l0b_buffer / c_size / dtype_size / double_buffer_size
    l0c_size = l0c_buffer / c_size / dtype_size / double_buffer_size

    return l0a_size, l0b_size, l0c_size


def mask_matmul_stage(progress, action_mask, l0a_size, l0b_size):
    '''
    matmul stage不能超过L0A、L0B的buffer
    '''
    start_factor_index = ActionTensorCfg.split_factor_s + \
                         progress.todo.cache_layer * AXIS_CNT
    factor = progress.action_tensor[progress.todo.stage_index][
        start_factor_index + progress.todo.axis_index]

    # L1的mn切分因子，mn的顺序无所谓，总之一个m一个n
    m_factor = progress.action_tensor[progress.stage_num - 1][
        start_factor_index]
    n_factor = progress.action_tensor[progress.stage_num - 1][
        start_factor_index + 1]

    for idx in range(SEARCH_N):
        # L0A和L0B的判断
        new_factor = factor + pow(SEARCH_N,
                                  progress.todo.sub_action_index) * idx
        if new_factor * m_factor > l0a_size or \
                new_factor * n_factor > l0b_size:
            action_mask[idx] = 0

    return action_mask


def mask_last_stage(progress,  # pylint: disable=R0912
                    action_mask,
                    l0a_size,
                    l0b_size,
                    l0c_size):
    '''
    最后一个stage不能超过L0A、L0B、L0C的buffer
    此时k的factor还没采样为1，不需要乘以k
    '''
    start_axis_index = get_start_axis_index(progress)
    start_factor_index = ActionTensorCfg.split_factor_s + \
                         progress.todo.cache_layer * AXIS_CNT
    factor = progress.action_tensor[progress.todo.stage_index][
        start_factor_index + progress.todo.axis_index]

    # n，此时m还没采样，为1
    if progress.todo.axis_index == 1 + start_axis_index:
        another_mn_factor = \
            progress.action_tensor[progress.todo.stage_index][
                start_factor_index]
        l0ab_size = l0b_size
    # m
    elif progress.todo.axis_index == 0 + start_axis_index:
        another_mn_factor = \
            progress.action_tensor[progress.todo.stage_index][
                start_factor_index + 1]
        l0ab_size = l0a_size
    else:
        log.dbg('axis_index: %s wrong.', progress.todo.axis_index)
        return action_mask

    for idx in range(SEARCH_N):
        new_factor = factor + pow(SEARCH_N,
                                  progress.todo.sub_action_index) * idx
        if new_factor > l0ab_size or \
                new_factor * another_mn_factor > l0c_size:
            action_mask[idx] = 0

    return action_mask


def proc(progress, action_mask):
    '''
    规则内容：gemm不超过L0 buffer的大小
    m*k<L0A
    n*k<L0B
    m*n<L0C
    '''
    if not condition_check(progress):
        return action_mask

    stage_tag = progress.op_schedule_info.stages_info[
        progress.todo.stage_index].get('tag')
    l0a_size, l0b_size, l0c_size = get_l0_buffer_size(progress)

    # matmul stage
    # 不能超过L0A、L0B的buffer
    if stage_tag == 'matmul':
        action_mask = mask_matmul_stage(progress,
                                        action_mask,
                                        l0a_size,
                                        l0b_size)

    # 最后一个stage
    # 不能超过L0A、L0B、L0C的buffer
    # 此时k的factor还没采样为1，不需要乘以k
    elif progress.todo.stage_index == progress.stage_num - 1:
        action_mask = mask_last_stage(progress,
                                      action_mask,
                                      l0a_size,
                                      l0b_size,
                                      l0c_size)

        # 不能全部都mask掉
    if sum(action_mask) == 0:
        action_mask[0] = 1

    log.dbg('r08_gemm_smaller_than_l0_buffer: %s', action_mask)
    return action_mask
