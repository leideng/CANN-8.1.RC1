#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
import copy
from functools import reduce as functools_reduce

from schedule_search import log
from schedule_search import comm
from schedule_search.controller.mcts_search.features import SEARCH_N
from schedule_search.ts_env import env_util
from schedule_search.ts_env.tensor_cfg import AXIS_CNT
from schedule_search.ts_env.tensor_cfg import ActionTensorCfg
from schedule_search.ts_env.tensor_to_code import t2c_util
from schedule_search.ts_env.tensor_to_code.generator import proc as \
    generate_te_schedule_proc


def proc(progress, action_mask): # pylint: disable=R0912,R0914,R0915
    """
    规则内容：数据块不能比32//size(dtype)小，但是尾块没有要求
    需要关注的stage有：单叶子输出、中间输出、虚节点对应的实际多叶子输出
    """
    if progress.c_op in comm.MAD_OP_ID_LIST:
        return action_mask

    # reduce atomic可能会mask掉一些比较好的
    if progress.op_schedule_info.tiling_case > 0:
        return action_mask

    stage_index = progress.todo.stage_index
    stages_info = progress.op_schedule_info.stages_info
    stage_info = stages_info[stage_index]
    if 'leaf' not in stage_info.get('type', []):
        return action_mask

    # block_size
    stages = list(progress.op_schedule_info.schedule_obj.stages)
    stage = stages[stage_index]
    stage_dtype = stage.op.output(0).dtype
    block_size = env_util.get_block_num(stage_dtype)

    total_size = 1
    curr_stage_nonzero_axes = progress.get_nonzero_axes(stage_index)
    if progress.todo.axis_index != len(curr_stage_nonzero_axes) - 1:
        items = curr_stage_nonzero_axes[progress.todo.axis_index + 1:]
        total_size = functools_reduce(lambda x, y: x * y, items)

    # WILLDO: 这里只对最后一层sub action做mask，是为了防止过clean？？
    if progress.todo.sub_action_index > 0:
        return action_mask

    # 导致数据块小于32byte的mask掉，需要倒推到中间输出、虚节点对应的实际多叶子输出
    factor_index = \
        ActionTensorCfg.split_factor_s + \
        progress.todo.cache_layer * AXIS_CNT + \
        progress.todo.axis_index
    factor = progress.action_tensor[stage_index][factor_index]
    inter_out_list = t2c_util.get_inter_out(stages_info)
    origin_leaf_out_list = t2c_util.get_origin_leaf_out(stages_info)
    special_stage_index_list = inter_out_list + origin_leaf_out_list
    for i in range(SEARCH_N):
        # 考虑sub_action
        factor_size = factor + pow(SEARCH_N,
                                   progress.todo.sub_action_index) * i
        if factor_size < block_size:
            log.dbg("[mask]%s factor_size <= 32b, need mask %s [%s, %s].",
                    stage, stage, factor_index, factor_size)
            action_mask[i] = 0
            continue
        # 导致中间输出、虚节点对应的实际多叶子输出尾块小于32byte的mask掉
        # WILLDO: reduce_atomic的时候get_factors逻辑不对，暂时不进行clean
        if not special_stage_index_list \
                or 'reduce_atomic' in stage_info.get('type', []):
            continue
        actions = copy.deepcopy(progress.action_tensor)
        actions[stage_index][factor_index] = factor_size
        op_sch_info_copy = copy.deepcopy(progress.op_schedule_info)
        sch_info = generate_te_schedule_proc(op_sch_info_copy,
                                             actions,
                                             proc_index_start=40,
                                             proc_index_end=40)
        op_sch_info = progress.op_schedule_info
        stage_factors, _ = t2c_util.get_factors(stages,
                                                op_sch_info.stages_info,
                                                op_sch_info.feature_tensor,
                                                sch_info.cleaned_actions,
                                                op_sch_info.reduce_axis_dict,
                                                op_sch_info.real_fanout_dict)
        for special_stage_index in special_stage_index_list:
            special_stage = stages[special_stage_index]
            factors = stage_factors[special_stage_index][0]
            # 获取数据块的大小
            special_stage_axis = special_stage.op.axis
            slice_size = t2c_util.get_slice_size(special_stage_axis, factors)
            log.dbg("[mask]%s [%s, %s]", stage, factor_index, factor_size)
            log.dbg("special_stage: %s, factors: %s, last_slice_size: %s",
                    special_stage, factors, slice_size)
            special_stage_dtype = special_stage.op.input_tensors[0].dtype
            if slice_size < env_util.get_block_num(special_stage_dtype):
                action_mask[i] = 0
                log.dbg("[mask]%s factor_size <= 32b, need mask %s [%s, %s].",
                        special_stage, stage, factor_index, factor_size)
                continue

    # 不能全部都mask掉，保留最大的
    if sum(action_mask) == 0:
        axis_len = curr_stage_nonzero_axes[progress.todo.axis_index]
        for i in range(SEARCH_N - 1, -1, -1):
            # 考虑sub_action
            factor_size = factor
            factor_size += pow(SEARCH_N, progress.todo.sub_action_index) * i
            if factor_size <= axis_len:
                action_mask[i] = 1
                break

    log.dbg("r05 action_mask:%s", action_mask)
    return action_mask
