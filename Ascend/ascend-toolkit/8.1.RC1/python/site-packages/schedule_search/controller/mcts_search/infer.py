#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
import copy
import datetime
import gzip
import os
import pickle
import sys
import time
from dataclasses import make_dataclass

from schedule_search import log
from schedule_search.timer import timer
from schedule_search.soc_cfg import set_soc_info
from schedule_search.controller.mcts_search import preprocessing as pp
from schedule_search.controller.mcts_search.strategies import MCTSSearcher
from schedule_search.controller.mcts_search.strategies import DFSSearcher
from schedule_search.controller.mcts_search.strategies import NUM_READOUTS
from schedule_search.controller.mcts_search.strategies import VAL_NUM_READOUTS
from schedule_search.controller.search_comm import get_move_prob_value

SAMPLE_PARAS = ['load_file', 'op_schedule_infos', 'infer_dir', 'gpu',
                'result_dir', 'index', 'process_share_infos']
SampleParaNamedTuple = make_dataclass('SampleParaNamedTuple', SAMPLE_PARAS)


class SamplePara(SampleParaNamedTuple):
    """
    采样的参数类
    """

    def post_proc(self):
        """
        :return:
        """
        if self.result_dir and isinstance(self.index, int):
            result_file = os.path.join(self.result_dir, '%s' % self.index)
            try:
                os.mknod(result_file)
            except (FileNotFoundError, FileExistsError) as excp:
                log.warn("RL exception occur: can not create result file, %s.", repr(excp))


def search(op_schedule_infos: list, valid: bool = False, process_share_infos: object = None) -> object:
    """
    mcts main search process
    :param op_schedule_infos:
    :param process_share_infos
    :param valid
    :return:
    """
    readouts = op_schedule_infos[0].option.get("num_readouts", NUM_READOUTS)
    try:
        search_handler = MCTSSearcher(valid=valid)
        search_handler.initialize_search(op_schedule_infos)
        # Valid时不需要噪声，就把这个temp_threshold置成0
        if valid:
            search_handler.temp_threshold = -1
            readouts = op_schedule_infos[0].option.get("num_readouts", VAL_NUM_READOUTS)

        first_node = search_handler.root.select_leaf()
        prob, val = get_move_prob_value()

        log.dbg("RL search info: first_node is %s, prob is %s, val is %s.", str(first_node), prob.tolist(), val)
        first_node.incorporate_results(prob, val, first_node)
        first_node.value = val
        log.dbg("RL search info: first_node is %s.", str(first_node))

        while True:
            # mcts tree search
            search_handler.tree_search(process_share_infos, readouts)

            if search_handler.root.is_done():
                search_handler.root.get_value(process_share_infos)
                log.dbg("RL search info: new_root is a leaf node, mcts search process end.")
                break
        return search_handler
    except Exception as exception:  # pylint: disable=broad-except
        log.warn("RL exception occur: MCTS searching for op: %s(op_md5 is %s), raise exception: %s.",
                 op_schedule_infos[0].op_name, op_schedule_infos[0].op_md5, repr(exception))
        return None


def dfs_search(op_schedule_infos: list, process_share_infos: object = None, dfs_res: object = None) -> object:
    """
    dfs search
    :param op_schedule_infos:
    :param process_share_infos
    :param valid
    :return:
    """
    start_ts = time.time()
    option = op_schedule_infos[0].option
    log.info("RL search info: op %s begin to create dfs search tree on the platform %s, core_type:%s, core_num:%s.",
             op_schedule_infos[0].op_name, option.get("soc_version"), option.get("core_type"), option.get("core_num"))
    set_soc_info(option.get("soc_version"), option.get("core_type"), option.get("core_num"), option.get("l1_fusion"))

    try:
        search_handler = DFSSearcher()
        search_handler.initialize_search(op_schedule_infos)
        search_handler.dfs_tree_search(process_share_infos)
        dfs_res.value = True
        log.info("RL search info: dfs search end successfully.")
        return search_handler
    except Exception as exception:
        log.warn("RL exception occur: DFS searching for op: %s(op_md5 is %s), raise exception: %s.",
                 op_schedule_infos[0].op_name, op_schedule_infos[0].op_md5, repr(exception))
        return None
    finally:
        end_ts = time.time()
        log.event("RL search info: op %s dfs search end, duration: %ds",
                   op_schedule_infos[0].op_name, end_ts - start_ts)


def gen_raw_data_valid(search_handler,  # pylint: disable=R0914
                       infer_dir,
                       output_name):
    '''
    :param search_handler:
    :param infer_dir:
    :param output_name:
    :return:
    '''
    if not search_handler.leaves:
        return None
    best_leaf_value = sorted(search_handler.leaves,
                             key=lambda x: x[1])[-1]
    best_leaf = best_leaf_value[0]
    states = []
    moves = []
    states = best_leaf.get_states(states)
    moves = best_leaf.get_moves(moves)
    op_schedule_infos = []
    action_tensors = []
    for progress in best_leaf.progress_chain.p_list:
        op_schedule_infos.append(progress.op_schedule_info)
        action_tensors.append(progress.action_tensor)
    value = best_leaf.value
    tick = best_leaf.progress.tick
    # 如果没有成功的tick，则打开oom_clean的开关，重新获取tick
    if tick in [0, sys.maxsize, None]:
        tmp_op_schedule_infos = copy.deepcopy(op_schedule_infos)
        tmp_op_schedule_infos[0].option["enable_oom"] = True
        infer_data = pp.InferData(tmp_op_schedule_infos, [], states[-1],
                                  [], action_tensors, [], states[-1])
        infer_data = pp.update_infer_data_tick(infer_data)
        tick = infer_data.tick
    # raw最后一个是argv，支持拓展
    raw_data = [[
        op_schedule_infos, state, None, value, action_tensors, move, tick
    ] for state, move in zip(states, moves)]
    # 直接append的话，用的地址一样
    raw_data.append(copy.deepcopy(raw_data[-1]))
    # dump到文件
    fname = os.path.join(infer_dir,
                         "{}_tick{}.pk".format(output_name, tick))
    with gzip.open(fname, 'wb') as file_handle:
        pickle.dump(raw_data, file_handle)
    return raw_data


def gen_raw_data_infer(search_handler,  # pylint: disable=R0914
                       infer_dir,
                       output_name):
    '''

    :param search_handler:
    :param infer_dir:
    :param output_name:
    :return:
    '''
    # 如果是infer，用所有的叶子节点的路径返回
    if not search_handler.leaves:
        return None
    leaves = sorted(search_handler.leaves,
                    key=lambda x: x[1],
                    reverse=True)
    log.dbg("leaves num: %s", len(leaves))
    all_raw_data = []
    all_state_str = []
    min_tick = 0
    for leaf in leaves:
        leaf = leaf[0]
        states = [leaf.progress.state]
        states = leaf.get_states(states)

        pis, action_tensors, moves = [leaf.children_as_pi()], \
                                     [leaf.progress.action_tensor], [0]
        pis = leaf.get_pis(pis)
        action_tensors = leaf.get_action_tensors(action_tensors)
        moves = leaf.get_moves(moves)
        op_schedule_infos = []
        leaf_actions_tensors = []
        for progress in leaf.progress_chain.p_list:
            op_schedule_infos.append(progress.op_schedule_info)
            leaf_actions_tensors.append(progress.action_tensor)
        value = leaf.value
        tick = leaf.progress.tick
        if tick is None:
            continue
        if min_tick == 0 or tick < min_tick:
            min_tick = tick
        raw_data = []
        for idx, state in enumerate(states[::-1]):
            state_idx = len(states) - 1 - idx
            all_state_str.append(state.tobytes())
            raw_data.append([
                op_schedule_infos, state, pis[state_idx], value,
                leaf_actions_tensors, moves[state_idx], tick
            ])
        raw_data = raw_data[::-1]
        log.dbg("RL search info: raw_data num: %s", len(raw_data))
        all_raw_data.extend(raw_data)

    # dump到文件
    fname = os.path.join(
        infer_dir,
        "{}_leafs_{}_mintick_{}.pk".format(output_name, len(leaves), min_tick))
    try:
        with gzip.open(fname, 'wb') as file_handle:
            pickle.dump(all_raw_data, file_handle)
    except (FileNotFoundError, FileExistsError) as excp:
            log.warn("RL exception occur: can not generate infer pk file, %s.", repr(excp))
    finally:
            pass
    log.dbg("RL search info: all_state num: %s", len(set(all_state_str)))
    return all_raw_data


@timer('sample_once_iter')
def sample_once_iter(sample_para: SamplePara, valid: bool = False) -> object:
    """
    try to create one mcts search tree
    :param sample_para:
    :param valid:
    :return:
    """
    sample_index = sample_para.index
    if sample_para.index is None:
        sample_index = -1
    log.dbg("RL search info: begin to create %dth mcts search tree.", sample_index)
    op_schedule_infos = sample_para.op_schedule_infos
    infer_dir = sample_para.infer_dir

    output_name = '{}@{}_{}_{}'.format(
        op_schedule_infos[0].op_name, op_schedule_infos[0].shape_list_str,
        os.getpid(), datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f'))

    search_handler = search(op_schedule_infos, valid, sample_para.process_share_infos)
    if search_handler is None:
        log.dbg("RL search info: can not create %dth mcts search tree.", sample_index)
        return None

    # 如果是Validation，用最优Value的路径返回
    if valid:
        raw_data = gen_raw_data_valid(search_handler, infer_dir, output_name)
    else:
        raw_data = gen_raw_data_infer(search_handler, infer_dir, output_name)
    log.dbg("RL search info: create %dth mcts search tree end successfully.", sample_index)
    return raw_data


def sample_once(sample_para: SamplePara, valid: bool = False) -> object:
    """
    用于包裹多线程调用sample_once解决非实例问题
    :param sample_para:
    :param valid:
    :return:
    """
    start_ts = time.time()
    option = sample_para.op_schedule_infos[0].option
    kernel_name = option.get("kernel_name", "default")
    log.info("RL search info: op %s sample once %d begin on the platform %s, core_type:%s, core_num:%s.",
        kernel_name, sample_para.index, option.get("soc_version"), option.get("core_type"), option.get("core_num"))

    set_soc_info(option.get("soc_version"), option.get("core_type"), option.get("core_num"), option.get("l1_fusion"))
    raw_data = sample_once_iter(sample_para, valid)
    if raw_data is not None:
        sample_para.post_proc()
    end_ts = time.time()
    log.info("RL search info: %s sample once %d end, duration: %s seconds.",
             kernel_name, sample_para.index, end_ts - start_ts)
    return raw_data
