#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
import copy
import json
import math
import os
import sys
from itertools import permutations

import numpy as np

from tbe.common.rl_bank.rl_bank import satisfy_bank
from schedule_search import log
from schedule_search import soc_cfg
from schedule_search import util
from schedule_search import global_manager
from schedule_search.config import WORKSPACE
from schedule_search.controller.mcts_search.features import SEARCH_N
from schedule_search.timer import set_timer_logger
from schedule_search.ts_env import env_util
from schedule_search.ts_env.estimator.evb import evb_util
from schedule_search.ts_env.estimator.estimate import re_get_base_tick
from schedule_search.ts_env.estimator.estimate import re_get_tick_om
from schedule_search.ts_env.estimator.kernel_runner import ErrorCode
from schedule_search.ts_env.te_auto_schedule_env import get_op_schedule_info
from schedule_search.ts_env.op_schedule_info import OpScheduleInfo
from schedule_search.ts_env.tensor_cfg import AXIS_CNT
from schedule_search.ts_env.tensor_cfg import FeatureTensorCfg
from schedule_search.ts_env.tensor_cfg import MAX_FACTOR
from schedule_search.ts_env.estimator.kernel_runner import ErrorCode
from schedule_search.util import OPEN_FILE_MODES_640
from schedule_search.util import WRITE_FILE_FLAGS

FILE_PATH = os.path.dirname(os.path.realpath(__file__))

MAX_STAGE_NUM = 100
ONE_HOUR = 3600

# 根据最大Factor算出来最大子树深度
MAX_SUB_ACTION_DEPTH = int(math.ceil(math.log(MAX_FACTOR, AXIS_CNT)))

# 获取ORDER_MAP_DICT
ORDER_MAP_DICT = {}
if not ORDER_MAP_DICT:
    for i in range(AXIS_CNT):
        order_map = {}
        perms = list(permutations(range(i + 1), i + 1))
        for j, perm in enumerate(perms):
            order_map.setdefault(j, list(perm))
        ORDER_MAP_DICT.setdefault(len(perms), order_map)

BLOCK_SIZE_BYTE = 32
BEST_TICK_IDX = 0
CHEQUE_INFO_IDX = 2


def print_user_flags(flags_dict: dict, line_limit: int = 80) -> None:
    """
    print user flags
    :param flags_dict:
    :param line_limit:
    """
    log.dbg("-" * 80)
    for flag_name in sorted(flags_dict.keys()):
        value = "{}".format(flags_dict[flag_name])
        dots = "." * (line_limit - len(flag_name) - len(value))
        log_string = flag_name + dots + value
        log.info("%s", log_string)


def get_base_sch_path(op_schedule_info: object, best_sch_name: str, run_succ_path: str) -> str:
    """
    如果没有best sch file，则使用base sch file
    :param op_schedule_info: 算子调度信息
    :param best_sch_name: 最优调度文件
    :param run_succ_path: 调度文件存放目录
    :return: best_sch_name
    """
    if not best_sch_name \
        or int(best_sch_name.split("_")[0]) > op_schedule_info.base_tick + 3:
        kernel_name, _ = env_util.gen_kernel_name(op_schedule_info.op_name)
        best_sch_name = "%s_%s_%s.py" % (op_schedule_info.base_tick,
                                         op_schedule_info.base_tick,
                                         kernel_name)
        op_file = os.path.join(run_succ_path, best_sch_name)
        env_util.gen_auto_schedule_py(op_schedule_info, op_file, kernel_name)
    return best_sch_name


def get_best_sch_path(op_schedule_info: object,
                      dst_dir: str = None,
                      silent: bool = False,
                      base_instead: bool = False) -> str:
    """
    获取算子最优调度路径
    :param op_schedule_info: 算子调度信息
    :param dst_dir: 目标路径
    :param silent: T/F
    :param base_instead: T/F
    :return: best_src_path
    """
    if not op_schedule_info:
        return ""

    op_name = op_schedule_info.op_name
    shape_list_str = op_schedule_info.shape_list_str
    store_dir = op_schedule_info.store_dir
    run_succ_path = os.path.join(store_dir, "run_succ")

    log.dbg("get_best_sch_path begin, op_name: %s, run_succ_path: %s.", op_name, run_succ_path)
    best_sch_name = ""
    best_src_path = ""
    if os.path.exists(run_succ_path):
        sch_list = os.listdir(run_succ_path)
        if not sch_list:
            return ""
        sch_list.sort(key=lambda file_name: int(file_name.split("_")[0]))
        best_sch_name = sch_list[0]

    # base_instead使能且有base时
    if base_instead and op_schedule_info.base_tick:
        best_sch_name = get_base_sch_path(op_schedule_info, best_sch_name, run_succ_path)

    if best_sch_name:
        best_src_path = os.path.join(run_succ_path, best_sch_name)

    if dst_dir and best_src_path:
        dst_path = os.path.join(dst_dir, "best_" + best_sch_name)
        util.cp_src_to_dst(best_src_path, dst_path)
        if not silent:
            log.info("%s@%s search result is %s!", op_name, shape_list_str, best_src_path)

    log.dbg("get_best_sch_path end, op_name: %s, best_src_path: %s.", op_name, best_src_path)
    return best_src_path


def get_top_cheque_info(op_schedule_info: object) -> list:
    """
    get top ten filtered cheque_infos from global_manager.BEST_CHEQUE_DICT keys
    :param op_schedule_info: op's unique info class
    :return: top_cheque_infos, list of dict, key:{best_tick, base_tick, bank_key, cheque}
    """
    if not op_schedule_info:
        return []

    if not global_manager.BEST_CHEQUE_DICT:
        log.info("RL tune info: BEST_CHEQUE_DICT is empty, no top_cheque_infos.")
        return []

    best_cheque_dict_values = global_manager.BEST_CHEQUE_DICT.values()
    total_saved_cheque_list = []
    for saved_cheque_list in best_cheque_dict_values:
        total_saved_cheque_list.extend(saved_cheque_list)
    log.dbg("RL tune info: get_top_cheque_info begin, BEST_CHEQUE_DICT has %s cheque_infos recorded.",
             len(total_saved_cheque_list))

    kernel_name = op_schedule_info.option.get('op_config', {}).get("kernel_name", "default")
    kernel_name = kernel_name.split("@")[0]

    # sort BEST_CHEQUE_DICT by best_tick, best_cheque_info: dict{best_tick, base_tick, bank_key, cheque}
    total_saved_cheque_list.sort(key=lambda item: item.get("best_tick", sys.maxsize))
    top_ten_cheque_infos = total_saved_cheque_list[:util.TOP_TEN_CHEQUE]
    top_cheque_infos = []
    for cheque_info in top_ten_cheque_infos:
        if not satisfy_bank(cheque_info["base_tick"], cheque_info["best_tick"], 'in'):
            break
        top_cheque_infos.append(cheque_info)

    log.dbg("RL tune info: get_top_cheque_info end, op %s, top_cheque_infos: %s.", kernel_name, top_cheque_infos)
    return top_cheque_infos


def get_best_cheque_info(op_schedule_info: object,
                         top_cheque_infos: list,
                         kernel_name: str,
                         communicate_option: dict,
                         need_get_base: bool) -> dict:
    """
    put top cheques to datacmp
    :param op_schedule_info:
    :param top_cheque_infos:
    :param kernel_name:
    :param communicate_option:
    :param need_get_base:
    :return: best_cheque_info
    """
    if not top_cheque_infos:
        log.info("RL tune info [datacmp]: op %s has no strategy need precision calibration.", kernel_name)
        if need_get_base:
            # Refresh the compilation cache of the operator to prevent performance regression in result om
            re_get_tick, _ = re_get_base_tick(op_schedule_info, communicate_option)
            log.dbg("RL tune info: op %s re_get_base_tick, tick is %s.", kernel_name, re_get_tick)
        return {}

    # conv2d_l1fusion doesn't need datacmp
    if op_schedule_info.option.get('is_conv2d_l1fusion', False):
        top_cheque_infos.sort(key=lambda item: item["best_tick"])
        best_cheque_info = top_cheque_infos[0]
        log.info("RL tune info [datacmp]: op %s get_best_cheque_info end, conv2d_l1fusion doesn't need datacmp, "
                 "best_cheque_info is %s.", kernel_name, best_cheque_info)
        return best_cheque_info

    log.info("RL tune info [datacmp]: op %s has %d strategies put to compile_and_run task with datacmp.",
              kernel_name, len(top_cheque_infos))
    cheque_to_cmp = [cheque_info.get("cheque") for cheque_info in top_cheque_infos]
    ret, om_ticks, err_codes = re_get_tick_om(op_schedule_info, cheque_to_cmp, communicate_option)
    log.dbg("RL tune info [datacmp]: op %s datacmp feedbacks: ret: %s, om_ticks: %s, err_codes: %s.",
             kernel_name, ret, om_ticks, err_codes)
    if not ret:
        log.warn("RL tune info [datacmp]: op %s datacmp can not compile and run tasks.", kernel_name)
        return {}

    tick_code_list = [(om_ticks[idx], err_codes[idx], top_cheque_infos[idx])
                      for idx in range(len(err_codes))
                      if err_codes[idx] == ErrorCode.RUN_SUCC]
    if not tick_code_list:
        log.warn("RL tune info [datacmp]: op %s has no strategy passed datacmp.", kernel_name)
        return {}

    tick_code_list.sort(key=lambda item: item[BEST_TICK_IDX])
    best_cheque_info = tick_code_list[0][CHEQUE_INFO_IDX]
    log.info("RL tune info [datacmp]: op %s get_best_cheque_info end, %d valid strategies passed datacmp, "
             "best_cheque_info is %s.", kernel_name, len(tick_code_list), best_cheque_info)
    return best_cheque_info


def feature_format_adaptor(feature_tensor: list) -> list:
    """

    :param feature_tensor:
    :return: new_feature_tensor
    """
    if AXIS_CNT != 8:
        return feature_tensor
    new_feature_tensor = []
    for stage_info in feature_tensor:
        if len(stage_info) >= FeatureTensorCfg.featurn_len:
            return feature_tensor
        new_stage_info = []
        for index, value in enumerate(stage_info):
            if index in [5, 10]:
                new_stage_info.extend([0, 0, 0])
            new_stage_info.append(value)
        new_feature_tensor.append(new_stage_info)
    new_feature_tensor = np.asarray(new_feature_tensor)
    return new_feature_tensor


def get_load_file(op_schedule_info: object) -> str:
    """
    获取匹配的模型load file
    :param op_schedule_info: 算子调度信息
    :return: load_file
    """
    if op_schedule_info.reduce_axis_dict:
        pattern = "reduce"
    else:
        pattern = 'elemwise_broadcast'
        log.warn('Current model only support specified ops. Other ops may '
                 'have errors or efficiency problems.')
    soc_version = soc_cfg.get_soc_version()
    load_file = os.path.join(FILE_PATH, "..", "model", soc_version, pattern,
                             "model")
    if not os.path.exists(load_file + ".index"):
        # model不存在，则从rl_libs下面获取
        load_file = os.path.join(FILE_PATH, "../../../../../../../build/bin/rl",
                                 "model", soc_version, pattern, "model")
        if not os.path.exists(load_file + ".index"):
            return None
    return load_file


def post_processing_proc(op_schedule_infos_list: list,
                         base_instead: bool = False) -> (bool, list):
    """
    获取算子最优调度路径列表
    :param op_schedule_infos_list: 算子调度信息列表
    :param base_instead:
    :return: T/F, best_tune_res_list
    """
    best_tune_res_list = []
    ret = True
    try:
        for op_schedule_infos in op_schedule_infos_list:
            if not op_schedule_infos:
                continue
            op_schedule_info = op_schedule_infos[0]
            base_instead = False if op_schedule_info.tik_op else base_instead
            best_src_path = get_best_sch_path(
                op_schedule_info, op_schedule_info.store_dir, base_instead=base_instead)
            best_tune_res_list.append(best_src_path)
    except Exception as exp:  # pylint: disable=broad-except
        log.warn("RL exception occur: post_processing_proc can not get best_tune_res_list, %s.", repr(exp))
        ret = False
    finally:
        pass
    log.info("RL tune info: post_processing_proc end, best_tune_res_list: %s.", best_tune_res_list)
    return ret, best_tune_res_list


def get_trs_ub_size(op_schedule_info: OpScheduleInfo, stage_index: int) -> int:
    """
    get trs ub size for choose_axis and split mask
    :param op_schedule_info:
    :param stage_index:
    :return:
    """
    ub_size = soc_cfg.get_ub_size() // 2
    trs_ub_size = ub_size // BLOCK_SIZE_BYTE * BLOCK_SIZE_BYTE
    stages = op_schedule_info.schedule_obj.stages
    stage_dtype = stages[stage_index].op.output(0).dtype
    trs_ub_size = trs_ub_size // util.get_dtype_size(stage_dtype)

    return trs_ub_size


def get_split_sub_tree_depth(axis_len: int) -> int:
    """

    :param axis_len:
    :return:
    """
    depth = int(math.log(axis_len, AXIS_CNT))
    if axis_len > pow(AXIS_CNT, depth):
        depth = depth + 1
    if depth == 0:
        return 1
    return min(depth, MAX_SUB_ACTION_DEPTH)


def get_dir_by_option(option: dict, op_schedule_infos: object, flags: object) -> None:
    """
    根据option获取replay和store等目录信息
    :param option: 算子推理和配置option
    :param op_schedule_infos: 算子调度信息
    :param flags: FLAGS
    """
    op_name = option.get("op_name", "default")
    workspace = option.get("WORKSPACE", WORKSPACE)
    replay_dir = os.path.join(workspace, "replay_dir")
    store_tmp_dir = os.path.join(flags.workspace, "store_tmp")
    option["output_dir"] = os.path.join(store_tmp_dir, op_name)
    util.ensure_dir_exists(replay_dir, reset=False)
    util.ensure_dir_exists(store_tmp_dir, reset=False)
    store_dir = os.path.join(store_tmp_dir, op_name, op_schedule_infos[0].shape_list_str)
    util.ensure_dir_exists(store_dir, reset=False)

    for op_schedule_info in op_schedule_infos:
        op_schedule_info.store_dir = store_dir
        op_schedule_info.replay_dir = replay_dir
        if len(op_schedule_infos) > 1 and len(op_schedule_info.schedule_obj.stages) > MAX_STAGE_NUM:
            op_schedule_info.option["num_readouts"] = 1
            op_schedule_info.option["val_num_readouts"] = 1


def get_op_schedule_infos(res_list: list,  # pylint: disable=R0914
                          option_list: list,
                          flags: object,
                          op_config_list: list) -> (list, list):
    """
    获取算子调度信息
    :param res_list: 算子res列表
    :param option_list: 算子推理和配置option列表
    :param flags: FLAGS
    :param op_config_list:
    :return: op_schedule_infos_list, op_config_list_new
    """
    op_schedule_infos_list = []
    op_config_list_new = []

    # 获取算子调度信息列表
    pool_result_list = []
    for res, option in zip(res_list, option_list):
        pool_result_list.append(get_op_schedule_info(res, option))

    for result, option, op_config in zip(pool_result_list, option_list, op_config_list):
        if option.get("run_by_om", False) and result[0].base_run_err_code != ErrorCode.RUN_SUCC:
            log.warn("RL tune info: op %s auto schedule can not run, skip it.", result[0].ori_op_name)
            continue
        op_schedule_infos = result

        if op_schedule_infos:
            # 各个Option可能是不同的，根据Option信息获取各个目录信息
            get_dir_by_option(option, op_schedule_infos, flags)
        op_schedule_infos_list.append(op_schedule_infos)
        op_config_list_new.append(op_config)
    return op_schedule_infos_list, op_config_list_new


def check_op_config_num(res_list: list, op_config_list: list) -> bool:
    """
    要求tune的算子config数量和算子res算子数量一致
    :param res_list: 算子res列表
    :param op_config_list: 算子config列表
    :return: bool
    """
    if op_config_list and len(op_config_list) != len(res_list):
        log.err("Num of res is %d differs from num of op_config, which is %d.",
                len(res_list), len(op_config_list))
        return False

    return True


def pre_check(flags: object, option: dict, res_list: list) -> (bool, dict):
    """
    输入参数检查和相应信息初始化设置
    :param flags: flags.FLAGS
    :param option: 算子调优推理选项
    :param res_list: 算子输出tensor列表
    :return: T/F, option
    """
    # res_list 暂时不检查，后续可以加上相应的检查流程
    if flags is not None:
        util.update_flags(flags, option)

    option = util.init_option(option)

    if not option.get('run_by_om', False):
        # 初始化evb
        for evb_info in option.get('evbs'):
            evb_info["workspace"] = option.get('WORKSPACE', '')
            evb_util.init_evb(evb_info, option)

    # 输入检查
    if not util.input_check(option, res_list):
        return False, option
    if not option.get('run_by_om', False):
        # 环境检查
        ret, _ = evb_util.env_check(option)
        if not ret:
            return False, option

    # 确认cpu_process_num
    evb_num = sum(len(evb_info.get("device_idx")) for evb_info in option.get('evbs'))
    if flags and "cpu_process_num" in flags:
        flags.cpu_process_num = min(evb_num * 8, flags.cpu_process_num)

    # 初始化timer logger
    if (flags and 'timer' in flags and flags.timer) or option.get('timer', False):
        set_timer_logger()

    return True, option


def pre_processing_proc(flags: object,
                        option: dict,
                        res_list: list,
                        op_config_list: list = None) -> (bool, list):
    """
    预处理将option和op_config_list结合成option_list
    :param flags: flags.FLAGS
    :param option: 算子调优推理选项
    :param res_list: 算子输出tensor列表
    :param op_config_list: 每个算子独有的一些配置
    :return: T/F, option_list
    """
    ret, option = pre_check(flags, option, res_list)
    option["TUNE_WORKSPACE"] = flags.workspace
    if not ret:
        return ret, option

    if not check_op_config_num(res_list, op_config_list):
        return False, option

    option_list = []
    for idx in range(len(res_list)):
        option_i = copy.deepcopy(option)
        if op_config_list:
            option_i['op_config'] = op_config_list[idx]
            option_i.update(op_config_list[idx])
        option_list.append(option_i)

    return True, option_list


def translate_reorder(index: int, reorder_choice_cnt: int = 120) -> list:
    """
    translate_action reorder处理
    :param index:
    :param reorder_choice_cnt:
    :return: order_list
    """
    # 这里要体现的是顺序，所以不宜直接用itertools.permutations来实现
    # 在5根轴全时，每个数对应一种顺序，如何分布影响不大
    # 在5根轴不全时，我们需要保证：
    # 1，当只有2根轴时，前面60类是一种，后面60类是另一种
    # 2，当只有3根轴时，[0,19],[20,39],[40,59],[60,79],[80,99],[100,119]分另表示同一类
    # 3，当只有4根轴时，每5个连续的数表示同一种顺序

    curr_order_map = ORDER_MAP_DICT.get(reorder_choice_cnt, {})
    if index not in curr_order_map:
        log.err("Failed to translate reorder action, %s is invalid index and it should be 0~119.", index)
        return list(range(AXIS_CNT))
    order_list = curr_order_map[index]
    # 不大于5根轴的reorder，需要后面用正常order_index补全
    if len(order_list) < AXIS_CNT:
        order_list = order_list + list(range(len(order_list), AXIS_CNT))
    return order_list


def translate_multi_label(factor: int, axis: int, factor_label_num: int) -> int:
    """
    translate_multi_label
    :param factor:
    :param axis:
    :param factor_label_num:
    :return: factor
    """
    # 拉伸映射factor
    if factor == 0:
        return 1
    if axis == 0:
        return 1

    # 支持尾块
    factor = int(round(factor / (2**factor_label_num) * axis))
    factor = min(factor, axis)
    if factor == 0:
        factor = 1
    return factor


def translate_action_by_stage_actions(stage_index: int, actions_of_stage: list,
                                      factor_cnt: int, input_feature: list,
                                      factor_label_num: int, reorder_choice_cnt: int) -> list:
    """
    遍历每个stage的actions，转化成ts_env可以看懂的action
    :param stage_index:
    :param actions_of_stage:
    :param action_tensor:
    :param factor_cnt:
    :param input_feature:
    :param factor_label_num:
    :param reorder_choice_cnt:
    :return: actions_of_stage_with_order
    """
    axis_num = factor_cnt // 2
    actions_of_stage_with_order = []
    # 遍历Action
    for action_index, action in enumerate(actions_of_stage):
        # Factor处理
        if action_index < factor_cnt:
            # 获取实际的axis_len, 存在reduce_axis时，以reduce_axis为准
            if sum(input_feature[stage_index][axis_num:factor_cnt]) > 0:
                axis_len = input_feature[stage_index][action_index % axis_num + axis_num]
            else:
                axis_len = input_feature[stage_index][action_index % axis_num]
            factor = translate_multi_label(action, axis_len, factor_label_num)
            actions_of_stage_with_order.append(factor)
        # Reorder处理
        elif action_index < factor_cnt + 2:
            order_list = translate_reorder(action, reorder_choice_cnt)
            actions_of_stage_with_order.extend(order_list)
        # At处理
        else:
            actions_of_stage_with_order.append(action)
    return actions_of_stage_with_order



def translate_action(action_tensor: list,
                     factor_cnt: int,
                     input_feature: list,
                     factor_label_num: int,
                     reorder_choice_cnt: int) -> list:
    """
    转化成ts_env可以看懂的action
    :param action_tensor:
    :param factor_cnt:
    :param input_feature:
    :param factor_label_num:
    :param reorder_choice_cnt:
    :return: action_tensor_with_order
    """
    action_tensor_with_order = []
    for stage_index, actions_of_stage in enumerate(action_tensor):
        # 遍历Action
        actions_of_stage_with_order = translate_action_by_stage_actions(stage_index, actions_of_stage,
                                                                        factor_cnt, input_feature,
                                                                        factor_label_num, reorder_choice_cnt)

        action_tensor_with_order.append(actions_of_stage_with_order)
    return action_tensor_with_order


def action_mask_with_one_op_layer(new_mask: list, op_layer: int, axis_cnt: int) -> None:
    """
    deal with action_mask when op_layer==1
    :param new_mask:
    :param op_layer:
    :param axis_cnt:
    """
    if op_layer == 1:
        # 第二轮的factor和reorder都mask掉
        new_mask[axis_cnt:axis_cnt * 2] = [True] * axis_cnt
        new_mask[axis_cnt * 2 + 1] = True


def get_action_mask(feature_tensor: list,
                    axis_cnt: int,
                    op_layer: int,
                    at_align: bool = True) -> list:
    """
    获取action_mask列表
    :param feature_tensor:
    :param axis_cnt:
    :param op_layer:
    :param at_align:
    :return: action_mask
    """
    # 获取action mask信息
    feature_tensor = feature_tensor.tolist()
    # 默认全部采样
    mask = [False] * (2 * axis_cnt + 2 * 1 + 1)
    action_mask = []
    stage_num = len(feature_tensor) - 1
    for stage_index, stage_feature in enumerate(feature_tensor):
        new_mask = mask[:]
        # reduce axis 存在情况下，当前stage的采样保留
        # reduce轴和为0则说明没有reduce轴
        if sum(stage_feature[axis_cnt:2 * axis_cnt]) == 0:
            if stage_index == stage_num:
                new_mask[-1] = True
                # 只进行一层cache采样
                action_mask_with_one_op_layer(new_mask, op_layer, axis_cnt)
            else:
                # 不是最后一个stage 只采样at轴，其他全部mask掉
                new_mask[0:(2 * axis_cnt + 2 * 1)] = [True] * (2 * axis_cnt + 2 * 1)
            axis_list = stage_feature[0:axis_cnt]
        else:
            # 只用一层buffer情况下，factor和reorder均只用一层
            action_mask_with_one_op_layer(new_mask, op_layer, axis_cnt)
            axis_list = stage_feature[axis_cnt:2 * axis_cnt]

        # 对于axis轴为0和1的factor也需要mask
        for axis_index, axis in enumerate(axis_list):
            if axis in [0, 1]:
                new_mask[axis_index] = True
                new_mask[axis_index + axis_cnt] = True

        # at采样都无脑mask掉
        if at_align:
            new_mask[-1] = True

        action_mask.append(new_mask)
    return action_mask


def dump_params_to_file(option: dict) -> None:
    """
    把option导出至文件
    :param option: 推理选项
    """
    output_dir = option.get("output_dir", "")
    params_dict = copy.deepcopy(option)
    params_dict.update(dict(os.environ))
    # 如果output_dir不存在，则需要新建
    if not os.path.exists(output_dir):
        util.create_dir(output_dir)

    with os.fdopen(os.open(os.path.join(output_dir, "params_dict.json"),
                   WRITE_FILE_FLAGS, OPEN_FILE_MODES_640), 'w') as file_handler:
        json.dump(params_dict, file_handler, indent=4, sort_keys=True)


def get_move_prob_value() -> (list, float):
    """
    :return: move_probs and values
    """
    move_prob = np.random.random(SEARCH_N)
    value = np.random.uniform(-1.0, 1.0)
    return move_prob, value


def wrt_op_schedule_infos(res_list: list,
                          option_list: list,
                          flags: object,
                          op_config_list: list = None) -> (list, list):
    """
    modify op_config_list wrt get_op_schedule_infos
    :param res_list: 算子res列表
    :param option_list: 算子推理和配置option列表
    :param flags: FLAGS
    :param op_config_list:
    :return: op_schedule_infos_list, all_op_schedule_infos_list
    """
    op_schedule_infos_list = []
    all_op_schedule_infos_list = []

    flags.load_file_rl = os.path.join(flags.workspace, flags.load_file_rl)
    flags.infer_dir_rl = os.path.join(flags.workspace, flags.infer_dir_rl)
    if not op_config_list:
        op_config_list = [None] * len(res_list)
    all_op_schedule_infos_list, _ = get_op_schedule_infos(res_list, option_list, flags, op_config_list)
    op_schedule_infos_list = [op_info for op_info in all_op_schedule_infos_list if op_info]
    log.info("RL tune info: get op schedule info end.")
    return op_schedule_infos_list, all_op_schedule_infos_list
