#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
from enum import Enum
from tbe.common.platform import platform_info as tbe_platform_info


class SplitStageType(Enum):
    DEFAULT = 0
    SPLIT = 1
    VECTOR = 2

SPLIT_AT_AXIS_OFFSET = {SplitStageType.DEFAULT:0,
                        SplitStageType.SPLIT:-1,
                        SplitStageType.VECTOR:1}

SPLIT_OP_LIST = ["dynamic_rnn"]

CUBE_VECTOR_SPLIT_STAGE = {"dynamic_rnn": "c_l0c"}

CUBE_STAGE_TAG = {"dynamic_rnn": "matmul"}

CUBE_VECTOR_COMMON_SCHEDULE_STAGE = {"dynamic_rnn": "update_h_gm"}

SUB_BLOCK_NUM = 2

NO_DATA_REQ_OP_LIST = ["dynamic_rnn"]

MULTI_SCH_BLOCKDIM = []

RNN_OP_LIST = [
    "dynamic_rnn", "dynamic_gru", "dynamic_gru_v2", "dynamic_augru", "dynamic_lstm_v2",
    "dynamic_gru_v2_hidden", "dynamic_rnn_v2", "dynamic_rnn_v3"
]

TIK_BIND_OP_LIST = RNN_OP_LIST

TIK_SYNC_OP_LIST = RNN_OP_LIST

ENABLE_PRELOAD_OP_LIST = ["dynamic_lstm_v2"]

MAX_CUT_K_INFO = {}

# key:op_type, value:a dict for mcts
TIK_TO_DSL_OP_LIST = {"Transpose": {"split_times": 2, "trs_reorder_times": 2, },
                      }


def get_action_map(op_schedule_info1, op_schedule_info2):
    """

    :param op_schedule_info1:
    :param op_schedule_info2:
    :return:
    """
    if op_schedule_info1.op_name not in TIK_BIND_OP_LIST:
        return {}
    compute_op_list1 = op_schedule_info1.get_compute_op_list()
    compute_op_list2 = op_schedule_info2.get_compute_op_list()

    if len(compute_op_list1) != len(compute_op_list2):
        return {}

    index_map = {}
    for i, compute_op1 in enumerate(compute_op_list1):
        if compute_op1[0].tag == compute_op_list2[i][0].tag or compute_op1[
                0].name == compute_op_list2[i][0].name:
            index_map[compute_op_list2[i][1]] = compute_op1[1]
            continue
        return {}
    return index_map


def tik_dsl_action_adjust(op_schedule_infos, action_tensors):
    """

    :param op_schedule_infos:
    :param action_tensors:
    :return:
    """
    if len(op_schedule_infos) == 1:
        return

    for i in range(1, len(op_schedule_infos)):
        action_map = get_action_map(op_schedule_infos[0], op_schedule_infos[i])
        if not action_map:
            continue
        for j in range(len(action_tensors[i])):
            if j in action_map:
                action_tensors[i][j] = action_tensors[0][action_map[j]]


def get_sub_block_factor():
    return SUB_BLOCK_NUM


def is_support_split(op_name):
    cube_vector_split = tbe_platform_info.get_soc_spec("CUBE_VECTOR_SPLIT")
    cube_vector_split = False
    if cube_vector_split and op_name in SPLIT_OP_LIST:
        return True
    return False
