#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
import os

from schedule_search import log
from schedule_search import util
from schedule_search import soc_cfg
from schedule_search.ts_env import env_util
from schedule_search.ts_env.env_classes import KernelRunArgsInfo
from schedule_search.ts_env.estimator.evb import evb_host
from schedule_search.ts_env.estimator.evb.evb_client import \
    copy_data_to_evb_host
from schedule_search.ts_env.estimator.kernel_runner import ErrorCode
from schedule_search.ts_env.estimator.kernel_runner import EvbRunner
import schedule_search.ts_env.env_consts as env_consts


def build_by_auto_schedule(op_schedule_info,  # pylint: disable=R0914
                           kernel_path):
    """

    :param op_schedule_info:
    :param kernel_path:
    :return:
    """
    kernel_name, unique_id = env_util.gen_kernel_name(op_schedule_info.op_name)
    auto_schedule_py = op_schedule_info.option["auto_schedule_py"]
    if auto_schedule_py:
        kernel_name = auto_schedule_py.split("/")[-1].split(".")[0]
        op_file = auto_schedule_py
    else:
        # 生成文件
        op_file_name = "base_te_%s.py" % kernel_name
        op_file = os.path.join(op_schedule_info.replay_dir, op_file_name)
        env_util.gen_auto_schedule_py(op_schedule_info, op_file, kernel_name)

    cmd = "python3 %s" % op_file
    ret, fail_str = util.run_cmd_comm(cmd)
    # 挪到store_tmp备份
    if not auto_schedule_py:
        util.mv_src_to_dst(op_file, op_schedule_info.store_dir)
        op_file = os.path.join(op_schedule_info.store_dir,
                               os.path.basename(op_file))
    else:
        op_file = None
    if not ret:
        log.warn("can not run base, output: %s", fail_str)
        return False, None, op_file
    kernel_bin_path = os.path.join(soc_cfg.kernel_meta_dir(),
                                   "%s.o" % kernel_name)
    # mv到self.kernel_path
    util.mv_src_to_dst(kernel_bin_path, kernel_path)
    kernel_json_path = kernel_bin_path.replace(".o", ".json")
    dst_kernel_json_path = kernel_path.replace(".o", ".json")
    util.mv_src_to_dst(kernel_json_path, dst_kernel_json_path)
    op_name = op_schedule_info.op_name
    output_cnt = len(op_schedule_info.output_info_list)
    gen_golden = 1 if op_schedule_info.option["auto_schedule_golden"] else 0
    kernel_run_obj = KernelRunArgsInfo(op_name,
                                       output_cnt,
                                       kernel_path,
                                       unique_id,
                                       gen_golden=gen_golden)
    return True, kernel_run_obj, op_file


DEFAULT_SCHEDULE_HEADER = """
import sys
import os
from tbe import tvm
import numpy as np
import pickle

if __name__ == '__main__':
        """


class BaseGoldenGen:
    """
    BaseGoldenGen
    """

    def __init__(self, op_schedule_info):
        self.op_schedule_info = op_schedule_info

    @staticmethod
    def _get_golden_kernel_path():
        return ""

    @staticmethod
    def _build():
        """
        接口函数，子类中实现
        """
        return False

    def build(self):
        """

        :return:
        """
        golden_kernel_path = self._get_golden_kernel_path()
        # 如果配置了base_kernel则是用户传入的，不能删除
        if os.path.exists(golden_kernel_path) \
                and self.op_schedule_info.option.get("base_kernel") is None:
            # 删除重新生成
            os.remove(golden_kernel_path)

        ret = self._build()
        if not ret:
            log.warn("can not build golden kernel for %s.",
                     self.op_schedule_info.shape_list_str)
            return False, golden_kernel_path
        return True, golden_kernel_path

    @staticmethod
    def _run():
        """
        接口函数，子类中实现
        """
        return False, 0

    def run(self):
        """

        :return:
        """
        ret, _ = self.build()
        if not ret:
            return False, 0

        ret, tick = self._run()
        if not ret:
            log.warn("can not run golden kernel for %s.",
                     self.op_schedule_info.shape_list_str)
            return False, tick

        return True, tick


def _read_input(base_size,  # pylint: disable=R0912,R0914
                curr_pos, input_size, input_info):
    tail_add = []
    input_dtype = input_info.dtype
    valid_size = base_size - curr_pos

    dtype_size = util.get_dtype_size(input_dtype)
    if input_size > valid_size:
        sub_data_list = [input_info.name + "_data0"]
        # 当input_size大于文件的大小时，则反复利用该数据填充
        tail_add.append("\n    %s = np.memmap(default_input_data_file_%s," \
                        "dtype=np.%s,mode='r',offset=%s,shape=(%s))" % \
                        (sub_data_list[0], input_dtype, input_dtype, curr_pos,
                         valid_size // dtype_size))
        reserve_size = input_size - valid_size
        index = 1
        while reserve_size != 0:
            if reserve_size > valid_size:
                copy_size = valid_size
            else:
                copy_size = reserve_size
            sub_data_name = f"{input_info.name}_data{str(index)}"
            tail_add.append(("\n    %s = np.memmap(default_input_data_file"
                             "_%s, dtype=np.%s, mode='r', offset=%s, "
                             "shape=(%s))") % (sub_data_name, input_dtype,
                                               input_dtype, curr_pos,
                                               copy_size // dtype_size))
            reserve_size -= copy_size
            index += 1
            sub_data_list.append(sub_data_name)
        concat_str = ",".join(sub_data_list)
        expr_str = "np.concatenate((%s)).reshape(%s)" % (
            concat_str, input_info.shape)
    else:
        # 可以一把读取
        shape_str = []
        for shape_value in input_info.shape:
            shape_str.append(f"{str(shape_value)}, ")
        expr_str = ("np.memmap(default_input_data_file_%s, "
                    "dtype=np.%s, mode='r', offset=%s, shape=(%s))"
                    ) % (input_dtype, input_dtype, curr_pos, ''.join(shape_str))
    return expr_str, ''.join(tail_add)


class DefaultSchGoldenGen(BaseGoldenGen):
    """
    DefaultSchGoldenGen
    """

    def __init__(self, op_schedule_info):
        self.op_schedule_info = None
        BaseGoldenGen.__init__(self, op_schedule_info)
        self.default_input_data_dict = {}
        for i, input_file in enumerate(op_schedule_info.input_file_list):
            input_dtype = op_schedule_info.input_info_list[i].dtype
            self.default_input_data_dict.setdefault(input_dtype, input_file)

        self.kernel_script = env_util.get_golden_kernel_path(op_schedule_info,
                                                             default_sch=True)

    def _get_golden_kernel_path(self):
        return self.kernel_script

    def _need_build_check(self):
        # 输出有了就不用再执行编译了
        if self.op_schedule_info.option.get("golden_output", None):
            return False
        need_build = False
        for output_file in self.op_schedule_info.expect_output_file_list:
            if not os.path.exists(output_file):
                need_build = True
        # 如果output存在，则无需重新生成脚本
        if need_build is False:
            return False
        return True

    def _input_proc(self,  # pylint: disable=R0912,R0914
                    input_data_dict, tail, tvm_base=True):
        data_list = []
        for i, input_info in enumerate(self.op_schedule_info.input_info_list):
            input_dtype = input_info.dtype
            pos_list = input_data_dict[input_dtype]["pos_list"]
            offset_cnt = input_data_dict[input_dtype]["offset_cnt"]
            # 为了避免临界资源，简化处理，如果用户配置了golden_input，
            # 就取input size，否则取默认64MB
            if self.op_schedule_info.option.get("golden_input", []):
                input_base_data_size = self.op_schedule_info.input_size_list[i]
            else:
                input_base_data_size = evb_host.DEFAULT_INPUT_SIZE

            dtype_size = util.get_dtype_size(input_dtype)
            input_size = dtype_size
            for size in input_info.shape:
                input_size *= size
            if not pos_list:
                curr_pos = 0
                pos_list.append((curr_pos, input_size))
            else:
                last_pos, last_size = pos_list[-1]
                if last_pos + last_size + input_size <= input_base_data_size:
                    # 如果文件足够大，则直接从上一次结束的位置开始读取
                    curr_pos = last_pos + last_size
                else:
                    # 否则从头开始，但是为了数据重复，故意偏移128个字节
                    curr_pos = offset_cnt * 128
                    offset_cnt += 1
                    input_data_dict[input_dtype]["offset_cnt"] = offset_cnt
                pos_list.append((curr_pos, input_size))
            input_data_dict[input_dtype]["pos_list"] = pos_list

            expr_str, tail_add = _read_input(
                input_base_data_size, curr_pos, input_size, input_info)

            tail.append(tail_add)
            if tvm_base:
                tail.append("\n    %s_data = tvm.nd.array(%s, ctx)" % (
                    input_info.name, expr_str))
            else:
                tail.append("\n    %s_data = %s" % (input_info.name, expr_str))
            data_list.append(input_info.name + '_data')
        return data_list, tail

    def _build(self):  # pylint: disable=R0912,R0914,R0915
        if not self._need_build_check():
            return True
        # compute_code 为初始compute_code
        argv_code_str = []
        tail = ["""
    tgt = "llvm"
    ctx = tvm.device(tgt, 0)
        """]
        # 获取输入输入的信息
        argv_index = 1

        input_data_dict = {}
        for input_dtype in self.default_input_data_dict:
            if input_dtype in input_data_dict:
                continue
            argv_code_str.append('\n    default_input_data_file_%s = ' \
                                 'sys.argv[%s]' % (input_dtype, str(argv_index)))
            input_data_dict.setdefault(input_dtype, {
                "pos_list": [],
                "offset_cnt": 1
            })
            argv_index += 1

        data_list, tail = self._input_proc(input_data_dict, tail)

        for index, output_info in enumerate(
                self.op_schedule_info.output_info_list):
            argv_code_str.append('\n    %s_data_file = sys.argv[%s]' % (
                output_info.name, str(argv_index + index)))
            data_list.append(output_info.name + '_data')

            # 增加input数据转换
            tail.append('\n    %s_data = tvm.nd.array(np.zeros(%s, dtype="%s"), ' \
                        'ctx)' % (output_info.name, output_info.shape,
                                  output_info.dtype))
        # build模型
        op_name = self.op_schedule_info.op_name
        tail.append('\n    %s = tvm.build(sch, %s, tgt, target_host=tgt, ' \
                    'name="%s")' % (op_name, self.op_schedule_info.tensor_list_str,
                                    op_name))
        # 运行模型
        tail.append('\n    %s(%s)' % (op_name, ','.join(data_list)))
        # 将output数据输出到data文件内
        for output_info in self.op_schedule_info.output_info_list:
            tail.append('\n    %s_arr = %s_data.asnumpy()' % (output_info.name,
                                                              output_info.name))
            tail.append('\n    if np.isnan(np.min(%s_arr)):' % (output_info.name))
            tail.append('\n        print("nan exists in %s")' % (output_info.name))
            tail.append('\n        exit(-1)')
            tail.append('\n    with open(%s_data_file, "wb") as f:' % (
                output_info.name))
            tail.append('\n        f.write(%s_arr)' % output_info.name)

        # 保存脚本
        default_header = DEFAULT_SCHEDULE_HEADER
        code_str = default_header + ''.join(argv_code_str) + '\n'
        code_str += self.op_schedule_info.compute_code + ''.join(tail)
        return util.write_to_file(self.kernel_script, code_str)

    def _run(self):  # pylint: disable=R0914,R0912
        cmd = ['python3 %s' % self.kernel_script]
        # 增加输入文件
        cmd.append(' %s' % " ".join(self.default_input_data_dict.values()))

        # 增加输出文件
        need_run = False
        for output_file in self.op_schedule_info.expect_output_file_list:
            if not os.path.exists(output_file):
                need_run = True
            cmd.append(' %s' % output_file)
        # 本地已经存在golden数据时，就不用再run default schedule了
        if need_run:
            ret, output = util.run_cmd_comm(''.join(cmd), timeout=3600, shell=False)
            if not ret:
                log.warn("can not run default schedule, output: %s.", output)
                return False, None

        # 不做cluster和local区分
        evb_info_list = self.op_schedule_info.option.get("evbs", [])
        updated_host_list = []
        for evb_info in evb_info_list:
            host_ip = evb_info.get("host_ip", "")
            # 如果host已经更新过了，则不需要重复更新
            if host_ip in updated_host_list:
                continue
            data_path = "%s/%s" % (evb_info['EVB_HOST_BASE_DIR'],
                                   evb_host.EVB_HOST_DATA_DIR_NAME)
            if self.op_schedule_info.option["golden_input"]:
                for input_file in self.op_schedule_info.input_file_list:
                    input_file_path = os.path.join(
                        data_path, os.path.basename(input_file))
                    ret = copy_data_to_evb_host(evb_info, input_file,
                                                input_file_path)
                    if not ret:
                        log.warn(
                            "copy default schedule input: %s to evb "
                            "host: %s failed!", input_file, input_file_path)
                        return False, None

            output_data_path = os.path.join(data_path,
                                            self.op_schedule_info.op_name)
            # 拷贝到evb host侧，主要evb local模式下使用，
            # 可以减少evb host对TE环境的依赖
            for output_file in self.op_schedule_info.expect_output_file_list:
                output_file_path = os.path.join(output_data_path,
                                                os.path.basename(output_file))
                ret = copy_data_to_evb_host(evb_info, output_file,
                                            output_file_path)
                if not ret:
                    log.warn(
                        "copy default schedule output: %s to evb host"
                        ": %s failed!", output_file, output_file_path)
                    return False, None

            # 放到已经更新的host列表中
            updated_host_list.append(host_ip)

        return True, None


class TETplGoldenGen(BaseGoldenGen):
    """
    TETplGoldenGen
    """

    def __init__(self, op_schedule_info):
        self.op_schedule_info = None
        BaseGoldenGen.__init__(self, op_schedule_info)
        self.kernel_path = env_util.get_golden_kernel_path(op_schedule_info,
                                                           default_sch=False)
        self.kernel_run_obj = None
        self.base_py = None

    def _get_golden_kernel_path(self):
        return self.kernel_path

    def _build(self):
        # 尝试使用auto schedule
        ret, self.kernel_run_obj, self.base_py = build_by_auto_schedule(
            self.op_schedule_info, self.kernel_path)
        return ret

    def _run(self):  # pylint: disable=R0912
        evb_info = util.get_evb_info(self.op_schedule_info.option)
        if self.op_schedule_info.option.get("auto_schedule", False):
            check_output = env_util.get_check_output_type()
        else:
            check_output = 0
        runner = EvbRunner(self.op_schedule_info,
                           self.kernel_run_obj,
                           print_output=False,
                           check_output=check_output,
                           run_base=True)
        for i in range(3):
            ret, tick, error_code = runner.run(evb_info)
            if ret:
                break
            if not ret:
                if error_code in [
                        ErrorCode.PROFILING_FAIL, ErrorCode.LOCK_TIMEOUT
                ]:
                    log.warn('Can not run base kernel, %d time(s):%s', i + 1,
                             error_code)
                    continue
                log.warn(
                    "Can not run base kernel, kernel_name: %s "
                    "error_code:%s.", self.kernel_run_obj.kernel_name,
                    error_code)
                return False, 0
        if self.base_py:
            # base也加上tick，方便观测
            dst_base_py = os.path.join(
                self.op_schedule_info.store_dir,
                "%s_%s" % (tick, os.path.basename(self.base_py)))
            util.mv_src_to_dst(self.base_py, dst_base_py)
        return ret, tick


class NoBuildGoldenGen(TETplGoldenGen):
    """
    NoBuildGoldenGen
    """

    def __init__(self, op_schedule_info):
        TETplGoldenGen.__init__(self, op_schedule_info)

    def build(self):
        """

        :return:
        """
        op_name = self.op_schedule_info.op_name
        output_cnt = len(self.op_schedule_info.output_info_list)
        self.kernel_run_obj = KernelRunArgsInfo(op_name,
                                                output_cnt,
                                                self.kernel_path,
                                                "",
                                                gen_golden=1)
        return True, None


class TikNpGoldenGen(DefaultSchGoldenGen):
    """
    TikNpGoldenGen
    """

    def __init__(self, op_schedule_info):
        DefaultSchGoldenGen.__init__(self, op_schedule_info)

    def _build(self):  # pylint: disable=R0912,R0914,R0915
        """

        :return:
        """
        if not self._need_build_check():
            return True
        op_name = self.op_schedule_info.op_name
        golden_func = "{}_np".format(op_name)
        argv_code_str = []
        tail = []
        # 获取输入输入的信息
        argv_index = 1

        input_data_dict = {}
        for input_dtype in self.default_input_data_dict:
            if input_dtype in input_data_dict:
                continue
            argv_code_str.append('\n    default_input_data_file_%s = ' \
                                 'sys.argv[%s]' % (input_dtype, str(argv_index)))
            input_data_dict.setdefault(input_dtype, {
                "pos_list": [],
                "offset_cnt": 1
            })
            argv_index += 1

        data_list, tail = self._input_proc(input_data_dict,
                                           tail,
                                           tvm_base=False)

        for index, output_info in enumerate(
                self.op_schedule_info.output_info_list):
            argv_code_str.append('\n    %s_data_file = sys.argv[%s]' % (
                output_info.name, str(argv_index + index)))

        param_list = "[[%s]] + %s" % (", ".join(
            data_list), list(self.op_schedule_info.option.get("inputs", [])))
        # 运行golden函数
        tail.append('\n    output_list = %s(*(%s))' % (golden_func, param_list))
        # 将output数据输出到data文件内
        for i, output_info in enumerate(
                self.op_schedule_info.output_info_list):
            tail.append('\n    %s_data = output_list[%s]' % (output_info.name, i))
            tail.append('\n    if np.isnan(np.min(%s_data)):' % (output_info.name))
            tail.append('\n        print("nan exists in %s")' % (output_info.name))
            tail.append('%s\n        exit(-1)' % tail)
            tail.append('\n    with open(%s_data_file, "wb") as f:' % (
                output_info.name))
            tail.append('\n        f.write(%s_data)' % output_info.name)

        # 保存脚本
        default_header = env_consts.TIK_DSL_GOLDEN_HEADER.format(
            op_name=op_name,
            opp_path=self.op_schedule_info.option.get("opp_path", ""))
        code_str = default_header + ''.join(argv_code_str) + '\n' + ''.join(tail)
        return util.write_to_file(self.kernel_script, code_str)
