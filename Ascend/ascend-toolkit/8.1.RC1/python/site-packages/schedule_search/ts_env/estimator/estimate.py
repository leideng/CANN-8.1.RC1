#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
import copy
import json
import os
import sys
from io import StringIO
from contextlib import redirect_stdout
from contextlib import redirect_stderr
import inspect

import numpy as np

from tbe import tvm
from tbe.common.rl_bank import bank_manager
import tbe
from tbe.common.buildcfg import build_config
from schedule_search import log
from schedule_search import comm
from schedule_search import soc_cfg
from schedule_search.timer import timer
from schedule_search.ts_env import env_util
from schedule_search.ts_env.cache_manager import CACHE_MODE_NONE
from schedule_search.ts_env.cache_manager import CACHE_SCHEDULE_TICK
from schedule_search.ts_env.cache_manager import ScheduleCacheManager
from schedule_search.ts_env.env_classes import KernelRunArgsInfo
from schedule_search.ts_env.env_classes import LocalLock
from schedule_search.ts_env.env_classes import OomError
from schedule_search.ts_env.env_consts import MODE_RUNTIME
from schedule_search.ts_env.estimator.evb import evb_host
from schedule_search.ts_env.estimator.golden_data import DefaultSchGoldenGen
from schedule_search.ts_env.estimator.golden_data import NoBuildGoldenGen
from schedule_search.ts_env.estimator.golden_data import TikNpGoldenGen
from schedule_search.ts_env.estimator.golden_data import TETplGoldenGen
from schedule_search.ts_env.estimator.kernel_runner import ErrorCode
from schedule_search.ts_env.estimator.kernel_runner import EvbRunner
from schedule_search.ts_env.estimator.kernel_runner import store_tmp_proc
from schedule_search.ts_env.estimator.om_runner import OMRunner

from schedule_search.ts_env.tensor_to_code import generator as \
    generate_te_schedule
from schedule_search.util import func_timeout
from schedule_search.util import get_evb_info
from schedule_search.util import run_cmd_comm
from schedule_search.ts_env.env_classes import SchInfo
from schedule_search.ts_env.env_classes import KernelInfo
from tbe.common.buildcfg import dynamic_build_config_dict


def re_get_base_tick(op_schedule_info: object, communicate_option: dict) -> tuple:
    """
    :param op_schedule_info:
    :param communicate_option:
    :return:
    """
    runbase_args_dict = {"re_runbase": True,
                         "rerun_task_q": communicate_option.get("tune_task_d", None),
                         "rerun_res_d": communicate_option.get("tune_result_d", None),
                         "rerun_release_q": communicate_option.get("release_tune_q", None)}
    runner = OMRunner(op_schedule_info,
                      None,
                      run_base=True,
                      datacmp_args_dict=runbase_args_dict)
    _, base_tick, err_code = runner.run()
    return base_tick, err_code


def re_get_tick_om(op_schedule_info: object, cheque_list: list, communicate_option: dict) -> (bool, list, list):
    """
    re om_runner with datacmp
    :param op_schedule_info:
    :param cheque_list:
    :param communicate_option:
    :return: ret, om_ticks, err_codes
    """
    sch_info = SchInfo(op_schedule_info.schedule_obj, None, None, None, cheque_list)
    kernel_info = KernelInfo(None, None, sch_info)
    datacmp_args_dict = {"need_datacmp": True,
                         "datacmp_task_q": communicate_option.get("datacmp_task_q", None),
                         "datacmp_res_d": communicate_option.get("datacmp_res_d", None)}
    runner = OMRunner(op_schedule_info, kernel_info, run_base=False, datacmp_args_dict=datacmp_args_dict)
    ret, om_ticks, err_codes = runner.run()
    return ret, om_ticks, err_codes


def get_oom_type(  # pylint: disable=R0911,R0912
        fail_str,
        default_type=ErrorCode.BUILD_FAIL):
    """

    :param fail_str:
    :param default_type:
    :return:
    """
    if 'exceed bound of memory' in fail_str:
        if 'local.UB' in fail_str:
            return OomError.UB_BUFF
        if 'local.L1' in fail_str:
            return OomError.L1_BUFF
        if 'local.L0C' in fail_str:
            return OomError.L0C
        if 'local.L0A' in fail_str or 'local.L0B' in fail_str:
            return OomError.L0AB

    for curr_fail_str in [
            'Allocation exceed bound of memory tag:local.L0',
            'm < Arch: :Matrix::MATRIX_MAX_M',
            'm < Arch::Matrix::MATRIX_MAX_M',
            'n < Arch: :Matrix::MATRIX_MAX_N',
            'n < Arch::Matrix::MATRIX_MAX_N',
            'k < Arch: :Matrix::MATRIX_MAX_K', 'k < Arch::Matrix::MATRIX_MAX_K'
    ]:
        if curr_fail_str in fail_str:
            return OomError.L0AB

    if 'Segmentation fault (core dumped)' in fail_str:
        return OomError.SEGMENT

    if ' overflow' in fail_str:
        return OomError.OVERFLOW

    if 'the start address of operands must be 32 byte aligned' in fail_str or \
            'vector shape is not 32B align' in fail_str:
        return ErrorCode.BUILD_NOALIGN
    return default_type


def get_base_tick(op_schedule_info, op_data_path):  # pylint: disable=R0912
    """

    :param op_schedule_info:
    :param op_data_path:
    :return:
    """

    if op_schedule_info.option.get("run_by_om", False):
        runner = OMRunner(op_schedule_info,
                          None,
                          run_base=True)
        _, base_tick, _ = runner.run()
    else:
        no_base_tune = op_schedule_info.option.get("no_base_tune", False)
        if no_base_tune:
            return sys.maxsize
        base_kernel = op_schedule_info.option.get("base_kernel", None)
        if base_kernel:
            golden_obj = NoBuildGoldenGen(op_schedule_info)
        else:
            if op_schedule_info.option.get("base_ignore", False):
                return 0
            golden_obj = TETplGoldenGen(op_schedule_info)
        _, base_tick = golden_obj.run()

    #  读取历史base_tick文件
    base_tick_file = os.path.join(op_data_path, "base_tick.json")
    lock_file = os.path.join(op_schedule_info.lock_dir, "base_tick")
    base_tick_dict = {}
    local_lock = LocalLock(lock_file)
    local_lock.lock()
    if os.path.exists(base_tick_file):
        try:
            with open(base_tick_file, 'r') as file_handler:
                base_tick_dict = json.load(file_handler)
        except ValueError as e:
            log.warn("base_tick.json can not be read. %s", e)
        finally:
            file_handler.close()
    base_tick_dict[op_schedule_info.shape_list_str] = base_tick
    # 将base tick数据dump到本地
    fd = os.open(base_tick_file, os.O_RDWR | os.O_CREAT, 0o640)
    with os.fdopen(fd, 'w') as file_handler:
        json.dump(base_tick_dict, file_handler)
        file_handler.flush()
    local_lock.unlock()

    return base_tick


def golden_proc(op_schedule_info):  # pylint: disable=R0912,R0914
    """

    :param op_schedule_info:
    :return:
    """

    # 获取锁
    lock_file = os.path.join(op_schedule_info.lock_dir,
                             op_schedule_info.op_md5)
    local_lock = LocalLock(lock_file)
    local_lock.lock()

    op_data_path = os.path.join(op_schedule_info.replay_dir, "data",
                                op_schedule_info.op_name)
    if not os.path.exists(op_data_path):
        run_cmd_comm("mkdir -p %s" % op_data_path)

    no_base_tune = op_schedule_info.option.get("no_base_tune", False)

    if not op_schedule_info.option["auto_schedule_golden"] or no_base_tune:
        # 暂时只支持evb的场景，camodel后续支持
        if op_schedule_info.option.get("tik_np_golden", False):
            golden_gen_obj = TikNpGoldenGen(op_schedule_info)
        else:
            golden_gen_obj = DefaultSchGoldenGen(op_schedule_info)
        ret, _ = golden_gen_obj.run()
        if not ret:
            log.warn("%s can not build, try to use auto sch golden",
                     op_schedule_info.shape_list_str)
            # 失败则尝试npu生成golden
            op_schedule_info.option["auto_schedule_golden"] = True
            for i, golden_file in enumerate(
                    op_schedule_info.expect_output_file_list):
                op_schedule_info.expect_output_file_list[i] = os.path.join(
                    os.path.dirname(golden_file),
                    "auto_sch_%s" % os.path.basename(golden_file))

    # 尝试拿一把base_tick
    base_tick = get_base_tick(op_schedule_info, op_data_path)

    local_lock.unlock()
    return True, base_tick


def actions_to_schedule(  # pylint: disable=R0913,R0914
        op_schedule_info,
        action_tensors,
        proc_index_start=31,
        proc_index_end=None,
        excluded_index=None,
        sample_actions=None,
        cache_name=None):
    """
    由action_tensors经过t2c的runtime模式获取schedule对象，
    同一个op_schedule_info可重入该函数
    """
    # 1、优先从本地cache里面拿
    cache_mode = op_schedule_info.option.get('cache_mode', CACHE_MODE_NONE)
    schedule_cache_obj = ScheduleCacheManager(op_schedule_info.feature_tensor,
                                              action_tensors,
                                              cache_name=cache_name,
                                              mode=cache_mode)
    cache_content = schedule_cache_obj.read_cache()
    if cache_content:
        sch, schedule_code, cleaned_actions = cache_content
        log.dbg("get schedule from local cache")
        # cache中需要存储cheque_list
        return SchInfo(sch, schedule_code, cleaned_actions, {}, [])

    # 2、MODE_RUNTIME获取schedule 对象，由于一个op_schedule_info会处理多次，
    # 需要重置一些变量
    actions = copy.deepcopy(action_tensors)

    # 重置schedule_obj
    if op_schedule_info.ori_schedule_obj is None:
        raise RuntimeError("ori_schedule_obj is None")
    old_schedule_obj = op_schedule_info.schedule_obj
    op_schedule_info.schedule_obj = copy.deepcopy(
        op_schedule_info.ori_schedule_obj)

    # atomic已经跑过t2c，需要把reduce_atomic_dict清空，
    # stages_info删除rfactor、reduce_write
    old_stages_info = op_schedule_info.stages_info
    old_reduce_atomic_dict = op_schedule_info.reduce_atomic_dict
    if op_schedule_info.tiling_case > 0:
        log.dbg(
            'actions: %s, stages_info: %s, reduce_atomic_dict: %s, '
            'stage_num: %s', len(action_tensors), op_schedule_info.stages_info,
            op_schedule_info.reduce_atomic_dict,
            len(op_schedule_info.schedule_obj.stages))
        rfactor_stage_index = op_schedule_info.reduce_atomic_dict.get(
            "rfactor_stage_index",
            len(op_schedule_info.schedule_obj.stages) + 2 - 3)
        reduce_write_stage_index = op_schedule_info.reduce_atomic_dict.get(
            "reduce_write_stage_index",
            len(op_schedule_info.schedule_obj.stages) + 2 - 2)
        if (len(actions) - 2) == len(op_schedule_info.schedule_obj.stages):
            actions = np.delete(
                actions, [rfactor_stage_index, reduce_write_stage_index],
                axis=0).tolist()
        if (len(op_schedule_info.stages_info) - 2) \
                == len(op_schedule_info.schedule_obj.stages):
            op_schedule_info.stages_info = copy.deepcopy(old_stages_info)
            op_schedule_info.stages_info = np.delete(
                op_schedule_info.stages_info,
                [rfactor_stage_index, reduce_write_stage_index],
                axis=0).tolist()
        op_schedule_info.reduce_atomic_dict = {}

    sch_info = generate_te_schedule.proc(op_schedule_info,
                                         actions,
                                         mode=MODE_RUNTIME,
                                         sample_actions=sample_actions,
                                         proc_index_start=proc_index_start,
                                         proc_index_end=proc_index_end,
                                         excluded_index=excluded_index)
    schedule_code = "%s    # check_output: %s\n" % (
        sch_info.code, op_schedule_info.check_output)

    sch = op_schedule_info.schedule_obj
    cleaned_actions = sch_info.cleaned_actions
    # 还原重置的变量
    op_schedule_info.schedule_obj = old_schedule_obj
    op_schedule_info.stages_info = old_stages_info
    op_schedule_info.reduce_atomic_dict = old_reduce_atomic_dict

    # 更新一下本地cache
    schedule_cache_obj.update_cache([sch, schedule_code, cleaned_actions])

    return SchInfo(sch, schedule_code, cleaned_actions,
                   sch_info.retry_t2c_rules, sch_info.cheque_list)


def get_tensors_by_tensors_str(tensor_list_str, all_tensors, all_tensor_names):
    """
    由op_schedule_info中记录的各种tensor_list_str，获取sch中实际的tensor
    """
    tensor_list = []

    tensor_list_str = tensor_list_str.lstrip('[').rstrip(']').replace(' ', '')
    if not tensor_list_str:
        return tensor_list
    tensor_name_list = tensor_list_str.split(',')
    for tensor_name in tensor_name_list:
        if tensor_name not in set(all_tensor_names):
            raise RuntimeError('cannot find tensor name %s in sch, %s' %
                               (tensor_name, all_tensor_names))
        tensor_list.append(all_tensors[all_tensor_names.index(tensor_name)])
    log.dbg("%s --> %s", tensor_name_list, tensor_list)
    return tensor_list


def get_all_tensors(sch, special_tensor_dict):  # pylint: disable=R0912
    """
    获取所有的cce_special、config需要的tensor
    """
    # 除了tuple_reduce_sum，这里认为多输出都会添加虚拟输出，所以只需要取sch.outputs[0]
    all_tensors = []
    for idx in range(sch.outputs[0].num_outputs):
        all_tensors.append(sch.outputs[0].output(idx))
    tensors = all_tensors[:]
    while tensors:
        new_tensors = []
        for tensor in tensors:
            if isinstance(tensor.op, tvm.PlaceholderOp):
                continue
            new_tensors.extend(tensor.op.input_tensors)
        new_tensors = list(set(new_tensors) - set(all_tensors))
        all_tensors.extend(new_tensors)
        tensors = new_tensors
    all_tensors = list(set(all_tensors))
    all_tensor_names = []
    for tensor in all_tensors:
        if tensor.name.startswith("%s.v" % tensor.op.name):
            tensor_idx = tensor.name.split('.v')[-1]
            all_tensor_names.append('%s_v%s' % (tensor.op.name, tensor_idx))
            continue
        all_tensor_names.append(tensor.op.name)
    for tensor_name, tensor in special_tensor_dict.items():
        all_tensor_names.append(tensor_name)
        all_tensors.append(tensor)
    log.dbg("all_tensors: %s, all_tensor names: %s", all_tensors,
            all_tensor_names)
    return all_tensors, all_tensor_names


def get_build_config(sch,
                     op_schedule_info,
                     print_output=False,
                     kernel_name=""):
    """
    生成cce_build_code的config，sch.cce_special挪到T2C里面做了
    """
    all_tensors, all_tensor_names = get_all_tensors(
        sch, op_schedule_info.special_tensor_dict)
    tensor_list_str = op_schedule_info.tensor_list_str

    # config
    config = {}
    config["print_ir"] = print_output
    config["need_build"] = True
    if not kernel_name:
        config["name"], config["unique_id"] = env_util.gen_kernel_name(
            op_schedule_info.op_name)
    else:
        config["name"] = kernel_name
    config["tensor_list"] = get_tensors_by_tensors_str(tensor_list_str,
                                                       all_tensors,
                                                       all_tensor_names)
    config["bool_storage_as_1bit"] = False
    config["kernel_meta_parent_dir"] = soc_cfg.kernel_meta_parent_dir()
    log.dbg("tensor list str: %s, config: %s", tensor_list_str, config)

    return config


def cce_build_code(sch, op_schedule_info, config, timeout=None):
    """
    将schedule对象build生成.o，注意有些算子lower会卡死，因此需要加超时保护
    """
    f_out = StringIO()
    f_err = StringIO()
    with redirect_stderr(f_err), redirect_stdout(f_out):

        if op_schedule_info.option.get('op_mode', '') in ['static']:
            if isinstance(timeout, int) and timeout > 0:
                func_timeout(tvm.build,
                             args=(
                                 sch,
                                 config["tensor_list"],
                                 "cce",
                                 None,
                                 config["name"]
                             ),
                             timeout=timeout,
                             context=dynamic_build_config_dict)
            return

        cfg_dict = op_schedule_info.option.get(
            'op_config', {}).get('build_config', {})
        if isinstance(timeout, int) and timeout > 0:
            func_timeout(tbe.dsl.build,
                         args=(
                             sch,
                             config,
                         ),
                         timeout=timeout,
                         context=cfg_dict)
        else:
            if cfg_dict:
                with build_config(**cfg_dict):
                    tbe.dsl.build(sch, config)
            else:
                tbe.dsl.build(sch, config)


def get_schedule_code(op_schedule_info, sch_info):
    """

    :param sch_info:
    :return:
    """
    if not isinstance(sch_info, list):
        return sch_info.code

    schedule_code = ""
    cheque_lists = []
    for i, single_sch_info in enumerate(sch_info):
        schedule_code += "\ndef dsl_func_{}():".format(i)
        schedule_code += "    {}\n".format(op_schedule_info[i].compute_code)
        schedule_code += "\n    # cheque_list: {}\n".format(
            single_sch_info.cheque_list)
        schedule_code += "    {}\n    return sch\n".format(
            single_sch_info.code)
        cheque_lists.append(single_sch_info.cheque_list)
    schedule_code += "\nCHEQUE_LISTS = {}\n\n".format(cheque_lists)
    return schedule_code


def tik_op_build(op_schedule_info, kernel_name):
    """
    tik算子编译
    """
    opp_path = op_schedule_info.option.get("opp_path", "")
    if os.path.exists(opp_path) and opp_path not in sys.path:
        sys.path.append(opp_path)
    op_name = op_schedule_info.op_name
    output_cnt = len(op_schedule_info.output_info_list)
    # tik算子编译，需要走算子入口进入
    bank_manager.clear_res_index()
    op_impl_module = __import__('impl.' + op_name, fromlist=['1'])
    op_func = getattr(op_impl_module, op_name)
    # 配置的入参长度超过了函数入参格式，截断处理
    func_args_len = len(inspect.signature(op_func).parameters)
    op_args = list(op_schedule_info.option["inputs"])
    if len(op_args) >= func_args_len:
        op_args = op_args[:func_args_len - 1]
    op_args.append(kernel_name)
    log.dbg("RL tune info: tik op build, op_func: %s, op_args: %s.", op_func, op_args)
    op_func(*op_args)
    bank_manager.clear_cheque_list()
    return output_cnt


def offline_build(sch_info, op_schedule_info, kernel_name):
    '''
    执行py文件的编译方式
    '''
    op_file = os.path.join(op_schedule_info.store_dir, "tmp",
                           "%s.py" % (kernel_name))
    schedule_code = get_schedule_code(op_schedule_info, sch_info)
    env_util.gen_schedule_py(op_schedule_info, schedule_code, kernel_name,
                             op_file)
    cmd = "python3 %s" % (op_file)
    timeout = op_schedule_info.option.get('cce_build_timeout', 60)
    ret, fail_str = run_cmd_comm(cmd, timeout=timeout, shell=False)
    os.remove(op_file)
    return ret, fail_str


def build_fail_proc(err_str, kernel_bin_path, op_schedule_info, sch_info,
                    kernel_name):
    """
    编译错误的后处理逻辑
    """
    error_code = get_oom_type(err_str)
    # 将指定的build错误放在指定的文件目录下
    if "timeout" in err_str:
        # 超时处理
        error_code = ErrorCode.BUILD_TIMEOUT
        error_dir = ErrorCode.BUILD_TIMEOUT
    elif error_code in OomError.ALL:
        error_dir = ErrorCode.BUILD_OOM
    elif error_code == ErrorCode.BUILD_NOALIGN:
        error_dir = ErrorCode.BUILD_NOALIGN
    else:
        error_dir = ErrorCode.BUILD_FAIL
    schedule_code = get_schedule_code(op_schedule_info, sch_info)
    if isinstance(op_schedule_info, list):
        single_op_schedule = op_schedule_info[0]
    else:
        single_op_schedule = op_schedule_info

    if not op_schedule_info.option.get("not_store_sch", False):
        py_file = store_tmp_proc(single_op_schedule, schedule_code, error_dir,
                                kernel_name, True)
        if error_dir == ErrorCode.BUILD_FAIL:
            log.dbg("RL tune info: generate py file %s.", py_file)
    # 删除所有相关文件
    if os.path.exists(kernel_bin_path):
        remove_dir, remove_file = os.path.split(
            os.path.splitext(kernel_bin_path)[0])
        run_cmd_comm("rm -rf %s" %
                     os.path.join(remove_dir, "*%s*" % remove_file))
    return error_code


def build_kernel(  # pylint: disable=R0912,R0914
        sch_info,
        config,
        op_schedule_info):
    """
    将schedule对象build生成.o，并捕获错误信息
    """
    kernel_name = config.get("name")
    unique_id = config.get("unique_id")
    # kernel_bin_path可以不放在os.getcwd()目录下，但是需要设置run cmd的cwd
    kernel_bin_path = os.path.join(soc_cfg.kernel_meta_dir(), "%s.o" % kernel_name)

    err_print = os.getenv('CONTEXT_MODELCOMPILING')
    os.environ['CONTEXT_MODELCOMPILING'] = 'TRUE'

    # 卷积深度融合场景下，runtime reused_by不生效，此处规避不用runtime方式生成.o
    if not isinstance(op_schedule_info, list) and \
            op_schedule_info.c_op in comm.MAD_OP_ID_MAP.values():
        op_name = op_schedule_info.op_name
        output_cnt = len(op_schedule_info.output_info_list)
        ret, fail_str = offline_build(sch_info, op_schedule_info, kernel_name)
        if not ret:
            log.dbg("%s build failed, output: %s", kernel_name, fail_str)
            error_code = build_fail_proc(fail_str, kernel_bin_path,
                                         op_schedule_info, sch_info,
                                         kernel_name)
            if err_print:
                os.environ['CONTEXT_MODELCOMPILING'] = err_print
            return error_code, None

        kernel_run_obj = KernelRunArgsInfo(op_name, output_cnt,
                                           kernel_bin_path, unique_id)
        if err_print:
            os.environ['CONTEXT_MODELCOMPILING'] = err_print
        return ErrorCode.BUILD_SUCC_, kernel_run_obj

    try:
        # 1、build没问题
        if isinstance(op_schedule_info, list):
            single_op_schedule = op_schedule_info[0]
            op_name = single_op_schedule.op_name
            output_cnt = tik_op_build(single_op_schedule, kernel_name)
        else:
            op_name = op_schedule_info.op_name
            output_cnt = len(op_schedule_info.output_info_list)
            cce_build_code(sch_info.sch,
                           op_schedule_info,
                           config,
                           timeout=op_schedule_info.option.get(
                               'cce_build_timeout', 60))

        kernel_run_obj = KernelRunArgsInfo(op_name, output_cnt,
                                           kernel_bin_path, unique_id)
        if err_print:
            os.environ['CONTEXT_MODELCOMPILING'] = err_print
        log.dbg("RL tune info: %s build kernel success.", op_name)
        return ErrorCode.BUILD_SUCC_, kernel_run_obj
    except Exception as exception:  # pylint: disable=broad-except
        # 2、build有问题
        log.dbg("RL exception occur: %s build_kernel failed, error msg: %s.", op_name, repr(exception))
        error_code = build_fail_proc(str(exception), kernel_bin_path,
                                     op_schedule_info, sch_info, kernel_name)
        if err_print:
            os.environ['CONTEXT_MODELCOMPILING'] = err_print
        return error_code, None


def actions_to_kernel_bin(action_tensors,
                          op_schedule_info,
                          sample_actions=None,
                          print_output=False):
    """
    输入的action_tensors经过t2c生成schedule对象，然后build生成.o，返回.o的路径
    """
    # tik op
    if isinstance(op_schedule_info, list):
        sch_info_list = []
        for i, op_schedule in enumerate(op_schedule_info):
            sch_info = actions_to_schedule(op_schedule,
                                           action_tensors[i],
                                           proc_index_end=110,
                                           sample_actions=sample_actions,
                                           cache_name=CACHE_SCHEDULE_TICK)
            sch_info_list.append(sch_info)
        op_name = op_schedule_info[0].op_name
        config = {}
        config["name"], config["unique_id"] = env_util.gen_kernel_name(op_name)
        if op_schedule_info[0].option.get("run_by_om", False):
            log.info("RL tune info: tik op and run_by_om do actions_to_kernel_bin.")
            kernel_info_list = []
            single_op_schedule = op_schedule_info[0]
            output_cnt = len(single_op_schedule.output_info_list)
            kernel_run_obj = KernelRunArgsInfo(op_name, output_cnt, "invalid_kernel_bin_path", config.get("name"))
            for sch_info in sch_info_list:
                kernel_info_list.append(KernelInfo(ErrorCode.BUILD_SUCC_, kernel_run_obj, sch_info))
            return kernel_info_list

        log.info("RL tune info: tik op do build_kernel.")
        bank_manager.clear_cheque_list()
        for sch_info in sch_info_list:
            bank_manager.set_cheque_list(sch_info.cheque_list)
        error_code, kernel_run_obj = build_kernel(sch_info_list, config, op_schedule_info)
        kernel_info_list = []
        for sch_info in sch_info_list:
            kernel_info_list.append(KernelInfo(error_code, kernel_run_obj, sch_info))
        return kernel_info_list

    # 1、获取schedule对象
    sch_info = actions_to_schedule(op_schedule_info,
                                   action_tensors,
                                   sample_actions=sample_actions,
                                   cache_name=CACHE_SCHEDULE_TICK)
    log.dbg("actions to schedule end.")

    # 2、获取cce_build_code的config
    config = get_build_config(sch_info.sch, op_schedule_info, print_output)
    log.dbg("get build config end, config: %s.", config)

    # 3、build生成.o，注意有些算子lower会卡死，因此需要加超时保护
    error_code, kernel_run_obj = build_kernel(sch_info, config,
                                              op_schedule_info)
    log.dbg("build_kernel end, error_code: %s.", error_code)

    return KernelInfo(error_code, kernel_run_obj, sch_info)


@timer('evb_run')
def proc(op_schedule_info,  # pylint: disable=R0914,R0912
         kernel_info,
         process_share_infos,
         store_tmp_sch=True,
         print_output=False):
    """

    :param op_schedule_info:
    :param kernel_info:
    :param store_tmp_sch:
    :param print_output:
    :return:
    """
    tick = 0
    if isinstance(op_schedule_info, list):
        single_op_schedule = op_schedule_info[0]
        single_kernel_info = kernel_info[0]
    else:
        single_op_schedule = op_schedule_info
        single_kernel_info = kernel_info

    kernel_run_obj = single_kernel_info.kernel_run_obj

    if single_op_schedule.option.get("run_by_om", False):
        runner = OMRunner(op_schedule_info,
                          kernel_info,
                          process_share_infos,
                          run_base=False)
        ret, tick, err_code = runner.run()
        log.dbg("RL tune info: evb_run success, kernel_name: %s, tick: %s, err_code: %s.",
                kernel_run_obj.kernel_name, tick, err_code)
        return err_code, tick

    if isinstance(kernel_info, list):
        sch_info = [x.sch_info for x in kernel_info]
    else:
        sch_info = kernel_info.sch_info
    schedule_code = get_schedule_code(op_schedule_info, sch_info)
    evb_info = get_evb_info(single_op_schedule.option)
    runner = EvbRunner(single_op_schedule,
                       kernel_run_obj,
                       schedule_code,
                       debug=single_op_schedule.option.get("debug", False),
                       store_tmp_sch=store_tmp_sch,
                       print_output=print_output)
    for i in range(3):
        ret, tick, err_code = runner.run(evb_info)
        if err_code in [ErrorCode.PROFILING_FAIL]:
            log.warn('Can not run on device, %d time(s).', i + 1)
            continue
        break

    # 如果不是Test或Debug模式，就删除掉Kernel文件，防止堆积，占用空间
    if os.path.exists(kernel_run_obj.kernel_bin_path):
        remove_dir, remove_file = os.path.split(
            os.path.splitext(kernel_run_obj.kernel_bin_path)[0])
        # 不仅.o，删除所有相关文件
        run_cmd_comm("rm -rf %s" %
                     os.path.join(remove_dir, "*%s*" % remove_file))
    if not ret:
        return err_code, tick

    log.dbg("replay.do, run kernel succ, unique_id: %s, tick: %d",
            kernel_run_obj.kernel_name, tick)
    return err_code, tick
