#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
from schedule_search import log
from schedule_search import comm
from schedule_search.ts_env.code_to_tensor.at_info import AtInfo
from schedule_search.ts_env.code_to_tensor.consumer_info import ConsumerInfo
import schedule_search.ts_env.tensor_to_code.t2c_util as t2c_util
from tbe import tvm


def normal_mad_op_proc(stage_tag, sub_stage_info):
    '''
    常规mad特殊节点的判断逻辑
    '''
    spec_node_flag = False
    sub_stage_tag = sub_stage_info.get('tag')
    sub_stage_types = sub_stage_info.get('type', [])
    # gemm的at比较特殊：tensor_a_l1、tensor_b_l1 at 到 tensor_c_gm
    if stage_tag in ['out_to_l1', "set_fmatrix"]:
        if 'leaf' in sub_stage_types:
            spec_node_flag = True
        return True, spec_node_flag

    # gemm的at比较特殊：tensor_a_l0a、tensor_b_l0b at 到 mad stage
    if stage_tag in ['l1_to_l0', "im2col"]:
        if sub_stage_tag in comm.MAD_TAG_LIST:
            spec_node_flag = True
        return True, spec_node_flag

    return False, spec_node_flag


def l1fuse_mad_op_proc(stage, stage_tag, sub_stage_info, redundancy_tensors):
    '''
    l1深度融合mad特殊节点的判断逻辑
    '''
    spec_node_flag = False
    sub_stage_tag = sub_stage_info.get('tag')
    sub_stage_types = sub_stage_info.get('type', [])

    # gemm的at比较特殊：tensor_a_l0a、tensor_b_l0b at 到 mad stage
    if stage_tag in ['l1_to_l0', "im2col"]:
        if sub_stage_tag in comm.MAD_TAG_LIST:
            spec_node_flag = True
        return True, spec_node_flag

    if stage.op.name in redundancy_tensors:
        if 'leaf' in sub_stage_types:
            spec_node_flag = True
        return True, spec_node_flag

    if 'leaf' in sub_stage_types or 'l1fuse_leaf' in sub_stage_types:
        return True, True

    return False, spec_node_flag


def mad_op_spec_node_proc(stage, stage_tag, sub_stage_info, c_op,
                          redundancy_tensors):
    '''
    涉及mad的算子的节点处理
    '''
    spec_node_flag = False
    if c_op in comm.MAD_OP_ID_MAP.keys():
        return normal_mad_op_proc(stage_tag, sub_stage_info)
    if c_op in comm.MAD_OP_ID_MAP.values():
        return l1fuse_mad_op_proc(stage, stage_tag, sub_stage_info,
                                  redundancy_tensors)

    return False, spec_node_flag


def is_spec_node(sub_stage_info, stage, stage_info, c_op, redundancy_tensors):  # pylint: disable=R0912
    """
    :param sub_stage_info:
    :param stage_info:
    :param c_op:
    :return:
    """
    stage_tag = stage_info.get('tag')
    sub_stage_tag = sub_stage_info.get('tag')
    sub_stage_types = sub_stage_info.get('type', [])

    spec_node_flag = False

    match_flag, spec_node_flag = mad_op_spec_node_proc(stage, stage_tag,
                                                       sub_stage_info, c_op,
                                                       redundancy_tensors)
    if match_flag:
        return spec_node_flag

    # 其它的只有leaf和reduce stage
    if 'leaf' in sub_stage_types:
        spec_node_flag = True
        return spec_node_flag

    if not sub_stage_tag:
        log.dbg('sub_stage_tag is blank!')
        return spec_node_flag

    spec_patterns = ['reduce']
    for pattern in spec_patterns:
        if pattern in sub_stage_tag:
            log.dbg('spec node: %s', sub_stage_tag)
            spec_node_flag = True
            break

    return spec_node_flag


def get_redundancy_tensors(schedule_obj, c_op):
    '''
    获取可能存在冗余搬移的tensor, 只对融合生效
    '''
    redundancy_tensors = []
    if c_op not in comm.MAD_OP_ID_MAP.values():
        return redundancy_tensors

    for stage in schedule_obj.stages:
        if stage.op.tag not in t2c_util.QUANT_CAST_TAGS:
            continue
        for input_tensor in stage.op.input_tensors:
            if isinstance(input_tensor.op, tvm.PlaceholderOp):
                redundancy_tensors.append(input_tensor.op.name)
    return redundancy_tensors


def get_at_info(op_schedule_info):  # pylint: disable=R0914,R0912,R0915
    """
    生成workspace信息，用于controller采样决策是否是workspace
    """
    def matmul_candidate_check(c_op, candidate, spec_nodes, subtree):
        if c_op not in comm.MAD_OP_ID_LIST:
            return False

        if candidate not in subtree:
            return False

        if candidate in spec_nodes:
            return True

        return False

    stages_info = op_schedule_info.stages_info
    c_op = op_schedule_info.c_op
    schedule_obj = op_schedule_info.schedule_obj
    redundancy_tensors = get_redundancy_tensors(schedule_obj, c_op)

    # 1, 根据sch获取所有stage的依赖关系图, depends
    _, dict_depended = comm.get_depends(schedule_obj)
    # 2, 遍历所有节点
    for i in range(len(stages_info) - 1, -1, -1):  # pylint:disable=R0914,R0101
        stage_info = stages_info[i]
        stage = schedule_obj.stages[i]
        # 如果分叉节点有workspace信息，说明已经处理过, 跳到下一个节点
        if stage_info.get("at_info"):
            log.dbg("skip handled forked node, index:%s", i)
            continue
        # 初始化at info
        at_info = AtInfo(i)
        stage_info["at_info"] = at_info
        # 最后一个stage的at target设为自己
        if i == len(stages_info) - 1:
            consumer_info = ConsumerInfo(i)
            consumer_info.set_at_candidates([i])
            consumer_info.set_sampled_target(i)
            at_info.add_consumer(consumer_info)
            continue
        # 可以at的特殊节点
        spec_nodes = []
        # 获取当前节点的子树和子树的at targets, 因为是倒序的，
        # 子树的at targets已经决策过
        subtree = []
        comm.get_sub_tree(i, dict_depended, subtree)
        dict_subtree_ats = {}
        workspace_nodes = []
        for k, sub_stage_info in enumerate(stages_info[i + 1:]):
            stage_index = k + i + 1
            # 1,叶子输出节点和特殊节点
            if is_spec_node(sub_stage_info, stage, stage_info, c_op,
                            redundancy_tensors):
                spec_nodes.append(stage_index)

            # 2,所有workspace节点
            if sub_stage_info["at_info"].is_fork():
                workspace_nodes.append(stage_index)

            if stage_index in subtree:
                dict_subtree_ats.setdefault(stage_index, [])
                dict_subtree_ats[stage_index] \
                    = sub_stage_info["at_info"].get_all_at_targets()
        # 查找workspace节点到所有候选的所有路径
        dict_paths = {}
        spec_nodes = list(set(spec_nodes))
        spec_stage_names = (stages_info[x]["name"] for x in spec_nodes)
        log.dbg("[%d]spec_nodes:%s, %s: %s", i, spec_nodes,
                stages_info[i]["name"], spec_stage_names)
        log.dbg("[%d]dict_paths:%s", i, dict_paths)

        # 遍历node的consumer, 每个consumer代表一条路（即一次cache read）
        for j in dict_depended[i]:
            consumer_info = ConsumerInfo(j)
            at_info.add_consumer(consumer_info)

            # 1, 如果j是workspace，则只能at到j
            if j in workspace_nodes:
                consumer_info.add_at_candidate(j)
            else:
                for candidate in workspace_nodes:
                    # 1,candidate == consumer, consumer是候选，
                    #   说明j是特殊节点(reduce)，可以at
                    # 2, 候选是consumer的at target, 可以at
                    if j == candidate or candidate in dict_subtree_ats.get(
                            j) or matmul_candidate_check(
                                c_op, candidate, spec_nodes, subtree):
                        consumer_info.add_at_candidate(candidate)
                reduce_candidate_list = []
                new_candidate_list = []
                for candidate in spec_nodes:
                    if j == candidate or candidate in dict_subtree_ats.get(
                            j) or matmul_candidate_check(
                                c_op, candidate, spec_nodes, subtree):
                        new_candidate_list.append(candidate)
                        if op_schedule_info.op_name not in [
                                "cosine_embedding_loss"
                        ]:
                            continue
                        for reduce_axis in schedule_obj.stages[
                                candidate].op.reduce_axis:
                            if reduce_axis.dom.extent.value >= 20000:
                                reduce_candidate_list.append(candidate)
                                break
                if reduce_candidate_list:
                    for candidate in reduce_candidate_list:
                        consumer_info.add_at_candidate(candidate)
                elif c_op in comm.MAD_OP_ID_MAP.values():
                    # 深度融合场景就近取candidate
                    consumer_info.add_at_candidate(min(new_candidate_list))
                    log.dbg("%s, candidate %s: %s", stages_info[i]["name"],
                            min(new_candidate_list),
                            stages_info[min(new_candidate_list)]["name"])
                else:
                    for candidate in new_candidate_list:
                        consumer_info.add_at_candidate(candidate)

            # 如果只有一个at target，直接设置sampled_target
            if len(consumer_info.at_candidates) == 1:
                consumer_info.set_sampled_target(
                    consumer_info.at_candidates[0])

            log.dbg(
                "[%d]consumer index:%s at_candidates:%s, "
                "dict_subtree_ats: %s", i, consumer_info.index,
                consumer_info.at_candidates, dict_subtree_ats.get(j))

        # 2.3 如果需要决策，返回给controller进行采样
        if at_info.need_sample():
            log.dbg("Is node:%s workspace need to be decided by sampler", i)
            return True

    return False
