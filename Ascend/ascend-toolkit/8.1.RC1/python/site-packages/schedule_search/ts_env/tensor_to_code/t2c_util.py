#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
import copy
import functools
from functools import reduce as functools_reduce

from schedule_search import log
from schedule_search import util
from schedule_search import comm
from schedule_search.ts_env import env_classes
from schedule_search.ts_env import env_util
from schedule_search.ts_env.tensor_cfg import AXIS_CNT
from schedule_search.ts_env.tensor_cfg import ActionTensorCfg
from schedule_search.ts_env.tensor_cfg import FeatureTensorCfg
from tbe import tvm

REDUCE_LAST_KEYWORD = "_last"
REDUCE_NIST_KEYWORD = "_nist"

# 编号与layer是对应好的，不允许随便调整
AXIS_LEVEL_O_INDEX = 0
AXIS_LEVEL_IO_INDEX = 1
AXIS_LEVEL_I_II_NORMAL_INDEX = 2
AXIS_LEVEL_C_INDEX = 3
AXIS_LEVEL_SUB_AXIS_INDEX = 4
AXIS_LEVEL_IIO_INDEX = 5
AXIS_LEVEL_OO_INDEX = 6

# Lv0 需要L1->L0的tags
NEED_WRITE_L1_TO_L0_TAGS = ["load2d", "l1_to_l0", "im2col", "transpose_true"]
# Lv0 需要OUT->L1的tag
NEED_READ_OUT_TO_L1_TAGS = NEED_WRITE_L1_TO_L0_TAGS + \
                           ["set_fmatrix", "matmul", "conv_mad"]
# Lv0 需要对应L1的tag
NEED_WRITE_L1_TAGS = ["set_fmatrix", "out_to_l1", "conv_l1fuse_reshape"]
# Lv0 需要对应L0的tag
NEED_WRITE_L0_TAGS = ["matmul", "conv_mad", "ub_to_l0", "mad_add_bias"]

NEED_READ_L1_CUSUMER_TAGS = ["set_fmatrix", "matmul", "conv_mad"]

# Lv1 需要cache_read L0->UB的tag
NEED_WRITE_L0_TO_UB_TAGS = ["matmul", "conv_mad"]
# Lv1 需要cache_read L1->L0的tag
NEED_READ_L1_TO_L0_TAGS = ["matmul", "conv_mad"]

# 量化相关tag，emit_insn时需要特殊切分
QUANT_SERIES_TAGS = [
    'reform_by_vector', 'data_transfer', "requant_s16_data_transfer"
]

QUANT_CAST_TAGS = [
    "requant_s16_vector", "dequant_s16_vector", "requant_vector",
    "dequant_vector"
]

MULTICORE_POSTFIX = '_multicore_o'
BROADCAST_AT_POSTFIX = '_broadcast_o'
COMMON_AT_POSTFIX = '_common_o'
TMP_POSTFIX = '_tmp_o'

# gemm规则轴的大小
C_SIZE = 16

L1_CACHE_LAYER = 0
L0_CACHE_LAYER = 1


class T2cParams:  # pylint: disable=R0902,R0903,R0913
    """
    T2cParams
    """

    def __init__(self, op_name, schedule, features, actions, op_schedule_info,
                 tvm_compute_code, mode):
        # 初始化之后就不能变的成员
        self.op_name = op_name
        self.schedule = schedule
        self.features = features
        self.actions = actions
        self.op_schedule_info = op_schedule_info
        self.tvm_compute_code = tvm_compute_code
        self.mode = mode
        self.op_layers = 0
        self.stages_info = op_schedule_info.stages_info
        self.fanout_sub_tree = {}
        # 可以变的成员
        self.cleaned_actions = []
        self.code_lines = []
        # T2C增加生成cheque_list
        self.cheque_list = []
        self.inlined_stages = []
        self.ori_axis_info_list = []
        self.axis_info_list = []
        self.at_targets = []
        self.leveled_axis_for_reorder = []
        self.outer_axis_infos = {}
        self.proc_flag_dict = {}
        # EmitInsn中使用的临时成员
        self.stage_index = 0
        self.stage = None
        self.stage_name = ''
        # storage_align中使用的临时成员
        self.stage_factors = None
        self.storage_align_info = {}
        self.at_choices = []
        # bind中使用的临时成员, 切分轴
        self.cut_axis_index = {}
        # 原cut_axis_index之前的轴按factor=1切分，reorder之后最内层的切分轴
        self.last_cut_axis_index = {}
        self.ated_axis_index = {}
        # find first cut part factor axis
        self.first_cut_part_factor_axis_index = {}
        self.bind_axis = {}
        self.bind_stages = []
        # inter_out reuse_input的stage name
        self.reuse_stages = []
        self.stage_axis_types = []
        self.reused_input_list = []
        self.reorder_axis_map = {}
        self.allocate_at_list = []
        self.retry_t2c_rules = {}
        self.double_buffer_list = []
        self.cube_info_dict = {}
        self.l1_cache_read_map = {}

    def update_ated_axis_index(self, stage_index, axis_index):
        """
        更新被at的第一根轴
        """
        if stage_index is None:
            return

        old_axis = self.ated_axis_index.get(stage_index, None)
        if old_axis is None or old_axis > axis_index:
            self.ated_axis_index[stage_index] = axis_index


def refine_at(action_tensors):
    """
    :param action_tensors:
    :return:
    """
    for i, item in enumerate(action_tensors):
        at_index = item[ActionTensorCfg.at_s]
        action_tensors[i][ActionTensorCfg.at_s] = min(at_index + 1,
                                                      max_axis() - 1)
    return action_tensors


def max_axis():
    """
    :return:
    """
    return (ActionTensorCfg.split_factor_e - ActionTensorCfg.split_factor_s +
            1) // 2


def get_axis_stride(stage_axis):
    """
    :param stage_axis:
    :return:
    """
    axis_num = len(stage_axis)
    stride_list = [1]
    for axis_index in range(1, axis_num):
        # 从后往前计算stride，最后一个轴的stride为1，从倒数第二个开始
        next_axis_value = stage_axis[axis_num - axis_index].dom.extent.value
        # 当前轴的轴长
        curr_stride = stride_list[axis_index - 1] * next_axis_value
        stride_list.append(curr_stride)
    stride_list.reverse()
    return stride_list


def clean_factor_forward(  # pylint: disable=R0913
        start,
        end,
        stage_axis,
        t2c_params,
        stage_index,
        base_factor_index):
    """
    :param start:
    :param end:
    :param stage_axis:
    :param t2c_params:
    :param stage_index:
    :param base_factor_index:
    :return:
    """
    full_axis_flag = False
    axis_all_eat_flag = True
    # 从前往后，对第一个非1的切分因子不做clean，后面轴的factor都clean为轴长
    for i in range(start, end + 1, 1):
        if full_axis_flag is False:
            if t2c_params.actions[stage_index][base_factor_index + i] != 1:
                full_axis_flag = True
        else:
            t2c_params.cleaned_actions[stage_index][
                base_factor_index + i] = stage_axis[i].dom.extent.value
        # 判断是否整吃
        if t2c_params.cleaned_actions[stage_index][
            base_factor_index + i] != stage_axis[i].dom.extent.value:
            axis_all_eat_flag = False
    return axis_all_eat_flag


def get_reduce_type(t2c_params, reduce_stage_name, features):
    """
    :param t2c_params:
    :param reduce_stage_name:
    :param features:
    :return:
    """
    reduce_type = "nist"
    for stage_index, stage in enumerate(t2c_params.schedule.stages):
        compute_id = features[stage_index][FeatureTensorCfg.compute_s]
        op_tag = t2c_params.op_schedule_info.op_intrin_key_index[
            compute_id].op_tag
        log.dbg("reduce_stage_name:%s stage.op.name:%s tag:%s",
                reduce_stage_name, stage.op.name, op_tag)
        if stage.op.name == reduce_stage_name and op_tag.endswith(
                REDUCE_LAST_KEYWORD):
            reduce_type = "last"
            break
    return reduce_type


def get_axis_list(op_schedule_info, stage, stage_info):  # pylint: disable=R0912
    """
    :param stage:
    :param stage_info:
    :return:
    """
    schedule = op_schedule_info.schedule_obj
    if stage.op.reduce_axis:
        axis_len_list = [
            axis.dom.extent.value
            for axis in stage.op.reduce_axis
        ]
    else:
        axis_len_list = [axis.dom.extent.value for axis in stage.op.axis]

    c_op = comm.c_op_identify(schedule)
    if c_op in comm.MAD_OP_ID_LIST:
        has_batch, _ = gemm_identify(op_schedule_info)
        if not stage.op.reduce_axis and has_batch:
            axis_len_list = axis_len_list[:len(axis_len_list) // 2 + 1]
        else:
            axis_len_list = axis_len_list[:len(axis_len_list) // 2]

    # 只有一个broadcast_groups不处理
    broadcast_groups = stage_info.get('broadcast_groups', [])
    if len(broadcast_groups) > 1:
        broadcast_axis_reorder = stage_info.get('broadcast_axis_reorder')
        axis_index_list = sorted(
            list(set(range(len(axis_len_list))) - set(broadcast_axis_reorder)))
        axis_index_list += broadcast_axis_reorder
        axis_list = [[axis_index, axis_len_list[axis_index]]
                     for axis_index in axis_index_list]
    else:
        axis_list = [[axis_index, axis_len]
                     for axis_index, axis_len in enumerate(axis_len_list)]

    return axis_list


def update_stage_info(stage_info, axis_index, new_stage_action):
    """
    broadcast_groups的相关信息更新，免得迷惑人
    """
    broadcast_axis_reorder = stage_info.get('broadcast_axis_reorder')
    if broadcast_axis_reorder:
        stage_info['choose_axis'] = axis_index
        stage_info['sample_action'] = new_stage_action[:AXIS_CNT]


def stage_need_split(stage_index, op_schedule_info):
    '''
    # reduce stage必须被at才会去切分reduce轴
    # leaf、workspace需要切分
    :param stage_index:
    :param op_schedule_info:
    :return:
    '''
    stage_types = op_schedule_info.stages_info[stage_index].get('type', [])
    if 'reduce' in stage_types and \
            stage_index in op_schedule_info.at_dict.values():
        return True
    if {'leaf', 'workspace', "l1fuse_leaf"} & set(stage_types):
        return True
    return False


def update_factor(actions,  # pylint: disable=R0914
                  op_schedule_info, layer=0, update_multiplier=2):
    """
    增大Factor
    """
    new_actions = []
    # 每个Stage
    schedule_obj = op_schedule_info.schedule_obj
    for stage_index, stage in enumerate(schedule_obj.stages):
        stage_action = actions[stage_index]
        new_stage_action = stage_action[:]

        if isinstance(stage.op, tvm.PlaceholderOp) or \
                not stage_need_split(stage_index, op_schedule_info):
            new_actions.append(new_stage_action)
            continue

        stage_info = op_schedule_info.stages_info[stage_index]
        axis_list = get_axis_list(op_schedule_info, stage, stage_info)

        # 第0层的Factor是0~7，第1层的Factor是8~15
        axis_index_start = 0
        if layer == 1:
            axis_index_start = max_axis()

        c_op = op_schedule_info.c_op
        split_axis = 0
        for axis_index, axis_len in reversed(axis_list):
            split_axis = axis_index
            if new_stage_action[axis_index] < axis_len:
                new_stage_action[axis_index + axis_index_start] = min(
                    axis_len, stage_action[axis_index] * update_multiplier)
                if c_op not in comm.MAD_OP_ID_LIST:
                    break

        update_stage_info(stage_info, split_axis, new_stage_action)

        new_actions.append(new_stage_action)

    return new_actions


def decay_factor(actions,  # pylint: disable=R0914
                 op_schedule_info, layer=0, decay_divisor=2):
    """
    减小Factor
    """
    new_actions = []
    # 每个Stage
    schedule_obj = op_schedule_info.schedule_obj
    for stage_index, stage in enumerate(schedule_obj.stages):
        stage_action = actions[stage_index]
        new_stage_action = stage_action[:]

        if isinstance(stage.op, tvm.PlaceholderOp) or \
                not stage_need_split(stage_index, op_schedule_info):
            new_actions.append(new_stage_action)
            continue

        stage_info = op_schedule_info.stages_info[stage_index]
        axis_list = get_axis_list(op_schedule_info, stage, stage_info)

        # 第0层的Factor是0~7，第1层的Factor是8~15
        axis_index_start = 0
        if layer == 1:
            axis_index_start = max_axis()

        c_op = op_schedule_info.c_op
        split_axis = 0
        for axis_index, _ in axis_list:
            split_axis = axis_index
            real_idx = axis_index + axis_index_start
            if new_stage_action[real_idx] > 1:
                new_stage_action[real_idx] = max(
                    1, stage_action[real_idx] // decay_divisor)
                if c_op not in comm.MAD_OP_ID_LIST:
                    break

        update_stage_info(stage_info, split_axis, new_stage_action)

        new_actions.append(new_stage_action)

    return new_actions


def refine_oom(actions, err_type, op_schedule_info):  # pylint: disable=R0912
    """
    :param op_schedule_info:
    :param actions:
    :param err_type:
    :return:
    """
    # 如果是Buffer超了，可以通过调整Factor来搞定，而不是直接返回失败
    # 这样可以再次缩小无效空间
    # L1和UB的是第一层
    if err_type in [
        env_classes.OomError.L1_BUFF, env_classes.OomError.UB_BUFF,
        env_classes.OomError.OVERFLOW, env_classes.OomError.SEGMENT
    ]:
        new_actions = decay_factor(actions,
                                   op_schedule_info,
                                   layer=0,
                                   decay_divisor=2)
        if new_actions != actions:
            return new_actions

    # L0的是第二层
    elif err_type in [
        env_classes.OomError.L0AB, env_classes.OomError.L0C,
        env_classes.OomError.OVERFLOW, env_classes.OomError.SEGMENT
    ]:
        layer_list = [1, 0]
        # L0A/L0B超buffer只需要缩减Factor2
        if err_type == env_classes.OomError.L0AB:
            layer_list = [1]
        for layer in layer_list:
            new_actions = decay_factor(actions,
                                       op_schedule_info,
                                       layer=layer,
                                       decay_divisor=2)
            if new_actions != actions:
                return new_actions
    else:
        log.warn('unknown err_type: [%s]', err_type)

    return actions


def gemm_identify(op_schedule_info):
    '''
    根据轴的个数判断gemm是否是带batch的、fractal的
    '''
    if op_schedule_info.c_op in comm.CONV_OP_ID_LIST:
        return True, True

    has_batch = False
    is_fractal = False

    sch = op_schedule_info.schedule_obj
    last_stage_axis_num = len(sch.stages[-1].op.axis)
    # 输出3（非fractal）、5（fractal）根轴则是带batch的
    if last_stage_axis_num in [3, 5]:
        has_batch = True
    # 输出4（非batch）、5（batch）根轴则是分型的
    if last_stage_axis_num in [4, 5]:
        is_fractal = True

    return has_batch, is_fractal


def is_reduce_axis_continuous(shape, reduce_axis):
    """
    check reduce continuous tailing axis
    """
    if len(reduce_axis) > 1:
        index_list = [index for index, _ in enumerate(shape)]

        if index_list[-len(reduce_axis):] == reduce_axis:
            return True

    return False


def need_move_emit_insn_axis(intrin):
    """
    :param intrin:
    :return:
    """
    if intrin.startswith("vector_"):
        return False

    # 只有指令类型的指令需要挪轴，后续切换到新的指令后，理论上都不需要挪轴
    if "elewise_" in intrin:
        return True

    if "reduce_" in intrin:
        return True

    if "broadcast" in intrin:
        return True

    if "segment_" in intrin:
        return True

    return False


def get_sub_axis_len(sub_axis, axis_info_dict):  # pylint: disable=R0911,R0912
    """
    :param sub_axis:
    :param axis_info_dict:
    :return:
    """
    if sub_axis.isdigit():
        return int(sub_axis)

    c0_value = 16
    if sub_axis in ["C0", "Ci0", "Co0"]:
        return c0_value

    # img2col的特殊情况
    if sub_axis == "HoWo1":
        sub_axis_len = (axis_info_dict["Ho"].value * axis_info_dict["Wo"].value
                        + c0_value - 1) // c0_value
        return sub_axis_len

    if sub_axis == "HoWo":
        sub_axis_len = axis_info_dict["Ho"].value * axis_info_dict["Wo"].value
        return sub_axis_len

    if sub_axis not in axis_info_dict:
        log.dbg("sub_axis: %s not found value", sub_axis)
        return None

    if isinstance(axis_info_dict[sub_axis], tvm.ir.container.Array):
        sub_axis_len_list = []
        for sub_axis_len in axis_info_dict[sub_axis]:
            sub_axis_len_list.append(sub_axis_len.value)
        return sub_axis_len_list
    sub_axis_len = axis_info_dict[sub_axis].value
    return sub_axis_len


def print_axis_info(axis_info_list, option_str=""):
    """
    :param axis_info_list:
    :param option_str:
    """
    if option_str:
        log.info('%s', option_str)
    for axis_infos in axis_info_list:
        if not isinstance(axis_infos, list):
            log.info('axis_info: %s', axis_infos)
            continue
        if not axis_infos:
            continue
        for axis_info in axis_infos:
            log.info('axis_info: %s', axis_info)


def get_inherit_at_o_axis(t2c_params, stage_index):
    """
    :param t2c_params:
    :param stage_index:
    :return:
    """
    # 获取at_target目标轴之前所有的轴，即切分得到继承的所有轴
    at_targets_axis_info = t2c_params.at_targets[stage_index]
    if at_targets_axis_info is None:
        return []
    at_target_stage_name = at_targets_axis_info.name.split('_reduce')[0].split(
        '_axis')[0]
    at_target_axis_info_list = t2c_params.outer_axis_infos[
        at_target_stage_name]

    # at target 所在轴在其所有轴中的位置
    at_target_axis_index = 0
    for i, axis_info in enumerate(at_target_axis_info_list):
        if axis_info.name == at_targets_axis_info.name:
            at_target_axis_index = i
            break

    return at_target_axis_info_list[:at_target_axis_index + 1]


def check_data_require(option, sch):
    """
    :param option:
    :param sch:
    :return:
    """
    # 检查是否有对输入有特殊依赖的IR
    special_tag_list = [
        "elewise_single_sqrt", "elewise_single_rec", "elewise_single_rsqrt",
        "elewise_binary_div", "elewise_single_log"
    ]

    tag_list = []
    for stage in sch.stages:
        tag_list.append(stage.op.tag.split("|")[0])
    if set(special_tag_list) & set(tag_list):
        # rl tune时，如果没有开启auto_schedule_golden， 就打开data_require
        if option.get("rl_tune", False):
            if not option.get("auto_schedule_golden", False):
                option["data_require"] = "positive"
        # 如果已经配置了positive则可以跳过校验
        if not (option.get("data_require", "") == "positive"
                or option.get("auto_schedule_golden", False)
                or option.get("golden_input", [])):
            log.dbg(
                'Special IR is existed, "golden_input" must be configured.')
            return False

    return True


def get_inter_out(stages_info):
    """
    :param stages_info:
    :return:
    """
    stage_index_list = []
    for stage_index, stage_info in enumerate(stages_info):
        if 'inter_out' in stage_info.get('type', []):
            stage_index_list.append(stage_index)
    return stage_index_list


def get_origin_leaf_out(stages_info):
    """
    :param stages_info:
    :return:
    """
    stage_index_list = []
    for stage_index, stage_info in enumerate(stages_info):
        if 'origin_leaf_out' in stage_info.get('type', []):
            stage_index_list.append(stage_index)
    return stage_index_list


def get_last_slice_size(stage_axis, factors):
    """
    :param stage_axis:
    :param factors:
    :return:
    """
    last_slice_size = 0
    tail_list = [1]
    for i in range(len(stage_axis) - 1, -1, -1):
        axis_len = stage_axis[i].dom.extent.value
        factor = factors[i]
        if factor < axis_len or i == 0:
            last_slice_size = util.get_last_slice_len(axis_len, factor,
                                                      tail_list)
            break
        tail_list.append(axis_len)
    return last_slice_size


def get_slice_size(stage_axis, factors):
    """
    :param stage_axis:
    :param factors:
    :return:
    """
    slice_size = 0
    tail_list = [1]
    for i in range(len(stage_axis) - 1, -1, -1):
        axis_len = stage_axis[i].dom.extent.value
        factor = factors[i]
        if factor < axis_len or i == 0:
            tail_size = 1
            if tail_list:
                tail_size = functools_reduce(lambda x, y: x * y, tail_list)
            # 获取数据块的大小
            slice_size = factor * tail_size
            break
        tail_list.append(axis_len)
    return slice_size


def factor_tail_check(t2c_params,  # pylint: disable=R0914,R0912
                      stage, stage_index):
    """

    :param t2c_params:
    :param stage:
    :param stage_index:
    :return:
    """
    if t2c_params.stages_info[stage_index].get('factor_tail_check',
                                               None) is False:
        return True

    cut_axis_index = t2c_params.cut_axis_index[stage_index]
    factor = t2c_params.cleaned_actions[stage_index][cut_axis_index]
    stage_dtype = stage.op.output(0).dtype
    block_size = env_util.get_block_num(stage_dtype)
    axis_num = len(stage.op.axis)

    total_size = 1
    if cut_axis_index + 1 < axis_num:
        total_size = functools_reduce(lambda x, y: x * y,
            t2c_params.cleaned_actions[stage_index][cut_axis_index + 1:axis_num])

    # 如果数据块小于32byte，返回False
    if factor * total_size < block_size:
        return False

    # 倒推到之前的中间输出、虚节点对应的实际多叶子输出，
    # 看数据块是不是小于32byte
    inter_out_list = get_inter_out(t2c_params.op_schedule_info.stages_info)
    origin_leaf_out_list = get_origin_leaf_out(t2c_params.op_schedule_info.stages_info)
    special_stage_index_list = inter_out_list + origin_leaf_out_list
    for special_stage_index in special_stage_index_list[:]:
        if special_stage_index >= stage_index:
            special_stage_index_list.remove(special_stage_index)
    if not special_stage_index_list \
            or 'reduce_atomic' in t2c_params.stages_info[stage_index]:
        return True

    stages = list(t2c_params.schedule.stages)
    stage_factors, _ = get_factors(
        stages, t2c_params.op_schedule_info.stages_info, t2c_params.features,
        t2c_params.cleaned_actions, t2c_params.op_schedule_info.reduce_axis_dict,
        t2c_params.op_schedule_info.real_fanout_dict)
    for special_stage_index in special_stage_index_list:
        factors = stage_factors[special_stage_index][0]
        # 获取数据块的大小，
        # 中间输出at到reduce stage, 数据不连续，获取尾块大小
        at_stage_index = t2c_params.op_schedule_info.at_dict.get(special_stage_index, None)
        at_stage_types = t2c_params.op_schedule_info.stages_info[at_stage_index].get('type', [])
        if special_stage_index in inter_out_list \
                and 'reduce' in at_stage_types:
            slice_size = get_last_slice_size(stages[special_stage_index].op.axis, factors)
        else:
            slice_size = get_slice_size(stages[special_stage_index].op.axis, factors)
        log.dbg("[t2c]stage: %s, factors: %s, last_slice_size: %s",
                stages[special_stage_index], factors, slice_size)
        special_stage_dtype = stages[special_stage_index].op.input_tensors[0].dtype
        if slice_size < env_util.get_block_num(special_stage_dtype):
            log.dbg("[t2c]%s tail_size not larger than 32b, block_dim need be 1",
                    stages[special_stage_index])
            return False
    return True


def update_factors_and_axis_types(  # pylint: disable=R0912,R0913,R0914
        stages,
        factors,
        stage_index,
        stage_factors,
        stages_info,
        axis_list,
        stage_axis_types,
        reduce_axis_dict,
        child_stages):
    """
    :param stages:
    :param factors:
    :param stage_index:
    :param stage_factors:
    :param stages_info:
    :param axis_list:
    :param stage_axis_types:
    :param reduce_axis_dict:
    :param child_stages:
    :return:
    """
    axis_types = ["axis"] * len(stages[stage_index].op.axis)

    # 我的下级节点是哪个，看看它们的Factor是啥，从它们那里面继承
    log.dbg('child_stages: %s', child_stages)
    if not child_stages:
        return factors, axis_types

    child_factors = stage_factors[child_stages[0]]
    log.dbg('child_factors: %s', child_factors)

    # 如果child stage是Reduce，需要把它的ReduceFactor插入到合适的位置，
    # 需要考虑多个reduce轴的场景
    if child_stages[0] in reduce_axis_dict:
        reduce_axis_list = reduce_axis_dict[child_stages[0]]["axis"]
        # reduce场景下，不继承下面的stage的reduce信息
        if 'reduce_atomic_rfactor' in stages_info[child_stages[0]].get(
                'type', []):
            axis_types = ["axis"] * len(axis_list)
            for reduce_axis_index in reduce_axis_list:
                axis_types[reduce_axis_index] = "reduce_axis"
        else:
            axis_types = ["axis"] * len(stages[child_stages[0]].op.axis)
            factors[0] = copy.deepcopy(child_factors[0])
            for tmp_index, reduce_axis_ind in enumerate(reduce_axis_list):
                if len(factors[0]) < len(axis_list):
                    factors[0].insert(reduce_axis_ind,
                                      child_factors[1][tmp_index])
                    axis_types.insert(reduce_axis_ind, "reduce_axis")
                else:
                    factors[0][reduce_axis_ind] = child_factors[1][tmp_index]
                    axis_types[reduce_axis_ind] = "reduce_axis"
    # 如果child stage是Broadcast或Elem
    else:
        axis_types = copy.deepcopy(stage_axis_types[child_stages[0]])
        factors[0] = copy.deepcopy(child_factors[0])
        # 这里针对的场景的是虚节点引入broadcast，可能会将reduce掉的轴再补回来
        # WILLDO: 这里可以从后往前倒推，直到当前shape和broadcast stage的shape一致为止
        # 当前stage的输出shape与子stage的shape不一样，说明经过了broadcast
        input_shape = [
            input_shape_item.value
            for input_shape_item in stages[stage_index].op.output(0).shape
        ]
        output_shape = stages[child_stages[0]].op.output(0).shape
        if len(input_shape) != len(output_shape):
            index = -1
            del_indices = []
            for i, output_shape_item in enumerate(output_shape):
                if output_shape_item.value not in input_shape:
                    del_indices.append(i)
                    index = i
            # 按照从后向前的顺序Del，因为del会导致后面的序号发生变化
            for idx in reversed(del_indices):
                del factors[0][idx]
            # 临时针对softmax的特殊处理
            if index == -1:
                del factors[0][index]

    return factors, axis_types


def get_factors(stages,  # pylint: disable=R0913,R0914,R0912
                stages_info, features, cleaned_actions,
                reduce_axis_dict, fanout_dict):
    """
    :param stages:
    :param stages_info:
    :param features:
    :param cleaned_actions:
    :param reduce_axis_dict:
    :param fanout_dict:
    :return:
    """
    stage_num = len(cleaned_actions)
    stage_factors = [None] * stage_num
    stage_axis_types = [None] * stage_num
    stage_axis_list = [None] * stage_num
    for i in range(len(cleaned_actions)):
        # 从后向前遍历各个Stage
        stage_index = stage_num - 1 - i
        # 普通轴、reduce轴的切分因子
        if str(stages[stage_index].op).startswith("placeholder"):
            continue
        factors = [[], []]
        factor_s = ActionTensorCfg.split_factor_s
        factor_e = ActionTensorCfg.split_factor_e + 1
        factor_vector = cleaned_actions[stage_index][factor_s:factor_e]
        for j, factor in enumerate(factor_vector):
            # 如果是Redeuce轴
            if stage_index in reduce_axis_dict:
                # Reduce的Factor大于0的，直接记录
                if factor > 0:
                    factors[1].append(factor)
                # Reduce的Factor等于0，但这是第一个Factor，
                # 那就意思是这个Reduce轴不切，那其实Factor就是Reduce轴本身
                elif j < len(reduce_axis_dict[stage_index]["axis"]):
                    factors[1].append(
                        features[stage_index][FeatureTensorCfg.reduce_axis_s +
                                              j])
            # 非Reduce轴的Factor
            elif factor > 0:
                factors[0].append(factor)

        log.dbg('factors: %s', factors)
        # 获取当前Stage的轴长，不包含ReduceAxis
        axis_list = []
        axis_s = FeatureTensorCfg.axis_s
        axis_e = FeatureTensorCfg.axis_e + 1
        for axis in features[stage_index][axis_s:axis_e]:
            if axis > 0:
                axis_list.append(axis)
        log.dbg('axis_list: %s', axis_list)
        stage_axis_list[stage_index] = axis_list

        # 对于那些不用切分的普通Stage，它们的Factor都会被Clean成0的。
        # 所以需要通过判断继承关系来获取，这也是Stage的循环要从下而上的原因
        factors, axis_types = update_factors_and_axis_types(
            stages, factors, stage_index, stage_factors, stages_info,
            axis_list, stage_axis_types, reduce_axis_dict,
            fanout_dict[stage_index])
        # 和Child节点保持一致，有可能有多个，我们随便找一个就好，
        # 事实上，对于Gemm这样的算子来说，可能情况会更复杂
        stage_factors[stage_index] = factors
        stage_axis_types[stage_index] = axis_types
        log.dbg('stage: %s, factors: %s, axis_types: %s', stages[stage_index],
                factors, axis_types)

    return stage_factors, stage_axis_types


def get_split_axis(t2c_params, stage_index):
    """
    :param t2c_params:
    :param stage_index:
    :return:
    """
    stage = t2c_params.op_schedule_info.schedule_obj.stages[stage_index]
    stage_types = t2c_params.op_schedule_info.stages_info[stage_index].get(
        'type', [])
    if 'reduce' in stage_types:
        axis_num = len(stage.op.reduce_axis)
        axis_obj = stage.op.reduce_axis
    else:
        axis_num = len(stage.op.axis)
        axis_obj = stage.op.axis

    split_axis = 0
    for axis_index in range(axis_num - 1, -1, -1):
        axis_len = axis_obj[axis_index].dom.extent.value
        split_action = t2c_params.cleaned_actions[stage_index][axis_index]
        if axis_len != split_action:
            split_axis = axis_index
            break
    return split_axis


def get_ori_order(stage_axis_list):
    """

    :param stage_axis_list:
    :return:
    """

    def axis_cmp(lhs, rhs):  # pylint: disable=R0911
        type_order = {'axis': 0, 'reduce_axis': 1}
        attr_order = {'oo': 0,
                      'o': 1,
                      'io': 2,
                      'all': 3,
                      'c': 4,
                      'i': 5,
                      'ii': 6}
        if type_order.get(lhs.type) > type_order.get(rhs.type):
            return 1
        if type_order.get(lhs.type) < type_order.get(rhs.type):
            return -1

        if lhs.index > rhs.index:
            return 1
        if lhs.index < rhs.index:
            return -1

        if attr_order.get(lhs.attr) > attr_order.get(rhs.attr):
            return 1
        if attr_order.get(lhs.attr) < attr_order.get(rhs.attr):
            return -1

        return 0

    return sorted(stage_axis_list,
                  key=functools.cmp_to_key(axis_cmp))


def gn_training_update_nchw(op_schedule_info):
    """
    :param op_schedule_info:
    :return:
    """
    if op_schedule_info.op_name != 'gn_training_update':
        return False

    inputs = op_schedule_info.option.get('op_config', {}). \
        get('inputs', [])
    if not inputs:
        return False

    if inputs[0].get('format') != 'NCHW':
        return False

    return True


def get_nm_axis_index(op_schedule_info):
    '''
    获取mad类算子的n轴和m轴的索引
    '''
    has_batch, _ = gemm_identify(op_schedule_info)
    if has_batch:
        return 1, 2

    return 0, 1
