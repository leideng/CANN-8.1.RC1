#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
T2C_CFG = {
    10: {
        'proc_name':
        'schedule_search.ts_env.tensor_to_code.proc_cache_rw.main',
        'rules': [
            'schedule_search.ts_env.tensor_to_code.proc_cache_rw.rules.'
            'lv0_read_out2l1',
            'schedule_search.ts_env.tensor_to_code.proc_cache_rw.rules.'
            'lv0_read_out2ub',
            'schedule_search.ts_env.tensor_to_code.proc_cache_rw.rules.'
            'lv0_write_l0',
            'schedule_search.ts_env.tensor_to_code.proc_cache_rw.rules.'
            'lv0_write_l1',
            'schedule_search.ts_env.tensor_to_code.proc_cache_rw.rules.'
            'lv0_write_l12l0',
            'schedule_search.ts_env.tensor_to_code.proc_cache_rw.rules.'
            'lv0_write_ub2out',
            'schedule_search.ts_env.tensor_to_code.proc_cache_rw.rules.'
            'lv1_read_l12l0',
            'schedule_search.ts_env.tensor_to_code.proc_cache_rw.rules.'
            'lv1_write_l0c2ub',
            'schedule_search.ts_env.tensor_to_code.proc_cache_rw.rules.'
            'lv1_read_ub2l1',
        ]
    },
    25: {
        'proc_name':
        'schedule_search.ts_env.tensor_to_code.proc_reuse.main',
        'rules': [
            # 指定的算子结构需要进行reuse
            'schedule_search.ts_env.tensor_to_code.proc_reuse.rules.'
            'r01_pattern_reuse',
            # 卷积L1融合时，两个卷积的交接处需要reuse
            'schedule_search.ts_env.tensor_to_code.proc_reuse.rules.'
            'r02_conv_l1fuse_reuse_rule',
        ]
    },
    30: {
        'proc_name':
        'schedule_search.ts_env.tensor_to_code.proc_inline.main',
        'rules': [
            # broadcast to tensor的Stage需要inline
            'schedule_search.ts_env.tensor_to_code.proc_inline.rules.'
            'r01_broadcast_to_tensor_should_inline',
            # 有cache_read/cache_write的非output的Stage需要inline
            'schedule_search.ts_env.tensor_to_code.proc_inline.rules.'
            'r02_cached_nonout_should_inline',
            # gemm后融合其它算子，tensor_c_gm需要被inline
            'schedule_search.ts_env.tensor_to_code.proc_inline.rules.'
            'r03_fused_gemm_should_inline',
            # split和elemetwise相连的可以直接inline
            'schedule_search.ts_env.tensor_to_code.proc_inline.rules.'
            "r04_split_with_elementwise_should_inline",
            # reshape的stage直接inline
            'schedule_search.ts_env.tensor_to_code.proc_inline.rules.'
            "r05_reshape_should_inline",
            # 当前stage是dma，且其父子stage均为vector指令，则直接inline
            'schedule_search.ts_env.tensor_to_code.proc_inline.rules.'
            "r06_dma_between_vector_instr_should_inline",
            # 不涉及padding的conv需要对remove_pad stage做inline
            'schedule_search.ts_env.tensor_to_code.proc_inline.rules.'
            "r07_remove_pad_in_no_padding_conv_should_inline",
            # requant_vector stage做inline
            'schedule_search.ts_env.tensor_to_code.proc_inline.rules.'
            "r08_requant_vector_should_inline",
            # trs mid tensor inline
            'schedule_search.ts_env.tensor_to_code.proc_inline.rules.'
            "r09_trs_mid_tensor_should_inline"
        ]
    },
    40: {
        'proc_name':
        'schedule_search.ts_env.tensor_to_code.proc_split.main',
        'rules': [
            # 不被at的stage不切分
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r01_no_at_stage_no_split',
            # 一个Stage中，不存在的Level不需要Split。比如只有Vector计算时，
            # Lavel只有一层，则第2层及更深层不需要Split
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r02_no_exist_level_no_split',
            # Factor不能比轴长大
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r03_factor_smaller_than_axis',
            # 多个mad深度融合场景下，L1层的M轴切分有关联
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r03_1_deep_fused_mad_split_same_input',
            # Conv howo轴的切分规则
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r03_2_conv_howo_axis_split_rule',
            # L1深度融合不切大K和大N
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r03_3_l1fuse_nk_no_split_in_l1',
            # 更深层的Factor不能比上一层的Factor大
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r04_deeper_factor_smaller',
            # 规格轴不做切分
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r05_c_axis_no_split',
            # 多个连续ReduceStage，只切其中一个
            # 'schedule_search.ts_env.tensor_to_code.proc_split.
            # rules.r11_consecutive_reduce_only_split_large_one',
            # ReduceLast的Stage中，Reduce轴的尾块不能为1
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r06_reduce_last_reduce_tail_not_1',
            # 如果reduce stage不作为compute_at的目标stage，
            # 则reduce stage无需做切分
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r07_no_at_reduce_stage_no_split',
            # workspace节点只切一根轴
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r08_workspace_only_split_one_axis',
            # 针对有物理含义的轴的切分约束，适用于cube类算子（如C0轴，HW等）
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r09_axis_physical_constraint',
            # 有些reduces stage需要切普通轴
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r10_split_none_reduce_axis',
            # 中间输出如果at到reduce stage，然后reduce stage又at到叶子输出，
            # 最后一块数据（factor能整除时为factor，否则为尾块）长度
            # 必须是32字节的整数倍
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r12_inter_out_tail_block_32b_align',
            # 只有一根轴进行reduce后又broadcast回来，需要对at的stage切分因子
            # 需要32b对齐
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r13_bc_followed_32b',
            # 算子包含broadcast_nist，且最后一根broadcast轴之后的所有普通轴
            # 不是32b对齐的，则只能切最后一根broadcast轴之后的普通轴
            # 'schedule_search.ts_env.tensor_to_code.proc_split.rules.
            # r14_broadcast_only_split_max_broadcast_after',
            # concat算子只能切concat_axis以及该轴之后的轴
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r15_concat_only_split_concat_axis_after',
            # gemm的batch轴不切
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r16_gemm_batch_axis_no_split',
            # 相似的轴保持相同的切分因子
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r17_similar_axis_same_factor',
            # 量化相关stage要切最后一根轴
            'schedule_search.ts_env.tensor_to_code.proc_split.rules.'
            'r18_quant_stage_should_split_last_axis',
        ]
    },
    50: {
        'proc_name':
        'schedule_search.ts_env.tensor_to_code.proc_reorder.main',
        'rules': [
            # 没有做Split的Stage不用做Reorder
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r01_no_split_stage_no_reorder',
            # 一个Stage中，不存在的Level不做Reorder。参考Split中类似规则。
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r02_no_exist_level_no_reorder',
            # 一个Stage中，不同层的Reorder要分开来做，比如o轴之间做Reorder，
            # io轴之间做Reorder
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r03_diff_layers_reorder_separately',
            # 规格轴要放在所有轴的最后面
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r04_set_c_axis_to_last_layer',
            # Reduce Stage中的普通轴（它们不会被Split）要放在i轴的前面
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r05_set_normal_axis_of_reduce_stage',
            # ReduceNlst的Stage中，需要把Reduce轴放在同级别轴的最前面
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r06_reduce_nist_order',
            # gemm对轴顺序有要求
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r07_adjust_gemm_order',
            # reduce atomic对轴顺序的要求
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r08_adjust_reduce_atomic_order',
            # reduce_prod_nist指令要求reduce轴必须reorder到外层去
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r10_reduce_prod_nist_order',
            # reducestage切普通轴要把reduce轴放在最后
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r11_split_none_reduce_axis_order',
            # Reduce+Broadcast场景， reduce掉axis轴放在普通轴后面
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r12_broadcast_axis_order',
            # gemm的batch轴不参与reorder
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r13_gemm_batch_axis_no_reorder',
            # gn_training_update reorder
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r14_gn_update_reorder',
            # conv的batch轴和group轴不参与reorder，放在最外面
            'schedule_search.ts_env.tensor_to_code.proc_reorder.rules.'
            'r15_conv_reorder_rule',
        ]
    },
    60: {
        'proc_name':
        'schedule_search.ts_env.tensor_to_code.proc_at.main',
        # Stage从下往上看，上面的Stage不能比它的Child Stage at的轴更靠后
        # （最后是数据连续轴）
        'rules': [
            # reduce_atomic的at规则
            'schedule_search.ts_env.tensor_to_code.proc_at.rules.'
            'r01_reduce_atomic_at_rule',
            # gemm的at规则
            'schedule_search.ts_env.tensor_to_code.proc_at.rules.'
            'r02_gemm_at_rule',
            # gn_training_update的at规则
            'schedule_search.ts_env.tensor_to_code.proc_at.rules.'
            'r03_gn_training_update_at_rule',
            # 通用的at规则
            'schedule_search.ts_env.tensor_to_code.proc_at.rules.'
            'r04_refine_at_structure'
        ]
    },
    70: {
        'proc_name':
        'schedule_search.ts_env.tensor_to_code.proc_bind.main',
        'rules': [
            # conv3d bind
            'schedule_search.ts_env.tensor_to_code.proc_bind.rules.'
            'r01_conv3d_rule',
            # reduce atomic bind
            'schedule_search.ts_env.tensor_to_code.proc_bind.rules.'
            'r02_reduce_atomic_bind_rule',
            # gemm bind
            'schedule_search.ts_env.tensor_to_code.proc_bind.rules.'
            'r03_gemm_bind_rule',
            # gn_training_update
            'schedule_search.ts_env.tensor_to_code.proc_bind.rules.'
            'r04_gn_training_update_bind_rule',
            # 通用bind
            'schedule_search.ts_env.tensor_to_code.proc_bind.rules.'
            'r05_fused_bind_rule'
        ]
    },
    75: {
        'proc_name':
        'schedule_search.ts_env.tensor_to_code.proc_block_sync.main',
        'rules': [
            # tik_dsl算子需要做软同步的情况
            'schedule_search.ts_env.tensor_to_code.proc_block_sync.rules.'
            'r01_tik_dsl_need_sync',
        ]
    },
    80: {
        'proc_name':
            'schedule_search.ts_env.tensor_to_code.proc_allocate_at.main',
        'rules': [
            # matmul可以只要L1可以装下，可以做allocate_at
            'schedule_search.ts_env.tensor_to_code.proc_allocate_at.'
            'rules.matmul_l1_reuse',
        ]
    },
    82: {
        'proc_name':
        'schedule_search.ts_env.tensor_to_code.proc_double_buffer.main',
        'rules': [
            'schedule_search.ts_env.tensor_to_code.proc_double_buffer.'
            'rules.ub_db',
            'schedule_search.ts_env.tensor_to_code.proc_double_buffer.'
            'rules.l1_l0_db'
        ]
    },
    85: {
        'proc_name':
            'schedule_search.ts_env.tensor_to_code.proc_preload.main',
        'rules': [
            # 不做double_buffer的stage不做preload
            'schedule_search.ts_env.tensor_to_code.proc_preload.'
            'rules.r01_no_double_buffer_no_preload',
            # rnn ops stage with ub fanin no need to preload
            'schedule_search.ts_env.tensor_to_code.proc_preload.'
            'rules.r02_rnn_check_if_need_preload',
            # mad的fanin fanout不做preload
            'schedule_search.ts_env.tensor_to_code.proc_preload.'
            'rules.r03_mad_fanin_fanout_no_preload',
            # 非mad的l0c及其依赖的stage需要做preload
            'schedule_search.ts_env.tensor_to_code.proc_preload.'
            'rules.r04_l0c_depends_need_preload',
            # 通过option配置使能preload
            'schedule_search.ts_env.tensor_to_code.proc_preload.'
            'rules.r05_other_ub_preload',
        ]
    },
    86: {
        'proc_name':
            'schedule_search.ts_env.tensor_to_code.proc_buffer_align.main',
        'rules': [
            # conv set_fmatrix做buffer_align
            'schedule_search.ts_env.tensor_to_code.proc_buffer_align.'
            'rules.r01_conv_set_fmatrix_need_align',
            # conv dequant做buffer_align
            'schedule_search.ts_env.tensor_to_code.proc_buffer_align.'
            'rules.r02_dequant_after_conv_need_align',
        ]
    },
    90: {
        'proc_name':
        'schedule_search.ts_env.tensor_to_code.proc_emit_insn.main',
        'rules': [
            # dma指令emit insn默认选取0轴
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r01_dma_axis',
            # emit insn for trs，增加指令的attrs参数配置
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r014_trs_dma_axis_add_attrs',
            # mad指令emit insn固定选取0轴，且需要添加定制化的pragma标签
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r02_mad_axis',
            # set_fmatrix指令emit insn固定选取0轴，且需要添加定制化的pragma标签
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r03_set_fmatrix_axis',
            # 根据勾取的shape和stride信息，将emit insn轴调整到数据连续的起始轴
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r04_vector_axis_correct',
            # reverse stage的emit insn轴强制填为reverse轴后面的那根轴
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r05_reverse_rule',
            # reduce atomic rfactor emit_insn的轴为inner轴
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r06_reduce_atomic_rule',
            # 先考虑处理reduce_nist的stage
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r07_reduce_nist_stage_rule',
            # virtual_leaf_out需要映射为空指令
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r08_phony_insn',
            # 判断是否可以使用vector_dichotomy_add、
            # vector_dichotomy_add_for_bn_reduce指令
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r09_vector_dichotomy_add_rule',
            # broadcast_enhance
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r010_broadcast_enhance',
            # softmax_cross_entropy_with_logits使用
            # reduce_last_axis_reduce_sum_2、reduce_last_axis_reduce_max_2
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r011_reduce_for_scewl_rule',
            # 判断是否可以使用vector_dichotomy_reduce
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r012_vector_dichotomy_reduce_rule',
            # gemm_add_bias
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'r013_mad_add_bias_rule',
            # 不需要挪轴的其他stage，取0轴做指令映射
            'schedule_search.ts_env.tensor_to_code.proc_emit_insn.rules.'
            'rlast_other_stage_axis',
        ]
    },
    100: {
        'proc_name':
        'schedule_search.ts_env.tensor_to_code.proc_storage_align.main',
        'rules': [
            # 非reduce_last场景， 与最后一根轴连续的轴对齐
            'schedule_search.ts_env.tensor_to_code.proc_storage_align.'
            'rules.r01_not_reduce_last',
            # reduce_last场景 对src tensor在与最后一根reduce轴连续的轴对齐
            'schedule_search.ts_env.tensor_to_code.proc_storage_align.'
            'rules.r02_reduce_last',
        ]
    },
    101: {
        'proc_name':
            'schedule_search.ts_env.tensor_to_code.proc_set_buffer_size.main',
        'rules': []
    },
    110: {
        'proc_name':
        'schedule_search.ts_env.tensor_to_code.proc_build_config.main',
        'rules': [
            'schedule_search.ts_env.tensor_to_code.proc_build_config.'
            'rules.r01_cce_special',
            'schedule_search.ts_env.tensor_to_code.proc_build_config.'
            'rules.r02_tbe_compile_para',
        ]
    },
}
