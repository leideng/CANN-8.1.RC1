#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
import copy

import numpy as np

from schedule_search import log
from schedule_search.timer import timer
from schedule_search.ts_env.env_consts import MODE_OFFLINE
from schedule_search.ts_env.env_util import get_init_action_tensor
from schedule_search.ts_env.tensor_to_code.t2c_cfg import T2C_CFG
from schedule_search.ts_env.tensor_to_code.t2c_util import T2cParams
from schedule_search.util import get_op_layers
from schedule_search.ts_env.env_classes import SchInfo
from schedule_search.ts_env.tensor_cfg import FeatureTensorCfg


def _action_pre_process(op_schedule_info, actions):
    """

    :param op_schedule_info:
    :param actions:
    :return:
    """
    if op_schedule_info.tiling_case > 0 and \
            op_schedule_info.reduce_atomic_dict and \
            len(actions) + 2 == len(op_schedule_info.schedule_obj.stages):
        rfactor_stage_index \
            = op_schedule_info.reduce_atomic_dict["rfactor_stage_index"]
        reduce_write_stage_index \
            = op_schedule_info.reduce_atomic_dict["reduce_write_stage_index"]
        action = get_init_action_tensor(1)
        action = action.tolist()[0]
        actions.insert(rfactor_stage_index, action)
        actions.insert(reduce_write_stage_index, action)


def _no_need_proc(proc_index,
                  proc_index_start,
                  proc_index_end,
                  excluded_index,
                  proc_cfg):
    """

    :param proc_index:
    :param proc_index_start:
    :param proc_index_end:
    :param excluded_index:
    :param proc_cfg:
    :return:
    """
    if proc_index_start and (proc_index < proc_index_start):
        return True
    if proc_index_end and (proc_index > proc_index_end):
        return True
    if excluded_index and proc_index in excluded_index:
        return True
    if 'proc_name' not in proc_cfg or 'rules' not in proc_cfg:
        log.warn('Invalid config: %s.', proc_index)
        return True
    return False


def _proc_code(t2c_params,
               op_schedule_info,
               features,
               sample_actions,
               actions):
    """

    :param t2c_params:
    :param op_schedule_info:
    :param features:
    :param sample_actions:
    :param actions:
    :return:
    """

    code_lines = t2c_params.code_lines
    code_lines.append('\n')
    code_lines.append('# feature(without action): %s' % str(
        features.tolist() if isinstance(features, np.ndarray) else features))
    if sample_actions is not None:
        code_lines.append(
            '# ori sampled actions: %s' %
            str(sample_actions.tolist() if isinstance(sample_actions, np.ndarray) else sample_actions))
    sample_actions = actions
    code_lines.append(
        '# sampled actions: %s' %
        str(sample_actions.tolist() if isinstance(sample_actions, np.ndarray) else sample_actions))
    cleaned_actions = t2c_params.cleaned_actions
    code_lines.append(
        '# cleaned actions: %s' %
        str(cleaned_actions.tolist() if isinstance(cleaned_actions, np.ndarray) else cleaned_actions))
    code_lines.append(
        '# Customized label: %s' % op_schedule_info.option.get("customized_label", ""))

    # 统一加上四个字符的缩进
    for i, _ in enumerate(code_lines):
        code_lines[i] = '    %s' % code_lines[i]
    # 再加1行空行
    code_lines.extend([''])
    code = '\n'.join(code_lines)
    return code, cleaned_actions


def get_cube_info(t2c_params):
    """

    :param t2c_params:
    :return:
    """
    set_fmatrix_set = set()
    mad_stage_set = set()
    for stage_index, stage in enumerate(t2c_params.schedule.stages):
        # 该stage已经Inline掉了
        if stage_index in t2c_params.inlined_stages:
            continue

        features = t2c_params.features
        intrin = t2c_params.op_schedule_info.op_intrin_key_index[
            features[stage_index][FeatureTensorCfg.compute_s]].intrin

        # 只有L1的stage需要做allocate_at
        if intrin == 'set_fmatrix':
            set_fmatrix_set.add(stage_index)
            a_all = t2c_params.cube_info_dict.setdefault("matrix_al1", [])
            a_l1_index = t2c_params.op_schedule_info.real_fanin_dict[
                stage_index][0]
            if a_l1_index not in a_all:
                a_all.append(a_l1_index)
        elif stage.op.name.endswith(".local.L0A"):
            a_l0_index = stage_index
            a_all = t2c_params.cube_info_dict.setdefault("matrix_al0", [])
            if a_l0_index not in a_all:
                a_all.append(a_l0_index)
            a_l1_index = t2c_params.op_schedule_info.real_fanin_dict[
                a_l0_index][0]
            if t2c_params.stages_info[a_l1_index]["tag"] == 'set_fmatrix':
                continue
            a_all = t2c_params.cube_info_dict.setdefault("matrix_al1", [])
            if a_l1_index not in a_all:
                a_all.append(a_l1_index)
        elif stage.op.name.endswith(".local.L0B"):
            b_l0_index = stage_index
            b_all = t2c_params.cube_info_dict.setdefault("matrix_bl0", [])
            if b_l0_index not in b_all:
                b_all.append(b_l0_index)
            b_l1_index = t2c_params.op_schedule_info.real_fanin_dict[
                b_l0_index][0]
            b_all = t2c_params.cube_info_dict.setdefault("matrix_bl1", [])
            if b_l1_index not in b_all:
                b_all.append(b_l1_index)
        elif intrin == 'mad':
            mad_stage_set.add(stage_index)
    t2c_params.cube_info_dict["mad_stage"] = sorted(mad_stage_set)
    t2c_params.cube_info_dict["set_fmatrix"] = sorted(set_fmatrix_set)
    log.dbg("cube_info_dict: %s", t2c_params.cube_info_dict)


@timer('tensor_to_code')
def proc(op_schedule_info,  # pylint: disable=R0914,R0915,R0912,R0913
         actions,
         mode=MODE_OFFLINE,
         sample_actions=None,
         proc_index_start=31,
         proc_index_end=None,
         excluded_index=None):
    """对代码有一定的要求：
    1, Tensor要有name,且与变量名保持一致，且不同Stage的名字不要相同，比如：
        A = tvm.placeholder(shape, name="A", dtype=dtype)
        B = tvm.compute(shape, lambda *indice:  tvm.log(A(*indice)),name="B")
    2, 对于cache_read/cache_write，其命名固定为对应变量加_l，比如：
        A_l = s.cache_read(A, scope_ubuf, [B])
        B_l = s.cache_write(B, scope_ubuf)
    """
    _action_pre_process(op_schedule_info, actions)

    features = op_schedule_info.feature_tensor
    op_name = op_schedule_info.op_name
    schedule = op_schedule_info.schedule_obj
    tvm_compute_code = op_schedule_info.compute_code
    log.dbg('features len: %d, stage_num : %d, action len: %d', len(features),
            len(schedule.stages), len(actions))
    t2c_params = T2cParams(op_name, schedule, features, actions,
                           op_schedule_info, tvm_compute_code, mode)

    # double_buffer、inline会变更T2cParams的code_lines、inlined_stages
    if op_schedule_info.code_lines is not None:
        t2c_params.code_lines = op_schedule_info.code_lines[:]
    if op_schedule_info.cheque_list is not None:
        t2c_params.cheque_list = op_schedule_info.cheque_list[:]
    if op_schedule_info.inlined_stages:
        t2c_params.inlined_stages = op_schedule_info.inlined_stages[:]
    op_layers = get_op_layers(schedule)
    t2c_params.op_layers = op_layers
    t2c_params.cleaned_actions = copy.deepcopy(actions)

    for proc_index, proc_cfg in sorted(T2C_CFG.items(), key=lambda x: x[0]):
        if _no_need_proc(proc_index,
                         proc_index_start,
                         proc_index_end,
                         excluded_index,
                         proc_cfg):
            continue
        proc_name = proc_cfg['proc_name']
        rules = proc_cfg['rules']
        module = __import__(proc_name, fromlist=['1'])
        ret = module.proc(t2c_params, rules)
        if not ret:
            log.warn('%s proc break.', proc_name)
            break
        # ori_schedule_obj记录一下做完cache rw、double buffer、
        # inline的schedule对象、stages_info
        if proc_index <= 30:
            op_schedule_info.ori_schedule_obj \
                = copy.deepcopy(op_schedule_info.schedule_obj)
            op_schedule_info.ori_stages_info \
                = copy.deepcopy(op_schedule_info.stages_info)
        else:
            get_cube_info(t2c_params)

    op_schedule_info.axis_info_list = t2c_params.axis_info_list
    op_schedule_info.at_choices = t2c_params.at_choices
    if op_schedule_info.code_lines is None:
        op_schedule_info.code_lines = t2c_params.code_lines[:]
    if op_schedule_info.cheque_list is None:
        op_schedule_info.cheque_list = t2c_params.cheque_list[:]
    if not op_schedule_info.inlined_stages:
        op_schedule_info.inlined_stages = t2c_params.inlined_stages[:]

    code, cleaned_actions = _proc_code(t2c_params,
                                       op_schedule_info,
                                       features,
                                       sample_actions,
                                       actions)
    log.dbg('tensor2code finished!')

    return SchInfo(schedule, code, cleaned_actions, t2c_params.retry_t2c_rules,
                   t2c_params.cheque_list)
