#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
from schedule_search import log
from schedule_search.ts_env.tensor_to_code import t2c_util as util
from schedule_search.ts_env.depend import get_fanouts_from_sch
from schedule_search.ts_env.tensor_to_code.proc_cache_rw.main import \
    gen_cache_rw_info
from schedule_search.ts_env.tensor_to_code.proc_cache_rw.main import \
    is_dma_intrin
from tbe.common.platform import platform_info
from tbe import tvm


def condition_check(input_dict): # pylint: disable=R0912
    """

    :param input_dict:
    :return:
    """
    tensor = input_dict["tensor"]
    op_type = type(tensor.op)
    tensor_name = tensor.op.name
    cache_level = input_dict["cache_level"]
    stage_info = input_dict['stage_info']
    l1_fusion_type = input_dict['l1_fusion_type']

    if cache_level != 0:
        log.dbg("Op name:%s, Cache Level:%s not 0, no need read OUT->UB!",
                tensor_name, cache_level)
        return False

    # 非workspace和 placeholder, inter_out
    if op_type != tvm.PlaceholderOp and \
            not set(stage_info.get('type', [])) & {'workspace', 'inter_out'}:
        log.dbg("Op name:%s, Op type:%s not Placeholder, no need read "
                "OUT->UB!", tensor_name, op_type)
        return False

    if stage_info["tag"] == "ub_to_out":
        log.dbg("ub_to_out op: %s no need to cache read!", tensor_name)
        return False

    # 当前是placeholder，且下一级属于dma，则跳过cache read，直接cache write即可
    if op_type == tvm.PlaceholderOp:
        sch = input_dict["schedule"]
        stages = list(sch.stages)
        fanout_list = get_fanouts_from_sch(sch, sch[tensor])
        all_dma = True
        for fanout in fanout_list:
            if stages[fanout].op.tag == "concat":
                if len(stages) - 1 != fanout:
                    return False

            if not is_dma_intrin(stages[fanout].op.tag, ["dma_copy"],
                                 l1_fusion_type, stages[fanout].op.name):
                all_dma = False
                break
        if all_dma:
            log.dbg("op: %s no need to cache read!", tensor_name)
            return False
        if input_dict["consumer_stages_info"][0][
                "tag"] in util.NEED_READ_L1_CUSUMER_TAGS:
            return False
    return True


def proc(input_dict):
    """
    进行cache read操作
    :param input_dict:
    :return:
    """
    # WILLDO: 涉及多个输出，而且不是同一种类型的，暂不支持
    if not condition_check(input_dict):
        return []

    return gen_cache_rw_info(input_dict["tensor"], input_dict["all_tensors"],
                             "CacheRead", platform_info.scope_ubuf,
                             input_dict['stage_info'])
