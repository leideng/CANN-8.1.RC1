#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
from schedule_search import log
from schedule_search.ts_env.tensor_to_code import t2c_util as util
from schedule_search.ts_env.tensor_to_code.proc_cache_rw.main import \
    gen_cache_rw_info
from tbe.common.platform import platform_info


def condition_check(input_dict):
    """

    :param input_dict:
    :return:
    """
    cache_level = input_dict["cache_level"]
    tensor = input_dict["tensor"]
    tensor_name = tensor.op.name
    stage_info = input_dict["stage_info"]
    stage_tag = stage_info.get("tag")

    if cache_level != 0:
        log.dbg("Op_name: %s, cache_level: %s, no need write L1->L0",
                tensor_name, cache_level)
        return False

    if stage_tag not in util.NEED_WRITE_L1_TO_L0_TAGS:
        log.dbg("Op_name: %s, tag: %s, no need write L1->L0.",
                tensor_name, stage_tag)
        return False

    return True


def get_scope(input_dict):
    """
    确认是L0A,还是L0B
    :param tensor:
    :param output_tensors:
    :return:
    """
    tensor = input_dict['tensor']
    stage_info = input_dict['stage_info']
    all_tensors = input_dict["all_tensors"]

    output_tensors = [
        all_tensors[consumer.index]
        for consumer in stage_info["at_info"].consumers
    ]

    tensor_name = tensor.op.name
    index = 0
    for index in range(len(output_tensors[0].op.input_tensors)):
        if tensor_name == output_tensors[0].op.input_tensors[index].op.name:
            break

    # tensor是其输出的第一个输入，则是L0A，否则是L0B
    if index == 0:
        buf = platform_info.scope_ca
    else:
        buf = platform_info.scope_cb

    return buf


def proc(input_dict):
    """
    :param input_dict:
    :return:
    """
    if not condition_check(input_dict):
        return []

    # 获取cache read buf
    scope = get_scope(input_dict)
    if scope is None:
        log.warn("Stage: %s, scope is None!", input_dict['tensor'].name)
        return []

    # Lv0_write_l0、Lv0_write_l1、Lv0_write_l12l0处理过的tensor，
    # Lv0_write_ub2out不用再处理，用这个标记记录一下
    input_dict['write_proc_flag'] = True

    return gen_cache_rw_info(input_dict["tensor"], input_dict["all_tensors"],
                             "CacheWrite", scope, input_dict['stage_info'])
