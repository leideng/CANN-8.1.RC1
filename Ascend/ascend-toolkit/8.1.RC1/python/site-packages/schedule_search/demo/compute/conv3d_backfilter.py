#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
Copyright (c) Huawei Technologies Co., Ltd. 2019-2020. All rights reserved.

rl schedule search, tss
"""
import sys

import numpy as np

from tbe import tvm

np.set_printoptions(threshold=sys.maxsize)


def dy_hwpad_compute(dy_hwpad_shape, dy_input, dtype):
    """
    对hw补pad
    """

    def _dy_hwpad_indices(indices, dy_input):  # pylint: disable=R0914
        _, do_axis, _, ho_axis, wo_axis, _ = dy_input.shape
        co1, n_do, hw_pad, co0 = indices

        n_index = n_do // do_axis

        do_index = n_do % do_axis

        co1_index = co1

        ho_index = hw_pad // wo_axis

        wo_index = hw_pad % wo_axis

        co0_index = co0

        return tvm.select(  # pylint: disable=no-member
            hw_pad >= ho_axis * wo_axis, tvm.const(0.0, dtype),
            dy_input(n_index, do_index, co1_index, ho_index, wo_index,
                     co0_index))

    return tvm.compute(dy_hwpad_shape,
                       lambda *indices: _dy_hwpad_indices(indices, dy_input),
                       name='dy_l1',
                       tag='out_to_l1',
                       attrs={'axis': ["Co1", "N * Do", "Ho * Wo", "Co0"]})


def dy_load2d_compute(dy_trans_shape, dy_hwpad):
    """
    一步到位，直接转成fractal z，并完成转置
    """
    def _dy_load2d_indices(indices, dy_hwpad):
        hw_block = 16
        _, _, hw_pad, _ = dy_hwpad.shape

        _, co1, j1_indice, co0, j0_indice = indices

        co1_index = co1

        n_do_index = (j1_indice * hw_block + j0_indice) // hw_pad

        hw_index = (j1_indice * hw_block + j0_indice) % hw_pad

        co0_index = co0

        # dy_hwpad: n_do, co1, hw_pad, co0
        return dy_hwpad(co1_index, n_do_index, hw_index, co0_index)

    return tvm.compute(
        dy_trans_shape,
        lambda *indices: _dy_load2d_indices(indices, dy_hwpad),
        name='dy_l0a',
        tag='load2d',
        attrs={'axis': ["1", "Co1", "N * Do * Ho * Wo / C0", "Co0", "C0"]})


def input_transpose_compute(input_transpose_shape, input_tensor):
    """
    转置操作，把n,di_indice,ci1,hi_indice,wi_indice,ci0转化成
    （ci1, n, di_indice, hi_indice, wi_indice, ci0）
    :param input_transpose_shape:
    :param input_tensor:
    :return:
    """

    def func(ci1,  # pylint: disable=R0913
             n_indice,
             di_indice,
             hi_indice,
             wi_indice,
             ci0):
        """

        :param ci1:
        :param n_indice:
        :param di_indice:
        :param hi_indice:
        :param wi_indice:
        :param ci0:
        :return:
        """
        return input_tensor(n_indice, di_indice, ci1, hi_indice, wi_indice,
                            ci0)

    return tvm.compute(input_transpose_shape,
                       func,
                       name='input_l1',
                       tag='out_to_l1',
                       attrs={'axis': ["Ci1", "N", "Di", "Hi", "Wi", "Ci0"]})


def input_pad_d_trans_compute(input_padding_shape, input_tensor, input_padding,
                              padding):
    """
    对D维度补padding
    """

    def _input_padding_d_indices(indices,  # pylint: disable=R0914
                                 input_tensor):
        _, di_axis, _, _, _, _ = input_tensor.shape
        ci1, n_indice, di_indice, hi_indice, wi_indice, ci0 = indices

        n_index = n_indice
        di_index = di_indice - padding[0]
        ci1_index = ci1
        hi_index = hi_indice
        wi_index = wi_indice
        ci0_index = ci0
        di_padding_index = di_indice % di_axis % padding[0]

        return tvm.select(  # pylint: disable=no-member
            tvm.any(di_index < 0, di_index > di_axis.value - 1),
            input_padding(di_padding_index, ci1_index, hi_index, wi_index,
                          ci0_index),
            input_tensor(n_index, di_index, ci1_index, hi_index, wi_index,
                         ci0_index))

    return tvm.compute(
        input_padding_shape,
        lambda *indices: _input_padding_d_indices(indices, input_tensor),
        name='input_padding',
        tag='out_to_l1',
        attrs={'axis': ["Ci1", "N", "Di", "Hi", "Wi", "Ci0"]})


def input_im2col_compute(  # pylint: disable=R0913
        input_im2col_shape,
        input_trans,
        dtype,
        dy_shape,
        filter_shape,
        padding,
        stride):
    """

    :param input_im2col_shape:
    :param input_trans:
    :param dtype:
    :param dy_shape:
    :param filter_shape:
    :param padding:
    :param stride:
    :return:
    """

    def _input_im2col_indices(indices, input_trans):  # pylint: disable=R0914
        _, _, _, h_axis, w_axis, _ = input_trans.shape
        stride_d, stride_h, stride_w = stride
        _, _, padding_top, _, padding_left, _ = padding
        _, do_axis, _, ho_axis, wo_axis, _ = dy_shape

        _, kd_axis, _, _, _, _ = filter_shape

        _, n_do_hw, ci1_kd, kh_indice, kw_indice, ci0 = indices

        n_index = n_do_hw // (do_axis * ho_axis * wo_axis)

        do_index = n_do_hw // (ho_axis * wo_axis) % do_axis
        ho_index = n_do_hw // wo_axis % ho_axis
        wo_index = n_do_hw % wo_axis

        c1_index = ci1_kd // kd_axis

        kd_tail = ci1_kd % kd_axis

        d_index = do_index * stride_d + kd_tail

        h_index = ho_index * stride_h + kh_indice

        w_index = wo_index * stride_w + kw_indice

        c0_index = ci0

        return tvm.select(  # pylint: disable=no-member
            tvm.any(h_index < padding_top,
                    h_index > h_axis.value + padding_top - 1,
                    w_index < padding_left,
                    w_index > w_axis.value + padding_left - 1),
            tvm.const(0.0, dtype),
            input_trans(c1_index, n_index, d_index, h_index - padding_top,
                        w_index - padding_left, c0_index))

    ci1_axis, _, kh_axis, kw_axis, _, ci0_axis = filter_shape
    _, _, _, h_axis, w_axis, _ = input_trans.shape
    return tvm.compute(
        input_im2col_shape,
        lambda *indices: _input_im2col_indices(indices, input_trans),
        name='im2col_row_major',
        tag='set_fmatrix',
        attrs={
            'kernel_h': kh_axis,
            'kernel_w': kw_axis,
            'padding': padding[2:],
            'stride': stride[1:],
            "Hi": h_axis,
            "Wi": w_axis,
            "Ci": ci1_axis * ci0_axis,
            'axis': ["1", "N * Do * Ho * Wo", "Ci1 * Kd", "Kh", "Kw", "Ci0"]
        })


def input_fractal_compute(input_fractal_shape, dy_shape, input_im2col, dtype):
    """

    :param input_fractal_shape:
    :param dy_shape:
    :param input_im2col:
    :param dtype:
    :return:
    """

    def _input_fractal_indices(indices, input_im2col):  # pylint: disable=R0914
        hw_block = 16
        _, _, _, kh_axis, kw_axis, _ = input_im2col.shape

        _, _, _, ho_axis, wo_axis, _ = dy_shape

        vir, n_do_hw1, c1_kd_kh_kw, c0_indice, hw0 = indices

        n_do_hw_index = n_do_hw1 * hw_block + hw0

        c1_kd_index = c1_kd_kh_kw // (kh_axis * kw_axis)

        kh_index = c1_kd_kh_kw // kw_axis % kh_axis

        kw_index = c1_kd_kh_kw % kw_axis

        c0_index = c0_indice

        hw_pad = (ho_axis * wo_axis + hw_block - 1) // hw_block * hw_block
        hw_len = n_do_hw_index % hw_pad

        n_do_hw_index = n_do_hw_index // hw_pad * ho_axis * wo_axis
        n_do_hw_index += n_do_hw_index % hw_pad

        return tvm.select(  # pylint: disable=no-member
            hw_len >= ho_axis * wo_axis, tvm.const(0.0, dtype),
            input_im2col(vir, n_do_hw_index, c1_kd_index, kh_index, kw_index,
                         c0_index))

    return tvm.compute(
        input_fractal_shape,
        lambda *indices: _input_fractal_indices(indices, input_im2col),
        name='im2col',
        tag='im2col',
        attrs={
            'axis':
            ["1", "N * Do * Ho * Wo / C0", "Ci1 * Kd * Kh * Kw", "Ci0", "C0"]
        })


def mad_compute(mad_shape,  # pylint: disable=R0914
                shape_a,
                shape_b,
                dy_shape):
    """

    :param mad_shape:
    :param shape_a:
    :param shape_b:
    :param dy_shape:
    :return:
    """
    n_axis, do_axis, _, ho_axis, wo_axis, _ = dy_shape
    hw_block = 16
    block_size = 16
    # n_do * hw_pad
    k = tvm.reduce_axis((0, n_axis * do_axis * ho_axis * wo_axis), name='k')
    hw_len = ho_axis * wo_axis
    hw_pad = (hw_len + hw_block - 1) // hw_block * hw_block
    k1_len = k.var // hw_len * hw_pad // hw_block + k.var % hw_len // hw_block
    k0_len = k.var % hw_len % hw_block

    # shape_a shape: (1, co1_axis, n_axis * do_axis * hw_pad // hw_block,
    #                   co0_axis, hw_block)
    # shape_b shape: (1, N_do_axis * hw_pad // hw_block,
    #               kd_axis * ci1_axis * kh_axis * kw_axis, ci0_axis, hw_block)
    # mad shape: (1, ci1_axis * kd_axis * kh_axis * kw_axis,
    #               co1_axis * co0_axis, ci0_axis)
    #                 j1       i       j0

    def conv_mad_func(vir, i, j1_indice, j0_indice):
        """
        conv_mad_func
        :param vir:
        :param i:
        :param j1_indice:
        :param j0_indice:
        :return:
        """
        mad_tensor = (
            shape_a[vir, i // block_size, k1_len, i % block_size, k0_len] *
            shape_b[vir, k1_len, j1_indice, j0_indice,
                    k0_len]).astype("float32")
        return tvm.sum(mad_tensor, axis=[k])

    dw_col = tvm.compute(mad_shape,
                         conv_mad_func,
                         name='mad',
                         tag="conv_mad",
                         attrs={
                             'axis':
                             ["1", "Ci1 * Kd * Kh * Kw", "Co1 * Co0", "Ci0"],
                             'reduce_axis': ["N * Do * Ho * Wo"]
                         })

    return dw_col


def _get_input_padding(axis_info_dict: dict, input_tensor: object, dtype: str) -> object:
    padding = axis_info_dict.get("padding")
    ci1_axis = axis_info_dict.get("Ci1")
    hi_axis = axis_info_dict.get("Hi")
    wi_axis = axis_info_dict.get("Wi")
    ci0_axis = axis_info_dict.get("Ci0")
    di_axis = axis_info_dict.get("Di")
    n_axis = axis_info_dict.get("N")
    if padding[0] != 0:
        padding_d = tvm.compute(
            (padding[0], ci1_axis, hi_axis, wi_axis, ci0_axis),
            lambda *indices: tvm.const(0, dtype),
            name="padding_d",
            tag="vector_dup",
            attrs={'axis': ["%s" % (padding[0]), "Ci1", "Hi", "Wi", "Ci0"]})
        di_axis_padding = di_axis + padding[0] + padding[1]
        input_padding_shape = (ci1_axis, n_axis, di_axis_padding, hi_axis, wi_axis, ci0_axis)
        input_padding = input_pad_d_trans_compute(input_padding_shape,
                                                  input_tensor, padding_d,
                                                  padding)
    else:
        input_transpose_shape = (ci1_axis, n_axis, di_axis, hi_axis, wi_axis, ci0_axis)
        input_padding = input_transpose_compute(input_transpose_shape, input_tensor)
    return input_padding


def _conv3d_dw_compute(dy_tensor,  # pylint: disable=R0913,R0914
                       input_tensor,
                       input_shape,
                       filter_shape,
                       dy_shape,
                       padding,
                       stride,
                       dtype="float16"):
    n_axis, do_axis, co1_axis, ho_axis, wo_axis, co0_axis = dy_shape
    n_axis, di_axis, ci1_axis, hi_axis, wi_axis, ci0_axis = input_shape

    # dy_tensor fractal
    hw_block = 16
    block_size = 16
    hw_pad = (ho_axis * wo_axis + hw_block - 1) // hw_block * hw_block

    dy_hwpad_shape = (co1_axis, n_axis * do_axis, hw_pad, co0_axis)
    dy_hwpad = dy_hwpad_compute(dy_hwpad_shape, dy_tensor, dtype)

    dy_trans_shape = (1, co1_axis, n_axis * do_axis * hw_pad // hw_block, co0_axis, hw_block)
    dy_l0a = dy_load2d_compute(dy_trans_shape, dy_hwpad)

    ci1_axis, kd_axis, kh_axis, kw_axis, co_axis, ci0_axis = filter_shape

    axis_info_dict = {
        "N": n_axis,
        "Do": do_axis,
        "Co1": co1_axis,
        "Co": co_axis,
        "Ho": ho_axis,
        "Wo": wo_axis,
        "Di": di_axis,
        "Ci1": ci1_axis,
        "Ci0": ci0_axis,
        "Ci": ci1_axis * ci0_axis,
        "Hi": hi_axis,
        "Wi": wi_axis,
        "Kd": kd_axis,
        "Kh": kh_axis,
        "Kw": kw_axis,
        "padding": padding,
        "stride": stride
    }

    input_padding = _get_input_padding(axis_info_dict, input_tensor, dtype)

    # input im2col
    hw_len = ho_axis * wo_axis
    input_im2col_shape = (1, n_axis * do_axis * hw_len, kd_axis * ci1_axis, kh_axis, kw_axis, ci0_axis)
    input_im2col = input_im2col_compute(
        input_im2col_shape, input_padding, dtype, dy_shape, filter_shape, padding, stride)

    # input L0B fractal 小n_axis大Z trans
    input_fractal_shape = (1, n_axis * do_axis * hw_pad // hw_block,
                           kd_axis * ci1_axis * kh_axis * kw_axis, ci0_axis, hw_block)
    input_l0b = input_fractal_compute(input_fractal_shape, dy_shape, input_im2col, dtype)

    # mad
    mad_shape = (1, kd_axis * ci1_axis * kh_axis * kw_axis, co1_axis * block_size, ci0_axis)
    mad_res = mad_compute(mad_shape, dy_l0a, input_l0b, dy_shape)

    mad_ub_shape = (kd_axis * ci1_axis * kh_axis * kw_axis, co_axis, ci0_axis)
    dw_ub = tvm.compute(mad_ub_shape,
                        lambda i, j, k: mad_res(0, i, j, k),
                        name='dw_ub',
                        tag="mem_copy",
                        attrs={
                            'axis': ["Ci1 * Kd * Kh * Kw", "Co1 * Co0", "Ci0"],
                            "axis_info": axis_info_dict
                        })

    return dw_ub, input_tensor


def conv3d_backprop_filter(input_shape,  # pylint: disable=R0913
                           filter_shape,
                           dy_shape,
                           padding,
                           stride,
                           dtype="float16"):
    """
    :param dy_shape:
    :param dtype:
    :param input_shape:
    :param filter_shape:
    :param padding:
    :param stride:
    :return:
    """
    if dtype != "float16":
        raise RuntimeError("unsupport dtype: %s!" % dtype)
    dy_input = tvm.placeholder(dy_shape, name='dy_input', dtype=dtype)
    input_tensor = tvm.placeholder(input_shape, name='input', dtype=dtype)
    res, _ = _conv3d_dw_compute(dy_input,
                                input_tensor,
                                input_shape,
                                filter_shape,
                                dy_shape,
                                padding,
                                stride,
                                dtype=dtype)
    return res
