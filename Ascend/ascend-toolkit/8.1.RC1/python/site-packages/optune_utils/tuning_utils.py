#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.

Define the tuning utils
"""
import os
import json
import time
import copy
import shutil
from distutils import dir_util
from typing import List

import numpy

from tbe.common.platform.platform_info import get_soc_spec
from tbe.common.rl_bank.dynamic_op_filter import dynamic_op_filter
from tbe.common.rl_bank.rl_op_filter import rl_op_filter
from tbe.common.tiling.tiling_api import instance_refresh
from optune_utils import log
from auto_tune.file_manager_module.repo_file_manager import cube_custom_repo_migrate
from auto_tune.update_repository import build_id
from auto_tune.update_repository import merge_bank_files
from auto_tune.util_atc import FILE_FLAG
from auto_tune.util_atc import FILE_MODE_640
from auto_tune.util_atc import DIR_MODE_750
from auto_tune.util_atc import VERSION_DICT
from auto_tune.util_atc import enable_auto_tune_support
from auto_tune.util_atc import remove_file
from schedule_search.tune_util import vector_custom_repo_migrate
from tik_tune.tik_tune_main import TIK_TUNE_SUPPORT_OP_TYPE


#COMPILE_OP wait time
COMPILE_TIMEOUT = 600
# int4\bfloat16\uint1 numpy is not support
SUPPORT_DTYPE = ('int64', 'uint64', 'float16', 'float', 'int32', 'uint32', 'uint8',
                'float32', 'int8', 'int16', 'uint16', 'bool', 'double')
DTYPE_SIZE = {
    'int64': 8,
    'uint64': 8,
    'float16': 2,
    'float': 4,
    'int32': 4,
    'uint32': 4,
    'uint8': 1,
    'float32': 4,
    'int8': 1,
    'int16': 2,
    'uint16': 2,
    'bool': 1,
    'double': 8
}
AOE_DATA = "aoe_data"

def tuning_get_json(file_path: str, graph_name: str) -> dict:
    """
    tuning_get_single_op_json
    """
    op_dict = {}
    file_list = os.listdir(file_path)
    for t_file in file_list:
        if not (t_file.startswith("fusion_op_") and t_file.endswith(".json")):
            continue
        with open(os.path.join(file_path, t_file), "r") as f_handle:
            json_dict = json.load(f_handle)
            json_str = json.dumps(json_dict)
            scope_id = json_dict.get("scope_id", None)
            graph_n = json_dict.get("graph_name", None)
            if graph_n != graph_name:
                continue
            if scope_id:
                op_dict[str(scope_id)] = json_str
                continue
            kernel_name = json_dict["SocInfo"].get("kernel_name", None)
            if kernel_name:
                op_dict[str(kernel_name)] = json_str
    return op_dict


def get_ori_node_name(json_str: str) -> str:
    """
    get_ori_node_name
    """
    json_dict = json.loads(json_str)
    ori_node_name = str()
    for op in json_dict.get("op_list"):
        if op.get("type") == 'Data':
            continue
        if not op.get("ori_name"):
            continue
        node_name = "+".join(op.get("ori_name"))
        ori_node_name = "%s+%s" % (ori_node_name, node_name)
    return ori_node_name


def get_file_list(path: str) -> List[str]:
    """
    get_file_list
    """
    file_list = []
    path = os.path.realpath(path)
    for cur_root, _, files in os.walk(path):
        for name in files:
            file_path = os.path.join(path, cur_root, name)
            file_list.append(file_path)
    return file_list


def create_folder(folder: str) -> bool:
    """
    create_folder
    """
    folder = os.path.realpath(folder)
    is_exists = os.path.exists(folder)
    if not is_exists:
        os.makedirs(folder, DIR_MODE_750, exist_ok=True)
    log.info("create_folder[%s]: is_exists[%s]!" % (str(folder), str(is_exists)))
    return True


def remove_folder(folder: str) -> bool:
    """
    remove_folder
    """
    folder = os.path.realpath(folder)
    is_exists = os.path.exists(folder)
    if is_exists:
        shutil.rmtree(folder, ignore_errors=True)
    log.info("remove_folder[%s]: is_exists[%s]!" % (str(folder), str(is_exists)))
    return True


def remove_repeat_json(file_path: str) -> dict:
    """
    remove_repeat_json
    """
    file_list = os.listdir(file_path)
    file_scopeid_dict = {}
    for t_file in file_list:
        if not (t_file.startswith("fusion_op_") and t_file.endswith(".json")):
            continue
        file_name_split_list = t_file.split('_')
        json_file_name = "_".join(file_name_split_list[:-2])
        scope_id = file_name_split_list[-1].split('.')[0]
        if json_file_name in file_scopeid_dict:
            remove_file(os.path.join(file_path, t_file))
            log.info("remove_repeat_json[%s].", str(t_file))
            file_scopeid_dict[json_file_name] = file_scopeid_dict.get(json_file_name) + "," + scope_id
        else:
            file_scopeid_dict[json_file_name] = scope_id
    scopeid_dict = {}
    for item in file_scopeid_dict.values():
        main_scope_id = item.split(',')[0]
        scopeid_dict[main_scope_id] = item
    return scopeid_dict


def tuning_get_mode(json_str: str) -> str:
    """
    tuning_get_mode
    """
    json_dict = json.loads(json_str)
    if rl_op_filter.is_conv2d_l1fusion(json_dict):
        log.info("tuning_get_mode: op is conv2d L1fusion, so tune mode is RL.")
        return "RL"

    ga_support = enable_auto_tune_support()
    tuning_mode = "vector"
    is_dynamic_impl_flag = False
    is_dyn_flag = False
    for op in json_dict.get("op_list", []):
        op_type = op.get("type")
        if op.get("is_dynamic_impl", False):
            is_dynamic_impl_flag = True
        if op.get("dyn_flag", False):
            is_dyn_flag = True
        if op_type == "Data":
            continue
        if op_type in ga_support:
            tuning_mode = "GA"
            break
        if op_type in TIK_TUNE_SUPPORT_OP_TYPE:
            tuning_mode = "TIK"
            log.info("#tuning_get_mode# get tik op:%s", op_type)
            break

    if tuning_mode == "vector":
        tuning_mode = tuning_get_vec_mode(json_dict, is_dynamic_impl_flag, is_dyn_flag)

    return tuning_mode


def tuning_get_vec_mode(json_dict: dict, is_dynamic_impl_flag: bool, is_dyn_flag: bool) -> str:
    """
    tuning_get_vec_mode
    """
    if not is_dynamic_impl_flag and not is_dyn_flag:
        tuning_mode = "RL"
        op_filter_func = rl_op_filter.rl_check_support
    elif is_dynamic_impl_flag and not is_dyn_flag:
        tuning_mode = "AS"
        op_filter_func = dynamic_op_filter.check_op_support
    else:
        return ""

    try:
        if not op_filter_func(json_dict):
            tuning_mode = ""
    except (KeyError, TypeError) as e:
        log.warn("rl_check_support meets something. excption: %s, op_info_list: %s.",
                    repr(e), json_dict.get("op_list"))
        tuning_mode = ""
    finally:
        log.debug("rl_check_support tuning_mode:%s, kernel_name:%s",
                    tuning_mode, json_dict.get("fusion_op_name"))
    return tuning_mode


def tuning_get_coretype(json_str: str) -> str:
    """
    tuning_get_coretype
    """
    json_dict = json.loads(json_str)
    return json_dict.get("SocInfo", {}).get("coreType", "")


def tuning_get_aicore_graph(file_path: str) -> List[str]:
    """
    tuning_get_aicore_graph
    """
    file_list = []
    for file_s in os.listdir(file_path):
        if file_s.startswith("aicore_subgraph_") and file_s.endswith(".txt"):
            file_list.append(os.path.join(file_path, file_s))
    return file_list


def validate_bank_path(file_path: str) -> bool:
    """
    check if file_path valid
    """
    if not os.path.isdir(file_path) or not os.access(file_path, os.R_OK | os.W_OK | os.X_OK):
        log.error("%s is not dir or is without access.", file_path)
        return False
    return True


def copy_src_to_dst(src_dir_path: str, dst_dir_path: str) -> bool:
    """
    copy_src_to_dst
    :param src_dir_path: bank path
    :param dst_dir_path: bank path
    :return: True or False
    """
    src_dir_path = os.path.realpath(src_dir_path)
    dst_dir_path = os.path.realpath(dst_dir_path)
    if not validate_bank_path(src_dir_path) or not validate_bank_path(dst_dir_path):
        return False
    soc_version = get_soc_spec("SHORT_SOC_VERSION")
    src_dir_path_soc = os.path.join(src_dir_path, soc_version)
    if not os.path.isdir(src_dir_path_soc):
        return True
    dst_dir_path_soc = os.path.join(dst_dir_path, soc_version)
    if os.path.isdir(dst_dir_path_soc):
        try:
            dir_util.copy_tree(src_dir_path_soc, dst_dir_path_soc)
        except OSError as e:
            log.error("Failed to copy src_path [%s] to dst_path [%s]. Error = %s", src_dir_path_soc, dst_dir_path, e)
            return False
        finally:
            pass
    else:
        try:
            shutil.copytree(src_dir_path_soc, dst_dir_path_soc)
        except OSError as e:
            log.error("Failed to copy src_path [%s] to dst_path [%s]. Error = %s", src_dir_path_soc, dst_dir_path, e)
            return False
        finally:
            pass
    return True


def update_custom_bank(tmp_bank_path: str, custom_bank_path: str) -> bool:
    """
    update_custom_bank
    :param tmp_bank_path: tmp bank path in ./fusion dir
    :param custom_bank_path: custome bank path in aoe/data
    :return:
    """
    tmp_bank_path = os.path.realpath(tmp_bank_path)
    custom_bank_path = os.path.realpath(custom_bank_path)
    if not validate_bank_path(tmp_bank_path) or not validate_bank_path(custom_bank_path):
        return False
    soc_version = get_soc_spec("SHORT_SOC_VERSION")
    dir_list = [custom_bank_path, tmp_bank_path]
    return merge_bank_files(dir_list, soc_version)


def get_input_shape(json_str: str, optune_option: dict) -> dict:
    """
    get input_shape from json_str
    :param json_str: json for optune
    :param optune_option: option for optune
    :return:
    """
    json_dict = json.loads(json_str)
    func_in_compile = {
        'prerun': (instance_refresh, ["auto_tiling", None, {}]),
        'postrun':(instance_refresh, ["auto_tiling", None, {}])}
    compile_key = "GA_compile_%s_%s" % (os.getpid(), str(time.time()).replace(".", "_")[-9:])
    compile_dict = {}
    compile_dict[compile_key] = {
        "json_str": json_str,
        "pre_and_post": func_in_compile
    }
    compile_q = optune_option.get("global_mgr").get("compile_task_d")
    compile_r = optune_option.get("global_mgr").get("compile_result_d")
    compile_q.put(compile_dict)
    compile_begin = time.time()
    while True:
        if compile_key in compile_r:
            compile_res = copy.deepcopy(compile_r.get(compile_key))
            optune_option.get("global_mgr").get("release_compile_q").put(compile_key)
            break
        if time.time() - compile_begin > COMPILE_TIMEOUT:
            log.warn("auto_tune can not get shape args.")
            raise TimeoutError("auto_tune get shape args failed.")
    shape_args = {}
    shape_args = compile_res.get("post_res").get("input_params")
    shape_args['test_case'] = json_dict.get("fusion_op_name")
    soc_version = json_dict.get("SocInfo").get("socVersion")
    shape_args['platform'] = VERSION_DICT[soc_version]
    return shape_args


def dump_fusion_json(json_str: str, dump_path: str, multi_tune: object, dup_check: bool = False) -> bool:
    """
    dump fusion json to kernel_meta directory
    """
    # get json data
    json_data = json.loads(json_str)
    json_file_name = json_data.get("fusion_op_name")

    # delete '_rl'/'_gl' suffix
    if json_file_name.endswith('_rl') or json_file_name.endswith('_ga'):
        json_file_name = json_file_name[:-3]
        json_data["fusion_op_name"] = json_file_name

    # remove sequence in file name
    if dup_check:
        json_file_name = "_".join(json_file_name.split('_')[:-1])
    try:
        shape_args = get_input_shape(json_str, {"global_mgr": multi_tune.global_mgr.mgr_dict})
        json_data['ttao_unique_id'] = build_id(shape_args)
        json_data['ttao_shape_args'] = shape_args
    except (TypeError, RuntimeError, IndexError, KeyError, TimeoutError, AttributeError):
        pass
    finally:
        pass
    json_str = json.dumps(json_data)
    dump_path = os.path.realpath(dump_path)

    if not os.path.exists(dump_path):
        os.mkdir(dump_path, DIR_MODE_750)

    dump_file = os.path.join(dump_path, "fusion_op_{}.json".format(json_file_name))
    if os.path.isfile(dump_file):
        os.remove(dump_file)
    with os.fdopen(os.open(dump_file, FILE_FLAG, FILE_MODE_640), "w") as fp:
        fp.write(json_str)
    return True


def jsonstr_set_new_item(json_str: str, new_item: object, value: object) -> str:
    """
    jsonstr_set_new_item
    """
    json_dict = json.loads(json_str)
    json_dict[new_item] = value
    return json.dumps(json_dict)


def repo_migrate() -> bool:
    """
    migrate cube and vector custom repo
    """
    tune_bank_path = os.getenv("TUNE_BANK_PATH", "")
    ascend_cache_path = os.getenv("ASCEND_CACHE_PATH", "")
    if tune_bank_path and not validate_bank_path(tune_bank_path):
        return False
    if ascend_cache_path and not validate_bank_path(os.path.join(ascend_cache_path, AOE_DATA)):
        return False
    log.info("Start to migrate repo for cube and vector.")
    cube_custom_repo_migrate()
    vector_custom_repo_migrate()
    log.info("Finish migrate repo for cube and vector.")
    return True


def gen_random_bytes_data(low: int, high: int, dtype: str, bytes_size: int) -> bytes:
    """
    Draw samples from a uniform distribution.
    Samples are uniformly distributed over the half-open interval [low, high) (includes low, but excludes high).
    In other words, any value within the given interval is equally likely to be drawn by uniform.
    The total returned number is 1 MB.

    Information supplement:
    Currently, the NPU and NumPy data is organized in little-endian mode and can be directly used.
    """
    if dtype not in SUPPORT_DTYPE:
        dtype = "uint8"
    return numpy.random.uniform(
        low, high, int(bytes_size / DTYPE_SIZE.get(dtype, DTYPE_SIZE["uint8"]))).astype(dtype).tobytes()