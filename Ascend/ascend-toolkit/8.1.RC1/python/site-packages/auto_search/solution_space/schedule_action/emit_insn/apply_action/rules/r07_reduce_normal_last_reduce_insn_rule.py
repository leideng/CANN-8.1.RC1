#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
# Copyright (c) Huawei Technologies Co., Ltd. 2022-2022. All rights reserved.
"""
reduce last reduce insn rule
"""
from auto_search.solution_space.tensor_cfg import FeatureTensorCfg
from auto_search.solution_space.progress import Progress
from auto_search.bank.cheque_generator import get_emit_insn_cheque
from auto_search.solution_space.schedule_action.emit_insn.apply_action.rules.comm import get_use_ub_size


def proc(progress: Progress) -> bool:
    """
    :param progress:
    :return:
    """
    op_schedule_info = progress.op_schedule_info
    if op_schedule_info.is_atomic:
        return True

    # reduce emit insn after rfactor
    ub_split_last_reduce_axis = op_schedule_info.last_reduce_and_ub_split_last_reduce_axis
    ub_split_nlast_reduce_axis = op_schedule_info.last_reduce_and_ub_split_nlast_reduce_axis
    if ub_split_last_reduce_axis or ub_split_nlast_reduce_axis:
        return _last_reduce_and_ub_split_r_axis(progress, ub_split_last_reduce_axis, ub_split_nlast_reduce_axis)
    # reduce do ub_transpose emit insn
    if op_schedule_info.is_ub_transpose:
        return _ar_and_enable_ub_transpose(progress)
    return True


def _last_reduce_and_ub_split_r_axis(progress: Progress, ub_split_last_reduce_axis: bool,
                                     ub_split_nlast_reduce_axis: bool) -> bool:
    """
    :param progress:
    :return:
    """
    op_schedule_info = progress.op_schedule_info

    stage_index = op_schedule_info.stage_index
    if op_schedule_info.proc_flag_dict.get(stage_index, False):
        return True

    stage_type = op_schedule_info.stages_info[stage_index].get('type', [])

    if "reduce_rfactor" in stage_type:
        _do_emit_insn_for_reduce_rfactor(op_schedule_info, ub_split_last_reduce_axis, ub_split_nlast_reduce_axis)
    elif "CacheWrite" in stage_type and "reduce" in stage_type:
        _do_emit_insn_for_reduce_cachewrite(op_schedule_info)

    return True


def _do_emit_insn_for_reduce_cachewrite(op_schedule_info):
    """
    :param op_schedule_info:
    :return:
    """
    stage_index = op_schedule_info.stage_index
    stage_name = op_schedule_info.stage_name
    curr_axis_info_list = op_schedule_info.axis_info_list[stage_index]
    # reduce emit insn need extra_space
    extra_space = get_use_ub_size(op_schedule_info)

    # reduce stage emit insn axis is the last reduce_axis(ub split inner axis)
    emit_insn_axis_index = 0
    for axis_index, axis_info in enumerate(curr_axis_info_list):
        if axis_info.type == "reduce_axis":
            emit_insn_axis = axis_info
            emit_insn_axis_obj = emit_insn_axis.body
            emit_insn_axis_index = axis_index
    attrs = {'storage_bound': extra_space}
    intrinsic_func_name = op_schedule_info.op_intrin_key_index[
        op_schedule_info.feature_tensor[stage_index][FeatureTensorCfg.compute_s]].intrin
    code_line = f"sch[{stage_name}].emit_insn({emit_insn_axis.name}, '{intrinsic_func_name}', {str(attrs)})"
    op_schedule_info.code_lines.append(code_line)
    op_schedule_info.stage.emit_insn(emit_insn_axis_obj, intrinsic_func_name, attrs=attrs)
    # gen emit_insn cheque
    cheque = get_emit_insn_cheque(stage_index, intrinsic_func_name,
                         (emit_insn_axis.name, emit_insn_axis_index), extra_info=attrs)
    op_schedule_info.cheque_list.append(cheque)
    op_schedule_info.proc_flag_dict[stage_index] = True


def _do_emit_insn_for_reduce_rfactor(op_schedule_info, ub_split_last_reduce_axis, ub_split_nlast_reduce_axis):
    """
    :param op_schedule_info:
    :param ub_split_last_reduce_axis:
    :param ub_split_nlast_reduce_axis:
    :return:
    """
    stage_index = op_schedule_info.stage_index
    stage_name = op_schedule_info.stage_name
    curr_axis_info_list = op_schedule_info.axis_info_list[stage_index]
    # reduce emit insn need extra_space
    extra_space = get_use_ub_size(op_schedule_info)

    emit_insn_axis_index = 0
    for axis_index, axis_info in enumerate(curr_axis_info_list):
        if ub_split_last_reduce_axis:
            # if ub split on last reduce axis
            # rfactor stage emit insn axis is ub split inner axis(last a axis after rfactor)
            if axis_info.type == "axis":
                emit_insn_axis = axis_info
                emit_insn_axis_obj = emit_insn_axis.body
                emit_insn_axis_index = axis_index
        elif ub_split_nlast_reduce_axis:
            # if ub split on nlast reduce axis
            # rfactor stage emit insn axis is ub split inner axis
            if axis_info.type == "reduce_axis" and axis_info.name.endswith('i'):
                emit_insn_axis = axis_info
                emit_insn_axis_obj = emit_insn_axis.body
                emit_insn_axis_index = axis_index
                break
    attrs = {'storage_bound': extra_space}
    intrinsic_func_name = op_schedule_info.op_intrin_key_index[
        op_schedule_info.feature_tensor[stage_index][FeatureTensorCfg.compute_s]].intrin
    code_line = f"sch[{stage_name}].emit_insn({emit_insn_axis.name}, '{intrinsic_func_name}', {str(attrs)})"
    op_schedule_info.code_lines.append(code_line)
    op_schedule_info.stage.emit_insn(emit_insn_axis_obj, intrinsic_func_name, attrs=attrs)
    cheque = get_emit_insn_cheque(stage_index, intrinsic_func_name,
                         (emit_insn_axis.name, emit_insn_axis_index), extra_info=attrs)
    op_schedule_info.cheque_list.append(cheque)
    op_schedule_info.proc_flag_dict[stage_index] = True


def _ar_and_enable_ub_transpose(progress: Progress) -> bool:
    """
    :param progress:
    :return:
    """
    op_schedule_info = progress.op_schedule_info

    stage_index = op_schedule_info.stage_index
    if op_schedule_info.proc_flag_dict.get(stage_index, False):
        return True

    if {'align_pad', 'remove_pad'} & set(op_schedule_info.stages_info[stage_index].get('type', [])):
        return True

    stage_name = op_schedule_info.stage_name
    axis_info_list = op_schedule_info.axis_info_list
    curr_axis_info_list = axis_info_list[stage_index]
    if not curr_axis_info_list:
        return True
    stage_type = op_schedule_info.stages_info[stage_index].get('type', [])
    if "CacheWrite" in stage_type and "reduce" in stage_type:
        op_schedule_info.is_ub_transpose = False
        emit_insn_axis_index = 0
        for axis_index, axis_info in enumerate(curr_axis_info_list):
            if axis_info.type == "axis" and axis_info.name.endswith('i'):
                emit_insn_axis = axis_info
                emit_insn_axis_obj = emit_insn_axis.body
                emit_insn_axis_index = axis_index

        attrs = {'trans': True}

        intrinsic_func_name = op_schedule_info.op_intrin_key_index[
            op_schedule_info.feature_tensor[stage_index][FeatureTensorCfg.compute_s]].intrin
        code_line = f"sch[{stage_name}].emit_insn({emit_insn_axis.name}, '{intrinsic_func_name}', {str(attrs)})"
        op_schedule_info.code_lines.append(code_line)

        op_schedule_info.stage.emit_insn(emit_insn_axis_obj, intrinsic_func_name, attrs=attrs)

        cheque = get_emit_insn_cheque(stage_index, intrinsic_func_name,
                             (emit_insn_axis.name, emit_insn_axis_index), extra_info=attrs)
        op_schedule_info.cheque_list.append(cheque)
        op_schedule_info.proc_flag_dict[stage_index] = True
        op_schedule_info.is_ub_transpose = True
    return True
