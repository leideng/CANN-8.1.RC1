#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
# Copyright (c) Huawei Technologies Co., Ltd. 2022-2022. All rights reserved.
"""
common apply action
"""
import copy

from tbe.common.platform import platform_info

from auto_search.utils import logger
from auto_search.solution_space.action import apply_action_register
from auto_search.solution_space.action import ScheduleActionType
from auto_search.compute_analysis import ComputePattern
from auto_search.solution_space.op_schedule_info import AtInfo
from auto_search.bank.cheque_generator import get_cache_read_cheque
from auto_search.bank.cheque_generator import get_cache_clone_cheque


def get_cache_clone_name(ori_tensor_name, scope, index=None, ub2l1=False):
    """
    get cache clone name
    :param ori_tensor_name:
    :param scope:
    :param index:
    :return:
    """
    head = ''
    tail = ''
    if ub2l1:
        head = 'sub'
    elif scope in [platform_info.scope_cbuf, platform_info.scope_ubuf]:
        tail = '_l'
    elif scope in [platform_info.scope_cc, platform_info.scope_ca,
                   platform_info.scope_cb]:
        head = 'sub'

    if index is not None:
        index_str = "_%03d" % index
    else:
        index_str = ""

    return head + ori_tensor_name + tail + index_str


def gen_cache_clone_info(cur_tensor,
                         all_tensors,
                         scope,
                         stage_info,
                         cache_clone_buff_with_ori_tenser_map):
    """
    gen cache clone info
    :param cur_tensor:
    :param all_tensors:
    :param scope:
    :param stage_info:
    :return:
    """
    tensor_name = cur_tensor.op.name
    cache_clone_info = {
        "scope": scope,
        "name": stage_info["name"],
    }


    ori_tensor_name = stage_info.get("ori_name", tensor_name)
    cache_clone_info['clone_name'] = get_cache_clone_name(ori_tensor_name,
                                                          scope,
                                                          index=10)
    cache_clone_info["tensor"] = cur_tensor
    cache_clone_info['fanout_tensors'] = []
    workspace_info = stage_info["at_info"]
    consumers_in_group = workspace_info.consumers_in_group()
    for i, group in enumerate(consumers_in_group):
        consumer_tensor = [
            all_tensors[consumer.index]
            for consumer in group
        ]
        if 'cache_clone' in stage_info.get("type", []) and i == 0:
            cache_clone_info['consumers'] = [consumer.index for consumer in group]
            for tensor in consumer_tensor:
                cache_clone_info.get('fanout_tensors', []).append(tensor)
        elif set(consumer_tensor) & set(cache_clone_buff_with_ori_tenser_map.keys()):
            cache_clone_info['consumers'] = [consumer.index for consumer in group]
            for tensor in consumer_tensor:
                cache_clone_info.get('fanout_tensors', []).append(cache_clone_buff_with_ori_tenser_map[tensor])

    return cache_clone_info


def _update_other_stage_info(cache_clone_info, consumer, clone_at_info, stages_info):
    """

    :param cache_clone_info:
    :param consumer:
    :param clone_at_info:
    :param stages_info:
    :return:
    """
    for stage_info in stages_info:
        if stage_info['at_info'].index in cache_clone_info['consumers'] \
                and 'cache_clone_ub' not in stage_info.get('type', []):
            at_target = stage_info['at_info'].consumers[0].sampled_target
            consumer.set_sampled_target(at_target)
        elif stage_info['at_info'].index in cache_clone_info['consumers'] \
                and 'cache_clone_ub' in stage_info.get('type', []):
            at_target = stage_info['at_info'].consumers[0].sampled_target
            clone_at_info.consumers[0].set_sampled_target(at_target)


def update_stages_info(op_schedule_info, cache_clone_info, clone_tensor):
    """
    update stages info
    :param op_schedule_info:
    :param cache_clone_info:
    :param clone_tensor:
    :return:
    """
    stages_info = op_schedule_info.stages_info
    src_stage_info = stages_info[cache_clone_info.get("tensor_ori_index")]
    src_at_info = src_stage_info['at_info']
    clone_at_info = AtInfo(src_at_info.index)
    sch = op_schedule_info.schedule_obj

    for i, consumer in enumerate(src_at_info.consumers):
        if consumer.index in cache_clone_info['consumers']:
            clone_at_info.consumers.append(copy.deepcopy(consumer))
            # first cache clone tensor stage info update
            if 'cache_clone' in src_stage_info.get('type', []):
                src_at_info.consumers.pop(i)
            # other cache clone tensor stage info update
            else:
                _update_other_stage_info(cache_clone_info, consumer, clone_at_info, stages_info)

    clone_stage_index = list(sch.stages).index(sch[clone_tensor])
    clone_stage_info = {
        'name': cache_clone_info['clone_name'],
        'type': ["cache_clone_ub"],
        'scope': str(cache_clone_info['scope']),
        'at_info': clone_at_info,
        'ori_name': src_stage_info.get('ori_name'),
        'tag': src_stage_info.get('tag'),
        "clone_tensor": clone_tensor
    }

    stages_info.insert(clone_stage_index, clone_stage_info)


def do_cache_clone(op_schedule_info, cache_clone_info):
    """
    do cache clone
    :param op_schedule_info:
    :param cache_clone_info:
    :return:
    """
    clone_tensor_name = cache_clone_info['clone_name']
    buf = cache_clone_info['scope']
    stage_names = (stage_info["name"] for stage_info in op_schedule_info.stages_info)
    tensor_ori_index = list(stage_names).index(cache_clone_info['name'])
    cache_clone_info["tensor_ori_index"] = tensor_ori_index

    sch = op_schedule_info.schedule_obj
    code_lines = []
    out_name_list = []
    real_fanouts = []
    consumer_stage_idx_list = []
    for fanout_tensor in cache_clone_info['fanout_tensors']:
        fanout_index = list(sch.stages).index(sch[fanout_tensor])
        real_fanouts.append(fanout_tensor)
        out_name_list.append(op_schedule_info.stages_info[fanout_index]["name"])
        consumer_stage_idx_list.append(fanout_index)

    if not {'placeholder', 'workspace'} & set(op_schedule_info.stages_info[tensor_ori_index].get('type', [])):
        code_line = "%s = sch.cache_clone(%s, '%s', [%s])" % (
            clone_tensor_name, cache_clone_info['name'], str(buf), ",".join(out_name_list))
        code_lines.append(code_line)
        clone_tensor = sch.cache_clone(cache_clone_info['tensor'], buf, real_fanouts)
        cheque = get_cache_clone_cheque(tensor_ori_index, buf, consumer_stage_idx_list)
        op_schedule_info.cheque_list.append(cheque)
    else:
        code_line = "%s = sch.cache_read(%s, '%s', [%s])" % (
            clone_tensor_name, cache_clone_info['name'], str(buf), ",".join(out_name_list))
        code_lines.append(code_line)
        clone_tensor = sch.cache_read(cache_clone_info['tensor'], buf, real_fanouts)
        cheque = get_cache_read_cheque(tensor_ori_index, buf, consumer_stage_idx_list)
        op_schedule_info.cheque_list.append(cheque)

    update_stages_info(op_schedule_info, cache_clone_info, clone_tensor)
    op_schedule_info.code_lines.extend(code_lines)
    return clone_tensor


def _gen_consumer_stages_info(op_schedule_info, cache_clone_tensors, ori_all_tensors, consumer_stages_info_dict,
                              stages_info_map):
    """
    gen_consumer_stages_info
    :param op_schedule_info:
    :param cache_clone_tensors:
    :param ori_all_tensors:
    :param consumer_stages_info_dict:
    :param stages_info_map:
    :return:
    """
    stages = op_schedule_info.schedule_obj.stages
    for i, stage_info in enumerate(op_schedule_info.stages_info):
        if 'cache_clone' in stage_info.get('type', []):
            cache_clone_tensors.append(stage_info.get("name"))
        for idx in range(stages[i].op.num_outputs):
            ori_all_tensors.append(stages[i].op.output(idx))
        for consumer in op_schedule_info.stages_info[i]["at_info"].consumers:
            consumer_stage_info = op_schedule_info.stages_info[consumer.index]
            consumer_stages_info_dict.setdefault(
                stage_info["name"], []).append(consumer_stage_info["name"])
            stages_info_map[stage_info["name"]] = stage_info


def _get_need_cache_clone_tensor(cache_clone_tensors, stages_info, consumer_stages_info_dict):
    """
    get all need do cache clone tensors
    :param cache_clone_tensors:
    :param stages_info:
    :param consumer_stages_info_dict:
    :return:
    """
    workspace_tensors = []
    for stage_info in stages_info:
        if 'workspace' in stage_info.get('type', []):
            workspace_tensors.append(stage_info.get('name', ''))

    cache_clone_tensors_tmp = cache_clone_tensors[:]
    while cache_clone_tensors_tmp:
        cache_clone_tensor = cache_clone_tensors_tmp.pop()
        if cache_clone_tensor not in cache_clone_tensors:
            cache_clone_tensors.append(cache_clone_tensor)
        if cache_clone_tensor in workspace_tensors:
            continue
        for stage_name, consumers in consumer_stages_info_dict.items():
            if cache_clone_tensor in consumers:
                cache_clone_tensors_tmp.append(stage_name)


@apply_action_register([ComputePattern.NORM], ScheduleActionType.CACHE_CLONE)
def apply(progress):
    """
    chche clone apply
    :param progress:
    :return:
    """
    op_schedule_info = progress.op_schedule_info

    op_schedule_info.code_lines.extend(['\n', '# cache_clone code'])

    consumer_stages_info_dict = {}
    stages_info_map = {}
    ori_all_tensors = []
    cache_clone_tensors = []
    _gen_consumer_stages_info(op_schedule_info, cache_clone_tensors, ori_all_tensors, consumer_stages_info_dict,
                              stages_info_map)

    _get_need_cache_clone_tensor(cache_clone_tensors, op_schedule_info.stages_info, consumer_stages_info_dict)

    cache_clone_buff_with_ori_tenser_map = {}
    for tensor_name in cache_clone_tensors:
        stage_idx = op_schedule_info.stages_info.index(stages_info_map.get(tensor_name))
        tmp_tensor_list = []
        for idx in range(op_schedule_info.schedule_obj.stages[stage_idx].op.num_outputs):
            tmp_tensor_list.append(op_schedule_info.schedule_obj.stages[stage_idx].op.output(idx))

        cache_clone_info = gen_cache_clone_info(tmp_tensor_list[0],
                                                ori_all_tensors,
                                                platform_info.scope_ubuf,
                                                stages_info_map.get(tensor_name),
                                                cache_clone_buff_with_ori_tenser_map)

        cache_clone_buff_with_ori_tenser_map[tmp_tensor_list[0]] = do_cache_clone(op_schedule_info, cache_clone_info)

    logger.debug('apply cache_clone done.')
