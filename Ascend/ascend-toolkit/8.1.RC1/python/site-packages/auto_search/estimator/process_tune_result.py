#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
# Copyright (c) Huawei Technologies Co., Ltd. 2022-2022. All rights reserved.
"""
upload info for aoe and add bank
"""
import re
import os
import hashlib
import json
import time
import multiprocessing

from tbe.common.context import op_context
from tbe.common.platform.platform_info import set_current_compile_soc_info

from auto_search.config.soc_cfg import get_core_num
from auto_search.bank.add_cheque import try_add_cheque
from auto_search.utils import logger
from auto_search.estimator import om_runner
from auto_search.utils.util import ErrorCode
from auto_search.utils import util
from auto_search.utils.util import KernelInfo
from auto_search.utils.util import SchInfo
from auto_search.utils.util import WRITE_FILE_FLAGS
from auto_search.utils.util import OPEN_FILE_MODES_640


BEST_TICK_IDX = 0
CHEQUE_INFO_IDX = 2


class PostRunAsync(multiprocessing.Process):
    """
    post_process_and_update_bank_async
    """
    def __init__(self,
                 interactive_mgr: dict,
                 op_mode: str,
                 global_mgr: object,
                 main_pid: int,
                 config: dict,
                 *args,
                 **kwds) -> None:
        super(PostRunAsync, self).__init__(*args, **kwds)
        self.interactive_mgr = interactive_mgr
        self.op_mode = op_mode
        self.main_pid = main_pid
        self.config = config
        self.exit_event = global_mgr.multi_mgr.Event()
        # op_schedule_info, option_info, top_cheque_infos, tune_res_flag
        self.update_bank_list = global_mgr.multi_mgr.list()
        # indicating bank_update result
        self.update_bank_res = global_mgr.multi_mgr.list()

    @staticmethod
    def _deal_with_not_full_core_num(best_cheque_info: dict, option_info: dict) -> None:
        """
        if block_dim less core_num, need warning log and save op args
        :param best_cheque_info:
        :param option_info:
        :return:
        """
        kernel_name = option_info.get("op_config").get("kernel_name", "default")
        if best_cheque_info.get("block_dim") >= get_core_num():
            return
        logger.warn("This strategy doesn't make use of all cores.")
        suboptimal_path = option_info.get("suboptimal_path")
        if suboptimal_path == '':
            return
        suboptimal_file_name = kernel_name + ".json"
        suboptimal_file_path = os.path.join(suboptimal_path, suboptimal_file_name)
        op_desc = option_info.get("op_config").get("op_desc")
        with os.fdopen(os.open(suboptimal_file_path, WRITE_FILE_FLAGS, OPEN_FILE_MODES_640), "w") as f_handle:
            json.dump(op_desc, f_handle, sort_keys=True, indent=4)

    def run(self) -> None:
        """
        post_process_and_update_bank
        """
        logger.event("PostRunAsync start to post_process_and_update_bank.")
        while not self.exit_event.is_set():
            if not self.update_bank_list:
                continue

            op_schedule_info, option_info, top_cheque_infos, tune_res = self.update_bank_list.pop()

            soc_version = option_info.get("soc_version")
            core_type = option_info.get("op_config").get("core_type")
            core_num = option_info.get("op_config").get("core_num")
            l1_fusion = option_info.get("op_config").get("l1_fusion")
            set_current_compile_soc_info(soc_version, core_type, core_num, l1_fusion)

            kernel_name = option_info.get("op_config").get("kernel_name", "default")
            cb_struct_key = option_info.get("op_config").get("cb_struct_key")
            if not tune_res:
                # auto search failed
                # Refresh the compilation cache of the operator to prevent performance regression in result om
                self._clean_legacy_task(cb_struct_key, kernel_name)
                self._report_tune_result(option_info, op_schedule_info, False, False)
                re_get_tick, _ = self._re_get_base_tick(op_schedule_info)
                logger.warn("op %s re_get_base_tick, tick is %s.", kernel_name, re_get_tick)
                continue

            self._clean_legacy_task(cb_struct_key, kernel_name)
            best_cheque_info = self._get_best_cheque_info(op_schedule_info, top_cheque_infos, kernel_name)
            if not best_cheque_info:
                logger.warn("op %s has no valid cheque_info.", kernel_name)
                self._report_tune_result(option_info, op_schedule_info, True, False)
                continue

            self._deal_with_not_full_core_num(best_cheque_info, option_info)

            bank_updated_flag = self._check_and_update_bank(best_cheque_info, op_schedule_info)
            self._report_tune_result(option_info, op_schedule_info, True, bank_updated_flag)
        logger.event("PostRunAsync exit_event set, post_process_and_update_bank end.")

    def stop(self) -> None:
        """
        stop PostRunAsync
        """
        self.exit_event.set()
        self.join()

    def _clean_legacy_task(self, cb_struct_key: str, kernel_name: str) -> None:
        """
        clean up tasks left over from the search process
        :param cb_struct_key:
        :param kernel_name:
        """
        # tell opat this op has been tuned, clean operations could be done
        cb_key_task_clean_q = self.interactive_mgr.get("cb_key_task_clean_q", None)
        cb_key_task_clean_res_dict = self.interactive_mgr.get("cb_key_clean_res_d", None)
        if cb_key_task_clean_q is not None and cb_key_task_clean_res_dict is not None:
            logger.debug("task %s is put to cb_key_task_clean_q.", cb_struct_key)
            cb_key_task_clean_q.put(cb_struct_key)
            while cb_key_task_clean_res_dict.pop(cb_struct_key, None) is None:
                time.sleep(0.001)
            logger.debug("task %s is cleaned.", cb_struct_key)
        logger.info("all compile_and_run tasks are cleaned (cb_struct_key: %s) for op %s.",
                    cb_struct_key, kernel_name)

    def _report_tune_result(self,
                            option_info: dict,
                            op_schedule_info: object,
                            tune_res: bool,
                            bank_updated_flag: bool) -> None:
        """
        clean compile_and_run tasks and report rl tune progress
        :param option_info:
        :param op_schedule_info:
        :param tune_res:
        :param bank_updated_flag:
        :return:
        """
        kernel_name = option_info.get("op_config").get("kernel_name", "default")
        self.update_bank_res.append(bank_updated_flag)
        logger.info("op %s update_bank: %s", kernel_name, bank_updated_flag)

        tune_report_info_q = self.interactive_mgr.get("tune_report_info_q")
        job_id = option_info.get("job_id", "")
        _report_rl_tune_result(op_schedule_info, tune_report_info_q, bank_updated_flag, tune_res, job_id)

    def _check_and_update_bank(self, best_cheque_info: dict, op_schedule_info: object) -> bool:
        """
        check best_cheque_info and try to add to bank
        :param best_cheque_info: a dict, including "base_tick" "best_tick" "bank_key" "cheque"
        :param op_schedule_info: op schedule info class
        :return: T/F, bank_updated_flag
        """
        kernel_name = op_schedule_info.option.get("op_config").get("kernel_name", "default")
        kernel_name = kernel_name.split("@")[0]
        op_info_str = "{}@{}@{}".format(kernel_name, op_schedule_info.op_name, op_schedule_info.shape_list_str)
        op_mode = op_schedule_info.option.get('op_config').get("op_mode", "static")
        op_desc = op_schedule_info.option.get("op_config").get("op_desc")
        if op_schedule_info.option.get("dump_tune_op") and op_desc:
            op_desc["rl_bank_key_md5"] = hashlib.md5(
                best_cheque_info.get("bank_key").encode(encoding="utf-8")).hexdigest()
            best_cheque_info['op_desc'] = op_desc

        with op_context.OpContext(op_mode) as context:
            context.add_addition("master_pid", self.config.get("ppid"))
            ret, ret_info = try_add_cheque(best_cheque_info, op_info_str, op_mode)
        logger.info("Add custom bank ret_info: %s", ret_info)
        if not ret:
            logger.error("Add custom bank error.")
            return False
        op_schedule_info.best_tick = best_cheque_info.get("best_tick")

        return True

    def _get_best_cheque_info(self, op_schedule_info: object,
                              top_cheque_infos: list, kernel_name: str) -> dict:
        """
        put top cheques to datacmp
        :param op_schedule_info:
        :param top_cheque_infos:
        :param kernel_name:
        :return: best_cheque_info
        """
        if not top_cheque_infos:
            logger.warn("[datacmp]: op %s has no strategy need precision calibration.",
                        kernel_name)
            # Refresh the compilation cache of the operator to prevent performance regression in result om
            re_get_tick, _ = self._re_get_base_tick(op_schedule_info)
            logger.info("op %s re_get_base_tick, tick is %s.", kernel_name, re_get_tick)
            return {}

        logger.info("[datacmp]: op %s has %d strategies "
                    "put to compile_and_run task with datacmp.", kernel_name, len(top_cheque_infos))

        cheque_to_cmp = [cheque_info.get("cheque") for cheque_info in top_cheque_infos]
        ret, om_ticks, err_codes = self._re_get_tick_om(op_schedule_info, cheque_to_cmp)
        logger.info("[datacmp]: op %s datacmp feedbacks: ret: %s, om_ticks: %s, err_codes: %s.",
                    kernel_name, ret, om_ticks, err_codes)
        if not ret:
            logger.warn("[datacmp]: op %s datacmp compile_and_run tasks exit.", kernel_name)
            return {}

        tick_code_list = [(om_ticks[idx], err_codes[idx], top_cheque_infos[idx])
                          for idx in range(len(err_codes))
                          if err_codes[idx] == ErrorCode.RUN_SUCC]
        if not tick_code_list:
            logger.warn("[datacmp]: op %s has no strategy passed datacmp.", kernel_name)
            return {}

        tick_code_list.sort(key=lambda item: item[BEST_TICK_IDX])
        best_cheque_info = tick_code_list[BEST_TICK_IDX][CHEQUE_INFO_IDX]
        logger.info("[datacmp]: op %s get_best_cheque_info end, %d "
                    "valid strategies passed datacmp, "
                    "best cheque info is %s.", kernel_name, len(tick_code_list), best_cheque_info)
        return best_cheque_info

    def _re_get_tick_om(self, op_schedule_info: object, cheque_list: list) -> (bool, list, list):
        """
        re om_runner with datacmp
        :param op_schedule_info:
        :param cheque_list:
        :return: ret, om_ticks, err_codes
        """
        sch_info = SchInfo(op_schedule_info.schedule_obj, None, None, None, cheque_list)
        kernel_info = KernelInfo(None, None, sch_info)
        datacmp_args_dict = {
            "need_datacmp": True,
            "datacmp_task_q": self.interactive_mgr.get("datacmp_task_q", None),
            "datacmp_res_d": self.interactive_mgr.get("datacmp_res_d", None)
        }
        runner = om_runner.OMRunner(op_schedule_info, kernel_info, run_base=False, datacmp_args_dict=datacmp_args_dict)
        ret, om_ticks, err_codes = runner.run()
        return ret, om_ticks, err_codes

    def _re_get_base_tick(self, op_schedule_info: object) -> tuple:
        """
        :param op_schedule_info:
        :return:
        """
        runbase_args_dict = {"re_runbase": True,
                             "rerun_task_q": self.interactive_mgr.get("tune_task_d", None),
                             "rerun_res_d": self.interactive_mgr.get("tune_result_d", None),
                             "rerun_release_q": self.interactive_mgr.get("release_tune_q", None)}
        runner = om_runner.OMRunner(op_schedule_info, None, run_base=True, datacmp_args_dict=runbase_args_dict)
        _, base_tick, err_code = runner.run()
        return base_tick, err_code


def _report_rl_tune_result(op_schedule_info: object,
                           tune_report_info_q: object,
                           update_bank: bool,
                           tune_op_succ: bool,
                           job_id: str) -> None:
    """
    report rl tune result after tune
    :param update_bank
    :param tune_op_succ
    :param job_id
    """
    status_data = {}
    res_data = {}
    hit_bank = op_schedule_info.option.get("op_config").get("hit_bank", False)
    op_type = op_schedule_info.option.get("op_config").get("op_type", "").split("__")
    op_type_print = op_type[0] if len(op_type) == 1 else op_type
    build_op_name = op_schedule_info.option.get("profiling_name", "")
    status_data["bank_hit"] = hit_bank
    status_data["bank_update"] = False
    status_data["bank_append"] = False
    status_data["bank_reserved"] = hit_bank
    status_data["bank_unsatisfied"] = False

    if update_bank:
        res_data["performance_after_tune(us)"] = op_schedule_info.best_tick
        res_data["performance_before_tune(us)"] = op_schedule_info.base_tick
        res_data["performance_improvement"] = "{:.2%}".format(
                        (op_schedule_info.base_tick - op_schedule_info.best_tick) / op_schedule_info.best_tick)
        if hit_bank:
            status_data["bank_update"] = True
            status_data["bank_reserved"] = False
        else:
            status_data["bank_append"] = True
        res_data["update_mode"] = "update" if status_data.get("bank_update", False) else "add"
    if not update_bank and not hit_bank and tune_op_succ:
        status_data["bank_unsatisfied"] = True

    if tune_report_info_q:
        report_info = {
            "job_id": job_id,
            "tune_mode": "Schedule",
            "op_type": op_type_print,
            "op_name": build_op_name,
            "tune_op_succ": tune_op_succ,
            "status_data": status_data,
            "result_data": res_data
        }
        tune_report_info_q.put(report_info)
        logger.debug("report tune result, op_name: %s, tune_op_succ: %s", build_op_name, tune_op_succ)
