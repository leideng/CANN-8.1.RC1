#!/usr/bin/env python
# -*- coding: UTF-8 -*-
# Copyright 2021-2022 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
opc fusion op compile
"""
import json
import copy

from tbe.common.buildcfg import build_config
from tbe import tvm
from tbe.tvm.target import cce as _cce
from tbe.common.buildcfg import set_L1_info
from tbe.dsl.unify_schedule.constants import Pattern
from tbe.dsl import auto_schedule
from tbe.common.context import op_context
from tbe.common.utils import log as logger
from tbe.tvm._api_config import api_config
from op_manager import get_compute_op_func
from constant import (OpcOptions, CompileParam)
from opc_common import get_new_attrs_for_op_compile, update_compile_info, get_json_file_path
import fusion_op_utils
import op_tensor_utils


class FusionOpCompile:
    """
    class for opc to compile fusion tbe op
    """

    def __init__(self, opc_compile_args, json_dict):
        """
        init
        :param json_dict: parse paras for fusion op compile
        :param opc_compile_args: type is namedtuple of COMPILE_PARAS, defined in opc_common
        """
        self.__opc_compile_args = opc_compile_args
        self.__json_dict = json_dict
        self.__use_int64_mode = False
        self.__fusion_op_impl_mode = {}

    def __call_op_compute(self, op_node, ins_attrs_options, op_input_list, dyn_input_dict,
                          ins_list_none=False):  # 'pylint: disable=too-many-locals
        """
        call op compute
        """
        with _cce():
            op_compute_func = get_compute_op_func(op_node[CompileParam.TYPE])
            if op_compute_func is None:
                raise RuntimeError("Compute function of node[{}] is null.".format(op_node.get(CompileParam.NAME)))

            all_args = op_input_list
            # add dyn input para to commpute args
            for dyn_input in dyn_input_dict:
                all_args.append(dyn_input_dict[dyn_input])
            fusion_op_utils.get_output_attrs_for_all_args(all_args, op_node, ins_list_none, ins_attrs_options)

            kernel_kwds = fusion_op_utils.get_fusion_op_kernel_name(op_compute_func,
                                                    self.__opc_compile_args.get(OpcOptions.BIN_FILENAME))
            json_data = self.__opc_compile_args[OpcOptions.FUSION_OP_PARAM]
            fusion_op_impl_mode = dict()
            op_impl_kwds = \
                fusion_op_utils.get_impl_mode(json_data[CompileParam.SOC_INFO].get(OpcOptions.IMPL_MODE, None),
                              op_node.get(OpcOptions.IMPL_MODE, None), op_compute_func,
                              op_node.get(CompileParam.NAME), fusion_op_impl_mode)
            self.__fusion_op_impl_mode.update(fusion_op_impl_mode)
            options_kwds = fusion_op_utils.get_options_kwds(op_node, op_compute_func, ins_list_none, ins_attrs_options)
            all_args_kwds = {}
            op_impl_kwds = fusion_op_utils.get_check_impl_mode(op_compute_func, op_node.get(CompileParam.NAME),
                                                               op_impl_kwds)
            logger.info("all_args is {}, kernel_kwds is {}, all_args_kwds is {}, op_impl_kwds is {}, \
                options_kwds is {}.".format(all_args, kernel_kwds, all_args_kwds, op_impl_kwds, options_kwds))
            op_output_list = op_compute_func(*all_args, **kernel_kwds,
                                             **all_args_kwds,
                                             **op_impl_kwds,
                                             **options_kwds)
        from tbe.tvm import Tensor
        if isinstance(op_output_list, Tensor):
            op_output_list = [op_output_list]

        return op_output_list

    def get_fusion_impl_mode(self):
        return self.__fusion_op_impl_mode

    def fetch_json_file_path(self, json_file_path):
        logger.debug("json_file_path is %s.", json_file_path)

        if not json_file_path:
            json_file_path = get_json_file_path(self.__opc_compile_args)
            logger.debug("json_file_path is %s.", json_file_path)
        return json_file_path

    def fusion_op_dynamic(self, json_data, fusion_op_name):
        """
        fusion op for dynamic shape
        """
        """
        Create classify, need fusion_pattern just like Pattern.BROADCAST (sub.py)
        ins_list: new inputs'shapes from create_classify
        update_op_list: update new shapes in op_list
        """
        op_list = json_data[CompileParam.OP_LIST]
        fusion_op_utils.add_optional_inputs(op_list)
        fusion_op_utils.set_op_info_to_context(op_list, fusion_op_name, json_data)
        new_op_list = copy.deepcopy(op_list)
        fusion_op_utils.call_all_registered_functions(new_op_list)
        fusion_pattern = fusion_op_utils.get_fusion_pattern(new_op_list)
        fusion_mode = fusion_op_utils.get_op_mode_by_pattern(fusion_pattern)
        vector_info = fusion_op_utils.get_classify_info(fusion_pattern, fusion_mode, new_op_list)
        ins_list_none, real_ins_list = fusion_op_utils.check_vector_info(vector_info)

        context = op_context.get_context()
        opt_input_mode = self.__opc_compile_args.get(OpcOptions.OPTIONAL_INPUT_MODE)
        logger.debug("[fusion_op_dynamic]:Cur optional_input_mode is: %s", str(opt_input_mode))
        context.add_addition(OpcOptions.OPTIONAL_INPUT_MODE, opt_input_mode)
        if fusion_pattern in [Pattern.REDUCE, ] and vector_info.label not in ["D", ] and \
            hasattr(vector_info, 'axis_idx'):
            context.add_compile_info("axes_idx", vector_info.axis_idx)
        # ins_list classify shape
        schedules_list, tensors_list = [], []
        cmp_bool_storage_as_1bit = True
        for ins_attrs_options in real_ins_list:
            tensor_list = {}  # collect all tensors in fusion template
            tensor_usecount = {}
            input_list = []  # record all input tensors for AI Core codegen
            input_tensor_cnt = {}  # record input tensor called count
            input_desc_names = []
            output_tensor_cnt = {}  # record output tensor called count
            output_list = []  # record output tensors' name for AI Core codegen
            compute_output_tensor_list = []  # record all compute output tensor
            input_to_attr_list = {}  # record input tensor which needs to be replaced by attr
            # record tensor used in fusion_op
            # a tensor which is not used is a output tensor
            is_used_tensor_list = set()
            # combine computes
            params_count = [0]
            cmp_bool_storage_as_1bit = True
            bool_storage_as_1bit_oplist = \
                ["Asinh", "Atanh", "Acosh", "Asin", "Atan2", "Acos", "Pow", "Xlogy",
                 "ApproximateEqual", "DataFormatDimMap", "Elu", "Select", "SelectV2",
                 "BNLL", "ClipByNormNoDivSum", "BesselI1e", "Expm1", "Log1p"]
            ins = fusion_op_utils.get_ins_by_flag(ins_list_none, ins_attrs_options)

            from tbe.dsl import compute as tbe_dsl_compute
            with tbe_dsl_compute():
                op_tensor_utils.replace_tvm_shapes(fusion_pattern, fusion_mode, vector_info, new_op_list,
                                   ins, input_to_attr_list, ins_attrs_options)

                # Placeholder + Compute
                for op_index, op_node in enumerate(new_op_list):
                    # op with 'bool_storage_as_1bit' needs to add this config in fusion_op
                    if op_node[CompileParam.TYPE] in bool_storage_as_1bit_oplist:
                        cmp_bool_storage_as_1bit = False

                    if op_node[CompileParam.TYPE] == "Data":
                        # create placeholder
                        op_tensor_utils.create_placeholder_tensor(op_node, tensor_list, input_list,
                                                                  new_op_list, params_count, True)
                        continue

                    # collect input tensors for this op
                    op_input_list = []
                    # Assem dynamic input parameter
                    dyn_input_dict = {}

                    op_tensor_utils.add_input_tensor(op_node, tensor_list, op_input_list,
                                     is_used_tensor_list, input_tensor_cnt, dyn_input_dict, input_desc_names)
                    is_replace_attr = fusion_pattern in [Pattern.REDUCE, ] and op_index in vector_info.reduce_op.idx
                    if is_replace_attr:
                        op_tensor_utils.replace_attr_for_op_input_list(op_input_list, input_to_attr_list)

                    # call op's compute
                    op_output_list = self.__call_op_compute(op_node, ins_attrs_options, op_input_list,
                                                            dyn_input_dict, ins_list_none)
                    fusion_op_utils.collect_out_tensor(op_node, tensor_list, op_output_list, compute_output_tensor_list,
                                       output_tensor_cnt)

                # After Compute, find sub-graph output
                fusion_op_utils.get_sub_graph_output(compute_output_tensor_list, is_used_tensor_list, output_list,
                                     output_tensor_cnt, input_tensor_cnt)

            # generate schedule
            with _cce():
                logger.debug("[fusion_op_dynamic]:start multi dynamic complie")
                # call auto_schedule
                sch = auto_schedule(output_list)

            real_output = fusion_op_utils.get_real_output(sch, output_list)
            input_list = [ele for ele in input_list if ele is not None]
            input_list += real_output
            # each sch: each input_list
            tensors_list.append(input_list)
            schedules_list.append(sch)
        # codegen
        config = {CompileParam.NAME: fusion_op_name,
                  "tensor_list": tensors_list,
                  "fusion_build_config": fusion_op_utils.get_fusion_build_cfg(),
                  "bool_storage_as_1bit": cmp_bool_storage_as_1bit}

        from tbe.dsl import build as tbe_dsl_build
        tbe_dsl_build(schedules_list, config)

        # fetch json file path for build result.
        json_file_path = self.fetch_json_file_path(context.get_build_res("json_file_path"))

        update_compile_info(json_file_path, context.get_compile_info(None))
        return json_file_path

    def update_op_real_attrs(self):
        """
        attrs in current json_data is not real op attrs
        """
        for op_node in self.__json_dict[CompileParam.OP_LIST]:
            if op_node[CompileParam.TYPE] == 'Data':
                continue
            op_func = get_compute_op_func(op_node[CompileParam.TYPE])
            attrs = {}
            if CompileParam.ATTRS in op_node and op_func is not None:
                attrs = get_new_attrs_for_op_compile(op_node, op_func,
                                                     self.__opc_compile_args.get(OpcOptions.OP_COMPILE_MODE))
            if attrs is not None:
                op_node[CompileParam.OP_ATTRS_DESC] = attrs

    def fusion_op(self, is_dyn_impl):
        """
        fusion_op
        """
        compile_type = "dynamic" if is_dyn_impl else "static"
        with op_context.OpContext(compile_type):
            json_data = self.__json_dict
            l1_info = -1
            if CompileParam.L1_SIZE in json_data:
                l1_info = json_data[CompileParam.L1_SIZE]

            set_L1_info(CompileParam.OP_L1_SPACE, l1_info)

            fusion_op_utils.modify_duplicated_inputs(json_data)

            # get params from json_data
            fusion_op_name = json_data[CompileParam.FUSION_OP_NAME]
            self.update_op_real_attrs()
            return self.fusion_op_dynamic(json_data, fusion_op_name)

    def __get_json_file_path(self, is_dyn_impl):
        if self.__use_int64_mode and not is_dyn_impl:
            with api_config.bit_width_64():
                json_file_path = self.fusion_op(is_dyn_impl)
        else:
            with api_config.bit_width_32():
                json_file_path = self.fusion_op(is_dyn_impl)
        return json_file_path

    def fusion_op_compile(self):
        """
        fusion op compile
        """
        # get json data
        json_dict = self.__json_dict
        logger.debug("Compile fusion op.")
        for op_node in json_dict[CompileParam.OP_LIST]:
            if CompileParam.INT64_MODE not in op_node.keys():
                continue
            if op_node[CompileParam.INT64_MODE]:
                self.__use_int64_mode = True
                break

        if CompileParam.DYNAMIC_IMPL in json_dict.keys():
            is_dyn_impl = bool(json_dict[CompileParam.DYNAMIC_IMPL])
        else:
            is_dyn_impl = bool(fusion_op_utils.has_dynshape(json_dict[CompileParam.OP_LIST]))
        json_dict[CompileParam.DYNAMIC_IMPL] = is_dyn_impl

        tbe_debug_level_value = int(self.__opc_compile_args.get(OpcOptions.OP_DEBUG_LEVEL, 0))
        if tbe_debug_level_value == 3:
            tbe_debug_level_value = 0
        debug_config = self.__opc_compile_args.get(OpcOptions.OP_DEBUG_CONFIG)
        logger.debug("debug_config %s.", debug_config)
        with build_config(tbe_debug_level=tbe_debug_level_value,
                          op_debug_config=debug_config,
                          compatible=True, enable_op_prebuild=False):
            json_file_path = self.__get_json_file_path(is_dyn_impl)
            return json_file_path